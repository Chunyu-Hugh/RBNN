saving to [DIR]/
creating model resnet20_bireal_1w1a
model structure: ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): LambdaLayer()
    )
    (1): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): LambdaLayer()
    )
    (1): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): BasicBlock_1w1a(
      (conv1): BinarizeConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): BinarizeConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (linear): Linear(in_features=64, out_features=10, bias=True)
)
number of parameters: 271194
criterion: CrossEntropyLoss()
scheduler: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7febfbafc1c0>
lr: 0.02
/home/lab/anaconda3/envs/chunyu/lib/python3.8/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1704987290659/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
TRAINING - Epoch: [0][0/196]	Time 0.764 (0.764)	Data 0.171 (0.171)	Loss 2.3039 (2.3039)	Prec@1 10.156 (10.156)	Prec@5 52.344 (52.344)
TRAINING - Epoch: [0][100/196]	Time 0.027 (0.036)	Data 0.000 (0.002)	Loss 1.9844 (2.1169)	Prec@1 26.562 (21.945)	Prec@5 79.297 (73.921)
EVALUATING - Epoch: [0][0/79]	Time 0.094 (0.094)	Data 0.042 (0.042)	Loss 1.8345 (1.8345)	Prec@1 33.594 (33.594)	Prec@5 82.812 (82.812)
Time cost: 00:07	Time of Finish: 2024-03-31 17:17:22

 Epoch: 1	Training Loss 2.0354 	Training Prec@1 24.670 	Training Prec@5 77.334 	Validation Loss 1.8898 	Validation Prec@1 30.440 	Validation Prec@5 82.930 

lr: 0.04
TRAINING - Epoch: [1][0/196]	Time 0.293 (0.293)	Data 0.090 (0.090)	Loss 1.9640 (1.9640)	Prec@1 25.391 (25.391)	Prec@5 81.641 (81.641)
TRAINING - Epoch: [1][100/196]	Time 0.025 (0.033)	Data 0.000 (0.001)	Loss 1.8609 (1.9018)	Prec@1 32.812 (28.960)	Prec@5 85.156 (82.565)
EVALUATING - Epoch: [1][0/79]	Time 0.061 (0.061)	Data 0.044 (0.044)	Loss 1.6686 (1.6686)	Prec@1 39.062 (39.062)	Prec@5 89.062 (89.062)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:07

 Epoch: 2	Training Loss 1.8367 	Training Prec@1 31.152 	Training Prec@5 84.482 	Validation Loss 1.8108 	Validation Prec@1 33.480 	Validation Prec@5 85.030 

lr: 0.06000000000000001
TRAINING - Epoch: [2][0/196]	Time 0.264 (0.264)	Data 0.073 (0.073)	Loss 1.8490 (1.8490)	Prec@1 34.375 (34.375)	Prec@5 82.812 (82.812)
TRAINING - Epoch: [2][100/196]	Time 0.030 (0.036)	Data 0.000 (0.001)	Loss 1.7655 (1.7620)	Prec@1 35.156 (33.822)	Prec@5 86.719 (86.274)
EVALUATING - Epoch: [2][0/79]	Time 0.062 (0.062)	Data 0.044 (0.044)	Loss 1.6353 (1.6353)	Prec@1 42.969 (42.969)	Prec@5 88.281 (88.281)
Time cost: 00:07	Time of Finish: 2024-03-31 17:22:02

 Epoch: 3	Training Loss 1.7366 	Training Prec@1 34.598 	Training Prec@5 87.182 	Validation Loss 1.6686 	Validation Prec@1 38.260 	Validation Prec@5 88.850 

lr: 0.08
TRAINING - Epoch: [3][0/196]	Time 0.266 (0.266)	Data 0.084 (0.084)	Loss 1.7011 (1.7011)	Prec@1 39.062 (39.062)	Prec@5 89.453 (89.453)
TRAINING - Epoch: [3][100/196]	Time 0.027 (0.033)	Data 0.000 (0.001)	Loss 1.6614 (1.6914)	Prec@1 38.672 (36.332)	Prec@5 89.844 (88.243)
EVALUATING - Epoch: [3][0/79]	Time 0.065 (0.065)	Data 0.047 (0.047)	Loss 1.8512 (1.8512)	Prec@1 36.719 (36.719)	Prec@5 87.500 (87.500)
Time cost: 00:06	Time of Finish: 2024-03-31 17:05:08

 Epoch: 4	Training Loss 1.6789 	Training Prec@1 37.026 	Training Prec@5 88.546 	Validation Loss 1.8488 	Validation Prec@1 35.840 	Validation Prec@5 86.040 

lr: 0.1
TRAINING - Epoch: [4][0/196]	Time 0.274 (0.274)	Data 0.079 (0.079)	Loss 1.7701 (1.7701)	Prec@1 33.984 (33.984)	Prec@5 87.109 (87.109)
TRAINING - Epoch: [4][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 1.7205 (1.6659)	Prec@1 38.672 (38.219)	Prec@5 85.547 (88.691)
EVALUATING - Epoch: [4][0/79]	Time 0.065 (0.065)	Data 0.045 (0.045)	Loss 1.5956 (1.5956)	Prec@1 35.156 (35.156)	Prec@5 92.969 (92.969)
Time cost: 00:06	Time of Finish: 2024-03-31 17:01:41

 Epoch: 5	Training Loss 1.6516 	Training Prec@1 38.558 	Training Prec@5 89.182 	Validation Loss 1.7032 	Validation Prec@1 36.970 	Validation Prec@5 87.380 

lr: 0.1000017411147667
TRAINING - Epoch: [5][0/196]	Time 0.273 (0.273)	Data 0.086 (0.086)	Loss 1.6954 (1.6954)	Prec@1 36.719 (36.719)	Prec@5 90.234 (90.234)
TRAINING - Epoch: [5][100/196]	Time 0.038 (0.031)	Data 0.000 (0.001)	Loss 1.5877 (1.6401)	Prec@1 38.281 (38.471)	Prec@5 91.797 (89.264)
EVALUATING - Epoch: [5][0/79]	Time 0.069 (0.069)	Data 0.054 (0.054)	Loss 1.5444 (1.5444)	Prec@1 45.312 (45.312)	Prec@5 90.625 (90.625)
Time cost: 00:06	Time of Finish: 2024-03-31 17:04:20

 Epoch: 6	Training Loss 1.6259 	Training Prec@1 39.142 	Training Prec@5 89.548 	Validation Loss 1.6133 	Validation Prec@1 39.900 	Validation Prec@5 90.120 

lr: 0.10000298478054478
TRAINING - Epoch: [6][0/196]	Time 0.270 (0.270)	Data 0.088 (0.088)	Loss 1.6036 (1.6036)	Prec@1 39.062 (39.062)	Prec@5 89.453 (89.453)
TRAINING - Epoch: [6][100/196]	Time 0.032 (0.030)	Data 0.000 (0.001)	Loss 1.5797 (1.6034)	Prec@1 44.531 (40.470)	Prec@5 92.578 (89.944)
EVALUATING - Epoch: [6][0/79]	Time 0.067 (0.067)	Data 0.049 (0.049)	Loss 1.5291 (1.5291)	Prec@1 44.531 (44.531)	Prec@5 89.844 (89.844)
Time cost: 00:06	Time of Finish: 2024-03-31 17:00:29

 Epoch: 7	Training Loss 1.5948 	Training Prec@1 40.764 	Training Prec@5 90.098 	Validation Loss 1.6346 	Validation Prec@1 42.400 	Validation Prec@5 88.860 

lr: 0.10000373098496097
TRAINING - Epoch: [7][0/196]	Time 0.318 (0.318)	Data 0.076 (0.076)	Loss 1.4348 (1.4348)	Prec@1 46.094 (46.094)	Prec@5 91.797 (91.797)
TRAINING - Epoch: [7][100/196]	Time 0.027 (0.031)	Data 0.000 (0.001)	Loss 1.5230 (1.5777)	Prec@1 44.531 (41.522)	Prec@5 90.625 (90.668)
EVALUATING - Epoch: [7][0/79]	Time 0.061 (0.061)	Data 0.044 (0.044)	Loss 1.4766 (1.4766)	Prec@1 46.094 (46.094)	Prec@5 92.969 (92.969)
Time cost: 00:06	Time of Finish: 2024-03-31 17:02:32

 Epoch: 8	Training Loss 1.5735 	Training Prec@1 41.632 	Training Prec@5 90.652 	Validation Loss 1.5496 	Validation Prec@1 43.070 	Validation Prec@5 90.910 

lr: 0.10000373098496097
TRAINING - Epoch: [8][0/196]	Time 0.271 (0.271)	Data 0.083 (0.083)	Loss 1.4975 (1.4975)	Prec@1 44.922 (44.922)	Prec@5 89.844 (89.844)
TRAINING - Epoch: [8][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 1.6468 (1.5479)	Prec@1 38.672 (42.392)	Prec@5 89.844 (91.182)
EVALUATING - Epoch: [8][0/79]	Time 0.066 (0.066)	Data 0.050 (0.050)	Loss 1.5175 (1.5175)	Prec@1 43.750 (43.750)	Prec@5 89.844 (89.844)
Time cost: 00:06	Time of Finish: 2024-03-31 16:58:59

 Epoch: 9	Training Loss 1.5407 	Training Prec@1 42.710 	Training Prec@5 91.220 	Validation Loss 1.6417 	Validation Prec@1 39.420 	Validation Prec@5 89.880 

lr: 0.10000348224994936
TRAINING - Epoch: [9][0/196]	Time 0.286 (0.286)	Data 0.088 (0.088)	Loss 1.4774 (1.4774)	Prec@1 47.266 (47.266)	Prec@5 92.188 (92.188)
TRAINING - Epoch: [9][100/196]	Time 0.025 (0.030)	Data 0.000 (0.001)	Loss 1.5741 (1.5108)	Prec@1 39.062 (44.133)	Prec@5 89.844 (91.723)
EVALUATING - Epoch: [9][0/79]	Time 0.065 (0.065)	Data 0.055 (0.055)	Loss 1.4778 (1.4778)	Prec@1 49.219 (49.219)	Prec@5 91.406 (91.406)
Time cost: 00:06	Time of Finish: 2024-03-31 17:03:54

 Epoch: 10	Training Loss 1.5005 	Training Prec@1 44.540 	Training Prec@5 91.840 	Validation Loss 1.4882 	Validation Prec@1 46.400 	Validation Prec@5 92.430 

lr: 0.10000273604738916
TRAINING - Epoch: [10][0/196]	Time 0.274 (0.274)	Data 0.083 (0.083)	Loss 1.5619 (1.5619)	Prec@1 41.797 (41.797)	Prec@5 89.453 (89.453)
TRAINING - Epoch: [10][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 1.3583 (1.4534)	Prec@1 48.828 (46.535)	Prec@5 95.312 (92.257)
EVALUATING - Epoch: [10][0/79]	Time 0.070 (0.070)	Data 0.052 (0.052)	Loss 1.5158 (1.5158)	Prec@1 49.219 (49.219)	Prec@5 88.281 (88.281)
Time cost: 00:06	Time of Finish: 2024-03-31 17:03:53

 Epoch: 11	Training Loss 1.4427 	Training Prec@1 46.908 	Training Prec@5 92.410 	Validation Loss 1.5212 	Validation Prec@1 44.500 	Validation Prec@5 91.270 

lr: 0.10000149238470439
TRAINING - Epoch: [11][0/196]	Time 0.278 (0.278)	Data 0.082 (0.082)	Loss 1.4449 (1.4449)	Prec@1 42.578 (42.578)	Prec@5 92.969 (92.969)
TRAINING - Epoch: [11][100/196]	Time 0.027 (0.029)	Data 0.000 (0.001)	Loss 1.3519 (1.4229)	Prec@1 50.391 (47.753)	Prec@5 92.969 (92.690)
EVALUATING - Epoch: [11][0/79]	Time 0.062 (0.062)	Data 0.045 (0.045)	Loss 1.4929 (1.4929)	Prec@1 51.562 (51.562)	Prec@5 89.062 (89.062)
Time cost: 00:06	Time of Finish: 2024-03-31 16:59:08

 Epoch: 12	Training Loss 1.4080 	Training Prec@1 48.324 	Training Prec@5 92.980 	Validation Loss 1.5680 	Validation Prec@1 44.400 	Validation Prec@5 90.270 

lr: 0.09999975127426829
TRAINING - Epoch: [12][0/196]	Time 0.264 (0.264)	Data 0.080 (0.080)	Loss 1.4813 (1.4813)	Prec@1 47.656 (47.656)	Prec@5 91.406 (91.406)
TRAINING - Epoch: [12][100/196]	Time 0.044 (0.031)	Data 0.000 (0.001)	Loss 1.5070 (1.3905)	Prec@1 42.578 (49.087)	Prec@5 93.750 (93.073)
EVALUATING - Epoch: [12][0/79]	Time 0.066 (0.066)	Data 0.050 (0.050)	Loss 1.3199 (1.3199)	Prec@1 52.344 (52.344)	Prec@5 95.312 (95.312)
Time cost: 00:06	Time of Finish: 2024-03-31 17:03:55

 Epoch: 13	Training Loss 1.3756 	Training Prec@1 49.766 	Training Prec@5 93.204 	Validation Loss 1.4260 	Validation Prec@1 47.950 	Validation Prec@5 93.160 

lr: 0.09999751273340318
TRAINING - Epoch: [13][0/196]	Time 0.287 (0.287)	Data 0.103 (0.103)	Loss 1.2785 (1.2785)	Prec@1 54.688 (54.688)	Prec@5 93.359 (93.359)
TRAINING - Epoch: [13][100/196]	Time 0.028 (0.029)	Data 0.000 (0.001)	Loss 1.4328 (1.3371)	Prec@1 51.562 (51.528)	Prec@5 93.750 (93.634)
EVALUATING - Epoch: [13][0/79]	Time 0.063 (0.063)	Data 0.047 (0.047)	Loss 1.2171 (1.2171)	Prec@1 54.688 (54.688)	Prec@5 94.531 (94.531)
Time cost: 00:06	Time of Finish: 2024-03-31 16:58:40

 Epoch: 14	Training Loss 1.3283 	Training Prec@1 51.736 	Training Prec@5 93.644 	Validation Loss 1.3784 	Validation Prec@1 50.980 	Validation Prec@5 94.070 

lr: 0.09999477678438042
TRAINING - Epoch: [14][0/196]	Time 0.261 (0.261)	Data 0.079 (0.079)	Loss 1.1825 (1.1825)	Prec@1 55.469 (55.469)	Prec@5 96.484 (96.484)
TRAINING - Epoch: [14][100/196]	Time 0.028 (0.029)	Data 0.000 (0.001)	Loss 1.2123 (1.3026)	Prec@1 57.422 (52.692)	Prec@5 95.312 (94.056)
EVALUATING - Epoch: [14][0/79]	Time 0.092 (0.092)	Data 0.069 (0.069)	Loss 1.3141 (1.3141)	Prec@1 48.438 (48.438)	Prec@5 92.969 (92.969)
Time cost: 00:07	Time of Finish: 2024-03-31 17:15:23

 Epoch: 15	Training Loss 1.2937 	Training Prec@1 53.114 	Training Prec@5 94.122 	Validation Loss 1.3067 	Validation Prec@1 52.240 	Validation Prec@5 94.030 

lr: 0.09999154345442002
TRAINING - Epoch: [15][0/196]	Time 0.495 (0.495)	Data 0.096 (0.096)	Loss 1.3063 (1.3063)	Prec@1 51.562 (51.562)	Prec@5 94.141 (94.141)
TRAINING - Epoch: [15][100/196]	Time 0.028 (0.039)	Data 0.000 (0.001)	Loss 1.2604 (1.2579)	Prec@1 57.422 (54.440)	Prec@5 96.094 (94.527)
EVALUATING - Epoch: [15][0/79]	Time 0.069 (0.069)	Data 0.052 (0.052)	Loss 1.6396 (1.6396)	Prec@1 35.156 (35.156)	Prec@5 92.969 (92.969)
Time cost: 00:07	Time of Finish: 2024-03-31 17:18:14

 Epoch: 16	Training Loss 1.2498 	Training Prec@1 54.912 	Training Prec@5 94.648 	Validation Loss 1.5219 	Validation Prec@1 47.740 	Validation Prec@5 92.180 

lr: 0.0999878127756905
TRAINING - Epoch: [16][0/196]	Time 0.292 (0.292)	Data 0.077 (0.077)	Loss 1.2137 (1.2137)	Prec@1 57.422 (57.422)	Prec@5 94.922 (94.922)
TRAINING - Epoch: [16][100/196]	Time 0.029 (0.034)	Data 0.000 (0.001)	Loss 1.1578 (1.2396)	Prec@1 57.422 (55.476)	Prec@5 96.094 (94.570)
EVALUATING - Epoch: [16][0/79]	Time 0.065 (0.065)	Data 0.047 (0.047)	Loss 1.3097 (1.3097)	Prec@1 52.344 (52.344)	Prec@5 92.969 (92.969)
Time cost: 00:06	Time of Finish: 2024-03-31 17:09:08

 Epoch: 17	Training Loss 1.2273 	Training Prec@1 55.850 	Training Prec@5 94.708 	Validation Loss 1.2805 	Validation Prec@1 52.900 	Validation Prec@5 94.520 

lr: 0.09998358478530844
TRAINING - Epoch: [17][0/196]	Time 0.275 (0.275)	Data 0.078 (0.078)	Loss 1.1289 (1.1289)	Prec@1 58.594 (58.594)	Prec@5 96.875 (96.875)
TRAINING - Epoch: [17][100/196]	Time 0.030 (0.031)	Data 0.000 (0.001)	Loss 1.2207 (1.1967)	Prec@1 58.984 (56.815)	Prec@5 93.359 (95.258)
EVALUATING - Epoch: [17][0/79]	Time 0.070 (0.070)	Data 0.050 (0.050)	Loss 1.3165 (1.3165)	Prec@1 55.469 (55.469)	Prec@5 91.406 (91.406)
Time cost: 00:06	Time of Finish: 2024-03-31 17:06:07

 Epoch: 18	Training Loss 1.1891 	Training Prec@1 57.142 	Training Prec@5 95.202 	Validation Loss 1.3272 	Validation Prec@1 54.140 	Validation Prec@5 93.490 

lr: 0.09997885952533829
TRAINING - Epoch: [18][0/196]	Time 0.278 (0.278)	Data 0.079 (0.079)	Loss 1.2136 (1.2136)	Prec@1 55.859 (55.859)	Prec@5 96.484 (96.484)
TRAINING - Epoch: [18][100/196]	Time 0.027 (0.033)	Data 0.000 (0.001)	Loss 1.0400 (1.1621)	Prec@1 61.328 (58.516)	Prec@5 96.875 (95.289)
EVALUATING - Epoch: [18][0/79]	Time 0.069 (0.069)	Data 0.051 (0.051)	Loss 1.3292 (1.3292)	Prec@1 50.781 (50.781)	Prec@5 95.312 (95.312)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:18

 Epoch: 19	Training Loss 1.1638 	Training Prec@1 58.384 	Training Prec@5 95.348 	Validation Loss 1.2863 	Validation Prec@1 53.460 	Validation Prec@5 95.220 

lr: 0.09997363704279176
TRAINING - Epoch: [19][0/196]	Time 0.324 (0.324)	Data 0.090 (0.090)	Loss 1.3165 (1.3165)	Prec@1 51.562 (51.562)	Prec@5 92.188 (92.188)
TRAINING - Epoch: [19][100/196]	Time 0.038 (0.037)	Data 0.000 (0.001)	Loss 1.1390 (1.1421)	Prec@1 57.031 (59.000)	Prec@5 92.969 (95.332)
EVALUATING - Epoch: [19][0/79]	Time 0.070 (0.070)	Data 0.050 (0.050)	Loss 1.0942 (1.0942)	Prec@1 60.156 (60.156)	Prec@5 96.875 (96.875)
Time cost: 00:07	Time of Finish: 2024-03-31 17:19:29

 Epoch: 20	Training Loss 1.1395 	Training Prec@1 59.280 	Training Prec@5 95.446 	Validation Loss 1.2375 	Validation Prec@1 56.710 	Validation Prec@5 95.060 

lr: 0.0999679173896275
TRAINING - Epoch: [20][0/196]	Time 0.290 (0.290)	Data 0.083 (0.083)	Loss 1.0528 (1.0528)	Prec@1 67.578 (67.578)	Prec@5 95.312 (95.312)
TRAINING - Epoch: [20][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 1.0580 (1.1252)	Prec@1 60.547 (59.862)	Prec@5 97.656 (95.661)
EVALUATING - Epoch: [20][0/79]	Time 0.076 (0.076)	Data 0.054 (0.054)	Loss 1.4405 (1.4405)	Prec@1 44.531 (44.531)	Prec@5 93.750 (93.750)
Time cost: 00:06	Time of Finish: 2024-03-31 17:02:09

 Epoch: 21	Training Loss 1.1139 	Training Prec@1 60.312 	Training Prec@5 95.764 	Validation Loss 1.5381 	Validation Prec@1 46.840 	Validation Prec@5 90.490 

lr: 0.09996170062275052
TRAINING - Epoch: [21][0/196]	Time 0.273 (0.273)	Data 0.088 (0.088)	Loss 1.1871 (1.1871)	Prec@1 57.812 (57.812)	Prec@5 94.922 (94.922)
TRAINING - Epoch: [21][100/196]	Time 0.037 (0.029)	Data 0.000 (0.001)	Loss 1.0696 (1.0942)	Prec@1 64.062 (60.945)	Prec@5 95.703 (95.842)
EVALUATING - Epoch: [21][0/79]	Time 0.071 (0.071)	Data 0.049 (0.049)	Loss 1.3260 (1.3260)	Prec@1 53.906 (53.906)	Prec@5 92.969 (92.969)
Time cost: 00:06	Time of Finish: 2024-03-31 17:00:08

 Epoch: 22	Training Loss 1.0852 	Training Prec@1 61.264 	Training Prec@5 95.968 	Validation Loss 1.2862 	Validation Prec@1 56.700 	Validation Prec@5 94.320 

lr: 0.0999549868040116
TRAINING - Epoch: [22][0/196]	Time 0.270 (0.270)	Data 0.084 (0.084)	Loss 1.1608 (1.1608)	Prec@1 62.109 (62.109)	Prec@5 95.703 (95.703)
TRAINING - Epoch: [22][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 1.0912 (1.0762)	Prec@1 59.375 (62.005)	Prec@5 95.312 (96.040)
EVALUATING - Epoch: [22][0/79]	Time 0.063 (0.063)	Data 0.045 (0.045)	Loss 1.0186 (1.0186)	Prec@1 64.062 (64.062)	Prec@5 94.531 (94.531)
Time cost: 00:06	Time of Finish: 2024-03-31 16:59:39

 Epoch: 23	Training Loss 1.0644 	Training Prec@1 62.308 	Training Prec@5 96.214 	Validation Loss 1.1053 	Validation Prec@1 60.310 	Validation Prec@5 96.210 

lr: 0.09994777600020674
TRAINING - Epoch: [23][0/196]	Time 0.288 (0.288)	Data 0.090 (0.090)	Loss 1.0494 (1.0494)	Prec@1 64.844 (64.844)	Prec@5 95.703 (95.703)
TRAINING - Epoch: [23][100/196]	Time 0.026 (0.029)	Data 0.000 (0.001)	Loss 0.9944 (1.0495)	Prec@1 64.062 (63.092)	Prec@5 97.656 (96.198)
EVALUATING - Epoch: [23][0/79]	Time 0.071 (0.071)	Data 0.053 (0.053)	Loss 1.2340 (1.2340)	Prec@1 61.719 (61.719)	Prec@5 93.750 (93.750)
Time cost: 00:06	Time of Finish: 2024-03-31 16:58:38

 Epoch: 24	Training Loss 1.0336 	Training Prec@1 63.458 	Training Prec@5 96.346 	Validation Loss 1.1972 	Validation Prec@1 59.490 	Validation Prec@5 95.630 

lr: 0.0999400682830764
TRAINING - Epoch: [24][0/196]	Time 0.279 (0.279)	Data 0.095 (0.095)	Loss 1.0132 (1.0132)	Prec@1 64.453 (64.453)	Prec@5 96.094 (96.094)
TRAINING - Epoch: [24][100/196]	Time 0.025 (0.029)	Data 0.000 (0.001)	Loss 1.0725 (1.0253)	Prec@1 61.328 (63.904)	Prec@5 95.312 (96.384)
EVALUATING - Epoch: [24][0/79]	Time 0.063 (0.063)	Data 0.045 (0.045)	Loss 1.1608 (1.1608)	Prec@1 57.812 (57.812)	Prec@5 96.094 (96.094)
Time cost: 00:06	Time of Finish: 2024-03-31 17:00:23

 Epoch: 25	Training Loss 1.0217 	Training Prec@1 63.874 	Training Prec@5 96.442 	Validation Loss 1.1846 	Validation Prec@1 57.880 	Validation Prec@5 96.100 

lr: 0.09993186372930492
TRAINING - Epoch: [25][0/196]	Time 0.271 (0.271)	Data 0.079 (0.079)	Loss 1.0482 (1.0482)	Prec@1 63.281 (63.281)	Prec@5 96.875 (96.875)
TRAINING - Epoch: [25][100/196]	Time 0.027 (0.032)	Data 0.000 (0.001)	Loss 1.0585 (0.9944)	Prec@1 60.156 (64.778)	Prec@5 95.703 (96.647)
EVALUATING - Epoch: [25][0/79]	Time 0.065 (0.065)	Data 0.046 (0.046)	Loss 0.9237 (0.9237)	Prec@1 64.844 (64.844)	Prec@5 96.094 (96.094)
Time cost: 00:06	Time of Finish: 2024-03-31 17:04:56

 Epoch: 26	Training Loss 0.9938 	Training Prec@1 64.768 	Training Prec@5 96.642 	Validation Loss 1.0842 	Validation Prec@1 60.760 	Validation Prec@5 96.490 

lr: 0.09992316242051962
TRAINING - Epoch: [26][0/196]	Time 0.283 (0.283)	Data 0.079 (0.079)	Loss 0.9282 (0.9282)	Prec@1 69.141 (69.141)	Prec@5 97.266 (97.266)
TRAINING - Epoch: [26][100/196]	Time 0.027 (0.031)	Data 0.000 (0.001)	Loss 0.8984 (0.9760)	Prec@1 66.797 (65.211)	Prec@5 97.266 (96.898)
EVALUATING - Epoch: [26][0/79]	Time 0.063 (0.063)	Data 0.047 (0.047)	Loss 0.9752 (0.9752)	Prec@1 63.281 (63.281)	Prec@5 95.312 (95.312)
Time cost: 00:06	Time of Finish: 2024-03-31 17:11:12

 Epoch: 27	Training Loss 0.9836 	Training Prec@1 65.118 	Training Prec@5 96.868 	Validation Loss 1.0344 	Validation Prec@1 64.340 	Validation Prec@5 96.450 

lr: 0.0999139644432901
TRAINING - Epoch: [27][0/196]	Time 0.290 (0.290)	Data 0.079 (0.079)	Loss 0.9971 (0.9971)	Prec@1 65.625 (65.625)	Prec@5 96.094 (96.094)
TRAINING - Epoch: [27][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.8571 (0.9829)	Prec@1 69.922 (65.319)	Prec@5 98.047 (96.713)
EVALUATING - Epoch: [27][0/79]	Time 0.064 (0.064)	Data 0.045 (0.045)	Loss 1.3397 (1.3397)	Prec@1 53.906 (53.906)	Prec@5 96.094 (96.094)
Time cost: 00:06	Time of Finish: 2024-03-31 17:00:04

 Epoch: 28	Training Loss 0.9701 	Training Prec@1 65.694 	Training Prec@5 96.804 	Validation Loss 1.2445 	Validation Prec@1 56.710 	Validation Prec@5 96.020 

lr: 0.09990426988912726
TRAINING - Epoch: [28][0/196]	Time 0.279 (0.279)	Data 0.080 (0.080)	Loss 0.8794 (0.8794)	Prec@1 69.141 (69.141)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [28][100/196]	Time 0.035 (0.030)	Data 0.000 (0.001)	Loss 0.8639 (0.9406)	Prec@1 70.703 (66.375)	Prec@5 96.875 (97.285)
EVALUATING - Epoch: [28][0/79]	Time 0.069 (0.069)	Data 0.048 (0.048)	Loss 0.9327 (0.9327)	Prec@1 67.969 (67.969)	Prec@5 94.531 (94.531)
Time cost: 00:06	Time of Finish: 2024-03-31 17:00:55

 Epoch: 29	Training Loss 0.9487 	Training Prec@1 66.198 	Training Prec@5 97.158 	Validation Loss 1.0457 	Validation Prec@1 63.320 	Validation Prec@5 96.750 

lr: 0.09989407885448254
TRAINING - Epoch: [29][0/196]	Time 0.291 (0.291)	Data 0.087 (0.087)	Loss 0.8114 (0.8114)	Prec@1 73.047 (73.047)	Prec@5 96.484 (96.484)
TRAINING - Epoch: [29][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.9426 (0.9415)	Prec@1 67.969 (66.870)	Prec@5 96.484 (97.119)
EVALUATING - Epoch: [29][0/79]	Time 0.064 (0.064)	Data 0.046 (0.046)	Loss 0.9795 (0.9795)	Prec@1 67.188 (67.188)	Prec@5 96.094 (96.094)
Time cost: 00:06	Time of Finish: 2024-03-31 17:00:44

 Epoch: 30	Training Loss 0.9347 	Training Prec@1 66.942 	Training Prec@5 97.106 	Validation Loss 1.0854 	Validation Prec@1 62.120 	Validation Prec@5 95.640 

lr: 0.09988339144074686
TRAINING - Epoch: [30][0/196]	Time 0.269 (0.269)	Data 0.080 (0.080)	Loss 0.8912 (0.8912)	Prec@1 67.969 (67.969)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [30][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 1.0244 (0.9364)	Prec@1 65.625 (66.797)	Prec@5 96.094 (97.084)
EVALUATING - Epoch: [30][0/79]	Time 0.064 (0.064)	Data 0.045 (0.045)	Loss 1.3113 (1.3113)	Prec@1 52.344 (52.344)	Prec@5 95.312 (95.312)
Time cost: 00:06	Time of Finish: 2024-03-31 17:02:28

 Epoch: 31	Training Loss 0.9346 	Training Prec@1 66.952 	Training Prec@5 97.076 	Validation Loss 1.3965 	Validation Prec@1 54.320 	Validation Prec@5 96.420 

lr: 0.09987220775424957
TRAINING - Epoch: [31][0/196]	Time 0.274 (0.274)	Data 0.081 (0.081)	Loss 0.8827 (0.8827)	Prec@1 69.141 (69.141)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [31][100/196]	Time 0.028 (0.030)	Data 0.000 (0.001)	Loss 0.9131 (0.9071)	Prec@1 67.188 (67.679)	Prec@5 97.266 (97.444)
EVALUATING - Epoch: [31][0/79]	Time 0.073 (0.073)	Data 0.054 (0.054)	Loss 1.0292 (1.0292)	Prec@1 58.594 (58.594)	Prec@5 96.094 (96.094)
Time cost: 00:06	Time of Finish: 2024-03-31 17:00:52

 Epoch: 32	Training Loss 0.9072 	Training Prec@1 67.912 	Training Prec@5 97.412 	Validation Loss 1.1001 	Validation Prec@1 61.850 	Validation Prec@5 96.180 

lr: 0.09986052790625753
TRAINING - Epoch: [32][0/196]	Time 0.268 (0.268)	Data 0.079 (0.079)	Loss 0.8863 (0.8863)	Prec@1 69.531 (69.531)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [32][100/196]	Time 0.026 (0.029)	Data 0.000 (0.001)	Loss 0.9245 (0.8931)	Prec@1 67.969 (68.584)	Prec@5 98.047 (97.420)
EVALUATING - Epoch: [32][0/79]	Time 0.066 (0.066)	Data 0.050 (0.050)	Loss 1.2588 (1.2588)	Prec@1 58.594 (58.594)	Prec@5 93.750 (93.750)
Time cost: 00:06	Time of Finish: 2024-03-31 16:57:00

 Epoch: 33	Training Loss 0.9015 	Training Prec@1 68.268 	Training Prec@5 97.360 	Validation Loss 1.2960 	Validation Prec@1 56.780 	Validation Prec@5 94.530 

lr: 0.09984835201297386
TRAINING - Epoch: [33][0/196]	Time 0.308 (0.308)	Data 0.095 (0.095)	Loss 0.9545 (0.9545)	Prec@1 69.141 (69.141)	Prec@5 97.266 (97.266)
TRAINING - Epoch: [33][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.8872 (0.8756)	Prec@1 69.141 (69.179)	Prec@5 96.875 (97.560)
EVALUATING - Epoch: [33][0/79]	Time 0.065 (0.065)	Data 0.044 (0.044)	Loss 1.1099 (1.1099)	Prec@1 62.500 (62.500)	Prec@5 95.312 (95.312)
Time cost: 00:06	Time of Finish: 2024-03-31 17:01:05

 Epoch: 34	Training Loss 0.8840 	Training Prec@1 68.660 	Training Prec@5 97.522 	Validation Loss 1.1116 	Validation Prec@1 61.530 	Validation Prec@5 96.080 

lr: 0.09983568019553689
TRAINING - Epoch: [34][0/196]	Time 0.284 (0.284)	Data 0.100 (0.100)	Loss 0.8163 (0.8163)	Prec@1 70.703 (70.703)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [34][100/196]	Time 0.027 (0.031)	Data 0.000 (0.001)	Loss 0.9104 (0.8801)	Prec@1 68.359 (69.160)	Prec@5 97.266 (97.312)
EVALUATING - Epoch: [34][0/79]	Time 0.072 (0.072)	Data 0.055 (0.055)	Loss 0.9136 (0.9136)	Prec@1 68.750 (68.750)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:04

 Epoch: 35	Training Loss 0.8740 	Training Prec@1 69.358 	Training Prec@5 97.532 	Validation Loss 0.9287 	Validation Prec@1 67.480 	Validation Prec@5 97.280 

lr: 0.09982251258001891
TRAINING - Epoch: [35][0/196]	Time 0.278 (0.278)	Data 0.079 (0.079)	Loss 0.7721 (0.7721)	Prec@1 71.484 (71.484)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [35][100/196]	Time 0.026 (0.032)	Data 0.000 (0.001)	Loss 0.9686 (0.8572)	Prec@1 67.969 (70.007)	Prec@5 96.875 (97.583)
EVALUATING - Epoch: [35][0/79]	Time 0.063 (0.063)	Data 0.047 (0.047)	Loss 0.9546 (0.9546)	Prec@1 71.094 (71.094)	Prec@5 96.875 (96.875)
Time cost: 00:06	Time of Finish: 2024-03-31 17:09:57

 Epoch: 36	Training Loss 0.8596 	Training Prec@1 69.876 	Training Prec@5 97.518 	Validation Loss 1.0382 	Validation Prec@1 64.460 	Validation Prec@5 97.240 

lr: 0.0998088492974249
TRAINING - Epoch: [36][0/196]	Time 0.280 (0.280)	Data 0.078 (0.078)	Loss 0.9667 (0.9667)	Prec@1 62.891 (62.891)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [36][100/196]	Time 0.031 (0.031)	Data 0.000 (0.001)	Loss 0.9529 (0.8611)	Prec@1 67.578 (69.933)	Prec@5 97.656 (97.591)
EVALUATING - Epoch: [36][0/79]	Time 0.074 (0.074)	Data 0.056 (0.056)	Loss 0.8114 (0.8114)	Prec@1 71.875 (71.875)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:07:22

 Epoch: 37	Training Loss 0.8521 	Training Prec@1 70.122 	Training Prec@5 97.626 	Validation Loss 0.9228 	Validation Prec@1 68.630 	Validation Prec@5 97.440 

lr: 0.09979469048369125
TRAINING - Epoch: [37][0/196]	Time 0.269 (0.269)	Data 0.092 (0.092)	Loss 0.8946 (0.8946)	Prec@1 66.797 (66.797)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [37][100/196]	Time 0.027 (0.032)	Data 0.000 (0.001)	Loss 0.8893 (0.8408)	Prec@1 67.969 (70.320)	Prec@5 96.484 (97.641)
EVALUATING - Epoch: [37][0/79]	Time 0.067 (0.067)	Data 0.050 (0.050)	Loss 0.9365 (0.9365)	Prec@1 63.281 (63.281)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:09:11

 Epoch: 38	Training Loss 0.8458 	Training Prec@1 70.128 	Training Prec@5 97.762 	Validation Loss 1.0317 	Validation Prec@1 64.940 	Validation Prec@5 96.960 

lr: 0.09978003627968443
TRAINING - Epoch: [38][0/196]	Time 0.268 (0.268)	Data 0.075 (0.075)	Loss 0.8071 (0.8071)	Prec@1 75.000 (75.000)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [38][100/196]	Time 0.025 (0.032)	Data 0.000 (0.001)	Loss 0.7416 (0.8116)	Prec@1 73.828 (71.484)	Prec@5 99.219 (97.950)
EVALUATING - Epoch: [38][0/79]	Time 0.074 (0.074)	Data 0.058 (0.058)	Loss 0.9751 (0.9751)	Prec@1 67.188 (67.188)	Prec@5 95.312 (95.312)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:08

 Epoch: 39	Training Loss 0.8200 	Training Prec@1 71.084 	Training Prec@5 97.852 	Validation Loss 1.0636 	Validation Prec@1 64.640 	Validation Prec@5 96.900 

lr: 0.09976488683119955
TRAINING - Epoch: [39][0/196]	Time 0.274 (0.274)	Data 0.077 (0.077)	Loss 0.7942 (0.7942)	Prec@1 70.703 (70.703)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [39][100/196]	Time 0.027 (0.032)	Data 0.000 (0.001)	Loss 0.7270 (0.8108)	Prec@1 77.344 (71.887)	Prec@5 96.875 (97.792)
EVALUATING - Epoch: [39][0/79]	Time 0.065 (0.065)	Data 0.045 (0.045)	Loss 0.7726 (0.7726)	Prec@1 67.188 (67.188)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:12:15

 Epoch: 40	Training Loss 0.8094 	Training Prec@1 71.820 	Training Prec@5 97.872 	Validation Loss 0.8955 	Validation Prec@1 68.170 	Validation Prec@5 97.710 

lr: 0.0997492422889589
TRAINING - Epoch: [40][0/196]	Time 0.304 (0.304)	Data 0.093 (0.093)	Loss 0.8034 (0.8034)	Prec@1 71.094 (71.094)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [40][100/196]	Time 0.031 (0.037)	Data 0.000 (0.001)	Loss 0.8011 (0.8001)	Prec@1 69.922 (72.010)	Prec@5 99.219 (97.935)
EVALUATING - Epoch: [40][0/79]	Time 0.066 (0.066)	Data 0.049 (0.049)	Loss 0.9988 (0.9988)	Prec@1 64.844 (64.844)	Prec@5 96.875 (96.875)
Time cost: 00:07	Time of Finish: 2024-03-31 17:21:50

 Epoch: 41	Training Loss 0.8023 	Training Prec@1 71.808 	Training Prec@5 97.902 	Validation Loss 1.0138 	Validation Prec@1 65.020 	Validation Prec@5 96.790 

lr: 0.0997331028086105
TRAINING - Epoch: [41][0/196]	Time 0.303 (0.303)	Data 0.077 (0.077)	Loss 0.9181 (0.9181)	Prec@1 66.016 (66.016)	Prec@5 96.484 (96.484)
TRAINING - Epoch: [41][100/196]	Time 0.034 (0.036)	Data 0.000 (0.001)	Loss 0.9110 (0.8156)	Prec@1 70.312 (71.442)	Prec@5 96.484 (97.703)
EVALUATING - Epoch: [41][0/79]	Time 0.067 (0.067)	Data 0.046 (0.046)	Loss 1.0513 (1.0513)	Prec@1 66.406 (66.406)	Prec@5 96.094 (96.094)
Time cost: 00:07	Time of Finish: 2024-03-31 17:15:32

 Epoch: 42	Training Loss 0.8016 	Training Prec@1 71.810 	Training Prec@5 97.830 	Validation Loss 1.2055 	Validation Prec@1 62.470 	Validation Prec@5 96.250 

lr: 0.09971646855072651
TRAINING - Epoch: [42][0/196]	Time 0.271 (0.271)	Data 0.079 (0.079)	Loss 0.7002 (0.7002)	Prec@1 73.438 (73.438)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [42][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.7104 (0.7758)	Prec@1 75.391 (72.722)	Prec@5 98.047 (98.008)
EVALUATING - Epoch: [42][0/79]	Time 0.066 (0.066)	Data 0.048 (0.048)	Loss 1.0459 (1.0459)	Prec@1 67.969 (67.969)	Prec@5 96.875 (96.875)
Time cost: 00:06	Time of Finish: 2024-03-31 17:01:49

 Epoch: 43	Training Loss 0.7766 	Training Prec@1 72.664 	Training Prec@5 98.104 	Validation Loss 1.1413 	Validation Prec@1 65.030 	Validation Prec@5 95.960 

lr: 0.09969933968080164
TRAINING - Epoch: [43][0/196]	Time 0.269 (0.269)	Data 0.078 (0.078)	Loss 0.7761 (0.7761)	Prec@1 73.828 (73.828)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [43][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.7323 (0.7845)	Prec@1 74.609 (72.405)	Prec@5 99.609 (98.012)
EVALUATING - Epoch: [43][0/79]	Time 0.068 (0.068)	Data 0.050 (0.050)	Loss 0.8995 (0.8995)	Prec@1 67.969 (67.969)	Prec@5 96.875 (96.875)
Time cost: 00:06	Time of Finish: 2024-03-31 17:02:15

 Epoch: 44	Training Loss 0.7776 	Training Prec@1 72.792 	Training Prec@5 98.050 	Validation Loss 0.9887 	Validation Prec@1 68.030 	Validation Prec@5 97.100 

lr: 0.09968171636925152
TRAINING - Epoch: [44][0/196]	Time 0.271 (0.271)	Data 0.079 (0.079)	Loss 0.7339 (0.7339)	Prec@1 70.703 (70.703)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [44][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.7296 (0.7648)	Prec@1 77.734 (73.496)	Prec@5 98.047 (98.116)
EVALUATING - Epoch: [44][0/79]	Time 0.066 (0.066)	Data 0.046 (0.046)	Loss 0.8438 (0.8438)	Prec@1 70.312 (70.312)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:00:26

 Epoch: 45	Training Loss 0.7607 	Training Prec@1 73.510 	Training Prec@5 98.190 	Validation Loss 0.9524 	Validation Prec@1 67.120 	Validation Prec@5 97.320 

lr: 0.099663598791411
TRAINING - Epoch: [45][0/196]	Time 0.313 (0.313)	Data 0.093 (0.093)	Loss 0.7616 (0.7616)	Prec@1 72.656 (72.656)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [45][100/196]	Time 0.039 (0.036)	Data 0.000 (0.001)	Loss 0.7995 (0.7674)	Prec@1 73.438 (72.935)	Prec@5 98.438 (98.178)
EVALUATING - Epoch: [45][0/79]	Time 0.073 (0.073)	Data 0.052 (0.052)	Loss 1.0945 (1.0945)	Prec@1 59.375 (59.375)	Prec@5 98.438 (98.438)
Time cost: 00:07	Time of Finish: 2024-03-31 17:19:40

 Epoch: 46	Training Loss 0.7537 	Training Prec@1 73.428 	Training Prec@5 98.180 	Validation Loss 1.1022 	Validation Prec@1 64.330 	Validation Prec@5 97.600 

lr: 0.09964498712753239
TRAINING - Epoch: [46][0/196]	Time 0.277 (0.277)	Data 0.083 (0.083)	Loss 0.7544 (0.7544)	Prec@1 72.266 (72.266)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [46][100/196]	Time 0.025 (0.038)	Data 0.000 (0.001)	Loss 0.7678 (0.7480)	Prec@1 71.094 (73.615)	Prec@5 97.656 (98.233)
EVALUATING - Epoch: [46][0/79]	Time 0.067 (0.067)	Data 0.050 (0.050)	Loss 1.1467 (1.1467)	Prec@1 67.188 (67.188)	Prec@5 98.438 (98.438)
Time cost: 00:07	Time of Finish: 2024-03-31 17:16:57

 Epoch: 47	Training Loss 0.7444 	Training Prec@1 73.930 	Training Prec@5 98.238 	Validation Loss 1.3280 	Validation Prec@1 60.690 	Validation Prec@5 95.880 

lr: 0.09962588156278368
TRAINING - Epoch: [47][0/196]	Time 0.270 (0.270)	Data 0.079 (0.079)	Loss 0.7535 (0.7535)	Prec@1 74.609 (74.609)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [47][100/196]	Time 0.028 (0.032)	Data 0.000 (0.001)	Loss 0.6773 (0.7411)	Prec@1 77.734 (74.257)	Prec@5 98.438 (98.167)
EVALUATING - Epoch: [47][0/79]	Time 0.068 (0.068)	Data 0.046 (0.046)	Loss 0.9109 (0.9109)	Prec@1 71.094 (71.094)	Prec@5 96.875 (96.875)
Time cost: 00:06	Time of Finish: 2024-03-31 17:11:30

 Epoch: 48	Training Loss 0.7396 	Training Prec@1 74.362 	Training Prec@5 98.188 	Validation Loss 1.0375 	Validation Prec@1 66.980 	Validation Prec@5 96.710 

lr: 0.09960628228724669
TRAINING - Epoch: [48][0/196]	Time 0.285 (0.285)	Data 0.081 (0.081)	Loss 0.6630 (0.6630)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [48][100/196]	Time 0.028 (0.032)	Data 0.000 (0.001)	Loss 0.7156 (0.7195)	Prec@1 74.609 (74.927)	Prec@5 96.875 (98.383)
EVALUATING - Epoch: [48][0/79]	Time 0.069 (0.069)	Data 0.052 (0.052)	Loss 0.8156 (0.8156)	Prec@1 70.312 (70.312)	Prec@5 96.875 (96.875)
Time cost: 00:06	Time of Finish: 2024-03-31 17:05:12

 Epoch: 49	Training Loss 0.7249 	Training Prec@1 74.868 	Training Prec@5 98.316 	Validation Loss 0.8653 	Validation Prec@1 70.970 	Validation Prec@5 97.320 

lr: 0.09958618949591519
TRAINING - Epoch: [49][0/196]	Time 0.296 (0.296)	Data 0.076 (0.076)	Loss 0.6467 (0.6467)	Prec@1 78.125 (78.125)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [49][100/196]	Time 0.030 (0.034)	Data 0.000 (0.001)	Loss 0.7147 (0.7216)	Prec@1 73.828 (74.911)	Prec@5 99.219 (98.325)
EVALUATING - Epoch: [49][0/79]	Time 0.072 (0.072)	Data 0.048 (0.048)	Loss 0.9360 (0.9360)	Prec@1 64.062 (64.062)	Prec@5 98.438 (98.438)
Time cost: 00:07	Time of Finish: 2024-03-31 17:20:13

 Epoch: 50	Training Loss 0.7256 	Training Prec@1 74.890 	Training Prec@5 98.358 	Validation Loss 1.0336 	Validation Prec@1 65.030 	Validation Prec@5 96.190 

lr: 0.09956560338869293
TRAINING - Epoch: [50][0/196]	Time 0.275 (0.275)	Data 0.079 (0.079)	Loss 0.6933 (0.6933)	Prec@1 74.219 (74.219)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [50][100/196]	Time 0.031 (0.032)	Data 0.000 (0.001)	Loss 0.6656 (0.7247)	Prec@1 78.906 (74.834)	Prec@5 98.828 (98.364)
EVALUATING - Epoch: [50][0/79]	Time 0.065 (0.065)	Data 0.048 (0.048)	Loss 0.8859 (0.8859)	Prec@1 69.531 (69.531)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:06:59

 Epoch: 51	Training Loss 0.7235 	Training Prec@1 74.820 	Training Prec@5 98.314 	Validation Loss 0.9607 	Validation Prec@1 67.880 	Validation Prec@5 97.240 

lr: 0.09954452417039172
TRAINING - Epoch: [51][0/196]	Time 0.270 (0.270)	Data 0.085 (0.085)	Loss 0.7063 (0.7063)	Prec@1 73.828 (73.828)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [51][100/196]	Time 0.040 (0.033)	Data 0.000 (0.001)	Loss 0.6831 (0.7122)	Prec@1 73.047 (74.957)	Prec@5 99.609 (98.403)
EVALUATING - Epoch: [51][0/79]	Time 0.064 (0.064)	Data 0.045 (0.045)	Loss 1.1332 (1.1332)	Prec@1 64.844 (64.844)	Prec@5 97.656 (97.656)
Time cost: 00:07	Time of Finish: 2024-03-31 17:13:06

 Epoch: 52	Training Loss 0.7050 	Training Prec@1 75.434 	Training Prec@5 98.374 	Validation Loss 1.2693 	Validation Prec@1 61.440 	Validation Prec@5 95.750 

lr: 0.09952295205072932
TRAINING - Epoch: [52][0/196]	Time 0.267 (0.267)	Data 0.088 (0.088)	Loss 0.6980 (0.6980)	Prec@1 73.828 (73.828)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [52][100/196]	Time 0.027 (0.032)	Data 0.000 (0.001)	Loss 0.6678 (0.7060)	Prec@1 78.125 (75.159)	Prec@5 97.266 (98.418)
EVALUATING - Epoch: [52][0/79]	Time 0.069 (0.069)	Data 0.053 (0.053)	Loss 0.8580 (0.8580)	Prec@1 68.750 (68.750)	Prec@5 96.094 (96.094)
Time cost: 00:06	Time of Finish: 2024-03-31 17:06:54

 Epoch: 53	Training Loss 0.7047 	Training Prec@1 75.294 	Training Prec@5 98.414 	Validation Loss 0.9204 	Validation Prec@1 69.640 	Validation Prec@5 97.760 

lr: 0.09950088724432733
TRAINING - Epoch: [53][0/196]	Time 0.270 (0.270)	Data 0.080 (0.080)	Loss 0.7580 (0.7580)	Prec@1 72.656 (72.656)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [53][100/196]	Time 0.028 (0.031)	Data 0.000 (0.001)	Loss 0.7659 (0.7039)	Prec@1 75.000 (75.623)	Prec@5 97.266 (98.399)
EVALUATING - Epoch: [53][0/79]	Time 0.067 (0.067)	Data 0.050 (0.050)	Loss 0.7559 (0.7559)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:05:57

 Epoch: 54	Training Loss 0.7095 	Training Prec@1 75.270 	Training Prec@5 98.400 	Validation Loss 0.8543 	Validation Prec@1 72.310 	Validation Prec@5 98.140 

lr: 0.09947832997070923
TRAINING - Epoch: [54][0/196]	Time 0.324 (0.324)	Data 0.083 (0.083)	Loss 0.5902 (0.5902)	Prec@1 80.469 (80.469)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [54][100/196]	Time 0.028 (0.033)	Data 0.000 (0.001)	Loss 0.6700 (0.6895)	Prec@1 75.000 (76.052)	Prec@5 98.828 (98.407)
EVALUATING - Epoch: [54][0/79]	Time 0.070 (0.070)	Data 0.045 (0.045)	Loss 0.8134 (0.8134)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:07	Time of Finish: 2024-03-31 17:13:53

 Epoch: 55	Training Loss 0.6959 	Training Prec@1 75.836 	Training Prec@5 98.392 	Validation Loss 0.8968 	Validation Prec@1 70.280 	Validation Prec@5 97.840 

lr: 0.09945528045429795
TRAINING - Epoch: [55][0/196]	Time 0.268 (0.268)	Data 0.077 (0.077)	Loss 0.7002 (0.7002)	Prec@1 74.609 (74.609)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [55][100/196]	Time 0.027 (0.032)	Data 0.000 (0.001)	Loss 0.6401 (0.7026)	Prec@1 77.344 (75.766)	Prec@5 99.219 (98.503)
EVALUATING - Epoch: [55][0/79]	Time 0.068 (0.068)	Data 0.049 (0.049)	Loss 0.9062 (0.9062)	Prec@1 71.094 (71.094)	Prec@5 96.875 (96.875)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:53

 Epoch: 56	Training Loss 0.6990 	Training Prec@1 75.744 	Training Prec@5 98.524 	Validation Loss 0.9096 	Validation Prec@1 69.430 	Validation Prec@5 97.600 

lr: 0.0994317389244138
TRAINING - Epoch: [56][0/196]	Time 0.273 (0.273)	Data 0.089 (0.089)	Loss 0.7181 (0.7181)	Prec@1 73.828 (73.828)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [56][100/196]	Time 0.028 (0.030)	Data 0.000 (0.001)	Loss 0.7245 (0.6878)	Prec@1 77.344 (76.087)	Prec@5 98.047 (98.554)
EVALUATING - Epoch: [56][0/79]	Time 0.068 (0.068)	Data 0.052 (0.052)	Loss 0.8638 (0.8638)	Prec@1 70.312 (70.312)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:01:20

 Epoch: 57	Training Loss 0.6828 	Training Prec@1 76.258 	Training Prec@5 98.618 	Validation Loss 0.9965 	Validation Prec@1 67.820 	Validation Prec@5 96.780 

lr: 0.09940770561527218
TRAINING - Epoch: [57][0/196]	Time 0.269 (0.269)	Data 0.077 (0.077)	Loss 0.6241 (0.6241)	Prec@1 75.781 (75.781)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [57][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.6469 (0.6766)	Prec@1 75.781 (76.474)	Prec@5 98.047 (98.584)
EVALUATING - Epoch: [57][0/79]	Time 0.072 (0.072)	Data 0.053 (0.053)	Loss 0.8725 (0.8725)	Prec@1 68.750 (68.750)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:03:02

 Epoch: 58	Training Loss 0.6764 	Training Prec@1 76.508 	Training Prec@5 98.572 	Validation Loss 0.9584 	Validation Prec@1 69.510 	Validation Prec@5 96.860 

lr: 0.09938318076598116
TRAINING - Epoch: [58][0/196]	Time 0.266 (0.266)	Data 0.079 (0.079)	Loss 0.6831 (0.6831)	Prec@1 76.562 (76.562)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [58][100/196]	Time 0.026 (0.029)	Data 0.000 (0.001)	Loss 0.6267 (0.6852)	Prec@1 78.906 (76.145)	Prec@5 98.438 (98.511)
EVALUATING - Epoch: [58][0/79]	Time 0.063 (0.063)	Data 0.046 (0.046)	Loss 1.0194 (1.0194)	Prec@1 67.969 (67.969)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:02:36

 Epoch: 59	Training Loss 0.6875 	Training Prec@1 76.066 	Training Prec@5 98.472 	Validation Loss 1.1682 	Validation Prec@1 63.530 	Validation Prec@5 97.050 

lr: 0.09935816462053919
TRAINING - Epoch: [59][0/196]	Time 0.274 (0.274)	Data 0.082 (0.082)	Loss 0.6124 (0.6124)	Prec@1 77.734 (77.734)	Prec@5 96.875 (96.875)
TRAINING - Epoch: [59][100/196]	Time 0.028 (0.030)	Data 0.000 (0.001)	Loss 0.7222 (0.6789)	Prec@1 73.828 (76.276)	Prec@5 98.828 (98.461)
EVALUATING - Epoch: [59][0/79]	Time 0.069 (0.069)	Data 0.046 (0.046)	Loss 0.9789 (0.9789)	Prec@1 64.844 (64.844)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:11:54

 Epoch: 60	Training Loss 0.6798 	Training Prec@1 76.194 	Training Prec@5 98.488 	Validation Loss 1.0076 	Validation Prec@1 66.520 	Validation Prec@5 97.000 

lr: 0.09933265742783262
TRAINING - Epoch: [60][0/196]	Time 0.314 (0.314)	Data 0.078 (0.078)	Loss 0.6724 (0.6724)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [60][100/196]	Time 0.030 (0.036)	Data 0.000 (0.001)	Loss 0.6793 (0.6767)	Prec@1 76.953 (76.373)	Prec@5 99.609 (98.557)
EVALUATING - Epoch: [60][0/79]	Time 0.068 (0.068)	Data 0.048 (0.048)	Loss 1.0428 (1.0428)	Prec@1 69.531 (69.531)	Prec@5 96.875 (96.875)
Time cost: 00:07	Time of Finish: 2024-03-31 17:17:37

 Epoch: 61	Training Loss 0.6747 	Training Prec@1 76.372 	Training Prec@5 98.526 	Validation Loss 1.0932 	Validation Prec@1 65.030 	Validation Prec@5 97.680 

lr: 0.09930665944163328
TRAINING - Epoch: [61][0/196]	Time 0.311 (0.311)	Data 0.102 (0.102)	Loss 0.7128 (0.7128)	Prec@1 71.875 (71.875)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [61][100/196]	Time 0.035 (0.035)	Data 0.000 (0.001)	Loss 0.7817 (0.6683)	Prec@1 73.047 (76.922)	Prec@5 98.828 (98.515)
EVALUATING - Epoch: [61][0/79]	Time 0.063 (0.063)	Data 0.045 (0.045)	Loss 0.8003 (0.8003)	Prec@1 69.531 (69.531)	Prec@5 98.438 (98.438)
Time cost: 00:07	Time of Finish: 2024-03-31 17:15:29

 Epoch: 62	Training Loss 0.6697 	Training Prec@1 76.854 	Training Prec@5 98.490 	Validation Loss 0.8007 	Validation Prec@1 72.170 	Validation Prec@5 98.130 

lr: 0.09928017092059589
TRAINING - Epoch: [62][0/196]	Time 0.295 (0.295)	Data 0.096 (0.096)	Loss 0.6113 (0.6113)	Prec@1 77.344 (77.344)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [62][100/196]	Time 0.028 (0.032)	Data 0.000 (0.001)	Loss 0.7415 (0.6630)	Prec@1 76.562 (76.825)	Prec@5 99.219 (98.608)
EVALUATING - Epoch: [62][0/79]	Time 0.070 (0.070)	Data 0.055 (0.055)	Loss 0.6645 (0.6645)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:00

 Epoch: 63	Training Loss 0.6667 	Training Prec@1 76.756 	Training Prec@5 98.622 	Validation Loss 0.8108 	Validation Prec@1 72.200 	Validation Prec@5 98.160 

lr: 0.09925319212825552
TRAINING - Epoch: [63][0/196]	Time 0.276 (0.276)	Data 0.077 (0.077)	Loss 0.7119 (0.7119)	Prec@1 73.828 (73.828)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [63][100/196]	Time 0.027 (0.031)	Data 0.000 (0.001)	Loss 0.5616 (0.6528)	Prec@1 79.688 (77.409)	Prec@5 99.219 (98.612)
EVALUATING - Epoch: [63][0/79]	Time 0.069 (0.069)	Data 0.048 (0.048)	Loss 0.8456 (0.8456)	Prec@1 72.656 (72.656)	Prec@5 95.312 (95.312)
Time cost: 00:06	Time of Finish: 2024-03-31 17:03:42

 Epoch: 64	Training Loss 0.6634 	Training Prec@1 77.014 	Training Prec@5 98.610 	Validation Loss 0.9215 	Validation Prec@1 69.980 	Validation Prec@5 96.530 

lr: 0.09922572333302496
TRAINING - Epoch: [64][0/196]	Time 0.288 (0.288)	Data 0.076 (0.076)	Loss 0.7796 (0.7796)	Prec@1 76.953 (76.953)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [64][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.6545 (0.6749)	Prec@1 79.688 (76.752)	Prec@5 98.047 (98.557)
EVALUATING - Epoch: [64][0/79]	Time 0.069 (0.069)	Data 0.053 (0.053)	Loss 0.9278 (0.9278)	Prec@1 69.531 (69.531)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:06:53

 Epoch: 65	Training Loss 0.6627 	Training Prec@1 77.096 	Training Prec@5 98.616 	Validation Loss 1.0090 	Validation Prec@1 67.220 	Validation Prec@5 97.740 

lr: 0.09919776480819205
TRAINING - Epoch: [65][0/196]	Time 0.266 (0.266)	Data 0.078 (0.078)	Loss 0.7087 (0.7087)	Prec@1 76.172 (76.172)	Prec@5 97.266 (97.266)
TRAINING - Epoch: [65][100/196]	Time 0.035 (0.032)	Data 0.000 (0.001)	Loss 0.6802 (0.6480)	Prec@1 76.953 (77.537)	Prec@5 98.047 (98.728)
EVALUATING - Epoch: [65][0/79]	Time 0.065 (0.065)	Data 0.046 (0.046)	Loss 1.4653 (1.4653)	Prec@1 58.594 (58.594)	Prec@5 89.844 (89.844)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:29

 Epoch: 66	Training Loss 0.6569 	Training Prec@1 77.184 	Training Prec@5 98.660 	Validation Loss 1.4078 	Validation Prec@1 57.490 	Validation Prec@5 93.180 

lr: 0.09916931683191699
TRAINING - Epoch: [66][0/196]	Time 0.277 (0.277)	Data 0.077 (0.077)	Loss 0.5749 (0.5749)	Prec@1 78.516 (78.516)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [66][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.5966 (0.6497)	Prec@1 80.859 (77.537)	Prec@5 98.438 (98.608)
EVALUATING - Epoch: [66][0/79]	Time 0.070 (0.070)	Data 0.054 (0.054)	Loss 0.9333 (0.9333)	Prec@1 67.188 (67.188)	Prec@5 96.875 (96.875)
Time cost: 00:06	Time of Finish: 2024-03-31 17:03:56

 Epoch: 67	Training Loss 0.6485 	Training Prec@1 77.562 	Training Prec@5 98.668 	Validation Loss 1.0064 	Validation Prec@1 66.770 	Validation Prec@5 97.670 

lr: 0.09914037968722952
TRAINING - Epoch: [67][0/196]	Time 0.274 (0.274)	Data 0.075 (0.075)	Loss 0.7896 (0.7896)	Prec@1 73.828 (73.828)	Prec@5 96.875 (96.875)
TRAINING - Epoch: [67][100/196]	Time 0.027 (0.031)	Data 0.000 (0.001)	Loss 0.7664 (0.6477)	Prec@1 73.438 (77.553)	Prec@5 98.047 (98.565)
EVALUATING - Epoch: [67][0/79]	Time 0.070 (0.070)	Data 0.054 (0.054)	Loss 0.7308 (0.7308)	Prec@1 67.969 (67.969)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:11:15

 Epoch: 68	Training Loss 0.6501 	Training Prec@1 77.372 	Training Prec@5 98.646 	Validation Loss 0.8334 	Validation Prec@1 72.370 	Validation Prec@5 98.130 

lr: 0.09911095366202614
TRAINING - Epoch: [68][0/196]	Time 0.276 (0.276)	Data 0.075 (0.075)	Loss 0.7121 (0.7121)	Prec@1 76.562 (76.562)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [68][100/196]	Time 0.026 (0.033)	Data 0.000 (0.001)	Loss 0.6745 (0.6456)	Prec@1 76.172 (77.464)	Prec@5 99.219 (98.693)
EVALUATING - Epoch: [68][0/79]	Time 0.066 (0.066)	Data 0.047 (0.047)	Loss 0.8438 (0.8438)	Prec@1 69.531 (69.531)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:05:23

 Epoch: 69	Training Loss 0.6464 	Training Prec@1 77.522 	Training Prec@5 98.660 	Validation Loss 0.9378 	Validation Prec@1 69.860 	Validation Prec@5 97.350 

lr: 0.09908103904906725
TRAINING - Epoch: [69][0/196]	Time 0.268 (0.268)	Data 0.072 (0.072)	Loss 0.7538 (0.7538)	Prec@1 75.000 (75.000)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [69][100/196]	Time 0.036 (0.032)	Data 0.000 (0.001)	Loss 0.7595 (0.6371)	Prec@1 72.656 (77.684)	Prec@5 97.656 (98.712)
EVALUATING - Epoch: [69][0/79]	Time 0.066 (0.066)	Data 0.046 (0.046)	Loss 0.8823 (0.8823)	Prec@1 69.531 (69.531)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:07:05

 Epoch: 70	Training Loss 0.6441 	Training Prec@1 77.480 	Training Prec@5 98.710 	Validation Loss 1.0886 	Validation Prec@1 63.900 	Validation Prec@5 97.040 

lr: 0.09905063614597419
TRAINING - Epoch: [70][0/196]	Time 0.294 (0.294)	Data 0.076 (0.076)	Loss 0.5868 (0.5868)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [70][100/196]	Time 0.040 (0.034)	Data 0.000 (0.001)	Loss 0.6574 (0.6393)	Prec@1 75.781 (77.761)	Prec@5 98.047 (98.697)
EVALUATING - Epoch: [70][0/79]	Time 0.076 (0.076)	Data 0.057 (0.057)	Loss 0.9907 (0.9907)	Prec@1 70.312 (70.312)	Prec@5 97.656 (97.656)
Time cost: 00:07	Time of Finish: 2024-03-31 17:21:12

 Epoch: 71	Training Loss 0.6396 	Training Prec@1 77.650 	Training Prec@5 98.722 	Validation Loss 0.9979 	Validation Prec@1 67.880 	Validation Prec@5 97.400 

lr: 0.09901974525522632
TRAINING - Epoch: [71][0/196]	Time 0.295 (0.295)	Data 0.085 (0.085)	Loss 0.6187 (0.6187)	Prec@1 79.297 (79.297)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [71][100/196]	Time 0.031 (0.032)	Data 0.000 (0.001)	Loss 0.6250 (0.6444)	Prec@1 78.906 (77.498)	Prec@5 98.438 (98.627)
EVALUATING - Epoch: [71][0/79]	Time 0.068 (0.068)	Data 0.045 (0.045)	Loss 1.0894 (1.0894)	Prec@1 64.844 (64.844)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:09:29

 Epoch: 72	Training Loss 0.6447 	Training Prec@1 77.420 	Training Prec@5 98.624 	Validation Loss 1.1536 	Validation Prec@1 64.450 	Validation Prec@5 96.690 

lr: 0.09898836668415804
TRAINING - Epoch: [72][0/196]	Time 0.320 (0.320)	Data 0.092 (0.092)	Loss 0.6659 (0.6659)	Prec@1 73.438 (73.438)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [72][100/196]	Time 0.027 (0.031)	Data 0.000 (0.001)	Loss 0.7073 (0.6377)	Prec@1 75.781 (77.932)	Prec@5 98.047 (98.759)
EVALUATING - Epoch: [72][0/79]	Time 0.069 (0.069)	Data 0.049 (0.049)	Loss 1.4291 (1.4291)	Prec@1 60.938 (60.938)	Prec@5 96.094 (96.094)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:13

 Epoch: 73	Training Loss 0.6398 	Training Prec@1 77.714 	Training Prec@5 98.784 	Validation Loss 1.3256 	Validation Prec@1 61.170 	Validation Prec@5 97.040 

lr: 0.09895650074495567
TRAINING - Epoch: [73][0/196]	Time 0.268 (0.268)	Data 0.076 (0.076)	Loss 0.6695 (0.6695)	Prec@1 74.219 (74.219)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [73][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.7322 (0.6445)	Prec@1 76.562 (77.642)	Prec@5 97.266 (98.681)
EVALUATING - Epoch: [73][0/79]	Time 0.067 (0.067)	Data 0.048 (0.048)	Loss 0.8610 (0.8610)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:03:17

 Epoch: 74	Training Loss 0.6442 	Training Prec@1 77.476 	Training Prec@5 98.712 	Validation Loss 0.8350 	Validation Prec@1 72.590 	Validation Prec@5 97.670 

lr: 0.09892414775465437
TRAINING - Epoch: [74][0/196]	Time 0.305 (0.305)	Data 0.081 (0.081)	Loss 0.5030 (0.5030)	Prec@1 81.250 (81.250)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [74][100/196]	Time 0.028 (0.033)	Data 0.000 (0.001)	Loss 0.6244 (0.6386)	Prec@1 78.125 (77.750)	Prec@5 98.438 (98.708)
EVALUATING - Epoch: [74][0/79]	Time 0.064 (0.064)	Data 0.045 (0.045)	Loss 1.0646 (1.0646)	Prec@1 66.406 (66.406)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:09:12

 Epoch: 75	Training Loss 0.6346 	Training Prec@1 77.950 	Training Prec@5 98.736 	Validation Loss 1.1619 	Validation Prec@1 64.460 	Validation Prec@5 96.900 

lr: 0.09889130803513499
TRAINING - Epoch: [75][0/196]	Time 0.284 (0.284)	Data 0.089 (0.089)	Loss 0.6226 (0.6226)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [75][100/196]	Time 0.032 (0.034)	Data 0.000 (0.001)	Loss 0.6466 (0.6401)	Prec@1 78.125 (77.738)	Prec@5 98.828 (98.751)
EVALUATING - Epoch: [75][0/79]	Time 0.066 (0.066)	Data 0.047 (0.047)	Loss 0.9446 (0.9446)	Prec@1 65.625 (65.625)	Prec@5 96.875 (96.875)
Time cost: 00:06	Time of Finish: 2024-03-31 17:11:07

 Epoch: 76	Training Loss 0.6344 	Training Prec@1 77.860 	Training Prec@5 98.782 	Validation Loss 1.1103 	Validation Prec@1 65.420 	Validation Prec@5 96.430 

lr: 0.09885798191312087
TRAINING - Epoch: [76][0/196]	Time 0.270 (0.270)	Data 0.087 (0.087)	Loss 0.5645 (0.5645)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [76][100/196]	Time 0.034 (0.031)	Data 0.000 (0.001)	Loss 0.6407 (0.6329)	Prec@1 73.828 (77.885)	Prec@5 98.828 (98.720)
EVALUATING - Epoch: [76][0/79]	Time 0.067 (0.067)	Data 0.047 (0.047)	Loss 0.7099 (0.7099)	Prec@1 74.219 (74.219)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:06:55

 Epoch: 77	Training Loss 0.6303 	Training Prec@1 77.984 	Training Prec@5 98.718 	Validation Loss 0.7662 	Validation Prec@1 74.620 	Validation Prec@5 98.180 

lr: 0.09882416972017453
TRAINING - Epoch: [77][0/196]	Time 0.275 (0.275)	Data 0.073 (0.073)	Loss 0.6056 (0.6056)	Prec@1 80.078 (80.078)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [77][100/196]	Time 0.037 (0.031)	Data 0.000 (0.001)	Loss 0.6729 (0.6313)	Prec@1 77.734 (78.013)	Prec@5 98.438 (98.801)
EVALUATING - Epoch: [77][0/79]	Time 0.072 (0.072)	Data 0.054 (0.054)	Loss 1.1127 (1.1127)	Prec@1 66.406 (66.406)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:16

 Epoch: 78	Training Loss 0.6252 	Training Prec@1 78.198 	Training Prec@5 98.784 	Validation Loss 1.3245 	Validation Prec@1 61.490 	Validation Prec@5 96.860 

lr: 0.09878987179269452
TRAINING - Epoch: [78][0/196]	Time 0.289 (0.289)	Data 0.078 (0.078)	Loss 0.5514 (0.5514)	Prec@1 81.250 (81.250)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [78][100/196]	Time 0.027 (0.034)	Data 0.000 (0.001)	Loss 0.8040 (0.6329)	Prec@1 75.391 (77.932)	Prec@5 97.266 (98.708)
EVALUATING - Epoch: [78][0/79]	Time 0.069 (0.069)	Data 0.050 (0.050)	Loss 0.8054 (0.8054)	Prec@1 72.656 (72.656)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:12:11

 Epoch: 79	Training Loss 0.6367 	Training Prec@1 77.706 	Training Prec@5 98.726 	Validation Loss 0.8048 	Validation Prec@1 72.230 	Validation Prec@5 98.530 

lr: 0.09875508847191189
TRAINING - Epoch: [79][0/196]	Time 0.272 (0.272)	Data 0.079 (0.079)	Loss 0.6385 (0.6385)	Prec@1 77.344 (77.344)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [79][100/196]	Time 0.026 (0.032)	Data 0.000 (0.001)	Loss 0.5699 (0.6256)	Prec@1 82.812 (78.473)	Prec@5 99.219 (98.700)
EVALUATING - Epoch: [79][0/79]	Time 0.068 (0.068)	Data 0.050 (0.050)	Loss 0.9738 (0.9738)	Prec@1 73.438 (73.438)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:07:46

 Epoch: 80	Training Loss 0.6361 	Training Prec@1 78.018 	Training Prec@5 98.674 	Validation Loss 1.0775 	Validation Prec@1 68.120 	Validation Prec@5 96.210 

lr: 0.09871982010388693
TRAINING - Epoch: [80][0/196]	Time 0.268 (0.268)	Data 0.079 (0.079)	Loss 0.7477 (0.7477)	Prec@1 76.953 (76.953)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [80][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.6957 (0.6076)	Prec@1 75.000 (78.670)	Prec@5 99.609 (98.809)
EVALUATING - Epoch: [80][0/79]	Time 0.070 (0.070)	Data 0.049 (0.049)	Loss 0.8830 (0.8830)	Prec@1 71.094 (71.094)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:00:08

 Epoch: 81	Training Loss 0.6190 	Training Prec@1 78.316 	Training Prec@5 98.778 	Validation Loss 0.9984 	Validation Prec@1 68.490 	Validation Prec@5 97.670 

lr: 0.09868406703950566
TRAINING - Epoch: [81][0/196]	Time 0.280 (0.280)	Data 0.092 (0.092)	Loss 0.5975 (0.5975)	Prec@1 78.125 (78.125)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [81][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.6100 (0.6153)	Prec@1 80.859 (78.589)	Prec@5 99.219 (98.801)
EVALUATING - Epoch: [81][0/79]	Time 0.068 (0.068)	Data 0.050 (0.050)	Loss 0.7592 (0.7592)	Prec@1 74.219 (74.219)	Prec@5 96.875 (96.875)
Time cost: 00:06	Time of Finish: 2024-03-31 17:00:45

 Epoch: 82	Training Loss 0.6166 	Training Prec@1 78.546 	Training Prec@5 98.760 	Validation Loss 0.8207 	Validation Prec@1 72.410 	Validation Prec@5 98.000 

lr: 0.09864782963447637
TRAINING - Epoch: [82][0/196]	Time 0.282 (0.282)	Data 0.103 (0.103)	Loss 0.6655 (0.6655)	Prec@1 76.562 (76.562)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [82][100/196]	Time 0.030 (0.030)	Data 0.000 (0.001)	Loss 0.6096 (0.6193)	Prec@1 78.125 (78.299)	Prec@5 99.219 (98.820)
EVALUATING - Epoch: [82][0/79]	Time 0.070 (0.070)	Data 0.045 (0.045)	Loss 1.0076 (1.0076)	Prec@1 67.188 (67.188)	Prec@5 96.875 (96.875)
Time cost: 00:06	Time of Finish: 2024-03-31 17:02:31

 Epoch: 83	Training Loss 0.6211 	Training Prec@1 78.454 	Training Prec@5 98.806 	Validation Loss 1.2280 	Validation Prec@1 63.240 	Validation Prec@5 96.370 

lr: 0.09861110824932605
TRAINING - Epoch: [83][0/196]	Time 0.281 (0.281)	Data 0.083 (0.083)	Loss 0.5911 (0.5911)	Prec@1 77.344 (77.344)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [83][100/196]	Time 0.027 (0.032)	Data 0.000 (0.001)	Loss 0.5291 (0.6233)	Prec@1 79.688 (78.427)	Prec@5 99.609 (98.762)
EVALUATING - Epoch: [83][0/79]	Time 0.065 (0.065)	Data 0.045 (0.045)	Loss 0.8421 (0.8421)	Prec@1 71.094 (71.094)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:07:35

 Epoch: 84	Training Loss 0.6261 	Training Prec@1 78.250 	Training Prec@5 98.780 	Validation Loss 0.8367 	Validation Prec@1 71.820 	Validation Prec@5 98.070 

lr: 0.09857390324939685
TRAINING - Epoch: [84][0/196]	Time 0.282 (0.282)	Data 0.082 (0.082)	Loss 0.6708 (0.6708)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [84][100/196]	Time 0.027 (0.031)	Data 0.000 (0.001)	Loss 0.7123 (0.6193)	Prec@1 76.172 (78.303)	Prec@5 98.047 (98.704)
EVALUATING - Epoch: [84][0/79]	Time 0.073 (0.073)	Data 0.055 (0.055)	Loss 0.7011 (0.7011)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:03:36

 Epoch: 85	Training Loss 0.6166 	Training Prec@1 78.456 	Training Prec@5 98.776 	Validation Loss 0.7327 	Validation Prec@1 74.870 	Validation Prec@5 98.380 

lr: 0.09853621500484241
TRAINING - Epoch: [85][0/196]	Time 0.279 (0.279)	Data 0.088 (0.088)	Loss 0.5131 (0.5131)	Prec@1 81.250 (81.250)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [85][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.6079 (0.6087)	Prec@1 78.906 (78.972)	Prec@5 100.000 (98.820)
EVALUATING - Epoch: [85][0/79]	Time 0.071 (0.071)	Data 0.054 (0.054)	Loss 0.6498 (0.6498)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:05:26

 Epoch: 86	Training Loss 0.6109 	Training Prec@1 78.786 	Training Prec@5 98.774 	Validation Loss 0.7349 	Validation Prec@1 75.520 	Validation Prec@5 98.210 

lr: 0.09849804389062415
TRAINING - Epoch: [86][0/196]	Time 0.269 (0.269)	Data 0.074 (0.074)	Loss 0.5454 (0.5454)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [86][100/196]	Time 0.035 (0.032)	Data 0.000 (0.001)	Loss 0.6099 (0.6115)	Prec@1 77.734 (78.508)	Prec@5 99.219 (98.971)
EVALUATING - Epoch: [86][0/79]	Time 0.066 (0.066)	Data 0.047 (0.047)	Loss 0.8019 (0.8019)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:07:14

 Epoch: 87	Training Loss 0.6138 	Training Prec@1 78.574 	Training Prec@5 98.858 	Validation Loss 0.8953 	Validation Prec@1 70.290 	Validation Prec@5 97.390 

lr: 0.09845939028650764
TRAINING - Epoch: [87][0/196]	Time 0.274 (0.274)	Data 0.078 (0.078)	Loss 0.6704 (0.6704)	Prec@1 77.344 (77.344)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [87][100/196]	Time 0.026 (0.029)	Data 0.000 (0.001)	Loss 0.7569 (0.6156)	Prec@1 73.828 (78.543)	Prec@5 98.438 (98.855)
EVALUATING - Epoch: [87][0/79]	Time 0.068 (0.068)	Data 0.047 (0.047)	Loss 0.7595 (0.7595)	Prec@1 77.344 (77.344)	Prec@5 95.312 (95.312)
Time cost: 00:06	Time of Finish: 2024-03-31 16:59:03

 Epoch: 88	Training Loss 0.6132 	Training Prec@1 78.548 	Training Prec@5 98.864 	Validation Loss 0.7597 	Validation Prec@1 74.450 	Validation Prec@5 98.320 

lr: 0.09842025457705869
TRAINING - Epoch: [88][0/196]	Time 0.263 (0.263)	Data 0.073 (0.073)	Loss 0.5593 (0.5593)	Prec@1 80.859 (80.859)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [88][100/196]	Time 0.027 (0.033)	Data 0.000 (0.001)	Loss 0.6401 (0.6193)	Prec@1 74.609 (78.581)	Prec@5 98.047 (98.844)
EVALUATING - Epoch: [88][0/79]	Time 0.062 (0.062)	Data 0.045 (0.045)	Loss 0.8643 (0.8643)	Prec@1 67.969 (67.969)	Prec@5 96.094 (96.094)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:43

 Epoch: 89	Training Loss 0.6151 	Training Prec@1 78.798 	Training Prec@5 98.814 	Validation Loss 0.8305 	Validation Prec@1 72.730 	Validation Prec@5 98.120 

lr: 0.09838063715163964
TRAINING - Epoch: [89][0/196]	Time 0.274 (0.274)	Data 0.081 (0.081)	Loss 0.5543 (0.5543)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [89][100/196]	Time 0.025 (0.030)	Data 0.000 (0.001)	Loss 0.6690 (0.6036)	Prec@1 80.078 (79.200)	Prec@5 98.438 (98.836)
EVALUATING - Epoch: [89][0/79]	Time 0.070 (0.070)	Data 0.053 (0.053)	Loss 0.6726 (0.6726)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:01:57

 Epoch: 90	Training Loss 0.6094 	Training Prec@1 78.998 	Training Prec@5 98.850 	Validation Loss 0.7772 	Validation Prec@1 73.660 	Validation Prec@5 98.290 

lr: 0.09834053840440539
TRAINING - Epoch: [90][0/196]	Time 0.294 (0.294)	Data 0.091 (0.091)	Loss 0.6336 (0.6336)	Prec@1 78.906 (78.906)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [90][100/196]	Time 0.026 (0.035)	Data 0.000 (0.001)	Loss 0.6351 (0.6124)	Prec@1 76.953 (78.527)	Prec@5 98.438 (98.801)
EVALUATING - Epoch: [90][0/79]	Time 0.072 (0.072)	Data 0.056 (0.056)	Loss 0.9324 (0.9324)	Prec@1 68.750 (68.750)	Prec@5 96.875 (96.875)
Time cost: 00:07	Time of Finish: 2024-03-31 17:17:52

 Epoch: 91	Training Loss 0.6171 	Training Prec@1 78.456 	Training Prec@5 98.784 	Validation Loss 1.0175 	Validation Prec@1 68.940 	Validation Prec@5 97.050 

lr: 0.09829995873429956
TRAINING - Epoch: [91][0/196]	Time 0.279 (0.279)	Data 0.081 (0.081)	Loss 0.5546 (0.5546)	Prec@1 80.859 (80.859)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [91][100/196]	Time 0.027 (0.037)	Data 0.000 (0.001)	Loss 0.6482 (0.6028)	Prec@1 78.906 (78.736)	Prec@5 98.828 (98.933)
EVALUATING - Epoch: [91][0/79]	Time 0.065 (0.065)	Data 0.047 (0.047)	Loss 0.7998 (0.7998)	Prec@1 71.875 (71.875)	Prec@5 96.875 (96.875)
Time cost: 00:07	Time of Finish: 2024-03-31 17:15:34

 Epoch: 92	Training Loss 0.6150 	Training Prec@1 78.446 	Training Prec@5 98.842 	Validation Loss 0.9756 	Validation Prec@1 66.680 	Validation Prec@5 96.770 

lr: 0.09825889854505047
TRAINING - Epoch: [92][0/196]	Time 0.272 (0.272)	Data 0.074 (0.074)	Loss 0.6147 (0.6147)	Prec@1 79.297 (79.297)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [92][100/196]	Time 0.033 (0.031)	Data 0.000 (0.001)	Loss 0.6988 (0.6152)	Prec@1 76.953 (78.581)	Prec@5 98.047 (98.739)
EVALUATING - Epoch: [92][0/79]	Time 0.065 (0.065)	Data 0.046 (0.046)	Loss 0.6468 (0.6468)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:05:35

 Epoch: 93	Training Loss 0.6164 	Training Prec@1 78.534 	Training Prec@5 98.726 	Validation Loss 0.7367 	Validation Prec@1 75.530 	Validation Prec@5 98.520 

lr: 0.09821735824516718
TRAINING - Epoch: [93][0/196]	Time 0.280 (0.280)	Data 0.104 (0.104)	Loss 0.5957 (0.5957)	Prec@1 77.734 (77.734)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [93][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.6304 (0.6101)	Prec@1 76.562 (78.895)	Prec@5 98.828 (98.770)
EVALUATING - Epoch: [93][0/79]	Time 0.065 (0.065)	Data 0.045 (0.045)	Loss 1.2169 (1.2169)	Prec@1 64.062 (64.062)	Prec@5 96.875 (96.875)
Time cost: 00:06	Time of Finish: 2024-03-31 17:03:17

 Epoch: 94	Training Loss 0.6057 	Training Prec@1 78.960 	Training Prec@5 98.778 	Validation Loss 1.1913 	Validation Prec@1 64.740 	Validation Prec@5 96.680 

lr: 0.0981753382479353
TRAINING - Epoch: [94][0/196]	Time 0.294 (0.294)	Data 0.086 (0.086)	Loss 0.6898 (0.6898)	Prec@1 75.781 (75.781)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [94][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.5112 (0.6063)	Prec@1 80.469 (79.080)	Prec@5 99.609 (98.731)
EVALUATING - Epoch: [94][0/79]	Time 0.067 (0.067)	Data 0.047 (0.047)	Loss 0.7967 (0.7967)	Prec@1 71.094 (71.094)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:02:38

 Epoch: 95	Training Loss 0.6079 	Training Prec@1 78.902 	Training Prec@5 98.734 	Validation Loss 0.8638 	Validation Prec@1 71.510 	Validation Prec@5 98.210 

lr: 0.09813283897141303
TRAINING - Epoch: [95][0/196]	Time 0.295 (0.295)	Data 0.073 (0.073)	Loss 0.4780 (0.4780)	Prec@1 82.422 (82.422)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [95][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.5736 (0.6067)	Prec@1 79.688 (78.895)	Prec@5 99.609 (98.871)
EVALUATING - Epoch: [95][0/79]	Time 0.076 (0.076)	Data 0.055 (0.055)	Loss 0.6835 (0.6835)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:04:30

 Epoch: 96	Training Loss 0.6073 	Training Prec@1 78.868 	Training Prec@5 98.850 	Validation Loss 0.7438 	Validation Prec@1 74.850 	Validation Prec@5 98.460 

lr: 0.09808986083842694
TRAINING - Epoch: [96][0/196]	Time 0.277 (0.277)	Data 0.087 (0.087)	Loss 0.6463 (0.6463)	Prec@1 76.953 (76.953)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [96][100/196]	Time 0.036 (0.033)	Data 0.000 (0.001)	Loss 0.5227 (0.6084)	Prec@1 81.250 (79.015)	Prec@5 99.219 (98.921)
EVALUATING - Epoch: [96][0/79]	Time 0.064 (0.064)	Data 0.046 (0.046)	Loss 0.8602 (0.8602)	Prec@1 71.094 (71.094)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:51

 Epoch: 97	Training Loss 0.6009 	Training Prec@1 79.260 	Training Prec@5 98.890 	Validation Loss 0.8602 	Validation Prec@1 71.250 	Validation Prec@5 98.050 

lr: 0.09804640427656769
TRAINING - Epoch: [97][0/196]	Time 0.269 (0.269)	Data 0.081 (0.081)	Loss 0.7168 (0.7168)	Prec@1 77.344 (77.344)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [97][100/196]	Time 0.037 (0.031)	Data 0.000 (0.001)	Loss 0.6785 (0.6119)	Prec@1 76.953 (78.794)	Prec@5 97.656 (98.824)
EVALUATING - Epoch: [97][0/79]	Time 0.064 (0.064)	Data 0.044 (0.044)	Loss 0.8812 (0.8812)	Prec@1 67.188 (67.188)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:05:23

 Epoch: 98	Training Loss 0.6069 	Training Prec@1 78.902 	Training Prec@5 98.884 	Validation Loss 0.9982 	Validation Prec@1 68.210 	Validation Prec@5 97.850 

lr: 0.09800246971818592
TRAINING - Epoch: [98][0/196]	Time 0.307 (0.307)	Data 0.078 (0.078)	Loss 0.5158 (0.5158)	Prec@1 81.641 (81.641)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [98][100/196]	Time 0.027 (0.031)	Data 0.000 (0.001)	Loss 0.5697 (0.6031)	Prec@1 78.906 (78.883)	Prec@5 98.828 (98.805)
EVALUATING - Epoch: [98][0/79]	Time 0.065 (0.065)	Data 0.047 (0.047)	Loss 1.1289 (1.1289)	Prec@1 64.062 (64.062)	Prec@5 94.531 (94.531)
Time cost: 00:06	Time of Finish: 2024-03-31 17:06:35

 Epoch: 99	Training Loss 0.6017 	Training Prec@1 78.894 	Training Prec@5 98.816 	Validation Loss 1.1906 	Validation Prec@1 64.430 	Validation Prec@5 96.280 

lr: 0.09795805760038784
TRAINING - Epoch: [99][0/196]	Time 0.297 (0.297)	Data 0.084 (0.084)	Loss 0.5896 (0.5896)	Prec@1 77.734 (77.734)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [99][100/196]	Time 0.026 (0.035)	Data 0.000 (0.001)	Loss 0.6834 (0.6026)	Prec@1 74.609 (79.134)	Prec@5 98.828 (98.898)
EVALUATING - Epoch: [99][0/79]	Time 0.075 (0.075)	Data 0.057 (0.057)	Loss 1.0770 (1.0770)	Prec@1 61.719 (61.719)	Prec@5 96.094 (96.094)
Time cost: 00:06	Time of Finish: 2024-03-31 17:10:22

 Epoch: 100	Training Loss 0.6035 	Training Prec@1 79.068 	Training Prec@5 98.834 	Validation Loss 1.2054 	Validation Prec@1 64.350 	Validation Prec@5 96.680 

lr: 0.09791316836503089
TRAINING - Epoch: [100][0/196]	Time 0.277 (0.277)	Data 0.082 (0.082)	Loss 0.6246 (0.6246)	Prec@1 79.297 (79.297)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [100][100/196]	Time 0.027 (0.032)	Data 0.000 (0.001)	Loss 0.5716 (0.6066)	Prec@1 80.469 (78.980)	Prec@5 98.438 (98.898)
EVALUATING - Epoch: [100][0/79]	Time 0.066 (0.066)	Data 0.045 (0.045)	Loss 0.6567 (0.6567)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:10:51

 Epoch: 101	Training Loss 0.6009 	Training Prec@1 79.196 	Training Prec@5 98.884 	Validation Loss 0.7485 	Validation Prec@1 73.820 	Validation Prec@5 98.490 

lr: 0.09786780245871937
TRAINING - Epoch: [101][0/196]	Time 0.278 (0.278)	Data 0.078 (0.078)	Loss 0.5532 (0.5532)	Prec@1 80.078 (80.078)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [101][100/196]	Time 0.030 (0.032)	Data 0.000 (0.001)	Loss 0.7026 (0.5992)	Prec@1 76.172 (79.270)	Prec@5 98.828 (98.859)
EVALUATING - Epoch: [101][0/79]	Time 0.066 (0.066)	Data 0.046 (0.046)	Loss 0.8450 (0.8450)	Prec@1 72.656 (72.656)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:06:28

 Epoch: 102	Training Loss 0.6012 	Training Prec@1 79.090 	Training Prec@5 98.832 	Validation Loss 0.9329 	Validation Prec@1 70.370 	Validation Prec@5 97.630 

lr: 0.09782196033280005
TRAINING - Epoch: [102][0/196]	Time 0.267 (0.267)	Data 0.077 (0.077)	Loss 0.6051 (0.6051)	Prec@1 78.516 (78.516)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [102][100/196]	Time 0.038 (0.032)	Data 0.000 (0.001)	Loss 0.5020 (0.6029)	Prec@1 81.641 (78.999)	Prec@5 99.609 (98.878)
EVALUATING - Epoch: [102][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 0.6322 (0.6322)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:09:23

 Epoch: 103	Training Loss 0.6048 	Training Prec@1 79.118 	Training Prec@5 98.848 	Validation Loss 0.8412 	Validation Prec@1 71.750 	Validation Prec@5 97.810 

lr: 0.09777564244335755
TRAINING - Epoch: [103][0/196]	Time 0.278 (0.278)	Data 0.075 (0.075)	Loss 0.5972 (0.5972)	Prec@1 77.344 (77.344)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [103][100/196]	Time 0.027 (0.032)	Data 0.000 (0.001)	Loss 0.5736 (0.6141)	Prec@1 81.641 (78.879)	Prec@5 99.219 (98.762)
EVALUATING - Epoch: [103][0/79]	Time 0.067 (0.067)	Data 0.047 (0.047)	Loss 0.8575 (0.8575)	Prec@1 70.312 (70.312)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:08

 Epoch: 104	Training Loss 0.6089 	Training Prec@1 78.980 	Training Prec@5 98.770 	Validation Loss 0.9297 	Validation Prec@1 70.130 	Validation Prec@5 97.140 

lr: 0.09772884925120995
TRAINING - Epoch: [104][0/196]	Time 0.272 (0.272)	Data 0.088 (0.088)	Loss 0.5788 (0.5788)	Prec@1 79.688 (79.688)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [104][100/196]	Time 0.027 (0.031)	Data 0.000 (0.001)	Loss 0.6022 (0.5951)	Prec@1 78.125 (79.266)	Prec@5 99.219 (98.820)
EVALUATING - Epoch: [104][0/79]	Time 0.071 (0.071)	Data 0.050 (0.050)	Loss 0.8875 (0.8875)	Prec@1 72.656 (72.656)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:03:10

 Epoch: 105	Training Loss 0.6006 	Training Prec@1 79.184 	Training Prec@5 98.796 	Validation Loss 0.9167 	Validation Prec@1 70.740 	Validation Prec@5 98.080 

lr: 0.09768158122190404
TRAINING - Epoch: [105][0/196]	Time 0.267 (0.267)	Data 0.077 (0.077)	Loss 0.6655 (0.6655)	Prec@1 76.953 (76.953)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [105][100/196]	Time 0.035 (0.032)	Data 0.000 (0.001)	Loss 0.5583 (0.5914)	Prec@1 80.859 (79.343)	Prec@5 98.828 (98.828)
EVALUATING - Epoch: [105][0/79]	Time 0.067 (0.067)	Data 0.045 (0.045)	Loss 0.7113 (0.7113)	Prec@1 71.875 (71.875)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:07:01

 Epoch: 106	Training Loss 0.6006 	Training Prec@1 79.122 	Training Prec@5 98.840 	Validation Loss 0.6647 	Validation Prec@1 76.680 	Validation Prec@5 98.640 

lr: 0.09763383882571085
TRAINING - Epoch: [106][0/196]	Time 0.288 (0.288)	Data 0.088 (0.088)	Loss 0.5383 (0.5383)	Prec@1 81.641 (81.641)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [106][100/196]	Time 0.026 (0.032)	Data 0.000 (0.001)	Loss 0.7211 (0.5946)	Prec@1 76.172 (79.200)	Prec@5 98.828 (98.925)
EVALUATING - Epoch: [106][0/79]	Time 0.072 (0.072)	Data 0.054 (0.054)	Loss 0.9370 (0.9370)	Prec@1 69.531 (69.531)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:05:50

 Epoch: 107	Training Loss 0.6004 	Training Prec@1 79.082 	Training Prec@5 98.910 	Validation Loss 0.9189 	Validation Prec@1 70.280 	Validation Prec@5 98.080 

lr: 0.09758562253762088
TRAINING - Epoch: [107][0/196]	Time 0.276 (0.276)	Data 0.087 (0.087)	Loss 0.5835 (0.5835)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [107][100/196]	Time 0.035 (0.031)	Data 0.000 (0.001)	Loss 0.4646 (0.5954)	Prec@1 82.812 (79.432)	Prec@5 99.609 (98.875)
EVALUATING - Epoch: [107][0/79]	Time 0.070 (0.070)	Data 0.054 (0.054)	Loss 0.6875 (0.6875)	Prec@1 74.219 (74.219)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:07:26

 Epoch: 108	Training Loss 0.5989 	Training Prec@1 79.198 	Training Prec@5 98.850 	Validation Loss 0.8104 	Validation Prec@1 72.810 	Validation Prec@5 98.170 

lr: 0.09753693283733939
TRAINING - Epoch: [108][0/196]	Time 0.266 (0.266)	Data 0.076 (0.076)	Loss 0.5512 (0.5512)	Prec@1 82.031 (82.031)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [108][100/196]	Time 0.046 (0.033)	Data 0.000 (0.001)	Loss 0.6968 (0.5918)	Prec@1 76.562 (79.320)	Prec@5 98.438 (98.890)
EVALUATING - Epoch: [108][0/79]	Time 0.062 (0.062)	Data 0.045 (0.045)	Loss 0.8251 (0.8251)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:41

 Epoch: 109	Training Loss 0.5994 	Training Prec@1 79.108 	Training Prec@5 98.872 	Validation Loss 0.8300 	Validation Prec@1 73.030 	Validation Prec@5 97.870 

lr: 0.09748777020928161
TRAINING - Epoch: [109][0/196]	Time 0.288 (0.288)	Data 0.077 (0.077)	Loss 0.6162 (0.6162)	Prec@1 76.562 (76.562)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [109][100/196]	Time 0.029 (0.033)	Data 0.000 (0.001)	Loss 0.8022 (0.5977)	Prec@1 75.000 (79.281)	Prec@5 96.484 (98.863)
EVALUATING - Epoch: [109][0/79]	Time 0.071 (0.071)	Data 0.055 (0.055)	Loss 0.7852 (0.7852)	Prec@1 74.219 (74.219)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:10:03

 Epoch: 110	Training Loss 0.5950 	Training Prec@1 79.412 	Training Prec@5 98.810 	Validation Loss 0.9076 	Validation Prec@1 70.750 	Validation Prec@5 97.720 

lr: 0.097438135142568
TRAINING - Epoch: [110][0/196]	Time 0.289 (0.289)	Data 0.099 (0.099)	Loss 0.5047 (0.5047)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [110][100/196]	Time 0.027 (0.032)	Data 0.000 (0.001)	Loss 0.4884 (0.5879)	Prec@1 83.203 (79.374)	Prec@5 99.219 (98.967)
EVALUATING - Epoch: [110][0/79]	Time 0.066 (0.066)	Data 0.047 (0.047)	Loss 1.4578 (1.4578)	Prec@1 60.938 (60.938)	Prec@5 92.188 (92.188)
Time cost: 00:06	Time of Finish: 2024-03-31 17:06:12

 Epoch: 111	Training Loss 0.5904 	Training Prec@1 79.422 	Training Prec@5 98.924 	Validation Loss 1.5164 	Validation Prec@1 59.670 	Validation Prec@5 92.790 

lr: 0.09738802813101927
TRAINING - Epoch: [111][0/196]	Time 0.273 (0.273)	Data 0.077 (0.077)	Loss 0.5907 (0.5907)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [111][100/196]	Time 0.028 (0.029)	Data 0.000 (0.001)	Loss 0.5866 (0.5988)	Prec@1 78.516 (79.138)	Prec@5 98.828 (98.871)
EVALUATING - Epoch: [111][0/79]	Time 0.065 (0.065)	Data 0.049 (0.049)	Loss 0.9503 (0.9503)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 16:59:08

 Epoch: 112	Training Loss 0.6007 	Training Prec@1 79.078 	Training Prec@5 98.840 	Validation Loss 0.8347 	Validation Prec@1 73.600 	Validation Prec@5 98.130 

lr: 0.09733744967315154
TRAINING - Epoch: [112][0/196]	Time 0.279 (0.279)	Data 0.077 (0.077)	Loss 0.6544 (0.6544)	Prec@1 76.562 (76.562)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [112][100/196]	Time 0.034 (0.030)	Data 0.000 (0.001)	Loss 0.5462 (0.5859)	Prec@1 78.125 (79.560)	Prec@5 100.000 (98.882)
EVALUATING - Epoch: [112][0/79]	Time 0.073 (0.073)	Data 0.054 (0.054)	Loss 0.7606 (0.7606)	Prec@1 74.219 (74.219)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:04:59

 Epoch: 113	Training Loss 0.5929 	Training Prec@1 79.342 	Training Prec@5 98.856 	Validation Loss 0.8836 	Validation Prec@1 70.350 	Validation Prec@5 98.010 

lr: 0.09728640027217138
TRAINING - Epoch: [113][0/196]	Time 0.272 (0.272)	Data 0.096 (0.096)	Loss 0.4875 (0.4875)	Prec@1 83.203 (83.203)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [113][100/196]	Time 0.035 (0.033)	Data 0.000 (0.001)	Loss 0.5482 (0.5888)	Prec@1 81.250 (79.448)	Prec@5 100.000 (98.979)
EVALUATING - Epoch: [113][0/79]	Time 0.068 (0.068)	Data 0.051 (0.051)	Loss 0.8292 (0.8292)	Prec@1 72.656 (72.656)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:06:43

 Epoch: 114	Training Loss 0.5918 	Training Prec@1 79.356 	Training Prec@5 98.926 	Validation Loss 0.9339 	Validation Prec@1 69.430 	Validation Prec@5 97.180 

lr: 0.0972348804359708
TRAINING - Epoch: [114][0/196]	Time 0.275 (0.275)	Data 0.083 (0.083)	Loss 0.6950 (0.6950)	Prec@1 74.609 (74.609)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [114][100/196]	Time 0.032 (0.032)	Data 0.000 (0.001)	Loss 0.5915 (0.6008)	Prec@1 76.562 (78.721)	Prec@5 99.609 (98.782)
EVALUATING - Epoch: [114][0/79]	Time 0.063 (0.063)	Data 0.045 (0.045)	Loss 0.6244 (0.6244)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:10:01

 Epoch: 115	Training Loss 0.5931 	Training Prec@1 79.278 	Training Prec@5 98.856 	Validation Loss 0.7782 	Validation Prec@1 73.840 	Validation Prec@5 97.910 

lr: 0.0971828906771221
TRAINING - Epoch: [115][0/196]	Time 0.287 (0.287)	Data 0.082 (0.082)	Loss 0.5366 (0.5366)	Prec@1 80.078 (80.078)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [115][100/196]	Time 0.027 (0.033)	Data 0.000 (0.001)	Loss 0.6123 (0.5932)	Prec@1 77.344 (79.463)	Prec@5 98.828 (98.844)
EVALUATING - Epoch: [115][0/79]	Time 0.069 (0.069)	Data 0.053 (0.053)	Loss 0.7318 (0.7318)	Prec@1 74.219 (74.219)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:04:43

 Epoch: 116	Training Loss 0.5929 	Training Prec@1 79.478 	Training Prec@5 98.892 	Validation Loss 1.0191 	Validation Prec@1 67.090 	Validation Prec@5 97.280 

lr: 0.09713043151287297
TRAINING - Epoch: [116][0/196]	Time 0.267 (0.267)	Data 0.075 (0.075)	Loss 0.5118 (0.5118)	Prec@1 79.297 (79.297)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [116][100/196]	Time 0.026 (0.032)	Data 0.000 (0.001)	Loss 0.6365 (0.5926)	Prec@1 77.344 (79.455)	Prec@5 99.219 (98.913)
EVALUATING - Epoch: [116][0/79]	Time 0.064 (0.064)	Data 0.045 (0.045)	Loss 0.7135 (0.7135)	Prec@1 75.781 (75.781)	Prec@5 96.875 (96.875)
Time cost: 00:06	Time of Finish: 2024-03-31 17:02:39

 Epoch: 117	Training Loss 0.5931 	Training Prec@1 79.446 	Training Prec@5 98.920 	Validation Loss 0.7435 	Validation Prec@1 75.040 	Validation Prec@5 98.440 

lr: 0.09707750346514113
TRAINING - Epoch: [117][0/196]	Time 0.264 (0.264)	Data 0.078 (0.078)	Loss 0.4663 (0.4663)	Prec@1 83.984 (83.984)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [117][100/196]	Time 0.026 (0.032)	Data 0.000 (0.001)	Loss 0.5994 (0.5811)	Prec@1 78.125 (79.997)	Prec@5 98.438 (98.979)
EVALUATING - Epoch: [117][0/79]	Time 0.068 (0.068)	Data 0.050 (0.050)	Loss 0.8858 (0.8858)	Prec@1 71.875 (71.875)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:07:06

 Epoch: 118	Training Loss 0.5903 	Training Prec@1 79.600 	Training Prec@5 98.920 	Validation Loss 0.8764 	Validation Prec@1 71.170 	Validation Prec@5 97.790 

lr: 0.09702410706050928
TRAINING - Epoch: [118][0/196]	Time 0.278 (0.278)	Data 0.078 (0.078)	Loss 0.6562 (0.6562)	Prec@1 76.562 (76.562)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [118][100/196]	Time 0.035 (0.032)	Data 0.000 (0.001)	Loss 0.6506 (0.5885)	Prec@1 76.562 (79.618)	Prec@5 98.828 (98.905)
EVALUATING - Epoch: [118][0/79]	Time 0.065 (0.065)	Data 0.047 (0.047)	Loss 0.7275 (0.7275)	Prec@1 73.438 (73.438)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 17:06:38

 Epoch: 119	Training Loss 0.5891 	Training Prec@1 79.646 	Training Prec@5 98.896 	Validation Loss 0.7573 	Validation Prec@1 74.100 	Validation Prec@5 98.370 

lr: 0.09697024283021984
TRAINING - Epoch: [119][0/196]	Time 0.297 (0.297)	Data 0.080 (0.080)	Loss 0.7387 (0.7387)	Prec@1 71.484 (71.484)	Prec@5 97.266 (97.266)
TRAINING - Epoch: [119][100/196]	Time 0.035 (0.038)	Data 0.000 (0.001)	Loss 0.6381 (0.5951)	Prec@1 78.906 (79.216)	Prec@5 98.047 (98.789)
EVALUATING - Epoch: [119][0/79]	Time 0.077 (0.077)	Data 0.057 (0.057)	Loss 0.8502 (0.8502)	Prec@1 71.094 (71.094)	Prec@5 97.656 (97.656)
Time cost: 00:07	Time of Finish: 2024-03-31 17:27:01

 Epoch: 120	Training Loss 0.5947 	Training Prec@1 79.196 	Training Prec@5 98.854 	Validation Loss 0.7683 	Validation Prec@1 74.480 	Validation Prec@5 98.550 

lr: 0.09691591131016959
TRAINING - Epoch: [120][0/196]	Time 0.270 (0.270)	Data 0.083 (0.083)	Loss 0.6408 (0.6408)	Prec@1 79.297 (79.297)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [120][100/196]	Time 0.026 (0.034)	Data 0.000 (0.001)	Loss 0.5134 (0.5842)	Prec@1 80.859 (79.966)	Prec@5 99.219 (98.956)
EVALUATING - Epoch: [120][0/79]	Time 0.068 (0.068)	Data 0.052 (0.052)	Loss 0.6037 (0.6037)	Prec@1 73.438 (73.438)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 17:07:57

 Epoch: 121	Training Loss 0.5867 	Training Prec@1 79.688 	Training Prec@5 98.886 	Validation Loss 0.7717 	Validation Prec@1 73.990 	Validation Prec@5 98.160 

lr: 0.09686111304090442
TRAINING - Epoch: [121][0/196]	Time 0.283 (0.283)	Data 0.088 (0.088)	Loss 0.5580 (0.5580)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [121][100/196]	Time 0.028 (0.029)	Data 0.000 (0.001)	Loss 0.5424 (0.5969)	Prec@1 79.688 (79.235)	Prec@5 98.828 (98.886)
EVALUATING - Epoch: [121][0/79]	Time 0.072 (0.072)	Data 0.053 (0.053)	Loss 0.7355 (0.7355)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 16:58:58

 Epoch: 122	Training Loss 0.5898 	Training Prec@1 79.546 	Training Prec@5 98.926 	Validation Loss 0.8338 	Validation Prec@1 73.440 	Validation Prec@5 97.860 

lr: 0.0968058485676139
TRAINING - Epoch: [122][0/196]	Time 0.271 (0.271)	Data 0.077 (0.077)	Loss 0.5785 (0.5785)	Prec@1 80.859 (80.859)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [122][100/196]	Time 0.025 (0.035)	Data 0.000 (0.001)	Loss 0.6682 (0.5808)	Prec@1 78.516 (79.958)	Prec@5 98.438 (98.963)
EVALUATING - Epoch: [122][0/79]	Time 0.064 (0.064)	Data 0.046 (0.046)	Loss 0.8219 (0.8219)	Prec@1 69.531 (69.531)	Prec@5 97.656 (97.656)
Time cost: 00:07	Time of Finish: 2024-03-31 17:12:38

 Epoch: 123	Training Loss 0.5825 	Training Prec@1 79.862 	Training Prec@5 98.928 	Validation Loss 1.0059 	Validation Prec@1 66.870 	Validation Prec@5 97.260 

lr: 0.09675011844012593
TRAINING - Epoch: [123][0/196]	Time 0.294 (0.294)	Data 0.080 (0.080)	Loss 0.6130 (0.6130)	Prec@1 79.297 (79.297)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [123][100/196]	Time 0.025 (0.033)	Data 0.000 (0.001)	Loss 0.6301 (0.5896)	Prec@1 78.516 (79.374)	Prec@5 99.219 (98.878)
EVALUATING - Epoch: [123][0/79]	Time 0.072 (0.072)	Data 0.055 (0.055)	Loss 0.5765 (0.5765)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:09

 Epoch: 124	Training Loss 0.5850 	Training Prec@1 79.556 	Training Prec@5 98.962 	Validation Loss 0.7531 	Validation Prec@1 74.890 	Validation Prec@5 97.880 

lr: 0.09669392321290114
TRAINING - Epoch: [124][0/196]	Time 0.274 (0.274)	Data 0.078 (0.078)	Loss 0.5523 (0.5523)	Prec@1 79.688 (79.688)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [124][100/196]	Time 0.028 (0.034)	Data 0.000 (0.001)	Loss 0.6096 (0.5898)	Prec@1 78.516 (79.525)	Prec@5 99.219 (98.894)
EVALUATING - Epoch: [124][0/79]	Time 0.062 (0.062)	Data 0.045 (0.045)	Loss 0.7025 (0.7025)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:09:25

 Epoch: 125	Training Loss 0.5928 	Training Prec@1 79.264 	Training Prec@5 98.868 	Validation Loss 0.7467 	Validation Prec@1 74.290 	Validation Prec@5 98.430 

lr: 0.09663726344502752
TRAINING - Epoch: [125][0/196]	Time 0.274 (0.274)	Data 0.077 (0.077)	Loss 0.6499 (0.6499)	Prec@1 75.391 (75.391)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [125][100/196]	Time 0.045 (0.035)	Data 0.000 (0.001)	Loss 0.5233 (0.5692)	Prec@1 82.812 (80.310)	Prec@5 98.828 (98.933)
EVALUATING - Epoch: [125][0/79]	Time 0.068 (0.068)	Data 0.047 (0.047)	Loss 0.6056 (0.6056)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:07	Time of Finish: 2024-03-31 17:19:32

 Epoch: 126	Training Loss 0.5823 	Training Prec@1 79.846 	Training Prec@5 98.912 	Validation Loss 0.7458 	Validation Prec@1 75.170 	Validation Prec@5 98.450 

lr: 0.09658013970021473
TRAINING - Epoch: [126][0/196]	Time 0.295 (0.295)	Data 0.081 (0.081)	Loss 0.6150 (0.6150)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [126][100/196]	Time 0.027 (0.032)	Data 0.000 (0.001)	Loss 0.5457 (0.5862)	Prec@1 80.078 (79.629)	Prec@5 98.828 (98.817)
EVALUATING - Epoch: [126][0/79]	Time 0.069 (0.069)	Data 0.052 (0.052)	Loss 0.7273 (0.7273)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:09:17

 Epoch: 127	Training Loss 0.5874 	Training Prec@1 79.596 	Training Prec@5 98.898 	Validation Loss 0.9124 	Validation Prec@1 70.540 	Validation Prec@5 98.150 

lr: 0.0965225525467886
TRAINING - Epoch: [127][0/196]	Time 0.286 (0.286)	Data 0.091 (0.091)	Loss 0.6285 (0.6285)	Prec@1 76.172 (76.172)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [127][100/196]	Time 0.030 (0.034)	Data 0.000 (0.001)	Loss 0.6532 (0.5860)	Prec@1 76.172 (79.807)	Prec@5 99.609 (98.836)
EVALUATING - Epoch: [127][0/79]	Time 0.066 (0.066)	Data 0.047 (0.047)	Loss 0.8856 (0.8856)	Prec@1 71.094 (71.094)	Prec@5 96.875 (96.875)
Time cost: 00:07	Time of Finish: 2024-03-31 17:13:57

 Epoch: 128	Training Loss 0.5837 	Training Prec@1 79.802 	Training Prec@5 98.892 	Validation Loss 0.9840 	Validation Prec@1 68.190 	Validation Prec@5 96.860 

lr: 0.09646450255768539
TRAINING - Epoch: [128][0/196]	Time 0.274 (0.274)	Data 0.093 (0.093)	Loss 0.7054 (0.7054)	Prec@1 75.391 (75.391)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [128][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.6041 (0.5835)	Prec@1 82.031 (79.660)	Prec@5 98.047 (98.917)
EVALUATING - Epoch: [128][0/79]	Time 0.062 (0.062)	Data 0.045 (0.045)	Loss 0.9401 (0.9401)	Prec@1 71.094 (71.094)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:01:46

 Epoch: 129	Training Loss 0.5867 	Training Prec@1 79.556 	Training Prec@5 98.884 	Validation Loss 0.9002 	Validation Prec@1 70.600 	Validation Prec@5 98.310 

lr: 0.09640599031044615
TRAINING - Epoch: [129][0/196]	Time 0.271 (0.271)	Data 0.081 (0.081)	Loss 0.5609 (0.5609)	Prec@1 81.641 (81.641)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [129][100/196]	Time 0.032 (0.031)	Data 0.000 (0.001)	Loss 0.7149 (0.5740)	Prec@1 75.781 (80.097)	Prec@5 97.266 (98.971)
EVALUATING - Epoch: [129][0/79]	Time 0.068 (0.068)	Data 0.049 (0.049)	Loss 0.8229 (0.8229)	Prec@1 71.875 (71.875)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:04:50

 Epoch: 130	Training Loss 0.5766 	Training Prec@1 80.164 	Training Prec@5 98.912 	Validation Loss 0.8142 	Validation Prec@1 72.720 	Validation Prec@5 98.200 

lr: 0.09634701638721094
TRAINING - Epoch: [130][0/196]	Time 0.275 (0.275)	Data 0.097 (0.097)	Loss 0.5133 (0.5133)	Prec@1 82.031 (82.031)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [130][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.5487 (0.5869)	Prec@1 80.469 (79.629)	Prec@5 98.047 (98.859)
EVALUATING - Epoch: [130][0/79]	Time 0.063 (0.063)	Data 0.046 (0.046)	Loss 0.9552 (0.9552)	Prec@1 71.094 (71.094)	Prec@5 96.094 (96.094)
Time cost: 00:06	Time of Finish: 2024-03-31 17:04:17

 Epoch: 131	Training Loss 0.5847 	Training Prec@1 79.834 	Training Prec@5 98.866 	Validation Loss 1.0182 	Validation Prec@1 68.080 	Validation Prec@5 97.600 

lr: 0.09628758137471305
TRAINING - Epoch: [131][0/196]	Time 0.285 (0.285)	Data 0.079 (0.079)	Loss 0.6450 (0.6450)	Prec@1 78.516 (78.516)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [131][100/196]	Time 0.040 (0.036)	Data 0.000 (0.001)	Loss 0.5224 (0.5823)	Prec@1 81.250 (79.981)	Prec@5 98.828 (98.909)
EVALUATING - Epoch: [131][0/79]	Time 0.078 (0.078)	Data 0.056 (0.056)	Loss 0.7246 (0.7246)	Prec@1 74.219 (74.219)	Prec@5 98.438 (98.438)
Time cost: 00:07	Time of Finish: 2024-03-31 17:23:58

 Epoch: 132	Training Loss 0.5806 	Training Prec@1 79.916 	Training Prec@5 98.990 	Validation Loss 0.8213 	Validation Prec@1 71.700 	Validation Prec@5 98.160 

lr: 0.09622768586427315
TRAINING - Epoch: [132][0/196]	Time 0.272 (0.272)	Data 0.086 (0.086)	Loss 0.7036 (0.7036)	Prec@1 75.781 (75.781)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [132][100/196]	Time 0.029 (0.031)	Data 0.000 (0.001)	Loss 0.5094 (0.5839)	Prec@1 82.422 (79.622)	Prec@5 98.828 (98.929)
EVALUATING - Epoch: [132][0/79]	Time 0.070 (0.070)	Data 0.053 (0.053)	Loss 1.0497 (1.0497)	Prec@1 65.625 (65.625)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:04:47

 Epoch: 133	Training Loss 0.5812 	Training Prec@1 79.730 	Training Prec@5 98.906 	Validation Loss 0.9602 	Validation Prec@1 69.480 	Validation Prec@5 97.020 

lr: 0.09616733045179343
TRAINING - Epoch: [133][0/196]	Time 0.271 (0.271)	Data 0.085 (0.085)	Loss 0.5771 (0.5771)	Prec@1 80.859 (80.859)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [133][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.5973 (0.5870)	Prec@1 81.250 (79.672)	Prec@5 98.828 (98.921)
EVALUATING - Epoch: [133][0/79]	Time 0.068 (0.068)	Data 0.051 (0.051)	Loss 0.9291 (0.9291)	Prec@1 65.625 (65.625)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:03:21

 Epoch: 134	Training Loss 0.5872 	Training Prec@1 79.586 	Training Prec@5 98.912 	Validation Loss 0.8901 	Validation Prec@1 70.960 	Validation Prec@5 98.190 

lr: 0.09610651573775167
TRAINING - Epoch: [134][0/196]	Time 0.268 (0.268)	Data 0.084 (0.084)	Loss 0.5888 (0.5888)	Prec@1 77.734 (77.734)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [134][100/196]	Time 0.036 (0.032)	Data 0.000 (0.001)	Loss 0.7484 (0.5851)	Prec@1 74.219 (79.757)	Prec@5 96.484 (98.844)
EVALUATING - Epoch: [134][0/79]	Time 0.064 (0.064)	Data 0.046 (0.046)	Loss 1.0496 (1.0496)	Prec@1 68.750 (68.750)	Prec@5 94.531 (94.531)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:41

 Epoch: 135	Training Loss 0.5791 	Training Prec@1 80.058 	Training Prec@5 98.930 	Validation Loss 1.1297 	Validation Prec@1 65.920 	Validation Prec@5 96.400 

lr: 0.09604524232719523
TRAINING - Epoch: [135][0/196]	Time 0.278 (0.278)	Data 0.080 (0.080)	Loss 0.5425 (0.5425)	Prec@1 80.078 (80.078)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [135][100/196]	Time 0.032 (0.033)	Data 0.000 (0.001)	Loss 0.5267 (0.5665)	Prec@1 84.375 (80.094)	Prec@5 98.828 (99.010)
EVALUATING - Epoch: [135][0/79]	Time 0.061 (0.061)	Data 0.049 (0.049)	Loss 1.0281 (1.0281)	Prec@1 66.406 (66.406)	Prec@5 97.656 (97.656)
Time cost: 00:07	Time of Finish: 2024-03-31 17:17:10

 Epoch: 136	Training Loss 0.5753 	Training Prec@1 79.900 	Training Prec@5 98.998 	Validation Loss 1.1482 	Validation Prec@1 65.760 	Validation Prec@5 95.750 

lr: 0.09598351082973507
TRAINING - Epoch: [136][0/196]	Time 0.271 (0.271)	Data 0.081 (0.081)	Loss 0.5960 (0.5960)	Prec@1 77.734 (77.734)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [136][100/196]	Time 0.027 (0.032)	Data 0.000 (0.001)	Loss 0.5969 (0.5770)	Prec@1 82.031 (79.885)	Prec@5 98.438 (98.991)
EVALUATING - Epoch: [136][0/79]	Time 0.079 (0.079)	Data 0.062 (0.062)	Loss 0.8277 (0.8277)	Prec@1 70.312 (70.312)	Prec@5 96.875 (96.875)
Time cost: 00:06	Time of Finish: 2024-03-31 17:06:47

 Epoch: 137	Training Loss 0.5783 	Training Prec@1 79.794 	Training Prec@5 99.008 	Validation Loss 0.8189 	Validation Prec@1 71.790 	Validation Prec@5 98.170 

lr: 0.09592132185953965
TRAINING - Epoch: [137][0/196]	Time 0.287 (0.287)	Data 0.086 (0.086)	Loss 0.5082 (0.5082)	Prec@1 83.984 (83.984)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [137][100/196]	Time 0.027 (0.034)	Data 0.000 (0.001)	Loss 0.6210 (0.5737)	Prec@1 81.250 (80.155)	Prec@5 97.656 (98.929)
EVALUATING - Epoch: [137][0/79]	Time 0.068 (0.068)	Data 0.048 (0.048)	Loss 0.8007 (0.8007)	Prec@1 74.219 (74.219)	Prec@5 97.656 (97.656)
Time cost: 00:07	Time of Finish: 2024-03-31 17:13:06

 Epoch: 138	Training Loss 0.5838 	Training Prec@1 79.774 	Training Prec@5 98.952 	Validation Loss 0.7843 	Validation Prec@1 72.850 	Validation Prec@5 98.130 

lr: 0.09585867603532887
TRAINING - Epoch: [138][0/196]	Time 0.277 (0.277)	Data 0.076 (0.076)	Loss 0.5723 (0.5723)	Prec@1 78.906 (78.906)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [138][100/196]	Time 0.029 (0.032)	Data 0.000 (0.001)	Loss 0.5767 (0.5622)	Prec@1 79.688 (80.326)	Prec@5 99.609 (99.037)
EVALUATING - Epoch: [138][0/79]	Time 0.068 (0.068)	Data 0.046 (0.046)	Loss 0.6117 (0.6117)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:07:24

 Epoch: 139	Training Loss 0.5744 	Training Prec@1 79.916 	Training Prec@5 98.906 	Validation Loss 0.6874 	Validation Prec@1 76.450 	Validation Prec@5 98.780 

lr: 0.09579557398036785
TRAINING - Epoch: [139][0/196]	Time 0.272 (0.272)	Data 0.080 (0.080)	Loss 0.5018 (0.5018)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [139][100/196]	Time 0.043 (0.032)	Data 0.000 (0.001)	Loss 0.5934 (0.5723)	Prec@1 81.641 (80.175)	Prec@5 99.609 (99.025)
EVALUATING - Epoch: [139][0/79]	Time 0.074 (0.074)	Data 0.059 (0.059)	Loss 0.8414 (0.8414)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:08:17

 Epoch: 140	Training Loss 0.5788 	Training Prec@1 79.922 	Training Prec@5 98.970 	Validation Loss 0.8411 	Validation Prec@1 71.750 	Validation Prec@5 98.340 

lr: 0.09573201632246081
TRAINING - Epoch: [140][0/196]	Time 0.267 (0.267)	Data 0.076 (0.076)	Loss 0.6263 (0.6263)	Prec@1 78.516 (78.516)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [140][100/196]	Time 0.028 (0.032)	Data 0.000 (0.001)	Loss 0.5540 (0.5850)	Prec@1 81.641 (79.804)	Prec@5 98.828 (98.867)
EVALUATING - Epoch: [140][0/79]	Time 0.069 (0.069)	Data 0.051 (0.051)	Loss 0.7538 (0.7538)	Prec@1 72.656 (72.656)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:06:28

 Epoch: 141	Training Loss 0.5844 	Training Prec@1 79.856 	Training Prec@5 98.930 	Validation Loss 0.8594 	Validation Prec@1 71.790 	Validation Prec@5 98.120 

lr: 0.09566800369394471
TRAINING - Epoch: [141][0/196]	Time 0.271 (0.271)	Data 0.079 (0.079)	Loss 0.6424 (0.6424)	Prec@1 77.734 (77.734)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [141][100/196]	Time 0.027 (0.029)	Data 0.000 (0.001)	Loss 0.5852 (0.5647)	Prec@1 82.031 (80.434)	Prec@5 98.047 (99.076)
EVALUATING - Epoch: [141][0/79]	Time 0.073 (0.073)	Data 0.056 (0.056)	Loss 0.7013 (0.7013)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:01:51

 Epoch: 142	Training Loss 0.5710 	Training Prec@1 80.164 	Training Prec@5 98.974 	Validation Loss 0.7711 	Validation Prec@1 74.320 	Validation Prec@5 98.290 

lr: 0.09560353673168309
TRAINING - Epoch: [142][0/196]	Time 0.275 (0.275)	Data 0.085 (0.085)	Loss 0.5195 (0.5195)	Prec@1 83.203 (83.203)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [142][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.5047 (0.5847)	Prec@1 85.156 (79.560)	Prec@5 98.828 (98.917)
EVALUATING - Epoch: [142][0/79]	Time 0.071 (0.071)	Data 0.055 (0.055)	Loss 1.1603 (1.1603)	Prec@1 67.969 (67.969)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:12:00

 Epoch: 143	Training Loss 0.5773 	Training Prec@1 79.860 	Training Prec@5 98.942 	Validation Loss 1.1141 	Validation Prec@1 65.690 	Validation Prec@5 98.040 

lr: 0.09553861607705967
TRAINING - Epoch: [143][0/196]	Time 0.288 (0.288)	Data 0.080 (0.080)	Loss 0.5466 (0.5466)	Prec@1 78.516 (78.516)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [143][100/196]	Time 0.034 (0.036)	Data 0.000 (0.001)	Loss 0.6053 (0.5732)	Prec@1 79.688 (79.916)	Prec@5 98.828 (99.002)
EVALUATING - Epoch: [143][0/79]	Time 0.071 (0.071)	Data 0.053 (0.053)	Loss 1.1655 (1.1655)	Prec@1 61.719 (61.719)	Prec@5 99.219 (99.219)
Time cost: 00:07	Time of Finish: 2024-03-31 17:16:57

 Epoch: 144	Training Loss 0.5742 	Training Prec@1 79.964 	Training Prec@5 99.010 	Validation Loss 1.2719 	Validation Prec@1 62.880 	Validation Prec@5 96.400 

lr: 0.09547324237597189
TRAINING - Epoch: [144][0/196]	Time 0.290 (0.290)	Data 0.104 (0.104)	Loss 0.6028 (0.6028)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [144][100/196]	Time 0.026 (0.029)	Data 0.000 (0.001)	Loss 0.5317 (0.5775)	Prec@1 82.422 (79.889)	Prec@5 99.219 (99.045)
EVALUATING - Epoch: [144][0/79]	Time 0.068 (0.068)	Data 0.049 (0.049)	Loss 0.6761 (0.6761)	Prec@1 75.000 (75.000)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:00:05

 Epoch: 145	Training Loss 0.5787 	Training Prec@1 79.840 	Training Prec@5 99.022 	Validation Loss 0.7161 	Validation Prec@1 76.460 	Validation Prec@5 98.240 

lr: 0.09540741627882464
TRAINING - Epoch: [145][0/196]	Time 0.281 (0.281)	Data 0.080 (0.080)	Loss 0.5493 (0.5493)	Prec@1 78.516 (78.516)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [145][100/196]	Time 0.027 (0.033)	Data 0.000 (0.001)	Loss 0.5468 (0.5642)	Prec@1 80.859 (80.322)	Prec@5 99.219 (98.967)
EVALUATING - Epoch: [145][0/79]	Time 0.065 (0.065)	Data 0.047 (0.047)	Loss 0.8369 (0.8369)	Prec@1 74.219 (74.219)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:09:44

 Epoch: 146	Training Loss 0.5727 	Training Prec@1 80.068 	Training Prec@5 98.908 	Validation Loss 0.9775 	Validation Prec@1 68.830 	Validation Prec@5 97.770 

lr: 0.09534113844052368
TRAINING - Epoch: [146][0/196]	Time 0.283 (0.283)	Data 0.081 (0.081)	Loss 0.5516 (0.5516)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [146][100/196]	Time 0.035 (0.032)	Data 0.000 (0.001)	Loss 0.6685 (0.5738)	Prec@1 76.953 (80.024)	Prec@5 99.219 (98.987)
EVALUATING - Epoch: [146][0/79]	Time 0.073 (0.073)	Data 0.058 (0.058)	Loss 0.7267 (0.7267)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:05:53

 Epoch: 147	Training Loss 0.5751 	Training Prec@1 79.958 	Training Prec@5 98.956 	Validation Loss 0.8045 	Validation Prec@1 73.340 	Validation Prec@5 98.470 

lr: 0.09527440952046919
TRAINING - Epoch: [147][0/196]	Time 0.289 (0.289)	Data 0.081 (0.081)	Loss 0.4872 (0.4872)	Prec@1 83.594 (83.594)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [147][100/196]	Time 0.028 (0.030)	Data 0.000 (0.001)	Loss 0.6308 (0.5720)	Prec@1 76.953 (80.012)	Prec@5 99.219 (98.987)
EVALUATING - Epoch: [147][0/79]	Time 0.063 (0.063)	Data 0.046 (0.046)	Loss 0.8538 (0.8538)	Prec@1 71.875 (71.875)	Prec@5 96.094 (96.094)
Time cost: 00:06	Time of Finish: 2024-03-31 17:02:58

 Epoch: 148	Training Loss 0.5739 	Training Prec@1 80.064 	Training Prec@5 99.026 	Validation Loss 0.9666 	Validation Prec@1 69.660 	Validation Prec@5 97.810 

lr: 0.09520723018254912
TRAINING - Epoch: [148][0/196]	Time 0.291 (0.291)	Data 0.079 (0.079)	Loss 0.5803 (0.5803)	Prec@1 79.297 (79.297)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [148][100/196]	Time 0.035 (0.031)	Data 0.000 (0.001)	Loss 0.5349 (0.5650)	Prec@1 82.812 (80.430)	Prec@5 98.828 (99.056)
EVALUATING - Epoch: [148][0/79]	Time 0.073 (0.073)	Data 0.055 (0.055)	Loss 0.9113 (0.9113)	Prec@1 68.750 (68.750)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:06:23

 Epoch: 149	Training Loss 0.5745 	Training Prec@1 80.172 	Training Prec@5 99.022 	Validation Loss 1.0884 	Validation Prec@1 67.970 	Validation Prec@5 97.270 

lr: 0.09513960109513266
TRAINING - Epoch: [149][0/196]	Time 0.278 (0.278)	Data 0.082 (0.082)	Loss 0.5804 (0.5804)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [149][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.5102 (0.5754)	Prec@1 81.641 (79.947)	Prec@5 99.609 (98.987)
EVALUATING - Epoch: [149][0/79]	Time 0.069 (0.069)	Data 0.053 (0.053)	Loss 0.8249 (0.8249)	Prec@1 71.094 (71.094)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:05:32

 Epoch: 150	Training Loss 0.5791 	Training Prec@1 79.982 	Training Prec@5 98.934 	Validation Loss 0.9695 	Validation Prec@1 69.090 	Validation Prec@5 97.660 

lr: 0.0950715229310636
TRAINING - Epoch: [150][0/196]	Time 0.274 (0.274)	Data 0.079 (0.079)	Loss 0.5792 (0.5792)	Prec@1 80.469 (80.469)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [150][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.5971 (0.5657)	Prec@1 78.516 (80.418)	Prec@5 98.828 (98.979)
EVALUATING - Epoch: [150][0/79]	Time 0.073 (0.073)	Data 0.059 (0.059)	Loss 0.8893 (0.8893)	Prec@1 67.188 (67.188)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:07:52

 Epoch: 151	Training Loss 0.5718 	Training Prec@1 79.996 	Training Prec@5 99.012 	Validation Loss 0.8563 	Validation Prec@1 70.160 	Validation Prec@5 98.200 

lr: 0.09500299636765361
TRAINING - Epoch: [151][0/196]	Time 0.277 (0.277)	Data 0.093 (0.093)	Loss 0.4743 (0.4743)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [151][100/196]	Time 0.037 (0.032)	Data 0.000 (0.001)	Loss 0.4602 (0.5762)	Prec@1 83.203 (79.985)	Prec@5 100.000 (98.967)
EVALUATING - Epoch: [151][0/79]	Time 0.070 (0.070)	Data 0.052 (0.052)	Loss 0.8350 (0.8350)	Prec@1 69.531 (69.531)	Prec@5 99.219 (99.219)
Time cost: 00:07	Time of Finish: 2024-03-31 17:17:34

 Epoch: 152	Training Loss 0.5732 	Training Prec@1 80.198 	Training Prec@5 98.964 	Validation Loss 0.9333 	Validation Prec@1 70.340 	Validation Prec@5 96.620 

lr: 0.09493402208667542
TRAINING - Epoch: [152][0/196]	Time 0.277 (0.277)	Data 0.086 (0.086)	Loss 0.5440 (0.5440)	Prec@1 79.688 (79.688)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [152][100/196]	Time 0.027 (0.031)	Data 0.000 (0.001)	Loss 0.5722 (0.5740)	Prec@1 79.297 (80.043)	Prec@5 99.219 (98.975)
EVALUATING - Epoch: [152][0/79]	Time 0.074 (0.074)	Data 0.057 (0.057)	Loss 0.9902 (0.9902)	Prec@1 66.406 (66.406)	Prec@5 98.438 (98.438)
Time cost: 00:07	Time of Finish: 2024-03-31 17:12:58

 Epoch: 153	Training Loss 0.5702 	Training Prec@1 80.120 	Training Prec@5 98.982 	Validation Loss 0.9689 	Validation Prec@1 69.240 	Validation Prec@5 97.090 

lr: 0.09486460077435621
TRAINING - Epoch: [153][0/196]	Time 0.279 (0.279)	Data 0.077 (0.077)	Loss 0.7334 (0.7334)	Prec@1 76.172 (76.172)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [153][100/196]	Time 0.036 (0.031)	Data 0.000 (0.001)	Loss 0.6524 (0.5645)	Prec@1 76.953 (80.449)	Prec@5 98.438 (98.967)
EVALUATING - Epoch: [153][0/79]	Time 0.071 (0.071)	Data 0.056 (0.056)	Loss 0.6435 (0.6435)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:04:38

 Epoch: 154	Training Loss 0.5672 	Training Prec@1 80.264 	Training Prec@5 98.940 	Validation Loss 0.7124 	Validation Prec@1 75.820 	Validation Prec@5 98.560 

lr: 0.09479473312137064
TRAINING - Epoch: [154][0/196]	Time 0.277 (0.277)	Data 0.089 (0.089)	Loss 0.6572 (0.6572)	Prec@1 77.734 (77.734)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [154][100/196]	Time 0.035 (0.030)	Data 0.000 (0.001)	Loss 0.7196 (0.5693)	Prec@1 77.734 (80.275)	Prec@5 98.438 (99.002)
EVALUATING - Epoch: [154][0/79]	Time 0.066 (0.066)	Data 0.047 (0.047)	Loss 0.7374 (0.7374)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:07	Time of Finish: 2024-03-31 17:14:10

 Epoch: 155	Training Loss 0.5651 	Training Prec@1 80.442 	Training Prec@5 99.036 	Validation Loss 0.8501 	Validation Prec@1 71.590 	Validation Prec@5 98.320 

lr: 0.09472441982283403
TRAINING - Epoch: [155][0/196]	Time 0.277 (0.277)	Data 0.081 (0.081)	Loss 0.5048 (0.5048)	Prec@1 83.203 (83.203)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [155][100/196]	Time 0.027 (0.034)	Data 0.000 (0.001)	Loss 0.4830 (0.5722)	Prec@1 81.641 (80.272)	Prec@5 99.219 (98.983)
EVALUATING - Epoch: [155][0/79]	Time 0.075 (0.075)	Data 0.053 (0.053)	Loss 0.7933 (0.7933)	Prec@1 75.000 (75.000)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:07:58

 Epoch: 156	Training Loss 0.5631 	Training Prec@1 80.462 	Training Prec@5 99.042 	Validation Loss 0.9193 	Validation Prec@1 70.300 	Validation Prec@5 97.470 

lr: 0.09465366157829545
TRAINING - Epoch: [156][0/196]	Time 0.273 (0.273)	Data 0.080 (0.080)	Loss 0.5925 (0.5925)	Prec@1 82.812 (82.812)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [156][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.5459 (0.5612)	Prec@1 80.469 (80.330)	Prec@5 100.000 (98.929)
EVALUATING - Epoch: [156][0/79]	Time 0.070 (0.070)	Data 0.052 (0.052)	Loss 0.7795 (0.7795)	Prec@1 71.875 (71.875)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:01:27

 Epoch: 157	Training Loss 0.5683 	Training Prec@1 80.248 	Training Prec@5 98.902 	Validation Loss 0.8934 	Validation Prec@1 71.400 	Validation Prec@5 97.450 

lr: 0.09458245909173074
TRAINING - Epoch: [157][0/196]	Time 0.278 (0.278)	Data 0.085 (0.085)	Loss 0.6754 (0.6754)	Prec@1 76.953 (76.953)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [157][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.5892 (0.5606)	Prec@1 80.859 (80.465)	Prec@5 98.828 (98.979)
EVALUATING - Epoch: [157][0/79]	Time 0.071 (0.071)	Data 0.056 (0.056)	Loss 0.7781 (0.7781)	Prec@1 71.875 (71.875)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:01:29

 Epoch: 158	Training Loss 0.5647 	Training Prec@1 80.226 	Training Prec@5 98.974 	Validation Loss 0.8220 	Validation Prec@1 72.170 	Validation Prec@5 98.170 

lr: 0.09451081307153554
TRAINING - Epoch: [158][0/196]	Time 0.285 (0.285)	Data 0.087 (0.087)	Loss 0.5947 (0.5947)	Prec@1 78.125 (78.125)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [158][100/196]	Time 0.030 (0.030)	Data 0.000 (0.001)	Loss 0.5542 (0.5684)	Prec@1 82.422 (80.279)	Prec@5 98.438 (98.890)
EVALUATING - Epoch: [158][0/79]	Time 0.073 (0.073)	Data 0.057 (0.057)	Loss 1.1119 (1.1119)	Prec@1 62.500 (62.500)	Prec@5 96.094 (96.094)
Time cost: 00:06	Time of Finish: 2024-03-31 17:05:07

 Epoch: 159	Training Loss 0.5702 	Training Prec@1 80.280 	Training Prec@5 98.932 	Validation Loss 1.3080 	Validation Prec@1 62.560 	Validation Prec@5 94.900 

lr: 0.09443872423051818
TRAINING - Epoch: [159][0/196]	Time 0.314 (0.314)	Data 0.087 (0.087)	Loss 0.6164 (0.6164)	Prec@1 78.516 (78.516)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [159][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.5976 (0.5656)	Prec@1 80.469 (80.484)	Prec@5 98.438 (98.917)
EVALUATING - Epoch: [159][0/79]	Time 0.068 (0.068)	Data 0.052 (0.052)	Loss 1.1775 (1.1775)	Prec@1 64.062 (64.062)	Prec@5 96.094 (96.094)
Time cost: 00:06	Time of Finish: 2024-03-31 17:06:24

 Epoch: 160	Training Loss 0.5725 	Training Prec@1 80.132 	Training Prec@5 98.954 	Validation Loss 1.1502 	Validation Prec@1 67.050 	Validation Prec@5 96.820 

lr: 0.09436619328589264
TRAINING - Epoch: [160][0/196]	Time 0.302 (0.302)	Data 0.081 (0.081)	Loss 0.5322 (0.5322)	Prec@1 83.203 (83.203)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [160][100/196]	Time 0.038 (0.039)	Data 0.000 (0.001)	Loss 0.5846 (0.5628)	Prec@1 81.641 (80.581)	Prec@5 99.219 (99.087)
EVALUATING - Epoch: [160][0/79]	Time 0.070 (0.070)	Data 0.055 (0.055)	Loss 0.7994 (0.7994)	Prec@1 71.875 (71.875)	Prec@5 96.875 (96.875)
Time cost: 00:07	Time of Finish: 2024-03-31 17:24:18

 Epoch: 161	Training Loss 0.5688 	Training Prec@1 80.320 	Training Prec@5 99.030 	Validation Loss 0.8515 	Validation Prec@1 72.920 	Validation Prec@5 97.830 

lr: 0.09429322095927145
TRAINING - Epoch: [161][0/196]	Time 0.283 (0.283)	Data 0.096 (0.096)	Loss 0.5323 (0.5323)	Prec@1 79.297 (79.297)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [161][100/196]	Time 0.027 (0.032)	Data 0.000 (0.001)	Loss 0.5072 (0.5625)	Prec@1 81.250 (80.210)	Prec@5 98.828 (98.971)
EVALUATING - Epoch: [161][0/79]	Time 0.066 (0.066)	Data 0.049 (0.049)	Loss 0.8899 (0.8899)	Prec@1 69.531 (69.531)	Prec@5 96.094 (96.094)
Time cost: 00:06	Time of Finish: 2024-03-31 17:04:08

 Epoch: 162	Training Loss 0.5628 	Training Prec@1 80.222 	Training Prec@5 98.940 	Validation Loss 0.8759 	Validation Prec@1 70.620 	Validation Prec@5 97.850 

lr: 0.09421980797665838
TRAINING - Epoch: [162][0/196]	Time 0.266 (0.266)	Data 0.078 (0.078)	Loss 0.5397 (0.5397)	Prec@1 79.688 (79.688)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [162][100/196]	Time 0.035 (0.030)	Data 0.000 (0.001)	Loss 0.6641 (0.5555)	Prec@1 77.734 (80.894)	Prec@5 99.219 (99.002)
EVALUATING - Epoch: [162][0/79]	Time 0.068 (0.068)	Data 0.047 (0.047)	Loss 0.7341 (0.7341)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:04:30

 Epoch: 163	Training Loss 0.5644 	Training Prec@1 80.548 	Training Prec@5 98.982 	Validation Loss 0.7189 	Validation Prec@1 76.080 	Validation Prec@5 98.510 

lr: 0.09414595506844138
TRAINING - Epoch: [163][0/196]	Time 0.353 (0.353)	Data 0.082 (0.082)	Loss 0.6465 (0.6465)	Prec@1 77.734 (77.734)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [163][100/196]	Time 0.026 (0.034)	Data 0.000 (0.001)	Loss 0.7139 (0.5637)	Prec@1 76.172 (80.268)	Prec@5 97.656 (98.975)
EVALUATING - Epoch: [163][0/79]	Time 0.069 (0.069)	Data 0.048 (0.048)	Loss 0.7642 (0.7642)	Prec@1 71.875 (71.875)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:09:36

 Epoch: 164	Training Loss 0.5642 	Training Prec@1 80.296 	Training Prec@5 99.026 	Validation Loss 0.8149 	Validation Prec@1 73.760 	Validation Prec@5 98.160 

lr: 0.09407166296938518
TRAINING - Epoch: [164][0/196]	Time 0.277 (0.277)	Data 0.077 (0.077)	Loss 0.4548 (0.4548)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [164][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.5127 (0.5675)	Prec@1 84.766 (80.330)	Prec@5 99.609 (98.979)
EVALUATING - Epoch: [164][0/79]	Time 0.075 (0.075)	Data 0.058 (0.058)	Loss 0.8541 (0.8541)	Prec@1 71.875 (71.875)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:04:29

 Epoch: 165	Training Loss 0.5730 	Training Prec@1 80.026 	Training Prec@5 98.972 	Validation Loss 0.9856 	Validation Prec@1 68.580 	Validation Prec@5 97.660 

lr: 0.09399693241862404
TRAINING - Epoch: [165][0/196]	Time 0.320 (0.320)	Data 0.081 (0.081)	Loss 0.5098 (0.5098)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [165][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.5594 (0.5608)	Prec@1 76.953 (80.484)	Prec@5 100.000 (98.998)
EVALUATING - Epoch: [165][0/79]	Time 0.074 (0.074)	Data 0.054 (0.054)	Loss 1.1644 (1.1644)	Prec@1 66.406 (66.406)	Prec@5 96.875 (96.875)
Time cost: 00:06	Time of Finish: 2024-03-31 17:04:16

 Epoch: 166	Training Loss 0.5621 	Training Prec@1 80.528 	Training Prec@5 99.024 	Validation Loss 1.0845 	Validation Prec@1 69.220 	Validation Prec@5 96.700 

lr: 0.09392176415965442
TRAINING - Epoch: [166][0/196]	Time 0.278 (0.278)	Data 0.089 (0.089)	Loss 0.4805 (0.4805)	Prec@1 81.250 (81.250)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [166][100/196]	Time 0.035 (0.034)	Data 0.000 (0.001)	Loss 0.5386 (0.5611)	Prec@1 82.031 (80.268)	Prec@5 98.047 (98.998)
EVALUATING - Epoch: [166][0/79]	Time 0.070 (0.070)	Data 0.054 (0.054)	Loss 1.1825 (1.1825)	Prec@1 63.281 (63.281)	Prec@5 94.531 (94.531)
Time cost: 00:07	Time of Finish: 2024-03-31 17:12:21

 Epoch: 167	Training Loss 0.5611 	Training Prec@1 80.294 	Training Prec@5 98.996 	Validation Loss 1.0668 	Validation Prec@1 68.230 	Validation Prec@5 95.960 

lr: 0.09384615894032748
TRAINING - Epoch: [167][0/196]	Time 0.273 (0.273)	Data 0.078 (0.078)	Loss 0.5139 (0.5139)	Prec@1 80.078 (80.078)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [167][100/196]	Time 0.028 (0.031)	Data 0.000 (0.001)	Loss 0.7108 (0.5538)	Prec@1 78.516 (80.794)	Prec@5 97.266 (99.037)
EVALUATING - Epoch: [167][0/79]	Time 0.072 (0.072)	Data 0.057 (0.057)	Loss 0.7584 (0.7584)	Prec@1 72.656 (72.656)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:04:41

 Epoch: 168	Training Loss 0.5630 	Training Prec@1 80.418 	Training Prec@5 98.990 	Validation Loss 0.9044 	Validation Prec@1 71.000 	Validation Prec@5 97.850 

lr: 0.09377011751284181
TRAINING - Epoch: [168][0/196]	Time 0.323 (0.323)	Data 0.078 (0.078)	Loss 0.5299 (0.5299)	Prec@1 83.984 (83.984)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [168][100/196]	Time 0.028 (0.030)	Data 0.000 (0.001)	Loss 0.5828 (0.5581)	Prec@1 80.859 (80.500)	Prec@5 99.609 (99.072)
EVALUATING - Epoch: [168][0/79]	Time 0.067 (0.067)	Data 0.049 (0.049)	Loss 0.8252 (0.8252)	Prec@1 71.875 (71.875)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:03:06

 Epoch: 169	Training Loss 0.5662 	Training Prec@1 80.284 	Training Prec@5 99.016 	Validation Loss 0.9284 	Validation Prec@1 70.940 	Validation Prec@5 97.310 

lr: 0.09369364063373578
TRAINING - Epoch: [169][0/196]	Time 0.275 (0.275)	Data 0.091 (0.091)	Loss 0.5743 (0.5743)	Prec@1 81.250 (81.250)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [169][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.4464 (0.5608)	Prec@1 85.156 (80.442)	Prec@5 100.000 (99.037)
EVALUATING - Epoch: [169][0/79]	Time 0.074 (0.074)	Data 0.055 (0.055)	Loss 0.8895 (0.8895)	Prec@1 71.875 (71.875)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:01:42

 Epoch: 170	Training Loss 0.5592 	Training Prec@1 80.472 	Training Prec@5 99.034 	Validation Loss 0.9747 	Validation Prec@1 71.330 	Validation Prec@5 97.070 

lr: 0.0936167290638801
TRAINING - Epoch: [170][0/196]	Time 0.291 (0.291)	Data 0.095 (0.095)	Loss 0.6864 (0.6864)	Prec@1 75.000 (75.000)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [170][100/196]	Time 0.036 (0.032)	Data 0.000 (0.001)	Loss 0.6060 (0.5526)	Prec@1 81.641 (80.627)	Prec@5 98.438 (99.056)
EVALUATING - Epoch: [170][0/79]	Time 0.069 (0.069)	Data 0.051 (0.051)	Loss 0.5254 (0.5254)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:11:27

 Epoch: 171	Training Loss 0.5616 	Training Prec@1 80.382 	Training Prec@5 99.014 	Validation Loss 0.6679 	Validation Prec@1 77.430 	Validation Prec@5 98.580 

lr: 0.09353938356847022
TRAINING - Epoch: [171][0/196]	Time 0.273 (0.273)	Data 0.076 (0.076)	Loss 0.6763 (0.6763)	Prec@1 76.953 (76.953)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [171][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.5928 (0.5593)	Prec@1 77.734 (80.794)	Prec@5 98.828 (99.080)
EVALUATING - Epoch: [171][0/79]	Time 0.073 (0.073)	Data 0.056 (0.056)	Loss 0.8183 (0.8183)	Prec@1 72.656 (72.656)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:07:15

 Epoch: 172	Training Loss 0.5606 	Training Prec@1 80.714 	Training Prec@5 99.090 	Validation Loss 0.8935 	Validation Prec@1 71.100 	Validation Prec@5 98.300 

lr: 0.09346160491701876
TRAINING - Epoch: [172][0/196]	Time 0.390 (0.390)	Data 0.078 (0.078)	Loss 0.5499 (0.5499)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [172][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.5327 (0.5553)	Prec@1 81.641 (80.689)	Prec@5 99.609 (99.010)
EVALUATING - Epoch: [172][0/79]	Time 0.068 (0.068)	Data 0.047 (0.047)	Loss 0.8027 (0.8027)	Prec@1 71.875 (71.875)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 17:01:15

 Epoch: 173	Training Loss 0.5562 	Training Prec@1 80.788 	Training Prec@5 98.980 	Validation Loss 0.8261 	Validation Prec@1 72.130 	Validation Prec@5 97.890 

lr: 0.09338339388334777
TRAINING - Epoch: [173][0/196]	Time 0.269 (0.269)	Data 0.079 (0.079)	Loss 0.5704 (0.5704)	Prec@1 80.859 (80.859)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [173][100/196]	Time 0.035 (0.030)	Data 0.000 (0.001)	Loss 0.5012 (0.5591)	Prec@1 81.250 (80.388)	Prec@5 99.609 (99.118)
EVALUATING - Epoch: [173][0/79]	Time 0.064 (0.064)	Data 0.047 (0.047)	Loss 0.8274 (0.8274)	Prec@1 70.312 (70.312)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:02:14

 Epoch: 174	Training Loss 0.5564 	Training Prec@1 80.578 	Training Prec@5 99.104 	Validation Loss 0.8250 	Validation Prec@1 72.970 	Validation Prec@5 98.000 

lr: 0.09330475124558113
TRAINING - Epoch: [174][0/196]	Time 0.278 (0.278)	Data 0.099 (0.099)	Loss 0.5311 (0.5311)	Prec@1 83.203 (83.203)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [174][100/196]	Time 0.029 (0.033)	Data 0.000 (0.001)	Loss 0.6142 (0.5574)	Prec@1 78.906 (80.716)	Prec@5 98.438 (98.971)
EVALUATING - Epoch: [174][0/79]	Time 0.065 (0.065)	Data 0.046 (0.046)	Loss 0.8045 (0.8045)	Prec@1 69.531 (69.531)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:07:10

 Epoch: 175	Training Loss 0.5605 	Training Prec@1 80.542 	Training Prec@5 99.012 	Validation Loss 0.7468 	Validation Prec@1 74.770 	Validation Prec@5 98.450 

lr: 0.09322567778613676
TRAINING - Epoch: [175][0/196]	Time 0.272 (0.272)	Data 0.098 (0.098)	Loss 0.5718 (0.5718)	Prec@1 80.469 (80.469)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [175][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.5786 (0.5577)	Prec@1 80.078 (80.500)	Prec@5 98.438 (98.936)
EVALUATING - Epoch: [175][0/79]	Time 0.070 (0.070)	Data 0.053 (0.053)	Loss 0.7440 (0.7440)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 17:01:13

 Epoch: 176	Training Loss 0.5537 	Training Prec@1 80.804 	Training Prec@5 99.024 	Validation Loss 0.7495 	Validation Prec@1 75.240 	Validation Prec@5 98.090 

lr: 0.09314617429171879
TRAINING - Epoch: [176][0/196]	Time 0.284 (0.284)	Data 0.078 (0.078)	Loss 0.5760 (0.5760)	Prec@1 76.953 (76.953)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [176][100/196]	Time 0.026 (0.032)	Data 0.000 (0.001)	Loss 0.5596 (0.5488)	Prec@1 81.250 (80.852)	Prec@5 100.000 (99.068)
EVALUATING - Epoch: [176][0/79]	Time 0.069 (0.069)	Data 0.048 (0.048)	Loss 0.7678 (0.7678)	Prec@1 71.875 (71.875)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 17:07:59

 Epoch: 177	Training Loss 0.5573 	Training Prec@1 80.712 	Training Prec@5 99.012 	Validation Loss 0.8976 	Validation Prec@1 70.930 	Validation Prec@5 97.870 

lr: 0.09306624155330982
TRAINING - Epoch: [177][0/196]	Time 0.276 (0.276)	Data 0.086 (0.086)	Loss 0.5772 (0.5772)	Prec@1 76.953 (76.953)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [177][100/196]	Time 0.041 (0.035)	Data 0.000 (0.001)	Loss 0.5597 (0.5450)	Prec@1 82.422 (81.014)	Prec@5 98.438 (99.107)
EVALUATING - Epoch: [177][0/79]	Time 0.067 (0.067)	Data 0.049 (0.049)	Loss 0.8042 (0.8042)	Prec@1 70.312 (70.312)	Prec@5 97.656 (97.656)
Time cost: 00:07	Time of Finish: 2024-03-31 17:17:38

 Epoch: 178	Training Loss 0.5593 	Training Prec@1 80.492 	Training Prec@5 99.036 	Validation Loss 0.7832 	Validation Prec@1 75.000 	Validation Prec@5 98.170 

lr: 0.09298588036616302
TRAINING - Epoch: [178][0/196]	Time 0.284 (0.284)	Data 0.080 (0.080)	Loss 0.5419 (0.5419)	Prec@1 80.078 (80.078)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [178][100/196]	Time 0.037 (0.035)	Data 0.000 (0.001)	Loss 0.5665 (0.5512)	Prec@1 81.250 (80.813)	Prec@5 98.828 (99.080)
EVALUATING - Epoch: [178][0/79]	Time 0.066 (0.066)	Data 0.049 (0.049)	Loss 1.1619 (1.1619)	Prec@1 65.625 (65.625)	Prec@5 96.875 (96.875)
Time cost: 00:07	Time of Finish: 2024-03-31 17:16:15

 Epoch: 179	Training Loss 0.5606 	Training Prec@1 80.468 	Training Prec@5 99.008 	Validation Loss 1.2394 	Validation Prec@1 63.330 	Validation Prec@5 96.330 

lr: 0.09290509152979419
TRAINING - Epoch: [179][0/196]	Time 0.276 (0.276)	Data 0.094 (0.094)	Loss 0.5267 (0.5267)	Prec@1 81.641 (81.641)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [179][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.5096 (0.5595)	Prec@1 81.250 (80.287)	Prec@5 99.609 (99.076)
EVALUATING - Epoch: [179][0/79]	Time 0.066 (0.066)	Data 0.047 (0.047)	Loss 0.6325 (0.6325)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 17:02:41

 Epoch: 180	Training Loss 0.5569 	Training Prec@1 80.462 	Training Prec@5 99.034 	Validation Loss 0.7077 	Validation Prec@1 75.840 	Validation Prec@5 98.500 

lr: 0.09282387584797383
TRAINING - Epoch: [180][0/196]	Time 0.280 (0.280)	Data 0.084 (0.084)	Loss 0.5025 (0.5025)	Prec@1 83.594 (83.594)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [180][100/196]	Time 0.028 (0.036)	Data 0.000 (0.001)	Loss 0.4459 (0.5578)	Prec@1 83.594 (80.728)	Prec@5 99.219 (99.041)
EVALUATING - Epoch: [180][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 1.1235 (1.1235)	Prec@1 70.312 (70.312)	Prec@5 97.656 (97.656)
Time cost: 00:07	Time of Finish: 2024-03-31 17:16:23

 Epoch: 181	Training Loss 0.5567 	Training Prec@1 80.710 	Training Prec@5 99.058 	Validation Loss 1.1062 	Validation Prec@1 67.870 	Validation Prec@5 97.860 

lr: 0.09274223412871911
TRAINING - Epoch: [181][0/196]	Time 0.287 (0.287)	Data 0.081 (0.081)	Loss 0.5783 (0.5783)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [181][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.5380 (0.5596)	Prec@1 82.422 (80.604)	Prec@5 98.438 (98.987)
EVALUATING - Epoch: [181][0/79]	Time 0.066 (0.066)	Data 0.047 (0.047)	Loss 0.5826 (0.5826)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:02:33

 Epoch: 182	Training Loss 0.5595 	Training Prec@1 80.866 	Training Prec@5 98.970 	Validation Loss 0.7172 	Validation Prec@1 76.650 	Validation Prec@5 98.380 

lr: 0.0926601671842859
TRAINING - Epoch: [182][0/196]	Time 0.272 (0.272)	Data 0.080 (0.080)	Loss 0.6040 (0.6040)	Prec@1 80.859 (80.859)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [182][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.5321 (0.5480)	Prec@1 80.078 (80.987)	Prec@5 99.609 (99.052)
EVALUATING - Epoch: [182][0/79]	Time 0.068 (0.068)	Data 0.050 (0.050)	Loss 0.6963 (0.6963)	Prec@1 73.438 (73.438)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:02:50

 Epoch: 183	Training Loss 0.5535 	Training Prec@1 80.596 	Training Prec@5 99.058 	Validation Loss 0.7657 	Validation Prec@1 75.050 	Validation Prec@5 98.180 

lr: 0.09257767583116064
TRAINING - Epoch: [183][0/196]	Time 0.281 (0.281)	Data 0.092 (0.092)	Loss 0.5619 (0.5619)	Prec@1 80.078 (80.078)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [183][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.4885 (0.5535)	Prec@1 82.031 (80.809)	Prec@5 98.438 (98.909)
EVALUATING - Epoch: [183][0/79]	Time 0.078 (0.078)	Data 0.063 (0.063)	Loss 0.7010 (0.7010)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:06	Time of Finish: 2024-03-31 17:10:26

 Epoch: 184	Training Loss 0.5544 	Training Prec@1 80.728 	Training Prec@5 98.994 	Validation Loss 0.7422 	Validation Prec@1 74.260 	Validation Prec@5 98.300 

lr: 0.09249476089005221
TRAINING - Epoch: [184][0/196]	Time 0.786 (0.786)	Data 0.096 (0.096)	Loss 0.6618 (0.6618)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [184][100/196]	Time 0.093 (0.093)	Data 0.000 (0.001)	Loss 0.5513 (0.5510)	Prec@1 81.641 (80.863)	Prec@5 99.219 (99.134)
EVALUATING - Epoch: [184][0/79]	Time 0.085 (0.085)	Data 0.066 (0.066)	Loss 0.6989 (0.6989)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:51:50

 Epoch: 185	Training Loss 0.5543 	Training Prec@1 80.618 	Training Prec@5 99.078 	Validation Loss 0.8227 	Validation Prec@1 72.800 	Validation Prec@5 97.690 

lr: 0.09241142318588379
TRAINING - Epoch: [185][0/196]	Time 0.805 (0.805)	Data 0.084 (0.084)	Loss 0.5905 (0.5905)	Prec@1 83.594 (83.594)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [185][100/196]	Time 0.087 (0.064)	Data 0.000 (0.001)	Loss 0.6122 (0.5632)	Prec@1 78.906 (80.461)	Prec@5 98.438 (99.072)
EVALUATING - Epoch: [185][0/79]	Time 0.069 (0.069)	Data 0.050 (0.050)	Loss 0.9954 (0.9954)	Prec@1 67.969 (67.969)	Prec@5 97.656 (97.656)
Time cost: 00:16	Time of Finish: 2024-03-31 19:16:56

 Epoch: 186	Training Loss 0.5541 	Training Prec@1 80.802 	Training Prec@5 99.070 	Validation Loss 0.9275 	Validation Prec@1 71.420 	Validation Prec@5 98.310 

lr: 0.09232766354778463
TRAINING - Epoch: [186][0/196]	Time 0.812 (0.812)	Data 0.104 (0.104)	Loss 0.6284 (0.6284)	Prec@1 78.516 (78.516)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [186][100/196]	Time 0.084 (0.093)	Data 0.000 (0.001)	Loss 0.5539 (0.5532)	Prec@1 82.422 (80.716)	Prec@5 98.828 (99.134)
EVALUATING - Epoch: [186][0/79]	Time 0.078 (0.078)	Data 0.060 (0.060)	Loss 0.7429 (0.7429)	Prec@1 77.344 (77.344)	Prec@5 96.875 (96.875)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:00

 Epoch: 187	Training Loss 0.5545 	Training Prec@1 80.794 	Training Prec@5 99.070 	Validation Loss 0.8467 	Validation Prec@1 71.960 	Validation Prec@5 97.960 

lr: 0.09224348280908183
TRAINING - Epoch: [187][0/196]	Time 0.937 (0.937)	Data 0.088 (0.088)	Loss 0.5835 (0.5835)	Prec@1 79.688 (79.688)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [187][100/196]	Time 0.093 (0.095)	Data 0.000 (0.001)	Loss 0.4980 (0.5488)	Prec@1 83.203 (80.941)	Prec@5 98.438 (98.987)
EVALUATING - Epoch: [187][0/79]	Time 0.087 (0.087)	Data 0.065 (0.065)	Loss 0.6615 (0.6615)	Prec@1 72.656 (72.656)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:41:50

 Epoch: 188	Training Loss 0.5553 	Training Prec@1 80.660 	Training Prec@5 99.016 	Validation Loss 0.7543 	Validation Prec@1 74.680 	Validation Prec@5 98.560 

lr: 0.09215888180729204
TRAINING - Epoch: [188][0/196]	Time 0.772 (0.772)	Data 0.104 (0.104)	Loss 0.5085 (0.5085)	Prec@1 83.203 (83.203)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [188][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.5961 (0.5515)	Prec@1 81.641 (80.743)	Prec@5 98.438 (98.960)
EVALUATING - Epoch: [188][0/79]	Time 0.079 (0.079)	Data 0.060 (0.060)	Loss 0.7324 (0.7324)	Prec@1 74.219 (74.219)	Prec@5 98.438 (98.438)
Time cost: 00:19	Time of Finish: 2024-03-31 19:55:53

 Epoch: 189	Training Loss 0.5542 	Training Prec@1 80.702 	Training Prec@5 98.996 	Validation Loss 0.8451 	Validation Prec@1 72.570 	Validation Prec@5 97.990 

lr: 0.09207386138411307
TRAINING - Epoch: [189][0/196]	Time 0.442 (0.442)	Data 0.080 (0.080)	Loss 0.5932 (0.5932)	Prec@1 80.078 (80.078)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [189][100/196]	Time 0.092 (0.079)	Data 0.000 (0.001)	Loss 0.4969 (0.5575)	Prec@1 85.938 (80.519)	Prec@5 99.609 (99.033)
EVALUATING - Epoch: [189][0/79]	Time 0.076 (0.076)	Data 0.053 (0.053)	Loss 0.5649 (0.5649)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:35:15

 Epoch: 190	Training Loss 0.5630 	Training Prec@1 80.430 	Training Prec@5 99.024 	Validation Loss 0.7626 	Validation Prec@1 74.600 	Validation Prec@5 98.640 

lr: 0.09198842238541559
TRAINING - Epoch: [190][0/196]	Time 0.790 (0.790)	Data 0.100 (0.100)	Loss 0.5769 (0.5769)	Prec@1 81.641 (81.641)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [190][100/196]	Time 0.051 (0.081)	Data 0.000 (0.001)	Loss 0.5491 (0.5523)	Prec@1 81.250 (80.840)	Prec@5 100.000 (99.080)
EVALUATING - Epoch: [190][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 1.1362 (1.1362)	Prec@1 64.844 (64.844)	Prec@5 96.875 (96.875)
Time cost: 00:17	Time of Finish: 2024-03-31 19:36:31

 Epoch: 191	Training Loss 0.5508 	Training Prec@1 80.846 	Training Prec@5 99.062 	Validation Loss 1.0643 	Validation Prec@1 66.970 	Validation Prec@5 97.270 

lr: 0.09190256566123473
TRAINING - Epoch: [191][0/196]	Time 0.771 (0.771)	Data 0.126 (0.126)	Loss 0.5447 (0.5447)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [191][100/196]	Time 0.091 (0.093)	Data 0.000 (0.001)	Loss 0.5698 (0.5555)	Prec@1 78.125 (80.504)	Prec@5 98.047 (99.072)
EVALUATING - Epoch: [191][0/79]	Time 0.076 (0.076)	Data 0.057 (0.057)	Loss 0.8337 (0.8337)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:27

 Epoch: 192	Training Loss 0.5547 	Training Prec@1 80.740 	Training Prec@5 99.046 	Validation Loss 0.8719 	Validation Prec@1 72.060 	Validation Prec@5 97.650 

lr: 0.09181629206576154
TRAINING - Epoch: [192][0/196]	Time 0.801 (0.801)	Data 0.100 (0.100)	Loss 0.6330 (0.6330)	Prec@1 77.734 (77.734)	Prec@5 97.266 (97.266)
TRAINING - Epoch: [192][100/196]	Time 0.093 (0.093)	Data 0.000 (0.001)	Loss 0.4871 (0.5570)	Prec@1 82.422 (80.647)	Prec@5 99.219 (98.987)
EVALUATING - Epoch: [192][0/79]	Time 0.109 (0.109)	Data 0.081 (0.081)	Loss 0.6169 (0.6169)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:24

 Epoch: 193	Training Loss 0.5552 	Training Prec@1 80.676 	Training Prec@5 99.004 	Validation Loss 0.7649 	Validation Prec@1 74.440 	Validation Prec@5 98.660 

lr: 0.09172960245733455
TRAINING - Epoch: [193][0/196]	Time 0.798 (0.798)	Data 0.102 (0.102)	Loss 0.5398 (0.5398)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [193][100/196]	Time 0.076 (0.095)	Data 0.000 (0.001)	Loss 0.6303 (0.5560)	Prec@1 78.906 (80.430)	Prec@5 98.828 (99.076)
EVALUATING - Epoch: [193][0/79]	Time 0.078 (0.078)	Data 0.056 (0.056)	Loss 0.6506 (0.6506)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:19	Time of Finish: 2024-03-31 19:56:58

 Epoch: 194	Training Loss 0.5590 	Training Prec@1 80.414 	Training Prec@5 99.046 	Validation Loss 0.7397 	Validation Prec@1 76.130 	Validation Prec@5 98.650 

lr: 0.09164249769843122
TRAINING - Epoch: [194][0/196]	Time 0.769 (0.769)	Data 0.105 (0.105)	Loss 0.5239 (0.5239)	Prec@1 82.422 (82.422)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [194][100/196]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.5173 (0.5487)	Prec@1 81.641 (80.917)	Prec@5 99.219 (98.998)
EVALUATING - Epoch: [194][0/79]	Time 0.074 (0.074)	Data 0.056 (0.056)	Loss 0.5754 (0.5754)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:06

 Epoch: 195	Training Loss 0.5511 	Training Prec@1 80.826 	Training Prec@5 99.048 	Validation Loss 0.6663 	Validation Prec@1 77.160 	Validation Prec@5 98.800 

lr: 0.09155497865565931
TRAINING - Epoch: [195][0/196]	Time 0.779 (0.779)	Data 0.114 (0.114)	Loss 0.5025 (0.5025)	Prec@1 82.422 (82.422)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [195][100/196]	Time 0.091 (0.084)	Data 0.000 (0.001)	Loss 0.5679 (0.5296)	Prec@1 82.812 (81.598)	Prec@5 98.438 (99.018)
EVALUATING - Epoch: [195][0/79]	Time 0.074 (0.074)	Data 0.050 (0.050)	Loss 0.7990 (0.7990)	Prec@1 75.781 (75.781)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:50

 Epoch: 196	Training Loss 0.5463 	Training Prec@1 81.072 	Training Prec@5 99.020 	Validation Loss 0.8114 	Validation Prec@1 73.880 	Validation Prec@5 98.440 

lr: 0.09146704619974837
TRAINING - Epoch: [196][0/196]	Time 0.767 (0.767)	Data 0.083 (0.083)	Loss 0.5361 (0.5361)	Prec@1 80.859 (80.859)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [196][100/196]	Time 0.062 (0.093)	Data 0.000 (0.001)	Loss 0.4823 (0.5586)	Prec@1 81.641 (80.643)	Prec@5 99.219 (99.099)
EVALUATING - Epoch: [196][0/79]	Time 0.078 (0.078)	Data 0.056 (0.056)	Loss 0.6527 (0.6527)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:39

 Epoch: 197	Training Loss 0.5598 	Training Prec@1 80.622 	Training Prec@5 99.060 	Validation Loss 0.8734 	Validation Prec@1 72.060 	Validation Prec@5 97.520 

lr: 0.09137870120554097
TRAINING - Epoch: [197][0/196]	Time 0.773 (0.773)	Data 0.103 (0.103)	Loss 0.5904 (0.5904)	Prec@1 81.641 (81.641)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [197][100/196]	Time 0.088 (0.094)	Data 0.000 (0.001)	Loss 0.5676 (0.5420)	Prec@1 77.344 (81.084)	Prec@5 99.219 (99.087)
EVALUATING - Epoch: [197][0/79]	Time 0.084 (0.084)	Data 0.065 (0.065)	Loss 0.6860 (0.6860)	Prec@1 75.000 (75.000)	Prec@5 96.875 (96.875)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:32

 Epoch: 198	Training Loss 0.5500 	Training Prec@1 80.928 	Training Prec@5 99.064 	Validation Loss 0.7836 	Validation Prec@1 74.040 	Validation Prec@5 97.960 

lr: 0.09128994455198404
TRAINING - Epoch: [198][0/196]	Time 0.785 (0.785)	Data 0.086 (0.086)	Loss 0.6229 (0.6229)	Prec@1 79.297 (79.297)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [198][100/196]	Time 0.092 (0.094)	Data 0.000 (0.001)	Loss 0.6442 (0.5489)	Prec@1 80.859 (80.906)	Prec@5 98.438 (99.095)
EVALUATING - Epoch: [198][0/79]	Time 0.074 (0.074)	Data 0.053 (0.053)	Loss 0.6916 (0.6916)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
Time cost: 00:19	Time of Finish: 2024-03-31 19:55:51

 Epoch: 199	Training Loss 0.5511 	Training Prec@1 80.784 	Training Prec@5 99.088 	Validation Loss 0.8258 	Validation Prec@1 72.360 	Validation Prec@5 98.540 

lr: 0.09120077712212013
TRAINING - Epoch: [199][0/196]	Time 0.649 (0.649)	Data 0.088 (0.088)	Loss 0.5028 (0.5028)	Prec@1 81.641 (81.641)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [199][100/196]	Time 0.076 (0.082)	Data 0.000 (0.001)	Loss 0.4890 (0.5525)	Prec@1 79.297 (80.840)	Prec@5 100.000 (99.018)
EVALUATING - Epoch: [199][0/79]	Time 0.074 (0.074)	Data 0.052 (0.052)	Loss 0.6542 (0.6542)	Prec@1 75.781 (75.781)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:15

 Epoch: 200	Training Loss 0.5586 	Training Prec@1 80.608 	Training Prec@5 98.992 	Validation Loss 0.7161 	Validation Prec@1 75.440 	Validation Prec@5 98.490 

lr: 0.09111119980307862
TRAINING - Epoch: [200][0/196]	Time 0.810 (0.810)	Data 0.097 (0.097)	Loss 0.5926 (0.5926)	Prec@1 75.000 (75.000)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [200][100/196]	Time 0.082 (0.086)	Data 0.000 (0.001)	Loss 0.5271 (0.5547)	Prec@1 81.250 (80.763)	Prec@5 99.219 (99.006)
EVALUATING - Epoch: [200][0/79]	Time 0.073 (0.073)	Data 0.053 (0.053)	Loss 0.7912 (0.7912)	Prec@1 71.094 (71.094)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:50

 Epoch: 201	Training Loss 0.5472 	Training Prec@1 80.922 	Training Prec@5 99.096 	Validation Loss 0.9282 	Validation Prec@1 70.820 	Validation Prec@5 98.150 

lr: 0.09102121348606686
TRAINING - Epoch: [201][0/196]	Time 0.766 (0.766)	Data 0.080 (0.080)	Loss 0.5663 (0.5663)	Prec@1 81.641 (81.641)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [201][100/196]	Time 0.093 (0.095)	Data 0.000 (0.001)	Loss 0.5167 (0.5383)	Prec@1 80.859 (81.335)	Prec@5 99.609 (99.052)
EVALUATING - Epoch: [201][0/79]	Time 0.070 (0.070)	Data 0.049 (0.049)	Loss 0.5771 (0.5771)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:51

 Epoch: 202	Training Loss 0.5440 	Training Prec@1 81.032 	Training Prec@5 99.096 	Validation Loss 0.7232 	Validation Prec@1 75.150 	Validation Prec@5 98.310 

lr: 0.09093081906636136
TRAINING - Epoch: [202][0/196]	Time 0.829 (0.829)	Data 0.119 (0.119)	Loss 0.4635 (0.4635)	Prec@1 85.547 (85.547)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [202][100/196]	Time 0.085 (0.095)	Data 0.000 (0.001)	Loss 0.6187 (0.5406)	Prec@1 78.516 (81.281)	Prec@5 98.438 (99.099)
EVALUATING - Epoch: [202][0/79]	Time 0.073 (0.073)	Data 0.051 (0.051)	Loss 0.6189 (0.6189)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:36:29

 Epoch: 203	Training Loss 0.5522 	Training Prec@1 80.826 	Training Prec@5 99.022 	Validation Loss 0.7483 	Validation Prec@1 75.220 	Validation Prec@5 98.610 

lr: 0.09084001744329885
TRAINING - Epoch: [203][0/196]	Time 0.804 (0.804)	Data 0.099 (0.099)	Loss 0.5170 (0.5170)	Prec@1 81.250 (81.250)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [203][100/196]	Time 0.094 (0.093)	Data 0.000 (0.001)	Loss 0.5161 (0.5544)	Prec@1 80.469 (80.589)	Prec@5 99.609 (99.060)
EVALUATING - Epoch: [203][0/79]	Time 0.074 (0.074)	Data 0.053 (0.053)	Loss 0.6977 (0.6977)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:53:03

 Epoch: 204	Training Loss 0.5506 	Training Prec@1 80.922 	Training Prec@5 99.056 	Validation Loss 0.8656 	Validation Prec@1 71.360 	Validation Prec@5 98.360 

lr: 0.09074880952026732
TRAINING - Epoch: [204][0/196]	Time 0.659 (0.659)	Data 0.103 (0.103)	Loss 0.5404 (0.5404)	Prec@1 83.203 (83.203)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [204][100/196]	Time 0.090 (0.083)	Data 0.000 (0.001)	Loss 0.5117 (0.5512)	Prec@1 79.688 (80.840)	Prec@5 100.000 (99.107)
EVALUATING - Epoch: [204][0/79]	Time 0.077 (0.077)	Data 0.059 (0.059)	Loss 0.8001 (0.8001)	Prec@1 71.875 (71.875)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:41

 Epoch: 205	Training Loss 0.5514 	Training Prec@1 80.756 	Training Prec@5 99.070 	Validation Loss 0.9907 	Validation Prec@1 67.780 	Validation Prec@5 97.600 

lr: 0.09065719620469707
TRAINING - Epoch: [205][0/196]	Time 0.769 (0.769)	Data 0.086 (0.086)	Loss 0.7006 (0.7006)	Prec@1 76.172 (76.172)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [205][100/196]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.7017 (0.5485)	Prec@1 78.516 (81.022)	Prec@5 98.047 (99.107)
EVALUATING - Epoch: [205][0/79]	Time 0.072 (0.072)	Data 0.051 (0.051)	Loss 1.3834 (1.3834)	Prec@1 61.719 (61.719)	Prec@5 94.531 (94.531)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:16

 Epoch: 206	Training Loss 0.5508 	Training Prec@1 80.946 	Training Prec@5 99.106 	Validation Loss 1.5429 	Validation Prec@1 57.810 	Validation Prec@5 94.230 

lr: 0.09056517840805166
TRAINING - Epoch: [206][0/196]	Time 0.808 (0.808)	Data 0.107 (0.107)	Loss 0.6895 (0.6895)	Prec@1 76.172 (76.172)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [206][100/196]	Time 0.086 (0.093)	Data 0.000 (0.001)	Loss 0.4754 (0.5472)	Prec@1 82.812 (81.045)	Prec@5 98.828 (99.060)
EVALUATING - Epoch: [206][0/79]	Time 0.083 (0.083)	Data 0.063 (0.063)	Loss 0.6252 (0.6252)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:33

 Epoch: 207	Training Loss 0.5445 	Training Prec@1 81.136 	Training Prec@5 99.084 	Validation Loss 0.7015 	Validation Prec@1 75.880 	Validation Prec@5 98.590 

lr: 0.09047275704581885
TRAINING - Epoch: [207][0/196]	Time 0.733 (0.733)	Data 0.083 (0.083)	Loss 0.4772 (0.4772)	Prec@1 82.812 (82.812)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [207][100/196]	Time 0.089 (0.093)	Data 0.000 (0.001)	Loss 0.5146 (0.5548)	Prec@1 81.250 (80.585)	Prec@5 100.000 (99.056)
EVALUATING - Epoch: [207][0/79]	Time 0.108 (0.108)	Data 0.080 (0.080)	Loss 0.7579 (0.7579)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:43

 Epoch: 208	Training Loss 0.5502 	Training Prec@1 80.884 	Training Prec@5 99.074 	Validation Loss 0.7739 	Validation Prec@1 75.260 	Validation Prec@5 98.320 

lr: 0.09037993303750146
TRAINING - Epoch: [208][0/196]	Time 0.817 (0.817)	Data 0.089 (0.089)	Loss 0.4570 (0.4570)	Prec@1 82.812 (82.812)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [208][100/196]	Time 0.087 (0.094)	Data 0.000 (0.001)	Loss 0.5187 (0.5452)	Prec@1 82.422 (80.712)	Prec@5 100.000 (99.138)
EVALUATING - Epoch: [208][0/79]	Time 0.077 (0.077)	Data 0.056 (0.056)	Loss 0.8360 (0.8360)	Prec@1 70.312 (70.312)	Prec@5 96.875 (96.875)
Time cost: 00:19	Time of Finish: 2024-03-31 19:57:07

 Epoch: 209	Training Loss 0.5445 	Training Prec@1 80.898 	Training Prec@5 99.082 	Validation Loss 0.8451 	Validation Prec@1 72.680 	Validation Prec@5 97.740 

lr: 0.0902867073066083
TRAINING - Epoch: [209][0/196]	Time 0.694 (0.694)	Data 0.089 (0.089)	Loss 0.5769 (0.5769)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [209][100/196]	Time 0.090 (0.085)	Data 0.000 (0.001)	Loss 0.5294 (0.5480)	Prec@1 80.859 (81.142)	Prec@5 98.828 (98.987)
EVALUATING - Epoch: [209][0/79]	Time 0.075 (0.075)	Data 0.055 (0.055)	Loss 0.6430 (0.6430)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:19

 Epoch: 210	Training Loss 0.5510 	Training Prec@1 80.914 	Training Prec@5 98.994 	Validation Loss 0.7148 	Validation Prec@1 76.140 	Validation Prec@5 98.570 

lr: 0.09019308078064486
TRAINING - Epoch: [210][0/196]	Time 0.764 (0.764)	Data 0.084 (0.084)	Loss 0.5325 (0.5325)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [210][100/196]	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 0.5880 (0.5466)	Prec@1 80.078 (81.184)	Prec@5 98.438 (99.045)
EVALUATING - Epoch: [210][0/79]	Time 0.074 (0.074)	Data 0.051 (0.051)	Loss 1.3125 (1.3125)	Prec@1 63.281 (63.281)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:04

 Epoch: 211	Training Loss 0.5472 	Training Prec@1 81.008 	Training Prec@5 99.040 	Validation Loss 1.2895 	Validation Prec@1 66.160 	Validation Prec@5 97.800 

lr: 0.09009905439110422
TRAINING - Epoch: [211][0/196]	Time 0.748 (0.748)	Data 0.085 (0.085)	Loss 0.4795 (0.4795)	Prec@1 83.203 (83.203)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [211][100/196]	Time 0.080 (0.094)	Data 0.000 (0.001)	Loss 0.4745 (0.5634)	Prec@1 83.984 (80.604)	Prec@5 99.219 (98.952)
EVALUATING - Epoch: [211][0/79]	Time 0.086 (0.086)	Data 0.066 (0.066)	Loss 0.7610 (0.7610)	Prec@1 74.219 (74.219)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:28

 Epoch: 212	Training Loss 0.5586 	Training Prec@1 80.724 	Training Prec@5 98.986 	Validation Loss 0.8437 	Validation Prec@1 72.000 	Validation Prec@5 98.140 

lr: 0.09000462907345765
TRAINING - Epoch: [212][0/196]	Time 0.754 (0.754)	Data 0.096 (0.096)	Loss 0.5486 (0.5486)	Prec@1 80.859 (80.859)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [212][100/196]	Time 0.086 (0.093)	Data 0.000 (0.001)	Loss 0.6353 (0.5434)	Prec@1 77.344 (81.049)	Prec@5 98.047 (99.091)
EVALUATING - Epoch: [212][0/79]	Time 0.087 (0.087)	Data 0.064 (0.064)	Loss 0.6773 (0.6773)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:37

 Epoch: 213	Training Loss 0.5438 	Training Prec@1 81.164 	Training Prec@5 99.056 	Validation Loss 0.8351 	Validation Prec@1 73.630 	Validation Prec@5 97.850 

lr: 0.08990980576714541
TRAINING - Epoch: [213][0/196]	Time 0.793 (0.793)	Data 0.083 (0.083)	Loss 0.5380 (0.5380)	Prec@1 80.469 (80.469)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [213][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.5523 (0.5447)	Prec@1 82.422 (81.010)	Prec@5 99.609 (99.188)
EVALUATING - Epoch: [213][0/79]	Time 0.079 (0.079)	Data 0.061 (0.061)	Loss 0.7474 (0.7474)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:54:43

 Epoch: 214	Training Loss 0.5504 	Training Prec@1 80.776 	Training Prec@5 99.072 	Validation Loss 0.7166 	Validation Prec@1 75.290 	Validation Prec@5 98.680 

lr: 0.08981458541556735
TRAINING - Epoch: [214][0/196]	Time 0.494 (0.494)	Data 0.098 (0.098)	Loss 0.5620 (0.5620)	Prec@1 80.859 (80.859)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [214][100/196]	Time 0.093 (0.081)	Data 0.000 (0.001)	Loss 0.4667 (0.5261)	Prec@1 82.031 (81.900)	Prec@5 99.609 (99.145)
EVALUATING - Epoch: [214][0/79]	Time 0.074 (0.074)	Data 0.049 (0.049)	Loss 0.7390 (0.7390)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:38:20

 Epoch: 215	Training Loss 0.5395 	Training Prec@1 81.350 	Training Prec@5 99.068 	Validation Loss 0.8559 	Validation Prec@1 71.630 	Validation Prec@5 98.040 

lr: 0.08971896896607355
TRAINING - Epoch: [215][0/196]	Time 0.763 (0.763)	Data 0.103 (0.103)	Loss 0.5010 (0.5010)	Prec@1 83.203 (83.203)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [215][100/196]	Time 0.094 (0.084)	Data 0.000 (0.001)	Loss 0.4575 (0.5550)	Prec@1 84.375 (80.631)	Prec@5 99.609 (99.080)
EVALUATING - Epoch: [215][0/79]	Time 0.074 (0.074)	Data 0.053 (0.053)	Loss 0.7393 (0.7393)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:47

 Epoch: 216	Training Loss 0.5451 	Training Prec@1 80.854 	Training Prec@5 99.082 	Validation Loss 0.7948 	Validation Prec@1 72.440 	Validation Prec@5 98.510 

lr: 0.08962295736995483
TRAINING - Epoch: [216][0/196]	Time 0.774 (0.774)	Data 0.094 (0.094)	Loss 0.4756 (0.4756)	Prec@1 83.203 (83.203)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [216][100/196]	Time 0.090 (0.093)	Data 0.000 (0.001)	Loss 0.5418 (0.5435)	Prec@1 78.906 (81.115)	Prec@5 99.219 (99.087)
EVALUATING - Epoch: [216][0/79]	Time 0.073 (0.073)	Data 0.052 (0.052)	Loss 0.9332 (0.9332)	Prec@1 71.875 (71.875)	Prec@5 96.875 (96.875)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:48

 Epoch: 217	Training Loss 0.5411 	Training Prec@1 81.186 	Training Prec@5 99.076 	Validation Loss 0.9736 	Validation Prec@1 70.320 	Validation Prec@5 97.650 

lr: 0.0895265515824334
TRAINING - Epoch: [217][0/196]	Time 0.813 (0.813)	Data 0.097 (0.097)	Loss 0.6003 (0.6003)	Prec@1 78.516 (78.516)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [217][100/196]	Time 0.081 (0.096)	Data 0.000 (0.001)	Loss 0.4940 (0.5440)	Prec@1 82.812 (81.095)	Prec@5 97.656 (98.948)
EVALUATING - Epoch: [217][0/79]	Time 0.080 (0.080)	Data 0.061 (0.061)	Loss 0.7030 (0.7030)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:11

 Epoch: 218	Training Loss 0.5492 	Training Prec@1 80.948 	Training Prec@5 98.966 	Validation Loss 0.7502 	Validation Prec@1 74.680 	Validation Prec@5 98.520 

lr: 0.08942975256265326
TRAINING - Epoch: [218][0/196]	Time 0.811 (0.811)	Data 0.098 (0.098)	Loss 0.5938 (0.5938)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [218][100/196]	Time 0.086 (0.094)	Data 0.000 (0.001)	Loss 0.4328 (0.5296)	Prec@1 82.031 (81.691)	Prec@5 99.609 (99.110)
EVALUATING - Epoch: [218][0/79]	Time 0.080 (0.080)	Data 0.059 (0.059)	Loss 0.8850 (0.8850)	Prec@1 67.188 (67.188)	Prec@5 98.438 (98.438)
Time cost: 00:19	Time of Finish: 2024-03-31 19:55:20

 Epoch: 219	Training Loss 0.5427 	Training Prec@1 81.128 	Training Prec@5 99.044 	Validation Loss 1.0494 	Validation Prec@1 66.710 	Validation Prec@5 97.300 

lr: 0.08933256127367069
TRAINING - Epoch: [219][0/196]	Time 0.475 (0.475)	Data 0.099 (0.099)	Loss 0.5633 (0.5633)	Prec@1 79.297 (79.297)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [219][100/196]	Time 0.091 (0.081)	Data 0.000 (0.001)	Loss 0.5721 (0.5354)	Prec@1 80.859 (81.339)	Prec@5 97.656 (99.095)
EVALUATING - Epoch: [219][0/79]	Time 0.082 (0.082)	Data 0.063 (0.063)	Loss 0.7604 (0.7604)	Prec@1 74.219 (74.219)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:51

 Epoch: 220	Training Loss 0.5421 	Training Prec@1 81.020 	Training Prec@5 99.058 	Validation Loss 0.7830 	Validation Prec@1 73.990 	Validation Prec@5 98.120 

lr: 0.08923497868244465
TRAINING - Epoch: [220][0/196]	Time 0.741 (0.741)	Data 0.078 (0.078)	Loss 0.5488 (0.5488)	Prec@1 80.469 (80.469)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [220][100/196]	Time 0.087 (0.080)	Data 0.000 (0.001)	Loss 0.4952 (0.5532)	Prec@1 82.422 (80.859)	Prec@5 99.609 (99.022)
EVALUATING - Epoch: [220][0/79]	Time 0.081 (0.081)	Data 0.062 (0.062)	Loss 0.6463 (0.6463)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:34:11

 Epoch: 221	Training Loss 0.5560 	Training Prec@1 80.684 	Training Prec@5 99.030 	Validation Loss 0.7074 	Validation Prec@1 76.570 	Validation Prec@5 98.350 

lr: 0.08913700575982719
TRAINING - Epoch: [221][0/196]	Time 0.766 (0.766)	Data 0.095 (0.095)	Loss 0.4877 (0.4877)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [221][100/196]	Time 0.086 (0.093)	Data 0.000 (0.001)	Loss 0.5664 (0.5513)	Prec@1 78.516 (81.010)	Prec@5 99.219 (99.056)
EVALUATING - Epoch: [221][0/79]	Time 0.072 (0.072)	Data 0.049 (0.049)	Loss 0.7644 (0.7644)	Prec@1 75.000 (75.000)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:22

 Epoch: 222	Training Loss 0.5448 	Training Prec@1 81.222 	Training Prec@5 99.106 	Validation Loss 0.6630 	Validation Prec@1 77.640 	Validation Prec@5 98.580 

lr: 0.08903864348055382
TRAINING - Epoch: [222][0/196]	Time 0.798 (0.798)	Data 0.100 (0.100)	Loss 0.5819 (0.5819)	Prec@1 79.688 (79.688)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [222][100/196]	Time 0.084 (0.094)	Data 0.000 (0.001)	Loss 0.6167 (0.5403)	Prec@1 78.906 (81.076)	Prec@5 98.828 (99.060)
EVALUATING - Epoch: [222][0/79]	Time 0.087 (0.087)	Data 0.064 (0.064)	Loss 0.6093 (0.6093)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:10

 Epoch: 223	Training Loss 0.5461 	Training Prec@1 81.026 	Training Prec@5 99.064 	Validation Loss 0.6995 	Validation Prec@1 76.050 	Validation Prec@5 98.550 

lr: 0.08893989282323372
TRAINING - Epoch: [223][0/196]	Time 0.827 (0.827)	Data 0.089 (0.089)	Loss 0.5732 (0.5732)	Prec@1 80.078 (80.078)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [223][100/196]	Time 0.092 (0.096)	Data 0.000 (0.001)	Loss 0.4349 (0.5485)	Prec@1 84.766 (81.002)	Prec@5 98.438 (99.037)
EVALUATING - Epoch: [223][0/79]	Time 0.087 (0.087)	Data 0.066 (0.066)	Loss 0.7507 (0.7507)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:19	Time of Finish: 2024-03-31 19:58:23

 Epoch: 224	Training Loss 0.5485 	Training Prec@1 80.982 	Training Prec@5 99.082 	Validation Loss 0.8718 	Validation Prec@1 71.420 	Validation Prec@5 97.980 

lr: 0.08884075477034006
TRAINING - Epoch: [224][0/196]	Time 0.785 (0.785)	Data 0.090 (0.090)	Loss 0.5342 (0.5342)	Prec@1 83.984 (83.984)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [224][100/196]	Time 0.090 (0.082)	Data 0.000 (0.001)	Loss 0.5282 (0.5522)	Prec@1 80.078 (80.759)	Prec@5 98.828 (99.025)
EVALUATING - Epoch: [224][0/79]	Time 0.091 (0.091)	Data 0.071 (0.071)	Loss 1.5718 (1.5718)	Prec@1 62.500 (62.500)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:16

 Epoch: 225	Training Loss 0.5476 	Training Prec@1 80.986 	Training Prec@5 99.038 	Validation Loss 1.4324 	Validation Prec@1 62.980 	Validation Prec@5 97.470 

lr: 0.08874123030820023
TRAINING - Epoch: [225][0/196]	Time 0.774 (0.774)	Data 0.098 (0.098)	Loss 0.5570 (0.5570)	Prec@1 77.734 (77.734)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [225][100/196]	Time 0.092 (0.083)	Data 0.000 (0.001)	Loss 0.5587 (0.5383)	Prec@1 82.812 (81.347)	Prec@5 98.828 (99.029)
EVALUATING - Epoch: [225][0/79]	Time 0.083 (0.083)	Data 0.064 (0.064)	Loss 0.8016 (0.8016)	Prec@1 73.438 (73.438)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:43

 Epoch: 226	Training Loss 0.5462 	Training Prec@1 80.986 	Training Prec@5 99.014 	Validation Loss 0.7307 	Validation Prec@1 76.090 	Validation Prec@5 98.100 

lr: 0.08864132042698604
TRAINING - Epoch: [226][0/196]	Time 0.794 (0.794)	Data 0.094 (0.094)	Loss 0.5780 (0.5780)	Prec@1 79.297 (79.297)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [226][100/196]	Time 0.092 (0.094)	Data 0.000 (0.001)	Loss 0.7150 (0.5478)	Prec@1 76.172 (81.049)	Prec@5 99.219 (99.010)
EVALUATING - Epoch: [226][0/79]	Time 0.078 (0.078)	Data 0.060 (0.060)	Loss 0.8305 (0.8305)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:36:33

 Epoch: 227	Training Loss 0.5470 	Training Prec@1 81.116 	Training Prec@5 99.000 	Validation Loss 0.9384 	Validation Prec@1 70.820 	Validation Prec@5 98.350 

lr: 0.0885410261207038
TRAINING - Epoch: [227][0/196]	Time 0.761 (0.761)	Data 0.078 (0.078)	Loss 0.4477 (0.4477)	Prec@1 84.375 (84.375)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [227][100/196]	Time 0.082 (0.093)	Data 0.000 (0.001)	Loss 0.5370 (0.5511)	Prec@1 82.031 (81.084)	Prec@5 99.609 (99.199)
EVALUATING - Epoch: [227][0/79]	Time 0.084 (0.084)	Data 0.067 (0.067)	Loss 0.7305 (0.7305)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:53

 Epoch: 228	Training Loss 0.5459 	Training Prec@1 81.086 	Training Prec@5 99.170 	Validation Loss 0.7481 	Validation Prec@1 74.430 	Validation Prec@5 98.650 

lr: 0.08844034838718452
TRAINING - Epoch: [228][0/196]	Time 0.809 (0.809)	Data 0.098 (0.098)	Loss 0.5018 (0.5018)	Prec@1 81.250 (81.250)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [228][100/196]	Time 0.088 (0.095)	Data 0.000 (0.001)	Loss 0.4536 (0.5376)	Prec@1 84.766 (81.474)	Prec@5 98.047 (99.087)
EVALUATING - Epoch: [228][0/79]	Time 0.082 (0.082)	Data 0.062 (0.062)	Loss 0.6812 (0.6812)	Prec@1 74.219 (74.219)	Prec@5 96.875 (96.875)
Time cost: 00:19	Time of Finish: 2024-03-31 19:57:27

 Epoch: 229	Training Loss 0.5377 	Training Prec@1 81.384 	Training Prec@5 99.154 	Validation Loss 0.7965 	Validation Prec@1 73.530 	Validation Prec@5 97.950 

lr: 0.0883392882280739
TRAINING - Epoch: [229][0/196]	Time 0.758 (0.758)	Data 0.100 (0.100)	Loss 0.4978 (0.4978)	Prec@1 82.422 (82.422)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [229][100/196]	Time 0.093 (0.085)	Data 0.000 (0.001)	Loss 0.6360 (0.5480)	Prec@1 80.469 (80.968)	Prec@5 98.828 (99.029)
EVALUATING - Epoch: [229][0/79]	Time 0.086 (0.086)	Data 0.067 (0.067)	Loss 0.6500 (0.6500)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:56

 Epoch: 230	Training Loss 0.5477 	Training Prec@1 80.914 	Training Prec@5 99.064 	Validation Loss 0.7402 	Validation Prec@1 75.480 	Validation Prec@5 98.130 

lr: 0.08823784664882241
TRAINING - Epoch: [230][0/196]	Time 0.807 (0.807)	Data 0.089 (0.089)	Loss 0.5880 (0.5880)	Prec@1 77.734 (77.734)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [230][100/196]	Time 0.074 (0.084)	Data 0.000 (0.001)	Loss 0.5531 (0.5432)	Prec@1 81.250 (81.146)	Prec@5 98.828 (99.002)
EVALUATING - Epoch: [230][0/79]	Time 0.073 (0.073)	Data 0.051 (0.051)	Loss 0.6423 (0.6423)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:08

 Epoch: 231	Training Loss 0.5531 	Training Prec@1 80.716 	Training Prec@5 98.994 	Validation Loss 0.7576 	Validation Prec@1 74.450 	Validation Prec@5 98.350 

lr: 0.0881360246586753
TRAINING - Epoch: [231][0/196]	Time 0.801 (0.801)	Data 0.105 (0.105)	Loss 0.4977 (0.4977)	Prec@1 84.375 (84.375)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [231][100/196]	Time 0.088 (0.092)	Data 0.000 (0.001)	Loss 0.5551 (0.5352)	Prec@1 78.906 (81.219)	Prec@5 98.438 (99.122)
EVALUATING - Epoch: [231][0/79]	Time 0.078 (0.078)	Data 0.059 (0.059)	Loss 1.0311 (1.0311)	Prec@1 67.188 (67.188)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:23

 Epoch: 232	Training Loss 0.5411 	Training Prec@1 81.142 	Training Prec@5 99.112 	Validation Loss 1.0656 	Validation Prec@1 67.920 	Validation Prec@5 97.470 

lr: 0.08803382327066255
TRAINING - Epoch: [232][0/196]	Time 0.790 (0.790)	Data 0.083 (0.083)	Loss 0.4742 (0.4742)	Prec@1 83.203 (83.203)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [232][100/196]	Time 0.080 (0.094)	Data 0.000 (0.001)	Loss 0.6083 (0.5374)	Prec@1 80.078 (81.277)	Prec@5 99.219 (99.080)
EVALUATING - Epoch: [232][0/79]	Time 0.083 (0.083)	Data 0.059 (0.059)	Loss 0.7614 (0.7614)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:10

 Epoch: 233	Training Loss 0.5426 	Training Prec@1 81.164 	Training Prec@5 99.018 	Validation Loss 0.7871 	Validation Prec@1 74.350 	Validation Prec@5 98.450 

lr: 0.08793124350158874
TRAINING - Epoch: [233][0/196]	Time 0.793 (0.793)	Data 0.088 (0.088)	Loss 0.5497 (0.5497)	Prec@1 79.688 (79.688)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [233][100/196]	Time 0.064 (0.092)	Data 0.000 (0.001)	Loss 0.5971 (0.5341)	Prec@1 80.078 (81.552)	Prec@5 98.828 (99.103)
EVALUATING - Epoch: [233][0/79]	Time 0.088 (0.088)	Data 0.068 (0.068)	Loss 0.6322 (0.6322)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:52:03

 Epoch: 234	Training Loss 0.5504 	Training Prec@1 80.944 	Training Prec@5 99.028 	Validation Loss 0.6644 	Validation Prec@1 77.000 	Validation Prec@5 98.540 

lr: 0.087828286372023
TRAINING - Epoch: [234][0/196]	Time 0.802 (0.802)	Data 0.091 (0.091)	Loss 0.6972 (0.6972)	Prec@1 76.172 (76.172)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [234][100/196]	Time 0.090 (0.085)	Data 0.000 (0.001)	Loss 0.5257 (0.5293)	Prec@1 81.641 (81.614)	Prec@5 99.219 (99.153)
EVALUATING - Epoch: [234][0/79]	Time 0.070 (0.070)	Data 0.050 (0.050)	Loss 0.6613 (0.6613)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:52

 Epoch: 235	Training Loss 0.5371 	Training Prec@1 81.306 	Training Prec@5 99.132 	Validation Loss 0.7556 	Validation Prec@1 74.790 	Validation Prec@5 98.560 

lr: 0.08772495290628882
TRAINING - Epoch: [235][0/196]	Time 0.813 (0.813)	Data 0.095 (0.095)	Loss 0.5462 (0.5462)	Prec@1 82.422 (82.422)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [235][100/196]	Time 0.088 (0.085)	Data 0.000 (0.001)	Loss 0.6361 (0.5410)	Prec@1 78.906 (81.258)	Prec@5 98.438 (99.091)
EVALUATING - Epoch: [235][0/79]	Time 0.079 (0.079)	Data 0.059 (0.059)	Loss 0.8011 (0.8011)	Prec@1 79.688 (79.688)	Prec@5 96.875 (96.875)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:22

 Epoch: 236	Training Loss 0.5423 	Training Prec@1 81.220 	Training Prec@5 99.038 	Validation Loss 0.8398 	Validation Prec@1 73.790 	Validation Prec@5 97.880 

lr: 0.08762124413245387
TRAINING - Epoch: [236][0/196]	Time 0.797 (0.797)	Data 0.117 (0.117)	Loss 0.5637 (0.5637)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [236][100/196]	Time 0.088 (0.093)	Data 0.000 (0.001)	Loss 0.5588 (0.5391)	Prec@1 78.906 (81.409)	Prec@5 99.219 (99.029)
EVALUATING - Epoch: [236][0/79]	Time 0.073 (0.073)	Data 0.051 (0.051)	Loss 0.7750 (0.7750)	Prec@1 74.219 (74.219)	Prec@5 96.875 (96.875)
Time cost: 00:18	Time of Finish: 2024-03-31 19:41:53

 Epoch: 237	Training Loss 0.5433 	Training Prec@1 81.248 	Training Prec@5 99.028 	Validation Loss 0.8650 	Validation Prec@1 72.880 	Validation Prec@5 98.010 

lr: 0.0875171610823198
TRAINING - Epoch: [237][0/196]	Time 0.836 (0.836)	Data 0.103 (0.103)	Loss 0.5212 (0.5212)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [237][100/196]	Time 0.087 (0.095)	Data 0.000 (0.001)	Loss 0.5926 (0.5375)	Prec@1 79.688 (81.246)	Prec@5 98.828 (99.211)
EVALUATING - Epoch: [237][0/79]	Time 0.083 (0.083)	Data 0.062 (0.062)	Loss 0.8811 (0.8811)	Prec@1 66.406 (66.406)	Prec@5 96.875 (96.875)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:36

 Epoch: 238	Training Loss 0.5422 	Training Prec@1 81.196 	Training Prec@5 99.114 	Validation Loss 0.8925 	Validation Prec@1 71.340 	Validation Prec@5 97.960 

lr: 0.08741270479141192
TRAINING - Epoch: [238][0/196]	Time 0.750 (0.750)	Data 0.089 (0.089)	Loss 0.5314 (0.5314)	Prec@1 82.812 (82.812)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [238][100/196]	Time 0.082 (0.094)	Data 0.000 (0.001)	Loss 0.6676 (0.5470)	Prec@1 77.344 (81.165)	Prec@5 98.047 (99.045)
EVALUATING - Epoch: [238][0/79]	Time 0.072 (0.072)	Data 0.051 (0.051)	Loss 0.6735 (0.6735)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:52:30

 Epoch: 239	Training Loss 0.5354 	Training Prec@1 81.540 	Training Prec@5 99.110 	Validation Loss 0.8474 	Validation Prec@1 73.660 	Validation Prec@5 97.250 

lr: 0.0873078762989689
TRAINING - Epoch: [239][0/196]	Time 0.458 (0.458)	Data 0.082 (0.082)	Loss 0.4541 (0.4541)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [239][100/196]	Time 0.094 (0.078)	Data 0.001 (0.001)	Loss 0.5398 (0.5349)	Prec@1 82.031 (81.293)	Prec@5 98.047 (99.018)
EVALUATING - Epoch: [239][0/79]	Time 0.083 (0.083)	Data 0.064 (0.064)	Loss 0.7437 (0.7437)	Prec@1 78.906 (78.906)	Prec@5 96.094 (96.094)
Time cost: 00:17	Time of Finish: 2024-03-31 19:34:29

 Epoch: 240	Training Loss 0.5433 	Training Prec@1 81.106 	Training Prec@5 99.010 	Validation Loss 0.8390 	Validation Prec@1 72.890 	Validation Prec@5 97.680 

lr: 0.08720267664793249
TRAINING - Epoch: [240][0/196]	Time 0.785 (0.785)	Data 0.085 (0.085)	Loss 0.5652 (0.5652)	Prec@1 80.859 (80.859)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [240][100/196]	Time 0.088 (0.081)	Data 0.000 (0.001)	Loss 0.4919 (0.5347)	Prec@1 84.766 (81.126)	Prec@5 99.609 (99.242)
EVALUATING - Epoch: [240][0/79]	Time 0.082 (0.082)	Data 0.063 (0.063)	Loss 0.5857 (0.5857)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:19

 Epoch: 241	Training Loss 0.5402 	Training Prec@1 81.070 	Training Prec@5 99.160 	Validation Loss 0.7861 	Validation Prec@1 73.930 	Validation Prec@5 98.530 

lr: 0.0870971068849371
TRAINING - Epoch: [241][0/196]	Time 0.790 (0.790)	Data 0.103 (0.103)	Loss 0.4556 (0.4556)	Prec@1 82.031 (82.031)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [241][100/196]	Time 0.081 (0.094)	Data 0.000 (0.001)	Loss 0.5784 (0.5298)	Prec@1 82.031 (81.641)	Prec@5 99.609 (99.126)
EVALUATING - Epoch: [241][0/79]	Time 0.080 (0.080)	Data 0.056 (0.056)	Loss 0.7215 (0.7215)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:17

 Epoch: 242	Training Loss 0.5292 	Training Prec@1 81.540 	Training Prec@5 99.164 	Validation Loss 0.8324 	Validation Prec@1 73.150 	Validation Prec@5 97.980 

lr: 0.08699116806029941
TRAINING - Epoch: [242][0/196]	Time 0.801 (0.801)	Data 0.098 (0.098)	Loss 0.5628 (0.5628)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [242][100/196]	Time 0.088 (0.095)	Data 0.000 (0.001)	Loss 0.5349 (0.5400)	Prec@1 81.641 (81.265)	Prec@5 100.000 (99.006)
EVALUATING - Epoch: [242][0/79]	Time 0.075 (0.075)	Data 0.054 (0.054)	Loss 0.6350 (0.6350)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:32

 Epoch: 243	Training Loss 0.5428 	Training Prec@1 81.070 	Training Prec@5 99.040 	Validation Loss 0.7878 	Validation Prec@1 74.290 	Validation Prec@5 97.810 

lr: 0.08688486122800787
TRAINING - Epoch: [243][0/196]	Time 0.758 (0.758)	Data 0.098 (0.098)	Loss 0.6328 (0.6328)	Prec@1 77.344 (77.344)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [243][100/196]	Time 0.088 (0.094)	Data 0.000 (0.001)	Loss 0.4770 (0.5375)	Prec@1 83.594 (81.138)	Prec@5 100.000 (99.138)
EVALUATING - Epoch: [243][0/79]	Time 0.087 (0.087)	Data 0.066 (0.066)	Loss 0.5966 (0.5966)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:52:44

 Epoch: 244	Training Loss 0.5448 	Training Prec@1 80.918 	Training Prec@5 99.074 	Validation Loss 0.6602 	Validation Prec@1 78.250 	Validation Prec@5 98.780 

lr: 0.08677818744571224
TRAINING - Epoch: [244][0/196]	Time 0.772 (0.772)	Data 0.086 (0.086)	Loss 0.4255 (0.4255)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [244][100/196]	Time 0.093 (0.082)	Data 0.000 (0.001)	Loss 0.5013 (0.5463)	Prec@1 82.422 (80.840)	Prec@5 99.609 (99.095)
EVALUATING - Epoch: [244][0/79]	Time 0.073 (0.073)	Data 0.052 (0.052)	Loss 0.8139 (0.8139)	Prec@1 72.656 (72.656)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:54

 Epoch: 245	Training Loss 0.5443 	Training Prec@1 80.988 	Training Prec@5 99.082 	Validation Loss 0.8275 	Validation Prec@1 72.950 	Validation Prec@5 97.880 

lr: 0.08667114777471314
TRAINING - Epoch: [245][0/196]	Time 0.777 (0.777)	Data 0.089 (0.089)	Loss 0.5575 (0.5575)	Prec@1 80.078 (80.078)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [245][100/196]	Time 0.073 (0.078)	Data 0.000 (0.001)	Loss 0.5233 (0.5405)	Prec@1 82.031 (81.366)	Prec@5 99.219 (99.025)
EVALUATING - Epoch: [245][0/79]	Time 0.083 (0.083)	Data 0.064 (0.064)	Loss 0.7389 (0.7389)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:34:19

 Epoch: 246	Training Loss 0.5391 	Training Prec@1 81.248 	Training Prec@5 99.020 	Validation Loss 0.6904 	Validation Prec@1 77.370 	Validation Prec@5 98.510 

lr: 0.0865637432799514
TRAINING - Epoch: [246][0/196]	Time 0.771 (0.771)	Data 0.104 (0.104)	Loss 0.5496 (0.5496)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [246][100/196]	Time 0.094 (0.093)	Data 0.000 (0.001)	Loss 0.4979 (0.5325)	Prec@1 82.422 (81.610)	Prec@5 99.609 (99.153)
EVALUATING - Epoch: [246][0/79]	Time 0.075 (0.075)	Data 0.050 (0.050)	Loss 0.7397 (0.7397)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:20

 Epoch: 247	Training Loss 0.5378 	Training Prec@1 81.272 	Training Prec@5 99.160 	Validation Loss 0.8729 	Validation Prec@1 71.600 	Validation Prec@5 98.130 

lr: 0.08645597502999743
TRAINING - Epoch: [247][0/196]	Time 0.800 (0.800)	Data 0.100 (0.100)	Loss 0.6924 (0.6924)	Prec@1 77.734 (77.734)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [247][100/196]	Time 0.092 (0.093)	Data 0.000 (0.001)	Loss 0.4967 (0.5379)	Prec@1 83.594 (81.323)	Prec@5 99.609 (99.211)
EVALUATING - Epoch: [247][0/79]	Time 0.071 (0.071)	Data 0.049 (0.049)	Loss 0.6367 (0.6367)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:48

 Epoch: 248	Training Loss 0.5363 	Training Prec@1 81.400 	Training Prec@5 99.170 	Validation Loss 0.7376 	Validation Prec@1 76.660 	Validation Prec@5 98.110 

lr: 0.08634784409704073
TRAINING - Epoch: [248][0/196]	Time 0.725 (0.725)	Data 0.094 (0.094)	Loss 0.5530 (0.5530)	Prec@1 83.203 (83.203)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [248][100/196]	Time 0.092 (0.093)	Data 0.000 (0.001)	Loss 0.5252 (0.5244)	Prec@1 81.250 (81.737)	Prec@5 99.609 (99.134)
EVALUATING - Epoch: [248][0/79]	Time 0.075 (0.075)	Data 0.052 (0.052)	Loss 0.7570 (0.7570)	Prec@1 73.438 (73.438)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:53:20

 Epoch: 249	Training Loss 0.5358 	Training Prec@1 81.346 	Training Prec@5 99.076 	Validation Loss 0.7858 	Validation Prec@1 74.580 	Validation Prec@5 98.160 

lr: 0.08623935155687912
TRAINING - Epoch: [249][0/196]	Time 0.827 (0.827)	Data 0.102 (0.102)	Loss 0.4765 (0.4765)	Prec@1 82.031 (82.031)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [249][100/196]	Time 0.086 (0.087)	Data 0.000 (0.001)	Loss 0.5039 (0.5300)	Prec@1 82.422 (81.474)	Prec@5 98.828 (99.068)
EVALUATING - Epoch: [249][0/79]	Time 0.080 (0.080)	Data 0.057 (0.057)	Loss 0.6359 (0.6359)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:48

 Epoch: 250	Training Loss 0.5370 	Training Prec@1 81.218 	Training Prec@5 99.096 	Validation Loss 0.8086 	Validation Prec@1 73.440 	Validation Prec@5 98.210 

lr: 0.08613049848890808
TRAINING - Epoch: [250][0/196]	Time 0.794 (0.794)	Data 0.085 (0.085)	Loss 0.6092 (0.6092)	Prec@1 76.172 (76.172)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [250][100/196]	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 0.4493 (0.5370)	Prec@1 82.031 (81.412)	Prec@5 99.219 (99.114)
EVALUATING - Epoch: [250][0/79]	Time 0.069 (0.069)	Data 0.049 (0.049)	Loss 0.8160 (0.8160)	Prec@1 70.312 (70.312)	Prec@5 96.875 (96.875)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:14

 Epoch: 251	Training Loss 0.5394 	Training Prec@1 81.252 	Training Prec@5 99.122 	Validation Loss 0.7007 	Validation Prec@1 75.890 	Validation Prec@5 98.190 

lr: 0.08602128597610992
TRAINING - Epoch: [251][0/196]	Time 0.814 (0.814)	Data 0.092 (0.092)	Loss 0.5356 (0.5356)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [251][100/196]	Time 0.092 (0.094)	Data 0.000 (0.001)	Loss 0.4068 (0.5379)	Prec@1 87.891 (81.177)	Prec@5 99.219 (99.226)
EVALUATING - Epoch: [251][0/79]	Time 0.080 (0.080)	Data 0.060 (0.060)	Loss 0.5686 (0.5686)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:57

 Epoch: 252	Training Loss 0.5404 	Training Prec@1 81.164 	Training Prec@5 99.094 	Validation Loss 0.6858 	Validation Prec@1 76.820 	Validation Prec@5 98.670 

lr: 0.08591171510504317
TRAINING - Epoch: [252][0/196]	Time 0.732 (0.732)	Data 0.083 (0.083)	Loss 0.5320 (0.5320)	Prec@1 79.688 (79.688)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [252][100/196]	Time 0.090 (0.094)	Data 0.000 (0.001)	Loss 0.6050 (0.5299)	Prec@1 77.734 (81.354)	Prec@5 99.219 (99.207)
EVALUATING - Epoch: [252][0/79]	Time 0.090 (0.090)	Data 0.070 (0.070)	Loss 1.2091 (1.2091)	Prec@1 61.719 (61.719)	Prec@5 95.312 (95.312)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:15

 Epoch: 253	Training Loss 0.5369 	Training Prec@1 81.358 	Training Prec@5 99.094 	Validation Loss 1.2630 	Validation Prec@1 62.440 	Validation Prec@5 96.520 

lr: 0.0858017869658316
TRAINING - Epoch: [253][0/196]	Time 0.768 (0.768)	Data 0.107 (0.107)	Loss 0.5698 (0.5698)	Prec@1 82.422 (82.422)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [253][100/196]	Time 0.084 (0.092)	Data 0.000 (0.001)	Loss 0.5242 (0.5319)	Prec@1 83.203 (81.532)	Prec@5 99.609 (99.145)
EVALUATING - Epoch: [253][0/79]	Time 0.071 (0.071)	Data 0.050 (0.050)	Loss 0.8697 (0.8697)	Prec@1 71.875 (71.875)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:51:19

 Epoch: 254	Training Loss 0.5324 	Training Prec@1 81.444 	Training Prec@5 99.140 	Validation Loss 0.8863 	Validation Prec@1 71.340 	Validation Prec@5 97.260 

lr: 0.0856915026521535
TRAINING - Epoch: [254][0/196]	Time 0.804 (0.804)	Data 0.094 (0.094)	Loss 0.5431 (0.5431)	Prec@1 79.297 (79.297)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [254][100/196]	Time 0.086 (0.084)	Data 0.000 (0.001)	Loss 0.5333 (0.5256)	Prec@1 78.906 (81.873)	Prec@5 99.219 (99.076)
EVALUATING - Epoch: [254][0/79]	Time 0.079 (0.079)	Data 0.062 (0.062)	Loss 0.6292 (0.6292)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:10

 Epoch: 255	Training Loss 0.5324 	Training Prec@1 81.520 	Training Prec@5 99.106 	Validation Loss 0.6482 	Validation Prec@1 78.710 	Validation Prec@5 98.820 

lr: 0.08558086326123075
TRAINING - Epoch: [255][0/196]	Time 0.783 (0.783)	Data 0.104 (0.104)	Loss 0.6020 (0.6020)	Prec@1 78.125 (78.125)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [255][100/196]	Time 0.092 (0.083)	Data 0.000 (0.001)	Loss 0.5501 (0.5326)	Prec@1 83.594 (81.470)	Prec@5 99.219 (99.141)
EVALUATING - Epoch: [255][0/79]	Time 0.073 (0.073)	Data 0.050 (0.050)	Loss 1.1416 (1.1416)	Prec@1 66.406 (66.406)	Prec@5 95.312 (95.312)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:47

 Epoch: 256	Training Loss 0.5410 	Training Prec@1 81.126 	Training Prec@5 99.132 	Validation Loss 1.2113 	Validation Prec@1 64.660 	Validation Prec@5 95.860 

lr: 0.08546986989381787
TRAINING - Epoch: [256][0/196]	Time 0.776 (0.776)	Data 0.100 (0.100)	Loss 0.5220 (0.5220)	Prec@1 82.812 (82.812)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [256][100/196]	Time 0.092 (0.094)	Data 0.000 (0.001)	Loss 0.5507 (0.5305)	Prec@1 82.031 (81.494)	Prec@5 99.219 (99.138)
EVALUATING - Epoch: [256][0/79]	Time 0.075 (0.075)	Data 0.050 (0.050)	Loss 0.6470 (0.6470)	Prec@1 74.219 (74.219)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:49

 Epoch: 257	Training Loss 0.5343 	Training Prec@1 81.496 	Training Prec@5 99.084 	Validation Loss 0.7162 	Validation Prec@1 75.850 	Validation Prec@5 98.560 

lr: 0.08535852365419111
TRAINING - Epoch: [257][0/196]	Time 0.784 (0.784)	Data 0.078 (0.078)	Loss 0.5805 (0.5805)	Prec@1 80.859 (80.859)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [257][100/196]	Time 0.093 (0.092)	Data 0.000 (0.001)	Loss 0.5798 (0.5337)	Prec@1 80.469 (81.412)	Prec@5 98.828 (99.138)
EVALUATING - Epoch: [257][0/79]	Time 0.075 (0.075)	Data 0.055 (0.055)	Loss 0.6896 (0.6896)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:36:44

 Epoch: 258	Training Loss 0.5356 	Training Prec@1 81.292 	Training Prec@5 99.074 	Validation Loss 0.8164 	Validation Prec@1 73.730 	Validation Prec@5 98.200 

lr: 0.08524682565013748
TRAINING - Epoch: [258][0/196]	Time 0.793 (0.793)	Data 0.082 (0.082)	Loss 0.4993 (0.4993)	Prec@1 81.250 (81.250)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [258][100/196]	Time 0.095 (0.093)	Data 0.000 (0.001)	Loss 0.5404 (0.5258)	Prec@1 79.688 (81.602)	Prec@5 99.219 (99.273)
EVALUATING - Epoch: [258][0/79]	Time 0.085 (0.085)	Data 0.066 (0.066)	Loss 0.7179 (0.7179)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:53:57

 Epoch: 259	Training Loss 0.5300 	Training Prec@1 81.602 	Training Prec@5 99.204 	Validation Loss 0.7491 	Validation Prec@1 75.400 	Validation Prec@5 98.390 

lr: 0.08513477699294368
TRAINING - Epoch: [259][0/196]	Time 0.723 (0.723)	Data 0.088 (0.088)	Loss 0.5649 (0.5649)	Prec@1 79.297 (79.297)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [259][100/196]	Time 0.073 (0.081)	Data 0.000 (0.001)	Loss 0.5345 (0.5306)	Prec@1 82.031 (81.323)	Prec@5 98.828 (99.188)
EVALUATING - Epoch: [259][0/79]	Time 0.077 (0.077)	Data 0.052 (0.052)	Loss 0.7597 (0.7597)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:10

 Epoch: 260	Training Loss 0.5300 	Training Prec@1 81.460 	Training Prec@5 99.148 	Validation Loss 0.7974 	Validation Prec@1 74.080 	Validation Prec@5 98.040 

lr: 0.08502237879738511
TRAINING - Epoch: [260][0/196]	Time 0.761 (0.761)	Data 0.087 (0.087)	Loss 0.4846 (0.4846)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [260][100/196]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.5754 (0.5380)	Prec@1 79.297 (81.169)	Prec@5 99.219 (99.080)
EVALUATING - Epoch: [260][0/79]	Time 0.079 (0.079)	Data 0.060 (0.060)	Loss 0.8509 (0.8509)	Prec@1 72.656 (72.656)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:38

 Epoch: 261	Training Loss 0.5331 	Training Prec@1 81.278 	Training Prec@5 99.084 	Validation Loss 0.9409 	Validation Prec@1 70.090 	Validation Prec@5 97.940 

lr: 0.08490963218171468
TRAINING - Epoch: [261][0/196]	Time 0.735 (0.735)	Data 0.084 (0.084)	Loss 0.6474 (0.6474)	Prec@1 78.906 (78.906)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [261][100/196]	Time 0.091 (0.093)	Data 0.000 (0.001)	Loss 0.5887 (0.5270)	Prec@1 76.172 (81.563)	Prec@5 99.219 (99.250)
EVALUATING - Epoch: [261][0/79]	Time 0.082 (0.082)	Data 0.064 (0.064)	Loss 0.5433 (0.5433)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:34:35

 Epoch: 262	Training Loss 0.5369 	Training Prec@1 81.182 	Training Prec@5 99.134 	Validation Loss 0.6768 	Validation Prec@1 76.640 	Validation Prec@5 98.590 

lr: 0.0847965382676518
TRAINING - Epoch: [262][0/196]	Time 0.749 (0.749)	Data 0.106 (0.106)	Loss 0.5916 (0.5916)	Prec@1 76.953 (76.953)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [262][100/196]	Time 0.091 (0.092)	Data 0.000 (0.001)	Loss 0.6232 (0.5314)	Prec@1 81.250 (81.455)	Prec@5 98.828 (99.145)
EVALUATING - Epoch: [262][0/79]	Time 0.076 (0.076)	Data 0.056 (0.056)	Loss 0.7756 (0.7756)	Prec@1 72.656 (72.656)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:43

 Epoch: 263	Training Loss 0.5327 	Training Prec@1 81.448 	Training Prec@5 99.118 	Validation Loss 0.8377 	Validation Prec@1 72.850 	Validation Prec@5 98.590 

lr: 0.08468309818037109
TRAINING - Epoch: [263][0/196]	Time 0.459 (0.459)	Data 0.126 (0.126)	Loss 0.4851 (0.4851)	Prec@1 82.812 (82.812)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [263][100/196]	Time 0.084 (0.091)	Data 0.000 (0.001)	Loss 0.5440 (0.5322)	Prec@1 81.641 (81.308)	Prec@5 99.219 (99.134)
EVALUATING - Epoch: [263][0/79]	Time 0.084 (0.084)	Data 0.064 (0.064)	Loss 0.6575 (0.6575)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:51:26

 Epoch: 264	Training Loss 0.5344 	Training Prec@1 81.430 	Training Prec@5 99.054 	Validation Loss 0.7843 	Validation Prec@1 74.590 	Validation Prec@5 97.940 

lr: 0.08456931304849132
TRAINING - Epoch: [264][0/196]	Time 0.799 (0.799)	Data 0.112 (0.112)	Loss 0.5543 (0.5543)	Prec@1 80.078 (80.078)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [264][100/196]	Time 0.093 (0.083)	Data 0.000 (0.001)	Loss 0.5975 (0.5345)	Prec@1 76.172 (81.316)	Prec@5 98.438 (99.118)
EVALUATING - Epoch: [264][0/79]	Time 0.072 (0.072)	Data 0.050 (0.050)	Loss 0.5178 (0.5178)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:42

 Epoch: 265	Training Loss 0.5334 	Training Prec@1 81.466 	Training Prec@5 99.202 	Validation Loss 0.6316 	Validation Prec@1 79.100 	Validation Prec@5 98.960 

lr: 0.08445518400406408
TRAINING - Epoch: [265][0/196]	Time 0.797 (0.797)	Data 0.110 (0.110)	Loss 0.6129 (0.6129)	Prec@1 78.516 (78.516)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [265][100/196]	Time 0.028 (0.084)	Data 0.000 (0.001)	Loss 0.4943 (0.5368)	Prec@1 82.422 (81.327)	Prec@5 98.828 (99.176)
EVALUATING - Epoch: [265][0/79]	Time 0.076 (0.076)	Data 0.057 (0.057)	Loss 0.6664 (0.6664)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:15

 Epoch: 266	Training Loss 0.5387 	Training Prec@1 81.228 	Training Prec@5 99.110 	Validation Loss 0.7639 	Validation Prec@1 74.860 	Validation Prec@5 98.340 

lr: 0.0843407121825626
TRAINING - Epoch: [266][0/196]	Time 0.758 (0.758)	Data 0.102 (0.102)	Loss 0.4533 (0.4533)	Prec@1 82.422 (82.422)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [266][100/196]	Time 0.092 (0.092)	Data 0.000 (0.001)	Loss 0.5145 (0.5236)	Prec@1 82.031 (81.470)	Prec@5 99.609 (99.165)
EVALUATING - Epoch: [266][0/79]	Time 0.079 (0.079)	Data 0.061 (0.061)	Loss 0.8073 (0.8073)	Prec@1 69.531 (69.531)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:15

 Epoch: 267	Training Loss 0.5316 	Training Prec@1 81.370 	Training Prec@5 99.160 	Validation Loss 0.7500 	Validation Prec@1 75.210 	Validation Prec@5 98.650 

lr: 0.08422589872287038
TRAINING - Epoch: [267][0/196]	Time 0.732 (0.732)	Data 0.092 (0.092)	Loss 0.4878 (0.4878)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [267][100/196]	Time 0.083 (0.093)	Data 0.000 (0.001)	Loss 0.5138 (0.5196)	Prec@1 82.031 (81.737)	Prec@5 100.000 (99.176)
EVALUATING - Epoch: [267][0/79]	Time 0.078 (0.078)	Data 0.058 (0.058)	Loss 0.4914 (0.4914)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:30

 Epoch: 268	Training Loss 0.5273 	Training Prec@1 81.648 	Training Prec@5 99.040 	Validation Loss 0.7329 	Validation Prec@1 75.330 	Validation Prec@5 98.600 

lr: 0.08411074476726987
TRAINING - Epoch: [268][0/196]	Time 0.543 (0.543)	Data 0.164 (0.164)	Loss 0.6340 (0.6340)	Prec@1 74.219 (74.219)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [268][100/196]	Time 0.083 (0.091)	Data 0.000 (0.002)	Loss 0.4622 (0.5313)	Prec@1 83.594 (81.200)	Prec@5 99.609 (99.196)
EVALUATING - Epoch: [268][0/79]	Time 0.081 (0.081)	Data 0.062 (0.062)	Loss 0.7657 (0.7657)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:52:09

 Epoch: 269	Training Loss 0.5346 	Training Prec@1 81.280 	Training Prec@5 99.136 	Validation Loss 0.8443 	Validation Prec@1 71.930 	Validation Prec@5 97.620 

lr: 0.08399525146143116
TRAINING - Epoch: [269][0/196]	Time 0.802 (0.802)	Data 0.105 (0.105)	Loss 0.5118 (0.5118)	Prec@1 82.031 (82.031)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [269][100/196]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.5471 (0.5362)	Prec@1 82.422 (81.656)	Prec@5 98.438 (99.091)
EVALUATING - Epoch: [269][0/79]	Time 0.072 (0.072)	Data 0.050 (0.050)	Loss 0.7393 (0.7393)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:02

 Epoch: 270	Training Loss 0.5317 	Training Prec@1 81.766 	Training Prec@5 99.080 	Validation Loss 0.8903 	Validation Prec@1 70.240 	Validation Prec@5 98.400 

lr: 0.08387941995440051
TRAINING - Epoch: [270][0/196]	Time 0.934 (0.934)	Data 0.254 (0.254)	Loss 0.5214 (0.5214)	Prec@1 80.469 (80.469)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [270][100/196]	Time 0.028 (0.087)	Data 0.000 (0.003)	Loss 0.6505 (0.5320)	Prec@1 78.516 (81.347)	Prec@5 98.828 (99.176)
EVALUATING - Epoch: [270][0/79]	Time 0.075 (0.075)	Data 0.057 (0.057)	Loss 0.8927 (0.8927)	Prec@1 72.656 (72.656)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:30

 Epoch: 271	Training Loss 0.5345 	Training Prec@1 81.382 	Training Prec@5 99.132 	Validation Loss 0.8704 	Validation Prec@1 72.320 	Validation Prec@5 98.090 

lr: 0.08376325139858902
TRAINING - Epoch: [271][0/196]	Time 0.793 (0.793)	Data 0.089 (0.089)	Loss 0.4897 (0.4897)	Prec@1 82.031 (82.031)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [271][100/196]	Time 0.087 (0.093)	Data 0.000 (0.001)	Loss 0.4177 (0.5373)	Prec@1 83.984 (81.378)	Prec@5 100.000 (99.180)
EVALUATING - Epoch: [271][0/79]	Time 0.083 (0.083)	Data 0.060 (0.060)	Loss 0.5820 (0.5820)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:13

 Epoch: 272	Training Loss 0.5408 	Training Prec@1 81.136 	Training Prec@5 99.126 	Validation Loss 0.9159 	Validation Prec@1 71.050 	Validation Prec@5 97.690 

lr: 0.083646746949761
TRAINING - Epoch: [272][0/196]	Time 0.756 (0.756)	Data 0.082 (0.082)	Loss 0.4058 (0.4058)	Prec@1 88.281 (88.281)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [272][100/196]	Time 0.089 (0.093)	Data 0.000 (0.001)	Loss 0.6123 (0.5396)	Prec@1 76.562 (81.231)	Prec@5 99.219 (99.153)
EVALUATING - Epoch: [272][0/79]	Time 0.088 (0.088)	Data 0.070 (0.070)	Loss 0.5308 (0.5308)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:45

 Epoch: 273	Training Loss 0.5296 	Training Prec@1 81.562 	Training Prec@5 99.160 	Validation Loss 0.7771 	Validation Prec@1 74.500 	Validation Prec@5 98.310 

lr: 0.08352990776702265
TRAINING - Epoch: [273][0/196]	Time 0.334 (0.334)	Data 0.106 (0.106)	Loss 0.4778 (0.4778)	Prec@1 82.812 (82.812)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [273][100/196]	Time 0.080 (0.090)	Data 0.000 (0.001)	Loss 0.5969 (0.5282)	Prec@1 79.297 (81.509)	Prec@5 99.609 (99.130)
EVALUATING - Epoch: [273][0/79]	Time 0.078 (0.078)	Data 0.057 (0.057)	Loss 0.6946 (0.6946)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:49:18

 Epoch: 274	Training Loss 0.5265 	Training Prec@1 81.422 	Training Prec@5 99.186 	Validation Loss 0.7002 	Validation Prec@1 76.190 	Validation Prec@5 98.590 

lr: 0.08341273501281042
TRAINING - Epoch: [274][0/196]	Time 0.718 (0.718)	Data 0.080 (0.080)	Loss 0.4332 (0.4332)	Prec@1 84.766 (84.766)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [274][100/196]	Time 0.086 (0.083)	Data 0.000 (0.001)	Loss 0.4718 (0.5350)	Prec@1 82.031 (81.119)	Prec@5 99.609 (99.188)
EVALUATING - Epoch: [274][0/79]	Time 0.083 (0.083)	Data 0.062 (0.062)	Loss 0.5935 (0.5935)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:59

 Epoch: 275	Training Loss 0.5295 	Training Prec@1 81.512 	Training Prec@5 99.160 	Validation Loss 0.7079 	Validation Prec@1 76.380 	Validation Prec@5 98.490 

lr: 0.08329522985287945
TRAINING - Epoch: [275][0/196]	Time 0.846 (0.846)	Data 0.118 (0.118)	Loss 0.5056 (0.5056)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [275][100/196]	Time 0.028 (0.089)	Data 0.000 (0.001)	Loss 0.5060 (0.5273)	Prec@1 83.203 (81.637)	Prec@5 98.828 (99.192)
EVALUATING - Epoch: [275][0/79]	Time 0.082 (0.082)	Data 0.064 (0.064)	Loss 0.8777 (0.8777)	Prec@1 70.312 (70.312)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:07

 Epoch: 276	Training Loss 0.5247 	Training Prec@1 81.634 	Training Prec@5 99.200 	Validation Loss 0.7981 	Validation Prec@1 73.640 	Validation Prec@5 98.450 

lr: 0.08317739345629203
TRAINING - Epoch: [276][0/196]	Time 0.817 (0.817)	Data 0.087 (0.087)	Loss 0.5808 (0.5808)	Prec@1 80.859 (80.859)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [276][100/196]	Time 0.093 (0.093)	Data 0.000 (0.001)	Loss 0.5167 (0.5325)	Prec@1 83.203 (81.451)	Prec@5 99.609 (99.134)
EVALUATING - Epoch: [276][0/79]	Time 0.086 (0.086)	Data 0.068 (0.068)	Loss 0.8261 (0.8261)	Prec@1 73.438 (73.438)	Prec@5 96.875 (96.875)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:55

 Epoch: 277	Training Loss 0.5316 	Training Prec@1 81.528 	Training Prec@5 99.148 	Validation Loss 0.9083 	Validation Prec@1 71.160 	Validation Prec@5 97.390 

lr: 0.08305922699540591
TRAINING - Epoch: [277][0/196]	Time 0.846 (0.846)	Data 0.105 (0.105)	Loss 0.5348 (0.5348)	Prec@1 83.203 (83.203)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [277][100/196]	Time 0.087 (0.094)	Data 0.000 (0.001)	Loss 0.5668 (0.5295)	Prec@1 78.516 (81.749)	Prec@5 98.438 (99.172)
EVALUATING - Epoch: [277][0/79]	Time 0.079 (0.079)	Data 0.059 (0.059)	Loss 0.9739 (0.9739)	Prec@1 68.750 (68.750)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:06

 Epoch: 278	Training Loss 0.5326 	Training Prec@1 81.556 	Training Prec@5 99.134 	Validation Loss 0.8335 	Validation Prec@1 73.360 	Validation Prec@5 98.510 

lr: 0.08294073164586269
TRAINING - Epoch: [278][0/196]	Time 0.680 (0.680)	Data 0.087 (0.087)	Loss 0.3916 (0.3916)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [278][100/196]	Time 0.061 (0.092)	Data 0.000 (0.001)	Loss 0.5588 (0.5329)	Prec@1 83.203 (81.625)	Prec@5 98.047 (99.033)
EVALUATING - Epoch: [278][0/79]	Time 0.077 (0.077)	Data 0.056 (0.056)	Loss 0.7839 (0.7839)	Prec@1 71.875 (71.875)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:48:03

 Epoch: 279	Training Loss 0.5298 	Training Prec@1 81.568 	Training Prec@5 99.082 	Validation Loss 1.0162 	Validation Prec@1 68.890 	Validation Prec@5 97.550 

lr: 0.08282190858657604
TRAINING - Epoch: [279][0/196]	Time 0.764 (0.764)	Data 0.098 (0.098)	Loss 0.4698 (0.4698)	Prec@1 84.375 (84.375)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [279][100/196]	Time 0.091 (0.081)	Data 0.000 (0.001)	Loss 0.5184 (0.5333)	Prec@1 84.766 (81.548)	Prec@5 99.219 (99.165)
EVALUATING - Epoch: [279][0/79]	Time 0.079 (0.079)	Data 0.056 (0.056)	Loss 1.1595 (1.1595)	Prec@1 63.281 (63.281)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:38

 Epoch: 280	Training Loss 0.5304 	Training Prec@1 81.670 	Training Prec@5 99.182 	Validation Loss 1.1494 	Validation Prec@1 67.140 	Validation Prec@5 98.090 

lr: 0.08270275899972007
TRAINING - Epoch: [280][0/196]	Time 0.810 (0.810)	Data 0.105 (0.105)	Loss 0.4604 (0.4604)	Prec@1 84.766 (84.766)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [280][100/196]	Time 0.057 (0.090)	Data 0.000 (0.001)	Loss 0.5308 (0.5255)	Prec@1 82.812 (81.532)	Prec@5 98.438 (99.126)
EVALUATING - Epoch: [280][0/79]	Time 0.077 (0.077)	Data 0.060 (0.060)	Loss 0.7825 (0.7825)	Prec@1 67.969 (67.969)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:13

 Epoch: 281	Training Loss 0.5301 	Training Prec@1 81.428 	Training Prec@5 99.120 	Validation Loss 0.9178 	Validation Prec@1 71.140 	Validation Prec@5 97.720 

lr: 0.08258328407071751
TRAINING - Epoch: [281][0/196]	Time 0.782 (0.782)	Data 0.084 (0.084)	Loss 0.4269 (0.4269)	Prec@1 86.328 (86.328)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [281][100/196]	Time 0.065 (0.094)	Data 0.000 (0.001)	Loss 0.5091 (0.5276)	Prec@1 82.422 (81.703)	Prec@5 99.219 (99.130)
EVALUATING - Epoch: [281][0/79]	Time 0.081 (0.081)	Data 0.060 (0.060)	Loss 0.9130 (0.9130)	Prec@1 67.969 (67.969)	Prec@5 96.094 (96.094)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:49

 Epoch: 282	Training Loss 0.5323 	Training Prec@1 81.442 	Training Prec@5 99.106 	Validation Loss 0.8733 	Validation Prec@1 72.370 	Validation Prec@5 98.210 

lr: 0.08246348498822793
TRAINING - Epoch: [282][0/196]	Time 0.801 (0.801)	Data 0.080 (0.080)	Loss 0.4900 (0.4900)	Prec@1 83.984 (83.984)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [282][100/196]	Time 0.087 (0.095)	Data 0.000 (0.001)	Loss 0.5465 (0.5383)	Prec@1 82.812 (81.192)	Prec@5 98.828 (99.114)
EVALUATING - Epoch: [282][0/79]	Time 0.093 (0.093)	Data 0.065 (0.065)	Loss 0.7608 (0.7608)	Prec@1 70.312 (70.312)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:50:38

 Epoch: 283	Training Loss 0.5387 	Training Prec@1 81.156 	Training Prec@5 99.160 	Validation Loss 0.7981 	Validation Prec@1 74.030 	Validation Prec@5 98.310 

lr: 0.08234336294413588
TRAINING - Epoch: [283][0/196]	Time 0.825 (0.825)	Data 0.097 (0.097)	Loss 0.5249 (0.5249)	Prec@1 82.422 (82.422)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [283][100/196]	Time 0.085 (0.094)	Data 0.000 (0.001)	Loss 0.4939 (0.5304)	Prec@1 80.469 (81.563)	Prec@5 99.609 (99.122)
EVALUATING - Epoch: [283][0/79]	Time 0.075 (0.075)	Data 0.056 (0.056)	Loss 0.8714 (0.8714)	Prec@1 73.438 (73.438)	Prec@5 96.094 (96.094)
Time cost: 00:18	Time of Finish: 2024-03-31 19:51:29

 Epoch: 284	Training Loss 0.5317 	Training Prec@1 81.516 	Training Prec@5 99.106 	Validation Loss 0.8148 	Validation Prec@1 73.620 	Validation Prec@5 98.020 

lr: 0.08222291913353913
TRAINING - Epoch: [284][0/196]	Time 0.817 (0.817)	Data 0.111 (0.111)	Loss 0.5194 (0.5194)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [284][100/196]	Time 0.096 (0.085)	Data 0.000 (0.001)	Loss 0.4870 (0.5262)	Prec@1 83.594 (81.548)	Prec@5 98.438 (99.118)
EVALUATING - Epoch: [284][0/79]	Time 0.072 (0.072)	Data 0.050 (0.050)	Loss 0.8382 (0.8382)	Prec@1 71.875 (71.875)	Prec@5 96.875 (96.875)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:07

 Epoch: 285	Training Loss 0.5306 	Training Prec@1 81.362 	Training Prec@5 99.140 	Validation Loss 0.9705 	Validation Prec@1 68.900 	Validation Prec@5 97.280 

lr: 0.08210215475473666
TRAINING - Epoch: [285][0/196]	Time 0.826 (0.826)	Data 0.109 (0.109)	Loss 0.6841 (0.6841)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [285][100/196]	Time 0.084 (0.084)	Data 0.000 (0.001)	Loss 0.6610 (0.5198)	Prec@1 75.391 (81.737)	Prec@5 98.828 (99.219)
EVALUATING - Epoch: [285][0/79]	Time 0.084 (0.084)	Data 0.064 (0.064)	Loss 0.8241 (0.8241)	Prec@1 73.438 (73.438)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:57

 Epoch: 286	Training Loss 0.5297 	Training Prec@1 81.382 	Training Prec@5 99.198 	Validation Loss 0.8204 	Validation Prec@1 73.400 	Validation Prec@5 98.370 

lr: 0.0819810710092168
TRAINING - Epoch: [286][0/196]	Time 0.724 (0.724)	Data 0.082 (0.082)	Loss 0.6065 (0.6065)	Prec@1 78.516 (78.516)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [286][100/196]	Time 0.093 (0.093)	Data 0.000 (0.001)	Loss 0.5647 (0.5204)	Prec@1 78.906 (81.962)	Prec@5 99.609 (99.138)
EVALUATING - Epoch: [286][0/79]	Time 0.082 (0.082)	Data 0.062 (0.062)	Loss 1.5003 (1.5003)	Prec@1 60.156 (60.156)	Prec@5 90.625 (90.625)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:18

 Epoch: 287	Training Loss 0.5169 	Training Prec@1 82.154 	Training Prec@5 99.160 	Validation Loss 1.5092 	Validation Prec@1 60.250 	Validation Prec@5 91.960 

lr: 0.08185966910164529
TRAINING - Epoch: [287][0/196]	Time 0.773 (0.773)	Data 0.106 (0.106)	Loss 0.6568 (0.6568)	Prec@1 76.953 (76.953)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [287][100/196]	Time 0.088 (0.094)	Data 0.000 (0.001)	Loss 0.4409 (0.5217)	Prec@1 83.984 (81.869)	Prec@5 100.000 (99.296)
EVALUATING - Epoch: [287][0/79]	Time 0.082 (0.082)	Data 0.064 (0.064)	Loss 0.5650 (0.5650)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:21

 Epoch: 288	Training Loss 0.5263 	Training Prec@1 81.620 	Training Prec@5 99.178 	Validation Loss 0.7085 	Validation Prec@1 76.380 	Validation Prec@5 98.630 

lr: 0.08173795023985325
TRAINING - Epoch: [288][0/196]	Time 0.805 (0.805)	Data 0.090 (0.090)	Loss 0.4420 (0.4420)	Prec@1 83.984 (83.984)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [288][100/196]	Time 0.092 (0.094)	Data 0.000 (0.001)	Loss 0.4305 (0.5275)	Prec@1 84.375 (81.745)	Prec@5 99.609 (99.203)
EVALUATING - Epoch: [288][0/79]	Time 0.074 (0.074)	Data 0.054 (0.054)	Loss 0.6787 (0.6787)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:52:18

 Epoch: 289	Training Loss 0.5317 	Training Prec@1 81.606 	Training Prec@5 99.114 	Validation Loss 0.6621 	Validation Prec@1 77.490 	Validation Prec@5 98.720 

lr: 0.08161591563482523
TRAINING - Epoch: [289][0/196]	Time 0.764 (0.764)	Data 0.109 (0.109)	Loss 0.5020 (0.5020)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [289][100/196]	Time 0.091 (0.083)	Data 0.000 (0.001)	Loss 0.4938 (0.5186)	Prec@1 82.812 (81.834)	Prec@5 99.219 (99.134)
EVALUATING - Epoch: [289][0/79]	Time 0.072 (0.072)	Data 0.049 (0.049)	Loss 0.5942 (0.5942)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:17

 Epoch: 290	Training Loss 0.5185 	Training Prec@1 81.836 	Training Prec@5 99.152 	Validation Loss 0.8004 	Validation Prec@1 73.210 	Validation Prec@5 98.440 

lr: 0.08149356650068704
TRAINING - Epoch: [290][0/196]	Time 0.801 (0.801)	Data 0.088 (0.088)	Loss 0.5797 (0.5797)	Prec@1 78.906 (78.906)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [290][100/196]	Time 0.089 (0.086)	Data 0.000 (0.001)	Loss 0.4948 (0.5363)	Prec@1 81.641 (81.354)	Prec@5 98.828 (99.114)
EVALUATING - Epoch: [290][0/79]	Time 0.084 (0.084)	Data 0.063 (0.063)	Loss 0.5633 (0.5633)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:21

 Epoch: 291	Training Loss 0.5330 	Training Prec@1 81.572 	Training Prec@5 99.150 	Validation Loss 0.7585 	Validation Prec@1 74.800 	Validation Prec@5 98.180 

lr: 0.08137090405469381
TRAINING - Epoch: [291][0/196]	Time 0.772 (0.772)	Data 0.096 (0.096)	Loss 0.5837 (0.5837)	Prec@1 80.859 (80.859)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [291][100/196]	Time 0.088 (0.094)	Data 0.000 (0.001)	Loss 0.4721 (0.5295)	Prec@1 85.156 (81.629)	Prec@5 99.609 (99.145)
EVALUATING - Epoch: [291][0/79]	Time 0.084 (0.084)	Data 0.063 (0.063)	Loss 0.8678 (0.8678)	Prec@1 73.438 (73.438)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:35:18

 Epoch: 292	Training Loss 0.5224 	Training Prec@1 81.726 	Training Prec@5 99.150 	Validation Loss 0.8165 	Validation Prec@1 72.360 	Validation Prec@5 98.270 

lr: 0.08124792951721783
TRAINING - Epoch: [292][0/196]	Time 0.797 (0.797)	Data 0.079 (0.079)	Loss 0.4141 (0.4141)	Prec@1 84.766 (84.766)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [292][100/196]	Time 0.101 (0.095)	Data 0.000 (0.001)	Loss 0.5396 (0.5251)	Prec@1 80.469 (81.749)	Prec@5 98.828 (99.114)
EVALUATING - Epoch: [292][0/79]	Time 0.079 (0.079)	Data 0.062 (0.062)	Loss 0.8565 (0.8565)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:14

 Epoch: 293	Training Loss 0.5239 	Training Prec@1 81.690 	Training Prec@5 99.106 	Validation Loss 0.7924 	Validation Prec@1 75.340 	Validation Prec@5 98.120 

lr: 0.08112464411173637
TRAINING - Epoch: [293][0/196]	Time 0.747 (0.747)	Data 0.091 (0.091)	Loss 0.4733 (0.4733)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [293][100/196]	Time 0.092 (0.094)	Data 0.000 (0.001)	Loss 0.6585 (0.5182)	Prec@1 76.172 (81.869)	Prec@5 98.047 (99.180)
EVALUATING - Epoch: [293][0/79]	Time 0.070 (0.070)	Data 0.049 (0.049)	Loss 0.8429 (0.8429)	Prec@1 75.000 (75.000)	Prec@5 96.094 (96.094)
Time cost: 00:18	Time of Finish: 2024-03-31 19:53:39

 Epoch: 294	Training Loss 0.5243 	Training Prec@1 81.884 	Training Prec@5 99.132 	Validation Loss 1.0052 	Validation Prec@1 67.400 	Validation Prec@5 95.630 

lr: 0.08100104906481952
TRAINING - Epoch: [294][0/196]	Time 0.712 (0.712)	Data 0.080 (0.080)	Loss 0.5272 (0.5272)	Prec@1 82.422 (82.422)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [294][100/196]	Time 0.079 (0.080)	Data 0.000 (0.001)	Loss 0.5906 (0.5401)	Prec@1 79.688 (81.323)	Prec@5 98.047 (99.130)
EVALUATING - Epoch: [294][0/79]	Time 0.085 (0.085)	Data 0.064 (0.064)	Loss 0.7298 (0.7298)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:33

 Epoch: 295	Training Loss 0.5392 	Training Prec@1 81.408 	Training Prec@5 99.110 	Validation Loss 0.8200 	Validation Prec@1 72.930 	Validation Prec@5 98.600 

lr: 0.08087714560611801
TRAINING - Epoch: [295][0/196]	Time 0.733 (0.733)	Data 0.100 (0.100)	Loss 0.4355 (0.4355)	Prec@1 83.203 (83.203)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [295][100/196]	Time 0.057 (0.087)	Data 0.000 (0.001)	Loss 0.5089 (0.5090)	Prec@1 83.594 (82.519)	Prec@5 98.828 (99.211)
EVALUATING - Epoch: [295][0/79]	Time 0.074 (0.074)	Data 0.054 (0.054)	Loss 0.6721 (0.6721)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:10

 Epoch: 296	Training Loss 0.5124 	Training Prec@1 82.230 	Training Prec@5 99.180 	Validation Loss 0.6671 	Validation Prec@1 77.690 	Validation Prec@5 98.970 

lr: 0.080752934968351
TRAINING - Epoch: [296][0/196]	Time 0.803 (0.803)	Data 0.083 (0.083)	Loss 0.5772 (0.5772)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [296][100/196]	Time 0.085 (0.093)	Data 0.000 (0.001)	Loss 0.5469 (0.5176)	Prec@1 82.031 (81.919)	Prec@5 98.047 (99.176)
EVALUATING - Epoch: [296][0/79]	Time 0.080 (0.080)	Data 0.065 (0.065)	Loss 1.0130 (1.0130)	Prec@1 67.969 (67.969)	Prec@5 96.094 (96.094)
Time cost: 00:17	Time of Finish: 2024-03-31 19:32:43

 Epoch: 297	Training Loss 0.5214 	Training Prec@1 81.814 	Training Prec@5 99.180 	Validation Loss 1.0609 	Validation Prec@1 68.470 	Validation Prec@5 96.800 

lr: 0.08062841838729376
TRAINING - Epoch: [297][0/196]	Time 0.842 (0.842)	Data 0.109 (0.109)	Loss 0.4506 (0.4506)	Prec@1 83.984 (83.984)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [297][100/196]	Time 0.083 (0.094)	Data 0.000 (0.001)	Loss 0.5462 (0.5200)	Prec@1 81.641 (81.648)	Prec@5 99.609 (99.238)
EVALUATING - Epoch: [297][0/79]	Time 0.078 (0.078)	Data 0.057 (0.057)	Loss 0.6763 (0.6763)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:51:30

 Epoch: 298	Training Loss 0.5244 	Training Prec@1 81.664 	Training Prec@5 99.200 	Validation Loss 0.7714 	Validation Prec@1 74.720 	Validation Prec@5 98.330 

lr: 0.08050359710176537
TRAINING - Epoch: [298][0/196]	Time 0.480 (0.480)	Data 0.096 (0.096)	Loss 0.4790 (0.4790)	Prec@1 82.422 (82.422)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [298][100/196]	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 0.4405 (0.5203)	Prec@1 86.328 (81.969)	Prec@5 98.828 (99.107)
EVALUATING - Epoch: [298][0/79]	Time 0.074 (0.074)	Data 0.054 (0.054)	Loss 0.9374 (0.9374)	Prec@1 66.406 (66.406)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:41:59

 Epoch: 299	Training Loss 0.5217 	Training Prec@1 81.942 	Training Prec@5 99.152 	Validation Loss 0.9564 	Validation Prec@1 69.510 	Validation Prec@5 96.430 

lr: 0.0803784723536165
TRAINING - Epoch: [299][0/196]	Time 0.836 (0.836)	Data 0.110 (0.110)	Loss 0.5024 (0.5024)	Prec@1 81.641 (81.641)	Prec@5 96.875 (96.875)
TRAINING - Epoch: [299][100/196]	Time 0.078 (0.081)	Data 0.000 (0.001)	Loss 0.4236 (0.5187)	Prec@1 87.109 (81.606)	Prec@5 99.609 (99.153)
EVALUATING - Epoch: [299][0/79]	Time 0.086 (0.086)	Data 0.064 (0.064)	Loss 0.6581 (0.6581)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:01

 Epoch: 300	Training Loss 0.5217 	Training Prec@1 81.746 	Training Prec@5 99.142 	Validation Loss 0.8520 	Validation Prec@1 72.420 	Validation Prec@5 97.860 

lr: 0.0802530453877169
TRAINING - Epoch: [300][0/196]	Time 0.783 (0.783)	Data 0.102 (0.102)	Loss 0.5222 (0.5222)	Prec@1 82.812 (82.812)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [300][100/196]	Time 0.072 (0.093)	Data 0.000 (0.001)	Loss 0.5396 (0.5219)	Prec@1 81.641 (81.830)	Prec@5 99.609 (99.153)
EVALUATING - Epoch: [300][0/79]	Time 0.086 (0.086)	Data 0.066 (0.066)	Loss 0.5539 (0.5539)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:43

 Epoch: 301	Training Loss 0.5224 	Training Prec@1 81.856 	Training Prec@5 99.154 	Validation Loss 0.6880 	Validation Prec@1 76.820 	Validation Prec@5 98.900 

lr: 0.08012731745194311
TRAINING - Epoch: [301][0/196]	Time 0.760 (0.760)	Data 0.108 (0.108)	Loss 0.4609 (0.4609)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [301][100/196]	Time 0.090 (0.093)	Data 0.000 (0.001)	Loss 0.4987 (0.5219)	Prec@1 83.594 (81.641)	Prec@5 99.609 (99.269)
EVALUATING - Epoch: [301][0/79]	Time 0.073 (0.073)	Data 0.053 (0.053)	Loss 0.8783 (0.8783)	Prec@1 67.969 (67.969)	Prec@5 96.875 (96.875)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:37

 Epoch: 302	Training Loss 0.5187 	Training Prec@1 81.936 	Training Prec@5 99.260 	Validation Loss 0.8592 	Validation Prec@1 72.960 	Validation Prec@5 98.220 

lr: 0.08000128979716607
TRAINING - Epoch: [302][0/196]	Time 0.785 (0.785)	Data 0.082 (0.082)	Loss 0.4218 (0.4218)	Prec@1 84.766 (84.766)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [302][100/196]	Time 0.086 (0.093)	Data 0.000 (0.001)	Loss 0.5808 (0.5294)	Prec@1 80.469 (81.482)	Prec@5 99.219 (99.165)
EVALUATING - Epoch: [302][0/79]	Time 0.075 (0.075)	Data 0.054 (0.054)	Loss 0.7380 (0.7380)	Prec@1 75.781 (75.781)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:52:20

 Epoch: 303	Training Loss 0.5241 	Training Prec@1 81.664 	Training Prec@5 99.186 	Validation Loss 0.8993 	Validation Prec@1 71.950 	Validation Prec@5 97.330 

lr: 0.07987496367723862
TRAINING - Epoch: [303][0/196]	Time 0.642 (0.642)	Data 0.088 (0.088)	Loss 0.6313 (0.6313)	Prec@1 77.734 (77.734)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [303][100/196]	Time 0.093 (0.084)	Data 0.000 (0.001)	Loss 0.5691 (0.5280)	Prec@1 79.688 (81.695)	Prec@5 99.219 (99.087)
EVALUATING - Epoch: [303][0/79]	Time 0.076 (0.076)	Data 0.056 (0.056)	Loss 0.7938 (0.7938)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:20

 Epoch: 304	Training Loss 0.5226 	Training Prec@1 81.718 	Training Prec@5 99.110 	Validation Loss 0.8423 	Validation Prec@1 73.330 	Validation Prec@5 97.730 

lr: 0.079748340348983
TRAINING - Epoch: [304][0/196]	Time 0.802 (0.802)	Data 0.106 (0.106)	Loss 0.5323 (0.5323)	Prec@1 81.641 (81.641)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [304][100/196]	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 0.5093 (0.5213)	Prec@1 81.250 (81.954)	Prec@5 98.438 (99.172)
EVALUATING - Epoch: [304][0/79]	Time 0.075 (0.075)	Data 0.053 (0.053)	Loss 0.7540 (0.7540)	Prec@1 76.562 (76.562)	Prec@5 96.094 (96.094)
Time cost: 00:17	Time of Finish: 2024-03-31 19:38:59

 Epoch: 305	Training Loss 0.5220 	Training Prec@1 81.950 	Training Prec@5 99.152 	Validation Loss 0.7937 	Validation Prec@1 74.350 	Validation Prec@5 98.210 

lr: 0.0796214210721784
TRAINING - Epoch: [305][0/196]	Time 0.772 (0.772)	Data 0.093 (0.093)	Loss 0.5886 (0.5886)	Prec@1 81.641 (81.641)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [305][100/196]	Time 0.069 (0.092)	Data 0.000 (0.001)	Loss 0.4857 (0.5160)	Prec@1 83.594 (81.911)	Prec@5 99.609 (99.288)
EVALUATING - Epoch: [305][0/79]	Time 0.071 (0.071)	Data 0.049 (0.049)	Loss 0.6503 (0.6503)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:36:21

 Epoch: 306	Training Loss 0.5217 	Training Prec@1 81.626 	Training Prec@5 99.222 	Validation Loss 0.7623 	Validation Prec@1 74.200 	Validation Prec@5 98.350 

lr: 0.07949420710954842
TRAINING - Epoch: [306][0/196]	Time 0.734 (0.734)	Data 0.080 (0.080)	Loss 0.5605 (0.5605)	Prec@1 82.422 (82.422)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [306][100/196]	Time 0.091 (0.093)	Data 0.000 (0.001)	Loss 0.5444 (0.5213)	Prec@1 82.812 (81.552)	Prec@5 99.609 (99.161)
EVALUATING - Epoch: [306][0/79]	Time 0.084 (0.084)	Data 0.061 (0.061)	Loss 0.6119 (0.6119)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:03

 Epoch: 307	Training Loss 0.5224 	Training Prec@1 81.652 	Training Prec@5 99.164 	Validation Loss 0.6516 	Validation Prec@1 77.550 	Validation Prec@5 98.820 

lr: 0.07936669972674854
TRAINING - Epoch: [307][0/196]	Time 0.766 (0.766)	Data 0.098 (0.098)	Loss 0.5048 (0.5048)	Prec@1 80.469 (80.469)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [307][100/196]	Time 0.090 (0.093)	Data 0.000 (0.001)	Loss 0.6784 (0.5232)	Prec@1 75.781 (81.838)	Prec@5 99.609 (99.176)
EVALUATING - Epoch: [307][0/79]	Time 0.069 (0.069)	Data 0.050 (0.050)	Loss 0.9814 (0.9814)	Prec@1 67.969 (67.969)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:51:16

 Epoch: 308	Training Loss 0.5239 	Training Prec@1 81.838 	Training Prec@5 99.168 	Validation Loss 1.0083 	Validation Prec@1 69.060 	Validation Prec@5 98.060 

lr: 0.0792389001923534
TRAINING - Epoch: [308][0/196]	Time 0.806 (0.806)	Data 0.092 (0.092)	Loss 0.4643 (0.4643)	Prec@1 83.203 (83.203)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [308][100/196]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.4797 (0.5215)	Prec@1 83.203 (81.880)	Prec@5 99.219 (99.145)
EVALUATING - Epoch: [308][0/79]	Time 0.092 (0.092)	Data 0.073 (0.073)	Loss 0.8137 (0.8137)	Prec@1 71.875 (71.875)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:52

 Epoch: 309	Training Loss 0.5234 	Training Prec@1 81.774 	Training Prec@5 99.144 	Validation Loss 0.8017 	Validation Prec@1 74.450 	Validation Prec@5 98.350 

lr: 0.07911080977784431
TRAINING - Epoch: [309][0/196]	Time 0.800 (0.800)	Data 0.084 (0.084)	Loss 0.4954 (0.4954)	Prec@1 80.469 (80.469)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [309][100/196]	Time 0.092 (0.085)	Data 0.000 (0.001)	Loss 0.4684 (0.5264)	Prec@1 82.422 (81.389)	Prec@5 99.609 (99.145)
EVALUATING - Epoch: [309][0/79]	Time 0.079 (0.079)	Data 0.058 (0.058)	Loss 0.6312 (0.6312)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:01

 Epoch: 310	Training Loss 0.5239 	Training Prec@1 81.642 	Training Prec@5 99.138 	Validation Loss 0.6128 	Validation Prec@1 79.220 	Validation Prec@5 98.960 

lr: 0.07898242975759656
TRAINING - Epoch: [310][0/196]	Time 0.681 (0.681)	Data 0.084 (0.084)	Loss 0.5719 (0.5719)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [310][100/196]	Time 0.089 (0.093)	Data 0.000 (0.001)	Loss 0.5318 (0.5187)	Prec@1 83.594 (81.896)	Prec@5 98.828 (99.246)
EVALUATING - Epoch: [310][0/79]	Time 0.076 (0.076)	Data 0.056 (0.056)	Loss 0.7678 (0.7678)	Prec@1 73.438 (73.438)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:36:34

 Epoch: 311	Training Loss 0.5184 	Training Prec@1 81.914 	Training Prec@5 99.224 	Validation Loss 0.7908 	Validation Prec@1 73.320 	Validation Prec@5 98.160 

lr: 0.07885376140886675
TRAINING - Epoch: [311][0/196]	Time 0.744 (0.744)	Data 0.087 (0.087)	Loss 0.4910 (0.4910)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [311][100/196]	Time 0.084 (0.092)	Data 0.000 (0.001)	Loss 0.4942 (0.5206)	Prec@1 83.984 (82.128)	Prec@5 99.219 (99.122)
EVALUATING - Epoch: [311][0/79]	Time 0.080 (0.080)	Data 0.059 (0.059)	Loss 0.6291 (0.6291)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:19

 Epoch: 312	Training Loss 0.5152 	Training Prec@1 82.216 	Training Prec@5 99.134 	Validation Loss 0.6137 	Validation Prec@1 79.280 	Validation Prec@5 98.990 

lr: 0.07872480601178002
TRAINING - Epoch: [312][0/196]	Time 0.774 (0.774)	Data 0.105 (0.105)	Loss 0.3359 (0.3359)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [312][100/196]	Time 0.091 (0.090)	Data 0.000 (0.001)	Loss 0.5218 (0.5198)	Prec@1 82.422 (82.074)	Prec@5 99.609 (99.230)
EVALUATING - Epoch: [312][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 0.6669 (0.6669)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:30

 Epoch: 313	Training Loss 0.5234 	Training Prec@1 81.986 	Training Prec@5 99.222 	Validation Loss 0.7392 	Validation Prec@1 75.060 	Validation Prec@5 98.530 

lr: 0.0785955648493174
TRAINING - Epoch: [313][0/196]	Time 0.791 (0.791)	Data 0.083 (0.083)	Loss 0.5528 (0.5528)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [313][100/196]	Time 0.082 (0.078)	Data 0.000 (0.001)	Loss 0.5934 (0.5200)	Prec@1 78.516 (82.004)	Prec@5 99.609 (99.172)
EVALUATING - Epoch: [313][0/79]	Time 0.075 (0.075)	Data 0.055 (0.055)	Loss 0.8164 (0.8164)	Prec@1 72.656 (72.656)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:36:20

 Epoch: 314	Training Loss 0.5200 	Training Prec@1 81.924 	Training Prec@5 99.184 	Validation Loss 0.8769 	Validation Prec@1 71.940 	Validation Prec@5 98.340 

lr: 0.07846603920730301
TRAINING - Epoch: [314][0/196]	Time 0.772 (0.772)	Data 0.082 (0.082)	Loss 0.5485 (0.5485)	Prec@1 80.859 (80.859)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [314][100/196]	Time 0.065 (0.088)	Data 0.000 (0.001)	Loss 0.5527 (0.5270)	Prec@1 82.422 (81.416)	Prec@5 98.438 (99.165)
EVALUATING - Epoch: [314][0/79]	Time 0.080 (0.080)	Data 0.053 (0.053)	Loss 0.9232 (0.9232)	Prec@1 71.094 (71.094)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:37

 Epoch: 315	Training Loss 0.5203 	Training Prec@1 81.724 	Training Prec@5 99.150 	Validation Loss 0.8610 	Validation Prec@1 72.730 	Validation Prec@5 97.810 

lr: 0.07833623037439122
TRAINING - Epoch: [315][0/196]	Time 0.741 (0.741)	Data 0.100 (0.100)	Loss 0.6299 (0.6299)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [315][100/196]	Time 0.087 (0.094)	Data 0.000 (0.001)	Loss 0.4819 (0.5110)	Prec@1 82.812 (82.082)	Prec@5 99.219 (99.180)
EVALUATING - Epoch: [315][0/79]	Time 0.075 (0.075)	Data 0.054 (0.054)	Loss 0.8966 (0.8966)	Prec@1 68.750 (68.750)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:52

 Epoch: 316	Training Loss 0.5169 	Training Prec@1 82.102 	Training Prec@5 99.168 	Validation Loss 0.9310 	Validation Prec@1 72.210 	Validation Prec@5 97.830 

lr: 0.07820613964205395
TRAINING - Epoch: [316][0/196]	Time 0.767 (0.767)	Data 0.092 (0.092)	Loss 0.4302 (0.4302)	Prec@1 83.984 (83.984)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [316][100/196]	Time 0.087 (0.093)	Data 0.000 (0.001)	Loss 0.5599 (0.5125)	Prec@1 79.688 (81.880)	Prec@5 98.828 (99.203)
EVALUATING - Epoch: [316][0/79]	Time 0.075 (0.075)	Data 0.052 (0.052)	Loss 0.8899 (0.8899)	Prec@1 71.875 (71.875)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:42

 Epoch: 317	Training Loss 0.5186 	Training Prec@1 81.798 	Training Prec@5 99.188 	Validation Loss 0.8899 	Validation Prec@1 71.880 	Validation Prec@5 97.870 

lr: 0.07807576830456768
TRAINING - Epoch: [317][0/196]	Time 0.779 (0.779)	Data 0.106 (0.106)	Loss 0.4482 (0.4482)	Prec@1 82.031 (82.031)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [317][100/196]	Time 0.079 (0.093)	Data 0.000 (0.001)	Loss 0.4591 (0.5072)	Prec@1 84.375 (82.283)	Prec@5 98.047 (99.165)
EVALUATING - Epoch: [317][0/79]	Time 0.073 (0.073)	Data 0.050 (0.050)	Loss 0.6421 (0.6421)	Prec@1 75.000 (75.000)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:52:32

 Epoch: 318	Training Loss 0.5158 	Training Prec@1 82.106 	Training Prec@5 99.174 	Validation Loss 0.7083 	Validation Prec@1 76.760 	Validation Prec@5 98.470 

lr: 0.07794511765900067
TRAINING - Epoch: [318][0/196]	Time 0.778 (0.778)	Data 0.080 (0.080)	Loss 0.5125 (0.5125)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [318][100/196]	Time 0.092 (0.082)	Data 0.000 (0.001)	Loss 0.4603 (0.5183)	Prec@1 83.203 (82.112)	Prec@5 99.219 (99.168)
EVALUATING - Epoch: [318][0/79]	Time 0.074 (0.074)	Data 0.051 (0.051)	Loss 0.9577 (0.9577)	Prec@1 74.219 (74.219)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:56

 Epoch: 319	Training Loss 0.5154 	Training Prec@1 82.188 	Training Prec@5 99.156 	Validation Loss 1.1362 	Validation Prec@1 65.630 	Validation Prec@5 98.040 

lr: 0.0778141890052
TRAINING - Epoch: [319][0/196]	Time 0.819 (0.819)	Data 0.079 (0.079)	Loss 0.5346 (0.5346)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [319][100/196]	Time 0.037 (0.085)	Data 0.000 (0.001)	Loss 0.4832 (0.5240)	Prec@1 82.031 (81.741)	Prec@5 99.609 (99.192)
EVALUATING - Epoch: [319][0/79]	Time 0.079 (0.079)	Data 0.056 (0.056)	Loss 1.3477 (1.3477)	Prec@1 55.469 (55.469)	Prec@5 95.312 (95.312)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:07

 Epoch: 320	Training Loss 0.5233 	Training Prec@1 81.846 	Training Prec@5 99.116 	Validation Loss 1.0509 	Validation Prec@1 67.380 	Validation Prec@5 96.520 

lr: 0.07768298364577869
TRAINING - Epoch: [320][0/196]	Time 0.817 (0.817)	Data 0.105 (0.105)	Loss 0.5320 (0.5320)	Prec@1 80.078 (80.078)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [320][100/196]	Time 0.083 (0.094)	Data 0.000 (0.001)	Loss 0.5433 (0.5146)	Prec@1 81.641 (81.989)	Prec@5 98.438 (99.196)
EVALUATING - Epoch: [320][0/79]	Time 0.080 (0.080)	Data 0.061 (0.061)	Loss 0.8868 (0.8868)	Prec@1 73.438 (73.438)	Prec@5 96.094 (96.094)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:27

 Epoch: 321	Training Loss 0.5160 	Training Prec@1 81.992 	Training Prec@5 99.158 	Validation Loss 0.8933 	Validation Prec@1 72.530 	Validation Prec@5 97.930 

lr: 0.07755150288610273
TRAINING - Epoch: [321][0/196]	Time 0.750 (0.750)	Data 0.096 (0.096)	Loss 0.4642 (0.4642)	Prec@1 84.375 (84.375)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [321][100/196]	Time 0.086 (0.094)	Data 0.000 (0.001)	Loss 0.4912 (0.5159)	Prec@1 81.250 (81.873)	Prec@5 99.219 (99.199)
EVALUATING - Epoch: [321][0/79]	Time 0.076 (0.076)	Data 0.056 (0.056)	Loss 0.6237 (0.6237)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:37

 Epoch: 322	Training Loss 0.5166 	Training Prec@1 81.816 	Training Prec@5 99.152 	Validation Loss 0.7670 	Validation Prec@1 75.760 	Validation Prec@5 98.490 

lr: 0.07741974803427798
TRAINING - Epoch: [322][0/196]	Time 0.610 (0.610)	Data 0.091 (0.091)	Loss 0.4712 (0.4712)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [322][100/196]	Time 0.090 (0.092)	Data 0.000 (0.001)	Loss 0.5476 (0.5164)	Prec@1 80.078 (82.016)	Prec@5 99.609 (99.215)
EVALUATING - Epoch: [322][0/79]	Time 0.071 (0.071)	Data 0.052 (0.052)	Loss 0.9972 (0.9972)	Prec@1 70.312 (70.312)	Prec@5 93.750 (93.750)
Time cost: 00:18	Time of Finish: 2024-03-31 19:50:44

 Epoch: 323	Training Loss 0.5097 	Training Prec@1 82.348 	Training Prec@5 99.182 	Validation Loss 0.8992 	Validation Prec@1 71.910 	Validation Prec@5 98.010 

lr: 0.07728772040113736
TRAINING - Epoch: [323][0/196]	Time 0.787 (0.787)	Data 0.096 (0.096)	Loss 0.5285 (0.5285)	Prec@1 82.031 (82.031)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [323][100/196]	Time 0.092 (0.085)	Data 0.000 (0.001)	Loss 0.6156 (0.5283)	Prec@1 80.469 (81.714)	Prec@5 99.219 (99.246)
EVALUATING - Epoch: [323][0/79]	Time 0.075 (0.075)	Data 0.054 (0.054)	Loss 0.7035 (0.7035)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:24

 Epoch: 324	Training Loss 0.5207 	Training Prec@1 81.848 	Training Prec@5 99.216 	Validation Loss 0.8435 	Validation Prec@1 73.840 	Validation Prec@5 98.460 

lr: 0.07715542130022768
TRAINING - Epoch: [324][0/196]	Time 0.731 (0.731)	Data 0.096 (0.096)	Loss 0.5185 (0.5185)	Prec@1 80.078 (80.078)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [324][100/196]	Time 0.035 (0.087)	Data 0.000 (0.001)	Loss 0.4989 (0.5247)	Prec@1 82.812 (81.536)	Prec@5 98.438 (99.203)
EVALUATING - Epoch: [324][0/79]	Time 0.076 (0.076)	Data 0.054 (0.054)	Loss 0.8395 (0.8395)	Prec@1 71.094 (71.094)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:32

 Epoch: 325	Training Loss 0.5275 	Training Prec@1 81.508 	Training Prec@5 99.176 	Validation Loss 0.8389 	Validation Prec@1 72.890 	Validation Prec@5 98.380 

lr: 0.0770228520477965
TRAINING - Epoch: [325][0/196]	Time 0.730 (0.730)	Data 0.092 (0.092)	Loss 0.6011 (0.6011)	Prec@1 79.297 (79.297)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [325][100/196]	Time 0.089 (0.094)	Data 0.000 (0.001)	Loss 0.5968 (0.5168)	Prec@1 80.469 (81.958)	Prec@5 98.438 (99.126)
EVALUATING - Epoch: [325][0/79]	Time 0.082 (0.082)	Data 0.063 (0.063)	Loss 0.7339 (0.7339)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:41

 Epoch: 326	Training Loss 0.5166 	Training Prec@1 81.896 	Training Prec@5 99.174 	Validation Loss 0.7763 	Validation Prec@1 74.490 	Validation Prec@5 98.720 

lr: 0.07689001396277925
TRAINING - Epoch: [326][0/196]	Time 0.736 (0.736)	Data 0.079 (0.079)	Loss 0.5137 (0.5137)	Prec@1 84.375 (84.375)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [326][100/196]	Time 0.088 (0.095)	Data 0.000 (0.001)	Loss 0.5723 (0.5135)	Prec@1 80.469 (82.112)	Prec@5 99.609 (99.180)
EVALUATING - Epoch: [326][0/79]	Time 0.088 (0.088)	Data 0.071 (0.071)	Loss 0.6718 (0.6718)	Prec@1 71.875 (71.875)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:48:40

 Epoch: 327	Training Loss 0.5113 	Training Prec@1 82.092 	Training Prec@5 99.224 	Validation Loss 0.7335 	Validation Prec@1 76.290 	Validation Prec@5 98.250 

lr: 0.0767569083667859
TRAINING - Epoch: [327][0/196]	Time 0.661 (0.661)	Data 0.084 (0.084)	Loss 0.5220 (0.5220)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [327][100/196]	Time 0.091 (0.092)	Data 0.000 (0.001)	Loss 0.6021 (0.5227)	Prec@1 79.688 (81.788)	Prec@5 99.609 (99.172)
EVALUATING - Epoch: [327][0/79]	Time 0.079 (0.079)	Data 0.061 (0.061)	Loss 0.6221 (0.6221)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:51:59

 Epoch: 328	Training Loss 0.5158 	Training Prec@1 82.102 	Training Prec@5 99.162 	Validation Loss 0.7152 	Validation Prec@1 76.510 	Validation Prec@5 98.750 

lr: 0.07662353658408792
TRAINING - Epoch: [328][0/196]	Time 0.796 (0.796)	Data 0.090 (0.090)	Loss 0.5491 (0.5491)	Prec@1 83.594 (83.594)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [328][100/196]	Time 0.093 (0.085)	Data 0.000 (0.001)	Loss 0.5171 (0.5094)	Prec@1 82.422 (82.178)	Prec@5 98.438 (99.196)
EVALUATING - Epoch: [328][0/79]	Time 0.073 (0.073)	Data 0.052 (0.052)	Loss 0.5444 (0.5444)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:30

 Epoch: 329	Training Loss 0.5089 	Training Prec@1 82.186 	Training Prec@5 99.174 	Validation Loss 0.6393 	Validation Prec@1 78.250 	Validation Prec@5 98.940 

lr: 0.0764898999416051
TRAINING - Epoch: [329][0/196]	Time 0.769 (0.769)	Data 0.105 (0.105)	Loss 0.4685 (0.4685)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [329][100/196]	Time 0.088 (0.086)	Data 0.000 (0.001)	Loss 0.4593 (0.4976)	Prec@1 83.594 (82.754)	Prec@5 99.609 (99.230)
EVALUATING - Epoch: [329][0/79]	Time 0.086 (0.086)	Data 0.064 (0.064)	Loss 0.9367 (0.9367)	Prec@1 68.750 (68.750)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:28

 Epoch: 330	Training Loss 0.5067 	Training Prec@1 82.288 	Training Prec@5 99.218 	Validation Loss 0.8930 	Validation Prec@1 73.190 	Validation Prec@5 97.970 

lr: 0.07635599976889228
TRAINING - Epoch: [330][0/196]	Time 0.831 (0.831)	Data 0.108 (0.108)	Loss 0.4374 (0.4374)	Prec@1 86.328 (86.328)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [330][100/196]	Time 0.084 (0.093)	Data 0.000 (0.001)	Loss 0.5180 (0.5087)	Prec@1 80.469 (82.426)	Prec@5 99.609 (99.188)
EVALUATING - Epoch: [330][0/79]	Time 0.079 (0.079)	Data 0.060 (0.060)	Loss 0.8302 (0.8302)	Prec@1 74.219 (74.219)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:11

 Epoch: 331	Training Loss 0.5152 	Training Prec@1 82.170 	Training Prec@5 99.200 	Validation Loss 0.7645 	Validation Prec@1 75.980 	Validation Prec@5 98.270 

lr: 0.07622183739812623
TRAINING - Epoch: [331][0/196]	Time 0.841 (0.841)	Data 0.114 (0.114)	Loss 0.4718 (0.4718)	Prec@1 80.469 (80.469)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [331][100/196]	Time 0.088 (0.094)	Data 0.000 (0.001)	Loss 0.5524 (0.5058)	Prec@1 80.469 (82.287)	Prec@5 98.438 (99.265)
EVALUATING - Epoch: [331][0/79]	Time 0.073 (0.073)	Data 0.053 (0.053)	Loss 0.9343 (0.9343)	Prec@1 70.312 (70.312)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:05

 Epoch: 332	Training Loss 0.5160 	Training Prec@1 82.042 	Training Prec@5 99.182 	Validation Loss 0.9414 	Validation Prec@1 71.370 	Validation Prec@5 97.810 

lr: 0.07608741416409227
TRAINING - Epoch: [332][0/196]	Time 0.822 (0.822)	Data 0.097 (0.097)	Loss 0.4365 (0.4365)	Prec@1 85.547 (85.547)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [332][100/196]	Time 0.080 (0.094)	Data 0.000 (0.001)	Loss 0.5999 (0.5127)	Prec@1 79.688 (82.070)	Prec@5 99.609 (99.165)
EVALUATING - Epoch: [332][0/79]	Time 0.083 (0.083)	Data 0.063 (0.063)	Loss 0.6375 (0.6375)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)
Time cost: 00:19	Time of Finish: 2024-03-31 19:53:18

 Epoch: 333	Training Loss 0.5156 	Training Prec@1 82.000 	Training Prec@5 99.150 	Validation Loss 0.7207 	Validation Prec@1 75.480 	Validation Prec@5 98.770 

lr: 0.07595273140417111
TRAINING - Epoch: [333][0/196]	Time 0.833 (0.833)	Data 0.099 (0.099)	Loss 0.4650 (0.4650)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [333][100/196]	Time 0.086 (0.084)	Data 0.000 (0.001)	Loss 0.5497 (0.5135)	Prec@1 79.688 (82.008)	Prec@5 99.219 (99.172)
EVALUATING - Epoch: [333][0/79]	Time 0.076 (0.076)	Data 0.056 (0.056)	Loss 0.5992 (0.5992)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:39

 Epoch: 334	Training Loss 0.5112 	Training Prec@1 82.172 	Training Prec@5 99.186 	Validation Loss 0.7568 	Validation Prec@1 75.730 	Validation Prec@5 98.750 

lr: 0.07581779045832547
TRAINING - Epoch: [334][0/196]	Time 0.790 (0.790)	Data 0.080 (0.080)	Loss 0.4571 (0.4571)	Prec@1 85.156 (85.156)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [334][100/196]	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 0.4725 (0.5170)	Prec@1 84.375 (82.093)	Prec@5 99.609 (99.157)
EVALUATING - Epoch: [334][0/79]	Time 0.073 (0.073)	Data 0.054 (0.054)	Loss 0.5951 (0.5951)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:55

 Epoch: 335	Training Loss 0.5162 	Training Prec@1 82.182 	Training Prec@5 99.160 	Validation Loss 0.7485 	Validation Prec@1 75.840 	Validation Prec@5 98.440 

lr: 0.07568259266908677
TRAINING - Epoch: [335][0/196]	Time 0.809 (0.809)	Data 0.101 (0.101)	Loss 0.5669 (0.5669)	Prec@1 80.078 (80.078)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [335][100/196]	Time 0.073 (0.094)	Data 0.000 (0.001)	Loss 0.5364 (0.5052)	Prec@1 78.125 (82.051)	Prec@5 100.000 (99.238)
EVALUATING - Epoch: [335][0/79]	Time 0.072 (0.072)	Data 0.051 (0.051)	Loss 0.6953 (0.6953)	Prec@1 77.344 (77.344)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:09

 Epoch: 336	Training Loss 0.5084 	Training Prec@1 82.214 	Training Prec@5 99.242 	Validation Loss 0.8558 	Validation Prec@1 72.200 	Validation Prec@5 98.600 

lr: 0.07554713938154174
TRAINING - Epoch: [336][0/196]	Time 0.788 (0.788)	Data 0.088 (0.088)	Loss 0.5121 (0.5121)	Prec@1 79.297 (79.297)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [336][100/196]	Time 0.084 (0.093)	Data 0.000 (0.001)	Loss 0.4462 (0.5039)	Prec@1 82.422 (82.383)	Prec@5 100.000 (99.238)
EVALUATING - Epoch: [336][0/79]	Time 0.102 (0.102)	Data 0.076 (0.076)	Loss 0.7528 (0.7528)	Prec@1 71.094 (71.094)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:49

 Epoch: 337	Training Loss 0.5081 	Training Prec@1 82.296 	Training Prec@5 99.248 	Validation Loss 0.7490 	Validation Prec@1 75.520 	Validation Prec@5 98.060 

lr: 0.07541143194331913
TRAINING - Epoch: [337][0/196]	Time 0.749 (0.749)	Data 0.096 (0.096)	Loss 0.4736 (0.4736)	Prec@1 82.812 (82.812)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [337][100/196]	Time 0.089 (0.092)	Data 0.000 (0.001)	Loss 0.5664 (0.5005)	Prec@1 80.078 (82.356)	Prec@5 98.828 (99.300)
EVALUATING - Epoch: [337][0/79]	Time 0.083 (0.083)	Data 0.064 (0.064)	Loss 0.6699 (0.6699)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:50:24

 Epoch: 338	Training Loss 0.5109 	Training Prec@1 82.018 	Training Prec@5 99.196 	Validation Loss 0.6718 	Validation Prec@1 77.000 	Validation Prec@5 98.660 

lr: 0.07527547170457623
TRAINING - Epoch: [338][0/196]	Time 0.819 (0.819)	Data 0.083 (0.083)	Loss 0.5153 (0.5153)	Prec@1 82.031 (82.031)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [338][100/196]	Time 0.091 (0.079)	Data 0.000 (0.001)	Loss 0.5152 (0.5072)	Prec@1 82.812 (82.105)	Prec@5 99.219 (99.219)
EVALUATING - Epoch: [338][0/79]	Time 0.073 (0.073)	Data 0.051 (0.051)	Loss 0.7801 (0.7801)	Prec@1 71.094 (71.094)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:35:44

 Epoch: 339	Training Loss 0.5165 	Training Prec@1 81.822 	Training Prec@5 99.168 	Validation Loss 0.9699 	Validation Prec@1 71.210 	Validation Prec@5 98.030 

lr: 0.07513926001798542
TRAINING - Epoch: [339][0/196]	Time 0.788 (0.788)	Data 0.098 (0.098)	Loss 0.4937 (0.4937)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [339][100/196]	Time 0.044 (0.082)	Data 0.000 (0.001)	Loss 0.4995 (0.4936)	Prec@1 82.031 (82.929)	Prec@5 99.609 (99.192)
EVALUATING - Epoch: [339][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 0.7309 (0.7309)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:43

 Epoch: 340	Training Loss 0.5086 	Training Prec@1 82.320 	Training Prec@5 99.214 	Validation Loss 0.7415 	Validation Prec@1 75.630 	Validation Prec@5 98.470 

lr: 0.07500279823872073
TRAINING - Epoch: [340][0/196]	Time 0.802 (0.802)	Data 0.088 (0.088)	Loss 0.4994 (0.4994)	Prec@1 80.859 (80.859)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [340][100/196]	Time 0.090 (0.095)	Data 0.000 (0.001)	Loss 0.4765 (0.5064)	Prec@1 82.812 (82.275)	Prec@5 99.219 (99.207)
EVALUATING - Epoch: [340][0/79]	Time 0.074 (0.074)	Data 0.051 (0.051)	Loss 0.7784 (0.7784)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:14

 Epoch: 341	Training Loss 0.5070 	Training Prec@1 82.244 	Training Prec@5 99.196 	Validation Loss 0.9982 	Validation Prec@1 69.070 	Validation Prec@5 97.370 

lr: 0.07486608772444445
TRAINING - Epoch: [341][0/196]	Time 0.816 (0.816)	Data 0.106 (0.106)	Loss 0.4709 (0.4709)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [341][100/196]	Time 0.091 (0.093)	Data 0.000 (0.001)	Loss 0.5709 (0.5121)	Prec@1 81.641 (82.391)	Prec@5 98.438 (99.223)
EVALUATING - Epoch: [341][0/79]	Time 0.077 (0.077)	Data 0.057 (0.057)	Loss 0.8292 (0.8292)	Prec@1 70.312 (70.312)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:16

 Epoch: 342	Training Loss 0.5097 	Training Prec@1 82.252 	Training Prec@5 99.182 	Validation Loss 1.1349 	Validation Prec@1 64.300 	Validation Prec@5 97.180 

lr: 0.07472912983529342
TRAINING - Epoch: [342][0/196]	Time 0.736 (0.736)	Data 0.088 (0.088)	Loss 0.4958 (0.4958)	Prec@1 82.031 (82.031)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [342][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.6148 (0.5093)	Prec@1 77.344 (82.271)	Prec@5 100.000 (99.257)
EVALUATING - Epoch: [342][0/79]	Time 0.077 (0.077)	Data 0.052 (0.052)	Loss 0.8107 (0.8107)	Prec@1 71.094 (71.094)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:53:00

 Epoch: 343	Training Loss 0.5125 	Training Prec@1 82.112 	Training Prec@5 99.266 	Validation Loss 0.7450 	Validation Prec@1 75.510 	Validation Prec@5 98.310 

lr: 0.07459192593386577
TRAINING - Epoch: [343][0/196]	Time 0.779 (0.779)	Data 0.102 (0.102)	Loss 0.5727 (0.5727)	Prec@1 80.078 (80.078)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [343][100/196]	Time 0.092 (0.083)	Data 0.000 (0.001)	Loss 0.5584 (0.5015)	Prec@1 80.078 (82.553)	Prec@5 98.828 (99.296)
EVALUATING - Epoch: [343][0/79]	Time 0.077 (0.077)	Data 0.053 (0.053)	Loss 0.8548 (0.8548)	Prec@1 65.625 (65.625)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:38:11

 Epoch: 344	Training Loss 0.5085 	Training Prec@1 82.278 	Training Prec@5 99.220 	Validation Loss 1.1004 	Validation Prec@1 67.520 	Validation Prec@5 97.310 

lr: 0.07445447738520707
TRAINING - Epoch: [344][0/196]	Time 0.808 (0.808)	Data 0.082 (0.082)	Loss 0.4414 (0.4414)	Prec@1 82.422 (82.422)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [344][100/196]	Time 0.040 (0.085)	Data 0.000 (0.001)	Loss 0.6160 (0.5033)	Prec@1 77.344 (82.244)	Prec@5 99.219 (99.223)
EVALUATING - Epoch: [344][0/79]	Time 0.087 (0.087)	Data 0.069 (0.069)	Loss 0.6713 (0.6713)	Prec@1 78.125 (78.125)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:38:30

 Epoch: 345	Training Loss 0.5075 	Training Prec@1 82.130 	Training Prec@5 99.202 	Validation Loss 0.7788 	Validation Prec@1 74.740 	Validation Prec@5 98.420 

lr: 0.07431678555679697
TRAINING - Epoch: [345][0/196]	Time 0.812 (0.812)	Data 0.118 (0.118)	Loss 0.4290 (0.4290)	Prec@1 87.109 (87.109)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [345][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.4715 (0.4937)	Prec@1 84.766 (82.743)	Prec@5 99.219 (99.238)
EVALUATING - Epoch: [345][0/79]	Time 0.073 (0.073)	Data 0.048 (0.048)	Loss 0.8564 (0.8564)	Prec@1 72.656 (72.656)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:21

 Epoch: 346	Training Loss 0.5046 	Training Prec@1 82.444 	Training Prec@5 99.196 	Validation Loss 0.8550 	Validation Prec@1 71.850 	Validation Prec@5 98.430 

lr: 0.07417885181853551
TRAINING - Epoch: [346][0/196]	Time 0.773 (0.773)	Data 0.081 (0.081)	Loss 0.4585 (0.4585)	Prec@1 83.984 (83.984)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [346][100/196]	Time 0.094 (0.094)	Data 0.000 (0.001)	Loss 0.5436 (0.5021)	Prec@1 80.469 (82.511)	Prec@5 99.219 (99.269)
EVALUATING - Epoch: [346][0/79]	Time 0.084 (0.084)	Data 0.065 (0.065)	Loss 0.7277 (0.7277)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:41

 Epoch: 347	Training Loss 0.5082 	Training Prec@1 82.286 	Training Prec@5 99.228 	Validation Loss 0.7969 	Validation Prec@1 73.190 	Validation Prec@5 97.810 

lr: 0.07404067754272946
TRAINING - Epoch: [347][0/196]	Time 0.358 (0.358)	Data 0.118 (0.118)	Loss 0.4228 (0.4228)	Prec@1 84.375 (84.375)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [347][100/196]	Time 0.100 (0.089)	Data 0.000 (0.001)	Loss 0.4694 (0.5019)	Prec@1 84.766 (82.596)	Prec@5 99.219 (99.192)
EVALUATING - Epoch: [347][0/79]	Time 0.081 (0.081)	Data 0.062 (0.062)	Loss 0.6357 (0.6357)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:17

 Epoch: 348	Training Loss 0.5065 	Training Prec@1 82.502 	Training Prec@5 99.236 	Validation Loss 0.6085 	Validation Prec@1 79.240 	Validation Prec@5 98.870 

lr: 0.07390226410407877
TRAINING - Epoch: [348][0/196]	Time 0.729 (0.729)	Data 0.104 (0.104)	Loss 0.4957 (0.4957)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [348][100/196]	Time 0.090 (0.084)	Data 0.000 (0.001)	Loss 0.3840 (0.5134)	Prec@1 85.938 (81.907)	Prec@5 99.609 (99.165)
EVALUATING - Epoch: [348][0/79]	Time 0.070 (0.070)	Data 0.049 (0.049)	Loss 0.5352 (0.5352)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:45

 Epoch: 349	Training Loss 0.5092 	Training Prec@1 82.048 	Training Prec@5 99.184 	Validation Loss 0.7068 	Validation Prec@1 77.250 	Validation Prec@5 98.600 

lr: 0.07376361287966277
TRAINING - Epoch: [349][0/196]	Time 0.719 (0.719)	Data 0.094 (0.094)	Loss 0.5001 (0.5001)	Prec@1 83.203 (83.203)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [349][100/196]	Time 0.052 (0.089)	Data 0.000 (0.001)	Loss 0.5771 (0.4964)	Prec@1 80.078 (82.557)	Prec@5 99.609 (99.269)
EVALUATING - Epoch: [349][0/79]	Time 0.075 (0.075)	Data 0.050 (0.050)	Loss 0.7150 (0.7150)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:01

 Epoch: 350	Training Loss 0.5068 	Training Prec@1 82.316 	Training Prec@5 99.174 	Validation Loss 0.7518 	Validation Prec@1 75.390 	Validation Prec@5 97.880 

lr: 0.07362472524892655
TRAINING - Epoch: [350][0/196]	Time 0.813 (0.813)	Data 0.098 (0.098)	Loss 0.4565 (0.4565)	Prec@1 83.203 (83.203)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [350][100/196]	Time 0.085 (0.093)	Data 0.000 (0.001)	Loss 0.4920 (0.5064)	Prec@1 83.203 (82.538)	Prec@5 99.219 (99.141)
EVALUATING - Epoch: [350][0/79]	Time 0.074 (0.074)	Data 0.051 (0.051)	Loss 0.7113 (0.7113)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:58

 Epoch: 351	Training Loss 0.5139 	Training Prec@1 82.194 	Training Prec@5 99.150 	Validation Loss 0.8267 	Validation Prec@1 73.590 	Validation Prec@5 98.250 

lr: 0.07348560259366722
TRAINING - Epoch: [351][0/196]	Time 0.774 (0.774)	Data 0.098 (0.098)	Loss 0.5207 (0.5207)	Prec@1 81.641 (81.641)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [351][100/196]	Time 0.078 (0.094)	Data 0.000 (0.001)	Loss 0.4310 (0.5074)	Prec@1 85.938 (82.244)	Prec@5 99.609 (99.184)
EVALUATING - Epoch: [351][0/79]	Time 0.094 (0.094)	Data 0.073 (0.073)	Loss 0.7954 (0.7954)	Prec@1 72.656 (72.656)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:27

 Epoch: 352	Training Loss 0.5087 	Training Prec@1 82.208 	Training Prec@5 99.242 	Validation Loss 0.6854 	Validation Prec@1 76.760 	Validation Prec@5 98.840 

lr: 0.07334624629802017
TRAINING - Epoch: [352][0/196]	Time 0.394 (0.394)	Data 0.082 (0.082)	Loss 0.5257 (0.5257)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [352][100/196]	Time 0.094 (0.086)	Data 0.000 (0.001)	Loss 0.4753 (0.5028)	Prec@1 84.766 (82.712)	Prec@5 98.828 (99.161)
EVALUATING - Epoch: [352][0/79]	Time 0.075 (0.075)	Data 0.057 (0.057)	Loss 0.8690 (0.8690)	Prec@1 75.000 (75.000)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:45

 Epoch: 353	Training Loss 0.5063 	Training Prec@1 82.510 	Training Prec@5 99.150 	Validation Loss 0.9663 	Validation Prec@1 71.780 	Validation Prec@5 97.780 

lr: 0.07320665774844522
TRAINING - Epoch: [353][0/196]	Time 0.696 (0.696)	Data 0.093 (0.093)	Loss 0.4019 (0.4019)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [353][100/196]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.4409 (0.4993)	Prec@1 83.594 (82.337)	Prec@5 99.609 (99.230)
EVALUATING - Epoch: [353][0/79]	Time 0.076 (0.076)	Data 0.054 (0.054)	Loss 0.5536 (0.5536)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:10

 Epoch: 354	Training Loss 0.5044 	Training Prec@1 82.260 	Training Prec@5 99.226 	Validation Loss 0.6847 	Validation Prec@1 77.020 	Validation Prec@5 98.560 

lr: 0.07306683833371297
TRAINING - Epoch: [354][0/196]	Time 0.811 (0.811)	Data 0.083 (0.083)	Loss 0.4848 (0.4848)	Prec@1 83.984 (83.984)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [354][100/196]	Time 0.051 (0.090)	Data 0.000 (0.001)	Loss 0.5101 (0.5020)	Prec@1 84.766 (82.464)	Prec@5 99.219 (99.242)
EVALUATING - Epoch: [354][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 0.5950 (0.5950)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:55

 Epoch: 355	Training Loss 0.5075 	Training Prec@1 82.284 	Training Prec@5 99.262 	Validation Loss 0.6666 	Validation Prec@1 77.100 	Validation Prec@5 98.790 

lr: 0.07292678944489082
TRAINING - Epoch: [355][0/196]	Time 0.799 (0.799)	Data 0.106 (0.106)	Loss 0.4980 (0.4980)	Prec@1 83.203 (83.203)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [355][100/196]	Time 0.076 (0.094)	Data 0.000 (0.001)	Loss 0.5022 (0.4931)	Prec@1 81.641 (82.782)	Prec@5 100.000 (99.257)
EVALUATING - Epoch: [355][0/79]	Time 0.085 (0.085)	Data 0.069 (0.069)	Loss 0.8298 (0.8298)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:25

 Epoch: 356	Training Loss 0.5045 	Training Prec@1 82.460 	Training Prec@5 99.178 	Validation Loss 0.8750 	Validation Prec@1 73.470 	Validation Prec@5 97.260 

lr: 0.07278651247532934
TRAINING - Epoch: [356][0/196]	Time 0.757 (0.757)	Data 0.094 (0.094)	Loss 0.5480 (0.5480)	Prec@1 82.031 (82.031)	Prec@5 97.266 (97.266)
TRAINING - Epoch: [356][100/196]	Time 0.089 (0.093)	Data 0.000 (0.001)	Loss 0.4565 (0.4998)	Prec@1 85.156 (82.449)	Prec@5 99.219 (99.242)
EVALUATING - Epoch: [356][0/79]	Time 0.081 (0.081)	Data 0.061 (0.061)	Loss 0.6482 (0.6482)	Prec@1 79.688 (79.688)	Prec@5 96.875 (96.875)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:34

 Epoch: 357	Training Loss 0.5016 	Training Prec@1 82.512 	Training Prec@5 99.230 	Validation Loss 0.6745 	Validation Prec@1 76.920 	Validation Prec@5 98.470 

lr: 0.07264600882064814
TRAINING - Epoch: [357][0/196]	Time 0.357 (0.357)	Data 0.098 (0.098)	Loss 0.5611 (0.5611)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [357][100/196]	Time 0.092 (0.090)	Data 0.000 (0.001)	Loss 0.5749 (0.5123)	Prec@1 80.078 (82.205)	Prec@5 99.609 (99.149)
EVALUATING - Epoch: [357][0/79]	Time 0.073 (0.073)	Data 0.049 (0.049)	Loss 0.8323 (0.8323)	Prec@1 72.656 (72.656)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:04

 Epoch: 358	Training Loss 0.5082 	Training Prec@1 82.238 	Training Prec@5 99.194 	Validation Loss 0.8903 	Validation Prec@1 71.550 	Validation Prec@5 97.680 

lr: 0.07250527987872224
TRAINING - Epoch: [358][0/196]	Time 0.778 (0.778)	Data 0.084 (0.084)	Loss 0.4191 (0.4191)	Prec@1 84.375 (84.375)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [358][100/196]	Time 0.092 (0.082)	Data 0.000 (0.001)	Loss 0.5678 (0.4958)	Prec@1 78.516 (82.627)	Prec@5 99.609 (99.319)
EVALUATING - Epoch: [358][0/79]	Time 0.070 (0.070)	Data 0.048 (0.048)	Loss 0.6454 (0.6454)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:24

 Epoch: 359	Training Loss 0.5041 	Training Prec@1 82.440 	Training Prec@5 99.248 	Validation Loss 0.6998 	Validation Prec@1 76.390 	Validation Prec@5 98.480 

lr: 0.07236432704966797
TRAINING - Epoch: [359][0/196]	Time 0.782 (0.782)	Data 0.093 (0.093)	Loss 0.4307 (0.4307)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [359][100/196]	Time 0.054 (0.089)	Data 0.000 (0.001)	Loss 0.5680 (0.4986)	Prec@1 79.297 (82.724)	Prec@5 98.828 (99.203)
EVALUATING - Epoch: [359][0/79]	Time 0.078 (0.078)	Data 0.059 (0.059)	Loss 0.6269 (0.6269)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:01

 Epoch: 360	Training Loss 0.5030 	Training Prec@1 82.484 	Training Prec@5 99.214 	Validation Loss 0.6508 	Validation Prec@1 78.290 	Validation Prec@5 98.730 

lr: 0.07222315173582916
TRAINING - Epoch: [360][0/196]	Time 0.818 (0.818)	Data 0.105 (0.105)	Loss 0.5625 (0.5625)	Prec@1 83.594 (83.594)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [360][100/196]	Time 0.087 (0.096)	Data 0.000 (0.001)	Loss 0.5517 (0.5075)	Prec@1 82.422 (82.267)	Prec@5 99.609 (99.296)
EVALUATING - Epoch: [360][0/79]	Time 0.078 (0.078)	Data 0.052 (0.052)	Loss 0.6603 (0.6603)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:43

 Epoch: 361	Training Loss 0.5039 	Training Prec@1 82.280 	Training Prec@5 99.242 	Validation Loss 0.8010 	Validation Prec@1 74.230 	Validation Prec@5 98.130 

lr: 0.07208175534176314
TRAINING - Epoch: [361][0/196]	Time 0.750 (0.750)	Data 0.088 (0.088)	Loss 0.4330 (0.4330)	Prec@1 84.766 (84.766)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [361][100/196]	Time 0.085 (0.094)	Data 0.000 (0.001)	Loss 0.4633 (0.5034)	Prec@1 81.641 (82.232)	Prec@5 99.609 (99.172)
EVALUATING - Epoch: [361][0/79]	Time 0.099 (0.099)	Data 0.083 (0.083)	Loss 0.8765 (0.8765)	Prec@1 70.312 (70.312)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:05

 Epoch: 362	Training Loss 0.5090 	Training Prec@1 82.114 	Training Prec@5 99.172 	Validation Loss 0.8569 	Validation Prec@1 72.260 	Validation Prec@5 98.010 

lr: 0.0719401392742268
TRAINING - Epoch: [362][0/196]	Time 0.614 (0.614)	Data 0.083 (0.083)	Loss 0.4581 (0.4581)	Prec@1 84.766 (84.766)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [362][100/196]	Time 0.092 (0.093)	Data 0.000 (0.001)	Loss 0.5592 (0.4912)	Prec@1 81.250 (82.731)	Prec@5 99.219 (99.273)
EVALUATING - Epoch: [362][0/79]	Time 0.075 (0.075)	Data 0.053 (0.053)	Loss 0.6687 (0.6687)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:49:26

 Epoch: 363	Training Loss 0.5039 	Training Prec@1 82.274 	Training Prec@5 99.218 	Validation Loss 0.7638 	Validation Prec@1 75.060 	Validation Prec@5 98.360 

lr: 0.0717983049421625
TRAINING - Epoch: [363][0/196]	Time 0.809 (0.809)	Data 0.108 (0.108)	Loss 0.6368 (0.6368)	Prec@1 78.125 (78.125)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [363][100/196]	Time 0.092 (0.083)	Data 0.000 (0.001)	Loss 0.5207 (0.5044)	Prec@1 81.641 (82.542)	Prec@5 98.828 (99.230)
EVALUATING - Epoch: [363][0/79]	Time 0.077 (0.077)	Data 0.054 (0.054)	Loss 0.8203 (0.8203)	Prec@1 71.094 (71.094)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:19

 Epoch: 364	Training Loss 0.5040 	Training Prec@1 82.468 	Training Prec@5 99.222 	Validation Loss 0.9157 	Validation Prec@1 71.170 	Validation Prec@5 97.330 

lr: 0.07165625375668416
TRAINING - Epoch: [364][0/196]	Time 0.749 (0.749)	Data 0.095 (0.095)	Loss 0.4179 (0.4179)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [364][100/196]	Time 0.053 (0.088)	Data 0.000 (0.001)	Loss 0.5329 (0.4927)	Prec@1 77.734 (82.793)	Prec@5 98.438 (99.331)
EVALUATING - Epoch: [364][0/79]	Time 0.073 (0.073)	Data 0.052 (0.052)	Loss 0.5843 (0.5843)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:34

 Epoch: 365	Training Loss 0.5029 	Training Prec@1 82.494 	Training Prec@5 99.298 	Validation Loss 0.7291 	Validation Prec@1 76.350 	Validation Prec@5 98.720 

lr: 0.07151398713106323
TRAINING - Epoch: [365][0/196]	Time 0.830 (0.830)	Data 0.113 (0.113)	Loss 0.4441 (0.4441)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [365][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.5047 (0.4965)	Prec@1 81.641 (82.685)	Prec@5 98.828 (99.273)
EVALUATING - Epoch: [365][0/79]	Time 0.079 (0.079)	Data 0.059 (0.059)	Loss 0.9254 (0.9254)	Prec@1 71.875 (71.875)	Prec@5 96.094 (96.094)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:14

 Epoch: 366	Training Loss 0.5019 	Training Prec@1 82.280 	Training Prec@5 99.216 	Validation Loss 0.8056 	Validation Prec@1 74.720 	Validation Prec@5 97.730 

lr: 0.07137150648071447
TRAINING - Epoch: [366][0/196]	Time 0.792 (0.792)	Data 0.094 (0.094)	Loss 0.5204 (0.5204)	Prec@1 78.906 (78.906)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [366][100/196]	Time 0.088 (0.094)	Data 0.000 (0.001)	Loss 0.5848 (0.4943)	Prec@1 80.078 (82.859)	Prec@5 99.219 (99.277)
EVALUATING - Epoch: [366][0/79]	Time 0.074 (0.074)	Data 0.055 (0.055)	Loss 0.5354 (0.5354)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:24

 Epoch: 367	Training Loss 0.5020 	Training Prec@1 82.614 	Training Prec@5 99.232 	Validation Loss 0.6427 	Validation Prec@1 77.950 	Validation Prec@5 98.930 

lr: 0.0712288132231821
TRAINING - Epoch: [367][0/196]	Time 0.354 (0.354)	Data 0.106 (0.106)	Loss 0.4633 (0.4633)	Prec@1 82.031 (82.031)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [367][100/196]	Time 0.093 (0.088)	Data 0.000 (0.001)	Loss 0.5207 (0.5030)	Prec@1 79.688 (82.383)	Prec@5 100.000 (99.184)
EVALUATING - Epoch: [367][0/79]	Time 0.090 (0.090)	Data 0.073 (0.073)	Loss 0.6411 (0.6411)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:49

 Epoch: 368	Training Loss 0.5056 	Training Prec@1 82.400 	Training Prec@5 99.194 	Validation Loss 0.6604 	Validation Prec@1 77.590 	Validation Prec@5 98.720 

lr: 0.07108590877812546
TRAINING - Epoch: [368][0/196]	Time 0.771 (0.771)	Data 0.083 (0.083)	Loss 0.5882 (0.5882)	Prec@1 79.297 (79.297)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [368][100/196]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.3547 (0.5082)	Prec@1 87.500 (82.058)	Prec@5 99.609 (99.300)
EVALUATING - Epoch: [368][0/79]	Time 0.076 (0.076)	Data 0.052 (0.052)	Loss 0.6188 (0.6188)	Prec@1 77.344 (77.344)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:38

 Epoch: 369	Training Loss 0.5001 	Training Prec@1 82.548 	Training Prec@5 99.238 	Validation Loss 0.6775 	Validation Prec@1 76.620 	Validation Prec@5 98.890 

lr: 0.07094279456730508
TRAINING - Epoch: [369][0/196]	Time 0.792 (0.792)	Data 0.105 (0.105)	Loss 0.5352 (0.5352)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [369][100/196]	Time 0.055 (0.088)	Data 0.000 (0.001)	Loss 0.6086 (0.4996)	Prec@1 81.250 (82.700)	Prec@5 98.438 (99.180)
EVALUATING - Epoch: [369][0/79]	Time 0.075 (0.075)	Data 0.056 (0.056)	Loss 0.7903 (0.7903)	Prec@1 74.219 (74.219)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:51

 Epoch: 370	Training Loss 0.5071 	Training Prec@1 82.386 	Training Prec@5 99.182 	Validation Loss 0.8048 	Validation Prec@1 73.080 	Validation Prec@5 97.680 

lr: 0.07079947201456845
TRAINING - Epoch: [370][0/196]	Time 0.726 (0.726)	Data 0.081 (0.081)	Loss 0.5118 (0.5118)	Prec@1 82.422 (82.422)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [370][100/196]	Time 0.089 (0.093)	Data 0.000 (0.001)	Loss 0.5204 (0.5059)	Prec@1 80.859 (82.414)	Prec@5 97.656 (99.230)
EVALUATING - Epoch: [370][0/79]	Time 0.081 (0.081)	Data 0.055 (0.055)	Loss 0.7754 (0.7754)	Prec@1 73.438 (73.438)	Prec@5 96.875 (96.875)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:37

 Epoch: 371	Training Loss 0.5044 	Training Prec@1 82.418 	Training Prec@5 99.220 	Validation Loss 0.6910 	Validation Prec@1 77.660 	Validation Prec@5 98.250 

lr: 0.0706559425458358
TRAINING - Epoch: [371][0/196]	Time 0.830 (0.830)	Data 0.096 (0.096)	Loss 0.4889 (0.4889)	Prec@1 81.641 (81.641)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [371][100/196]	Time 0.086 (0.095)	Data 0.000 (0.001)	Loss 0.6293 (0.4905)	Prec@1 78.906 (82.898)	Prec@5 98.828 (99.265)
EVALUATING - Epoch: [371][0/79]	Time 0.088 (0.088)	Data 0.061 (0.061)	Loss 0.8480 (0.8480)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:48:28

 Epoch: 372	Training Loss 0.4949 	Training Prec@1 82.852 	Training Prec@5 99.276 	Validation Loss 0.8659 	Validation Prec@1 74.020 	Validation Prec@5 96.930 

lr: 0.07051220758908609
TRAINING - Epoch: [372][0/196]	Time 0.345 (0.345)	Data 0.102 (0.102)	Loss 0.5195 (0.5195)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [372][100/196]	Time 0.084 (0.088)	Data 0.000 (0.001)	Loss 0.6490 (0.5036)	Prec@1 78.516 (82.356)	Prec@5 97.656 (99.184)
EVALUATING - Epoch: [372][0/79]	Time 0.087 (0.087)	Data 0.069 (0.069)	Loss 0.7253 (0.7253)	Prec@1 75.781 (75.781)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:56

 Epoch: 373	Training Loss 0.5007 	Training Prec@1 82.432 	Training Prec@5 99.218 	Validation Loss 0.6852 	Validation Prec@1 76.750 	Validation Prec@5 98.710 

lr: 0.07036826857434253
TRAINING - Epoch: [373][0/196]	Time 0.708 (0.708)	Data 0.079 (0.079)	Loss 0.4766 (0.4766)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [373][100/196]	Time 0.083 (0.079)	Data 0.000 (0.001)	Loss 0.4912 (0.4966)	Prec@1 82.812 (82.546)	Prec@5 99.609 (99.192)
EVALUATING - Epoch: [373][0/79]	Time 0.076 (0.076)	Data 0.052 (0.052)	Loss 0.9763 (0.9763)	Prec@1 72.656 (72.656)	Prec@5 95.312 (95.312)
Time cost: 00:17	Time of Finish: 2024-03-31 19:36:57

 Epoch: 374	Training Loss 0.5014 	Training Prec@1 82.442 	Training Prec@5 99.204 	Validation Loss 1.1240 	Validation Prec@1 66.870 	Validation Prec@5 96.250 

lr: 0.07022412693365863
TRAINING - Epoch: [374][0/196]	Time 0.798 (0.798)	Data 0.090 (0.090)	Loss 0.5538 (0.5538)	Prec@1 79.297 (79.297)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [374][100/196]	Time 0.056 (0.090)	Data 0.000 (0.001)	Loss 0.5571 (0.4991)	Prec@1 80.859 (82.700)	Prec@5 99.609 (99.238)
EVALUATING - Epoch: [374][0/79]	Time 0.082 (0.082)	Data 0.063 (0.063)	Loss 0.8039 (0.8039)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:38:56

 Epoch: 375	Training Loss 0.4971 	Training Prec@1 82.724 	Training Prec@5 99.216 	Validation Loss 0.7506 	Validation Prec@1 75.080 	Validation Prec@5 98.690 

lr: 0.0700797841011038
TRAINING - Epoch: [375][0/196]	Time 0.776 (0.776)	Data 0.095 (0.095)	Loss 0.4696 (0.4696)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [375][100/196]	Time 0.083 (0.093)	Data 0.000 (0.001)	Loss 0.4990 (0.4967)	Prec@1 82.812 (82.662)	Prec@5 99.219 (99.284)
EVALUATING - Epoch: [375][0/79]	Time 0.079 (0.079)	Data 0.055 (0.055)	Loss 0.8034 (0.8034)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:29

 Epoch: 376	Training Loss 0.5019 	Training Prec@1 82.448 	Training Prec@5 99.290 	Validation Loss 0.7838 	Validation Prec@1 73.770 	Validation Prec@5 98.310 

lr: 0.06993524151274909
TRAINING - Epoch: [376][0/196]	Time 0.726 (0.726)	Data 0.083 (0.083)	Loss 0.5649 (0.5649)	Prec@1 78.125 (78.125)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [376][100/196]	Time 0.091 (0.093)	Data 0.000 (0.001)	Loss 0.5528 (0.4947)	Prec@1 78.906 (82.901)	Prec@5 99.219 (99.176)
EVALUATING - Epoch: [376][0/79]	Time 0.079 (0.079)	Data 0.063 (0.063)	Loss 1.0292 (1.0292)	Prec@1 64.844 (64.844)	Prec@5 96.094 (96.094)
Time cost: 00:18	Time of Finish: 2024-03-31 19:51:04

 Epoch: 377	Training Loss 0.4936 	Training Prec@1 82.840 	Training Prec@5 99.226 	Validation Loss 0.9014 	Validation Prec@1 71.140 	Validation Prec@5 98.220 

lr: 0.06979050060665293
TRAINING - Epoch: [377][0/196]	Time 0.483 (0.483)	Data 0.120 (0.120)	Loss 0.5012 (0.5012)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [377][100/196]	Time 0.083 (0.087)	Data 0.000 (0.001)	Loss 0.4977 (0.5010)	Prec@1 80.859 (82.561)	Prec@5 99.609 (99.250)
EVALUATING - Epoch: [377][0/79]	Time 0.073 (0.073)	Data 0.052 (0.052)	Loss 0.6665 (0.6665)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:24

 Epoch: 378	Training Loss 0.5046 	Training Prec@1 82.426 	Training Prec@5 99.230 	Validation Loss 0.6910 	Validation Prec@1 76.870 	Validation Prec@5 98.500 

lr: 0.06964556282284687
TRAINING - Epoch: [378][0/196]	Time 0.788 (0.788)	Data 0.081 (0.081)	Loss 0.4726 (0.4726)	Prec@1 82.812 (82.812)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [378][100/196]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 0.5147 (0.4935)	Prec@1 82.812 (82.708)	Prec@5 99.219 (99.315)
EVALUATING - Epoch: [378][0/79]	Time 0.084 (0.084)	Data 0.063 (0.063)	Loss 0.6635 (0.6635)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:47

 Epoch: 379	Training Loss 0.4935 	Training Prec@1 82.682 	Training Prec@5 99.330 	Validation Loss 0.8374 	Validation Prec@1 74.170 	Validation Prec@5 98.000 

lr: 0.06950042960332112
TRAINING - Epoch: [379][0/196]	Time 0.726 (0.726)	Data 0.099 (0.099)	Loss 0.4514 (0.4514)	Prec@1 81.641 (81.641)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [379][100/196]	Time 0.055 (0.091)	Data 0.000 (0.001)	Loss 0.4378 (0.4964)	Prec@1 83.594 (82.646)	Prec@5 99.219 (99.254)
EVALUATING - Epoch: [379][0/79]	Time 0.074 (0.074)	Data 0.052 (0.052)	Loss 0.5354 (0.5354)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:13

 Epoch: 380	Training Loss 0.4976 	Training Prec@1 82.680 	Training Prec@5 99.242 	Validation Loss 0.6711 	Validation Prec@1 78.030 	Validation Prec@5 98.780 

lr: 0.06935510239201036
TRAINING - Epoch: [380][0/196]	Time 0.761 (0.761)	Data 0.079 (0.079)	Loss 0.4914 (0.4914)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [380][100/196]	Time 0.098 (0.092)	Data 0.000 (0.001)	Loss 0.4915 (0.4885)	Prec@1 82.812 (83.014)	Prec@5 100.000 (99.223)
EVALUATING - Epoch: [380][0/79]	Time 0.074 (0.074)	Data 0.051 (0.051)	Loss 0.6532 (0.6532)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:41

 Epoch: 381	Training Loss 0.4952 	Training Prec@1 82.704 	Training Prec@5 99.188 	Validation Loss 0.8291 	Validation Prec@1 73.630 	Validation Prec@5 97.790 

lr: 0.06920958263477923
TRAINING - Epoch: [381][0/196]	Time 0.823 (0.823)	Data 0.104 (0.104)	Loss 0.4834 (0.4834)	Prec@1 85.547 (85.547)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [381][100/196]	Time 0.093 (0.095)	Data 0.000 (0.001)	Loss 0.6298 (0.4977)	Prec@1 78.906 (82.565)	Prec@5 99.219 (99.315)
EVALUATING - Epoch: [381][0/79]	Time 0.071 (0.071)	Data 0.049 (0.049)	Loss 0.4580 (0.4580)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:51:32

 Epoch: 382	Training Loss 0.4982 	Training Prec@1 82.642 	Training Prec@5 99.284 	Validation Loss 0.6472 	Validation Prec@1 78.040 	Validation Prec@5 98.870 

lr: 0.06906387177940809
TRAINING - Epoch: [382][0/196]	Time 0.315 (0.315)	Data 0.096 (0.096)	Loss 0.4848 (0.4848)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [382][100/196]	Time 0.086 (0.088)	Data 0.000 (0.001)	Loss 0.4461 (0.4863)	Prec@1 85.156 (82.998)	Prec@5 100.000 (99.331)
EVALUATING - Epoch: [382][0/79]	Time 0.072 (0.072)	Data 0.052 (0.052)	Loss 0.6500 (0.6500)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:56

 Epoch: 383	Training Loss 0.4914 	Training Prec@1 82.842 	Training Prec@5 99.292 	Validation Loss 0.7594 	Validation Prec@1 75.400 	Validation Prec@5 98.310 

lr: 0.06891797127557851
TRAINING - Epoch: [383][0/196]	Time 0.770 (0.770)	Data 0.081 (0.081)	Loss 0.4526 (0.4526)	Prec@1 83.203 (83.203)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [383][100/196]	Time 0.079 (0.082)	Data 0.000 (0.001)	Loss 0.6660 (0.4995)	Prec@1 77.734 (82.488)	Prec@5 98.047 (99.335)
EVALUATING - Epoch: [383][0/79]	Time 0.079 (0.079)	Data 0.060 (0.060)	Loss 0.5894 (0.5894)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:33

 Epoch: 384	Training Loss 0.5034 	Training Prec@1 82.428 	Training Prec@5 99.248 	Validation Loss 0.6664 	Validation Prec@1 77.400 	Validation Prec@5 98.450 

lr: 0.06877188257485883
TRAINING - Epoch: [384][0/196]	Time 0.828 (0.828)	Data 0.106 (0.106)	Loss 0.4908 (0.4908)	Prec@1 83.984 (83.984)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [384][100/196]	Time 0.054 (0.091)	Data 0.000 (0.001)	Loss 0.6260 (0.4981)	Prec@1 80.859 (82.542)	Prec@5 98.828 (99.230)
EVALUATING - Epoch: [384][0/79]	Time 0.080 (0.080)	Data 0.061 (0.061)	Loss 0.5939 (0.5939)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:47

 Epoch: 385	Training Loss 0.4939 	Training Prec@1 82.690 	Training Prec@5 99.274 	Validation Loss 0.6844 	Validation Prec@1 76.200 	Validation Prec@5 98.910 

lr: 0.06862560713068987
TRAINING - Epoch: [385][0/196]	Time 0.751 (0.751)	Data 0.083 (0.083)	Loss 0.5064 (0.5064)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [385][100/196]	Time 0.092 (0.094)	Data 0.000 (0.001)	Loss 0.5917 (0.5009)	Prec@1 79.688 (82.406)	Prec@5 98.828 (99.284)
EVALUATING - Epoch: [385][0/79]	Time 0.070 (0.070)	Data 0.050 (0.050)	Loss 0.6842 (0.6842)	Prec@1 75.781 (75.781)	Prec@5 96.094 (96.094)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:09

 Epoch: 386	Training Loss 0.4934 	Training Prec@1 82.686 	Training Prec@5 99.292 	Validation Loss 0.7393 	Validation Prec@1 75.850 	Validation Prec@5 97.980 

lr: 0.06847914639837026
TRAINING - Epoch: [386][0/196]	Time 0.786 (0.786)	Data 0.079 (0.079)	Loss 0.5366 (0.5366)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [386][100/196]	Time 0.082 (0.093)	Data 0.000 (0.001)	Loss 0.4519 (0.5096)	Prec@1 85.156 (82.147)	Prec@5 99.219 (99.254)
EVALUATING - Epoch: [386][0/79]	Time 0.078 (0.078)	Data 0.060 (0.060)	Loss 0.5878 (0.5878)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:51:19

 Epoch: 387	Training Loss 0.5030 	Training Prec@1 82.372 	Training Prec@5 99.248 	Validation Loss 0.6563 	Validation Prec@1 77.960 	Validation Prec@5 98.460 

lr: 0.06833250183504212
TRAINING - Epoch: [387][0/196]	Time 0.488 (0.488)	Data 0.089 (0.089)	Loss 0.4539 (0.4539)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [387][100/196]	Time 0.089 (0.086)	Data 0.000 (0.001)	Loss 0.6090 (0.4933)	Prec@1 78.906 (83.021)	Prec@5 98.438 (99.246)
EVALUATING - Epoch: [387][0/79]	Time 0.071 (0.071)	Data 0.050 (0.050)	Loss 0.7500 (0.7500)	Prec@1 75.000 (75.000)	Prec@5 96.875 (96.875)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:05

 Epoch: 388	Training Loss 0.4975 	Training Prec@1 82.758 	Training Prec@5 99.218 	Validation Loss 0.8188 	Validation Prec@1 74.220 	Validation Prec@5 97.650 

lr: 0.06818567489967652
TRAINING - Epoch: [388][0/196]	Time 0.774 (0.774)	Data 0.098 (0.098)	Loss 0.4703 (0.4703)	Prec@1 84.766 (84.766)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [388][100/196]	Time 0.092 (0.084)	Data 0.000 (0.001)	Loss 0.5048 (0.4879)	Prec@1 82.031 (82.762)	Prec@5 99.609 (99.335)
EVALUATING - Epoch: [388][0/79]	Time 0.080 (0.080)	Data 0.063 (0.063)	Loss 0.7353 (0.7353)	Prec@1 73.438 (73.438)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:55

 Epoch: 389	Training Loss 0.4941 	Training Prec@1 82.620 	Training Prec@5 99.250 	Validation Loss 0.7932 	Validation Prec@1 74.260 	Validation Prec@5 98.530 

lr: 0.06803866705305892
TRAINING - Epoch: [389][0/196]	Time 0.770 (0.770)	Data 0.087 (0.087)	Loss 0.4674 (0.4674)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [389][100/196]	Time 0.061 (0.092)	Data 0.000 (0.001)	Loss 0.4694 (0.4965)	Prec@1 84.375 (82.646)	Prec@5 98.828 (99.254)
EVALUATING - Epoch: [389][0/79]	Time 0.074 (0.074)	Data 0.052 (0.052)	Loss 0.7675 (0.7675)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:07

 Epoch: 390	Training Loss 0.4958 	Training Prec@1 82.636 	Training Prec@5 99.230 	Validation Loss 0.7986 	Validation Prec@1 73.330 	Validation Prec@5 98.510 

lr: 0.06789147975777468
TRAINING - Epoch: [390][0/196]	Time 0.835 (0.835)	Data 0.114 (0.114)	Loss 0.5412 (0.5412)	Prec@1 78.516 (78.516)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [390][100/196]	Time 0.083 (0.093)	Data 0.000 (0.001)	Loss 0.5153 (0.4963)	Prec@1 84.766 (82.550)	Prec@5 99.219 (99.277)
EVALUATING - Epoch: [390][0/79]	Time 0.081 (0.081)	Data 0.062 (0.062)	Loss 0.8633 (0.8633)	Prec@1 75.000 (75.000)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:32

 Epoch: 391	Training Loss 0.4985 	Training Prec@1 82.620 	Training Prec@5 99.252 	Validation Loss 0.7721 	Validation Prec@1 75.250 	Validation Prec@5 97.840 

lr: 0.06774411447819452
TRAINING - Epoch: [391][0/196]	Time 0.726 (0.726)	Data 0.102 (0.102)	Loss 0.4943 (0.4943)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [391][100/196]	Time 0.086 (0.092)	Data 0.000 (0.001)	Loss 0.4749 (0.4990)	Prec@1 83.203 (82.406)	Prec@5 99.609 (99.250)
EVALUATING - Epoch: [391][0/79]	Time 0.071 (0.071)	Data 0.050 (0.050)	Loss 0.8261 (0.8261)	Prec@1 77.344 (77.344)	Prec@5 96.875 (96.875)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:39

 Epoch: 392	Training Loss 0.4967 	Training Prec@1 82.536 	Training Prec@5 99.246 	Validation Loss 0.7773 	Validation Prec@1 74.360 	Validation Prec@5 98.190 

lr: 0.06759657268045992
TRAINING - Epoch: [392][0/196]	Time 0.766 (0.766)	Data 0.095 (0.095)	Loss 0.5268 (0.5268)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [392][100/196]	Time 0.091 (0.081)	Data 0.000 (0.001)	Loss 0.5114 (0.4899)	Prec@1 81.641 (82.623)	Prec@5 98.438 (99.238)
EVALUATING - Epoch: [392][0/79]	Time 0.086 (0.086)	Data 0.065 (0.065)	Loss 0.6381 (0.6381)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:00

 Epoch: 393	Training Loss 0.4885 	Training Prec@1 82.812 	Training Prec@5 99.194 	Validation Loss 0.6974 	Validation Prec@1 77.500 	Validation Prec@5 98.440 

lr: 0.06744885583246855
TRAINING - Epoch: [393][0/196]	Time 0.812 (0.812)	Data 0.093 (0.093)	Loss 0.4597 (0.4597)	Prec@1 85.547 (85.547)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [393][100/196]	Time 0.082 (0.083)	Data 0.000 (0.001)	Loss 0.5042 (0.4950)	Prec@1 82.422 (82.596)	Prec@5 98.828 (99.215)
EVALUATING - Epoch: [393][0/79]	Time 0.073 (0.073)	Data 0.054 (0.054)	Loss 0.6254 (0.6254)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:33

 Epoch: 394	Training Loss 0.4943 	Training Prec@1 82.656 	Training Prec@5 99.194 	Validation Loss 0.7730 	Validation Prec@1 73.840 	Validation Prec@5 98.300 

lr: 0.06730096540385964
TRAINING - Epoch: [394][0/196]	Time 0.811 (0.811)	Data 0.090 (0.090)	Loss 0.4988 (0.4988)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [394][100/196]	Time 0.089 (0.094)	Data 0.000 (0.001)	Loss 0.5318 (0.4915)	Prec@1 80.078 (82.600)	Prec@5 100.000 (99.304)
EVALUATING - Epoch: [394][0/79]	Time 0.081 (0.081)	Data 0.061 (0.061)	Loss 0.9314 (0.9314)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:21

 Epoch: 395	Training Loss 0.4973 	Training Prec@1 82.552 	Training Prec@5 99.272 	Validation Loss 0.7943 	Validation Prec@1 73.550 	Validation Prec@5 98.820 

lr: 0.06715290286599941
TRAINING - Epoch: [395][0/196]	Time 0.745 (0.745)	Data 0.079 (0.079)	Loss 0.5951 (0.5951)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [395][100/196]	Time 0.089 (0.093)	Data 0.000 (0.001)	Loss 0.4614 (0.4989)	Prec@1 83.203 (82.863)	Prec@5 98.828 (99.284)
EVALUATING - Epoch: [395][0/79]	Time 0.074 (0.074)	Data 0.051 (0.051)	Loss 0.5058 (0.5058)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:22

 Epoch: 396	Training Loss 0.4958 	Training Prec@1 82.778 	Training Prec@5 99.296 	Validation Loss 0.6338 	Validation Prec@1 78.520 	Validation Prec@5 98.780 

lr: 0.06700466969196639
TRAINING - Epoch: [396][0/196]	Time 0.962 (0.962)	Data 0.182 (0.182)	Loss 0.4561 (0.4561)	Prec@1 80.078 (80.078)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [396][100/196]	Time 0.091 (0.095)	Data 0.000 (0.002)	Loss 0.5225 (0.4840)	Prec@1 78.906 (82.983)	Prec@5 99.219 (99.358)
EVALUATING - Epoch: [396][0/79]	Time 0.078 (0.078)	Data 0.059 (0.059)	Loss 0.6157 (0.6157)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:53:02

 Epoch: 397	Training Loss 0.4891 	Training Prec@1 82.964 	Training Prec@5 99.248 	Validation Loss 0.7220 	Validation Prec@1 75.560 	Validation Prec@5 98.410 

lr: 0.06685626735653671
TRAINING - Epoch: [397][0/196]	Time 0.477 (0.477)	Data 0.092 (0.092)	Loss 0.4870 (0.4870)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [397][100/196]	Time 0.089 (0.078)	Data 0.000 (0.001)	Loss 0.6271 (0.4725)	Prec@1 80.469 (83.536)	Prec@5 97.656 (99.296)
EVALUATING - Epoch: [397][0/79]	Time 0.072 (0.072)	Data 0.053 (0.053)	Loss 0.5967 (0.5967)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:35:03

 Epoch: 398	Training Loss 0.4812 	Training Prec@1 83.120 	Training Prec@5 99.296 	Validation Loss 0.6341 	Validation Prec@1 78.250 	Validation Prec@5 98.970 

lr: 0.06670769733616963
TRAINING - Epoch: [398][0/196]	Time 0.688 (0.688)	Data 0.090 (0.090)	Loss 0.3923 (0.3923)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [398][100/196]	Time 0.095 (0.084)	Data 0.000 (0.001)	Loss 0.4256 (0.4948)	Prec@1 85.547 (82.700)	Prec@5 99.219 (99.219)
EVALUATING - Epoch: [398][0/79]	Time 0.072 (0.072)	Data 0.049 (0.049)	Loss 0.6612 (0.6612)	Prec@1 79.688 (79.688)	Prec@5 96.875 (96.875)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:19

 Epoch: 399	Training Loss 0.4918 	Training Prec@1 82.902 	Training Prec@5 99.240 	Validation Loss 0.7612 	Validation Prec@1 75.010 	Validation Prec@5 98.300 

lr: 0.06655896110899256
TRAINING - Epoch: [399][0/196]	Time 0.730 (0.730)	Data 0.101 (0.101)	Loss 0.4972 (0.4972)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [399][100/196]	Time 0.085 (0.092)	Data 0.000 (0.001)	Loss 0.4270 (0.4872)	Prec@1 83.594 (83.006)	Prec@5 99.219 (99.211)
EVALUATING - Epoch: [399][0/79]	Time 0.080 (0.080)	Data 0.060 (0.060)	Loss 0.6394 (0.6394)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:35:20

 Epoch: 400	Training Loss 0.4875 	Training Prec@1 83.054 	Training Prec@5 99.262 	Validation Loss 0.8403 	Validation Prec@1 73.060 	Validation Prec@5 98.130 

lr: 0.06641006015478663
TRAINING - Epoch: [400][0/196]	Time 0.784 (0.784)	Data 0.086 (0.086)	Loss 0.4608 (0.4608)	Prec@1 82.031 (82.031)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [400][100/196]	Time 0.089 (0.096)	Data 0.000 (0.001)	Loss 0.6300 (0.4948)	Prec@1 79.297 (82.696)	Prec@5 97.656 (99.257)
EVALUATING - Epoch: [400][0/79]	Time 0.086 (0.086)	Data 0.075 (0.075)	Loss 0.6535 (0.6535)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:42

 Epoch: 401	Training Loss 0.4900 	Training Prec@1 82.948 	Training Prec@5 99.264 	Validation Loss 0.7014 	Validation Prec@1 76.430 	Validation Prec@5 98.630 

lr: 0.06626099595497177
TRAINING - Epoch: [401][0/196]	Time 0.809 (0.809)	Data 0.095 (0.095)	Loss 0.4418 (0.4418)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [401][100/196]	Time 0.091 (0.095)	Data 0.000 (0.001)	Loss 0.4022 (0.4879)	Prec@1 85.547 (82.782)	Prec@5 99.219 (99.335)
EVALUATING - Epoch: [401][0/79]	Time 0.089 (0.089)	Data 0.071 (0.071)	Loss 0.7631 (0.7631)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:19	Time of Finish: 2024-03-31 19:52:56

 Epoch: 402	Training Loss 0.4904 	Training Prec@1 82.788 	Training Prec@5 99.296 	Validation Loss 0.7795 	Validation Prec@1 74.970 	Validation Prec@5 98.260 

lr: 0.06611176999259206
TRAINING - Epoch: [402][0/196]	Time 0.790 (0.790)	Data 0.080 (0.080)	Loss 0.3867 (0.3867)	Prec@1 88.672 (88.672)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [402][100/196]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.3754 (0.4820)	Prec@1 86.719 (83.211)	Prec@5 99.219 (99.254)
EVALUATING - Epoch: [402][0/79]	Time 0.073 (0.073)	Data 0.049 (0.049)	Loss 0.5235 (0.5235)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:30

 Epoch: 403	Training Loss 0.4889 	Training Prec@1 82.932 	Training Prec@5 99.266 	Validation Loss 0.6401 	Validation Prec@1 78.370 	Validation Prec@5 98.880 

lr: 0.06596238375230097
TRAINING - Epoch: [403][0/196]	Time 0.754 (0.754)	Data 0.105 (0.105)	Loss 0.6004 (0.6004)	Prec@1 78.125 (78.125)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [403][100/196]	Time 0.086 (0.078)	Data 0.000 (0.001)	Loss 0.5116 (0.4984)	Prec@1 81.250 (82.515)	Prec@5 100.000 (99.238)
EVALUATING - Epoch: [403][0/79]	Time 0.070 (0.070)	Data 0.050 (0.050)	Loss 0.8677 (0.8677)	Prec@1 72.656 (72.656)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:36:25

 Epoch: 404	Training Loss 0.4890 	Training Prec@1 82.768 	Training Prec@5 99.274 	Validation Loss 0.9459 	Validation Prec@1 71.070 	Validation Prec@5 97.950 

lr: 0.06581283872034657
TRAINING - Epoch: [404][0/196]	Time 0.787 (0.787)	Data 0.078 (0.078)	Loss 0.4895 (0.4895)	Prec@1 80.078 (80.078)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [404][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.4541 (0.4837)	Prec@1 83.594 (82.959)	Prec@5 100.000 (99.234)
EVALUATING - Epoch: [404][0/79]	Time 0.084 (0.084)	Data 0.061 (0.061)	Loss 0.8499 (0.8499)	Prec@1 73.438 (73.438)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:39

 Epoch: 405	Training Loss 0.4921 	Training Prec@1 82.726 	Training Prec@5 99.216 	Validation Loss 0.8882 	Validation Prec@1 71.950 	Validation Prec@5 97.280 

lr: 0.06566313638455679
TRAINING - Epoch: [405][0/196]	Time 0.778 (0.778)	Data 0.079 (0.079)	Loss 0.5136 (0.5136)	Prec@1 80.078 (80.078)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [405][100/196]	Time 0.090 (0.093)	Data 0.000 (0.001)	Loss 0.5131 (0.4950)	Prec@1 82.031 (82.623)	Prec@5 99.219 (99.273)
EVALUATING - Epoch: [405][0/79]	Time 0.084 (0.084)	Data 0.068 (0.068)	Loss 0.6097 (0.6097)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:32

 Epoch: 406	Training Loss 0.4933 	Training Prec@1 82.720 	Training Prec@5 99.258 	Validation Loss 0.6748 	Validation Prec@1 77.700 	Validation Prec@5 98.610 

lr: 0.06551327823432451
TRAINING - Epoch: [406][0/196]	Time 0.758 (0.758)	Data 0.099 (0.099)	Loss 0.4411 (0.4411)	Prec@1 82.812 (82.812)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [406][100/196]	Time 0.078 (0.097)	Data 0.000 (0.001)	Loss 0.5033 (0.4862)	Prec@1 82.031 (82.867)	Prec@5 99.609 (99.300)
EVALUATING - Epoch: [406][0/79]	Time 0.076 (0.076)	Data 0.057 (0.057)	Loss 0.7032 (0.7032)	Prec@1 71.875 (71.875)	Prec@5 100.000 (100.000)
Time cost: 00:19	Time of Finish: 2024-03-31 19:55:21

 Epoch: 407	Training Loss 0.4854 	Training Prec@1 83.060 	Training Prec@5 99.322 	Validation Loss 0.8184 	Validation Prec@1 72.910 	Validation Prec@5 98.220 

lr: 0.0653632657605929
TRAINING - Epoch: [407][0/196]	Time 0.794 (0.794)	Data 0.091 (0.091)	Loss 0.4642 (0.4642)	Prec@1 85.547 (85.547)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [407][100/196]	Time 0.098 (0.087)	Data 0.000 (0.001)	Loss 0.5349 (0.4812)	Prec@1 82.812 (83.222)	Prec@5 99.219 (99.315)
EVALUATING - Epoch: [407][0/79]	Time 0.080 (0.080)	Data 0.058 (0.058)	Loss 0.7013 (0.7013)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:47

 Epoch: 408	Training Loss 0.4811 	Training Prec@1 83.060 	Training Prec@5 99.322 	Validation Loss 0.8427 	Validation Prec@1 74.990 	Validation Prec@5 98.100 

lr: 0.06521310045584039
TRAINING - Epoch: [408][0/196]	Time 0.741 (0.741)	Data 0.104 (0.104)	Loss 0.5660 (0.5660)	Prec@1 82.422 (82.422)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [408][100/196]	Time 0.081 (0.085)	Data 0.000 (0.001)	Loss 0.5259 (0.4825)	Prec@1 82.812 (83.103)	Prec@5 99.609 (99.226)
EVALUATING - Epoch: [408][0/79]	Time 0.083 (0.083)	Data 0.066 (0.066)	Loss 0.5461 (0.5461)	Prec@1 83.594 (83.594)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:24

 Epoch: 409	Training Loss 0.4865 	Training Prec@1 82.958 	Training Prec@5 99.258 	Validation Loss 0.6775 	Validation Prec@1 77.380 	Validation Prec@5 98.620 

lr: 0.06506278381406606
TRAINING - Epoch: [409][0/196]	Time 0.777 (0.777)	Data 0.105 (0.105)	Loss 0.5354 (0.5354)	Prec@1 81.250 (81.250)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [409][100/196]	Time 0.090 (0.092)	Data 0.000 (0.001)	Loss 0.4698 (0.4762)	Prec@1 84.766 (83.497)	Prec@5 100.000 (99.370)
EVALUATING - Epoch: [409][0/79]	Time 0.076 (0.076)	Data 0.056 (0.056)	Loss 0.6067 (0.6067)	Prec@1 81.250 (81.250)	Prec@5 96.875 (96.875)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:24

 Epoch: 410	Training Loss 0.4821 	Training Prec@1 83.290 	Training Prec@5 99.310 	Validation Loss 0.8556 	Validation Prec@1 73.620 	Validation Prec@5 98.090 

lr: 0.06491231733077453
TRAINING - Epoch: [410][0/196]	Time 0.736 (0.736)	Data 0.081 (0.081)	Loss 0.5154 (0.5154)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [410][100/196]	Time 0.094 (0.091)	Data 0.000 (0.001)	Loss 0.5571 (0.4930)	Prec@1 81.641 (82.553)	Prec@5 98.047 (99.354)
EVALUATING - Epoch: [410][0/79]	Time 0.095 (0.095)	Data 0.065 (0.065)	Loss 0.5485 (0.5485)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:10

 Epoch: 411	Training Loss 0.4900 	Training Prec@1 82.760 	Training Prec@5 99.350 	Validation Loss 0.7581 	Validation Prec@1 75.920 	Validation Prec@5 98.410 

lr: 0.06476170250296127
TRAINING - Epoch: [411][0/196]	Time 0.810 (0.810)	Data 0.108 (0.108)	Loss 0.4437 (0.4437)	Prec@1 87.109 (87.109)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [411][100/196]	Time 0.090 (0.094)	Data 0.000 (0.001)	Loss 0.6317 (0.4951)	Prec@1 79.297 (82.774)	Prec@5 98.438 (99.238)
EVALUATING - Epoch: [411][0/79]	Time 0.071 (0.071)	Data 0.050 (0.050)	Loss 0.9162 (0.9162)	Prec@1 73.438 (73.438)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:51:00

 Epoch: 412	Training Loss 0.4907 	Training Prec@1 82.958 	Training Prec@5 99.222 	Validation Loss 0.8040 	Validation Prec@1 74.270 	Validation Prec@5 98.120 

lr: 0.06461094082909759
TRAINING - Epoch: [412][0/196]	Time 0.779 (0.779)	Data 0.093 (0.093)	Loss 0.5832 (0.5832)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [412][100/196]	Time 0.082 (0.081)	Data 0.000 (0.001)	Loss 0.4741 (0.4953)	Prec@1 82.812 (82.739)	Prec@5 99.609 (99.176)
EVALUATING - Epoch: [412][0/79]	Time 0.075 (0.075)	Data 0.057 (0.057)	Loss 0.7684 (0.7684)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:30

 Epoch: 413	Training Loss 0.4889 	Training Prec@1 82.950 	Training Prec@5 99.216 	Validation Loss 0.7406 	Validation Prec@1 76.490 	Validation Prec@5 98.590 

lr: 0.06446003380911582
TRAINING - Epoch: [413][0/196]	Time 0.763 (0.763)	Data 0.089 (0.089)	Loss 0.5057 (0.5057)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [413][100/196]	Time 0.089 (0.085)	Data 0.000 (0.001)	Loss 0.4841 (0.4866)	Prec@1 85.938 (83.052)	Prec@5 99.219 (99.261)
EVALUATING - Epoch: [413][0/79]	Time 0.078 (0.078)	Data 0.057 (0.057)	Loss 0.5894 (0.5894)	Prec@1 77.344 (77.344)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:09

 Epoch: 414	Training Loss 0.4866 	Training Prec@1 83.012 	Training Prec@5 99.270 	Validation Loss 0.7085 	Validation Prec@1 76.700 	Validation Prec@5 98.570 

lr: 0.06430898294439429
TRAINING - Epoch: [414][0/196]	Time 0.752 (0.752)	Data 0.086 (0.086)	Loss 0.5037 (0.5037)	Prec@1 81.641 (81.641)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [414][100/196]	Time 0.094 (0.093)	Data 0.000 (0.001)	Loss 0.4229 (0.4771)	Prec@1 85.938 (83.277)	Prec@5 99.609 (99.377)
EVALUATING - Epoch: [414][0/79]	Time 0.084 (0.084)	Data 0.062 (0.062)	Loss 0.6185 (0.6185)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:51

 Epoch: 415	Training Loss 0.4856 	Training Prec@1 83.078 	Training Prec@5 99.336 	Validation Loss 0.7731 	Validation Prec@1 74.800 	Validation Prec@5 98.540 

lr: 0.06415778973774248
TRAINING - Epoch: [415][0/196]	Time 0.769 (0.769)	Data 0.081 (0.081)	Loss 0.5424 (0.5424)	Prec@1 78.516 (78.516)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [415][100/196]	Time 0.085 (0.094)	Data 0.000 (0.001)	Loss 0.5138 (0.4774)	Prec@1 81.641 (83.226)	Prec@5 98.438 (99.284)
EVALUATING - Epoch: [415][0/79]	Time 0.071 (0.071)	Data 0.049 (0.049)	Loss 0.6391 (0.6391)	Prec@1 77.344 (77.344)	Prec@5 96.094 (96.094)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:48

 Epoch: 416	Training Loss 0.4792 	Training Prec@1 83.246 	Training Prec@5 99.308 	Validation Loss 0.7400 	Validation Prec@1 75.620 	Validation Prec@5 98.430 

lr: 0.06400645569338609
TRAINING - Epoch: [416][0/196]	Time 0.810 (0.810)	Data 0.082 (0.082)	Loss 0.4824 (0.4824)	Prec@1 85.547 (85.547)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [416][100/196]	Time 0.072 (0.092)	Data 0.000 (0.001)	Loss 0.5015 (0.4944)	Prec@1 83.984 (82.778)	Prec@5 99.219 (99.323)
EVALUATING - Epoch: [416][0/79]	Time 0.079 (0.079)	Data 0.056 (0.056)	Loss 0.7537 (0.7537)	Prec@1 78.125 (78.125)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:44

 Epoch: 417	Training Loss 0.4861 	Training Prec@1 83.030 	Training Prec@5 99.346 	Validation Loss 0.8037 	Validation Prec@1 74.070 	Validation Prec@5 98.350 

lr: 0.06385498231695186
TRAINING - Epoch: [417][0/196]	Time 0.762 (0.762)	Data 0.087 (0.087)	Loss 0.4167 (0.4167)	Prec@1 86.719 (86.719)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [417][100/196]	Time 0.077 (0.081)	Data 0.000 (0.001)	Loss 0.5172 (0.4853)	Prec@1 82.031 (83.010)	Prec@5 99.219 (99.261)
EVALUATING - Epoch: [417][0/79]	Time 0.072 (0.072)	Data 0.049 (0.049)	Loss 0.7421 (0.7421)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:38:16

 Epoch: 418	Training Loss 0.4868 	Training Prec@1 82.906 	Training Prec@5 99.280 	Validation Loss 0.7072 	Validation Prec@1 76.920 	Validation Prec@5 98.650 

lr: 0.0637033711154529
TRAINING - Epoch: [418][0/196]	Time 0.766 (0.766)	Data 0.084 (0.084)	Loss 0.5369 (0.5369)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [418][100/196]	Time 0.043 (0.085)	Data 0.000 (0.001)	Loss 0.3842 (0.4822)	Prec@1 84.375 (83.319)	Prec@5 100.000 (99.238)
EVALUATING - Epoch: [418][0/79]	Time 0.081 (0.081)	Data 0.063 (0.063)	Loss 0.6410 (0.6410)	Prec@1 78.125 (78.125)	Prec@5 96.875 (96.875)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:22

 Epoch: 419	Training Loss 0.4864 	Training Prec@1 83.048 	Training Prec@5 99.256 	Validation Loss 0.7800 	Validation Prec@1 75.230 	Validation Prec@5 98.460 

lr: 0.0635516235972735
TRAINING - Epoch: [419][0/196]	Time 0.772 (0.772)	Data 0.084 (0.084)	Loss 0.5057 (0.5057)	Prec@1 82.031 (82.031)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [419][100/196]	Time 0.084 (0.094)	Data 0.000 (0.001)	Loss 0.4293 (0.4828)	Prec@1 83.984 (82.874)	Prec@5 100.000 (99.424)
EVALUATING - Epoch: [419][0/79]	Time 0.083 (0.083)	Data 0.064 (0.064)	Loss 0.7102 (0.7102)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:23

 Epoch: 420	Training Loss 0.4851 	Training Prec@1 83.030 	Training Prec@5 99.352 	Validation Loss 0.7638 	Validation Prec@1 74.880 	Validation Prec@5 98.360 

lr: 0.06339974127215411
TRAINING - Epoch: [420][0/196]	Time 0.792 (0.792)	Data 0.091 (0.091)	Loss 0.4915 (0.4915)	Prec@1 82.422 (82.422)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [420][100/196]	Time 0.094 (0.094)	Data 0.000 (0.001)	Loss 0.4017 (0.4840)	Prec@1 84.766 (83.188)	Prec@5 100.000 (99.296)
EVALUATING - Epoch: [420][0/79]	Time 0.077 (0.077)	Data 0.057 (0.057)	Loss 0.6162 (0.6162)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:00

 Epoch: 421	Training Loss 0.4848 	Training Prec@1 83.106 	Training Prec@5 99.278 	Validation Loss 0.6499 	Validation Prec@1 78.370 	Validation Prec@5 99.020 

lr: 0.06324772565117648
TRAINING - Epoch: [421][0/196]	Time 0.755 (0.755)	Data 0.109 (0.109)	Loss 0.4924 (0.4924)	Prec@1 82.031 (82.031)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [421][100/196]	Time 0.094 (0.093)	Data 0.000 (0.001)	Loss 0.4594 (0.4709)	Prec@1 84.375 (83.474)	Prec@5 99.609 (99.350)
EVALUATING - Epoch: [421][0/79]	Time 0.072 (0.072)	Data 0.052 (0.052)	Loss 0.7460 (0.7460)	Prec@1 78.125 (78.125)	Prec@5 96.875 (96.875)
Time cost: 00:18	Time of Finish: 2024-03-31 19:51:37

 Epoch: 422	Training Loss 0.4834 	Training Prec@1 83.120 	Training Prec@5 99.294 	Validation Loss 0.7177 	Validation Prec@1 76.380 	Validation Prec@5 98.570 

lr: 0.06309557824674844
TRAINING - Epoch: [422][0/196]	Time 0.747 (0.747)	Data 0.086 (0.086)	Loss 0.5096 (0.5096)	Prec@1 80.859 (80.859)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [422][100/196]	Time 0.063 (0.082)	Data 0.000 (0.001)	Loss 0.6056 (0.4801)	Prec@1 78.516 (83.257)	Prec@5 99.609 (99.292)
EVALUATING - Epoch: [422][0/79]	Time 0.079 (0.079)	Data 0.057 (0.057)	Loss 0.5657 (0.5657)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:07

 Epoch: 423	Training Loss 0.4797 	Training Prec@1 83.288 	Training Prec@5 99.296 	Validation Loss 0.6855 	Validation Prec@1 77.720 	Validation Prec@5 98.760 

lr: 0.06294330057258897
TRAINING - Epoch: [423][0/196]	Time 0.807 (0.807)	Data 0.107 (0.107)	Loss 0.4217 (0.4217)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [423][100/196]	Time 0.028 (0.083)	Data 0.000 (0.001)	Loss 0.5176 (0.4941)	Prec@1 82.031 (82.778)	Prec@5 98.438 (99.292)
EVALUATING - Epoch: [423][0/79]	Time 0.087 (0.087)	Data 0.069 (0.069)	Loss 0.5403 (0.5403)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:33

 Epoch: 424	Training Loss 0.4913 	Training Prec@1 82.700 	Training Prec@5 99.274 	Validation Loss 0.6422 	Validation Prec@1 78.680 	Validation Prec@5 98.950 

lr: 0.06279089414371312
TRAINING - Epoch: [424][0/196]	Time 0.756 (0.756)	Data 0.109 (0.109)	Loss 0.5071 (0.5071)	Prec@1 84.375 (84.375)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [424][100/196]	Time 0.085 (0.093)	Data 0.000 (0.001)	Loss 0.4655 (0.4758)	Prec@1 84.766 (83.176)	Prec@5 99.609 (99.343)
EVALUATING - Epoch: [424][0/79]	Time 0.073 (0.073)	Data 0.052 (0.052)	Loss 0.5680 (0.5680)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:29

 Epoch: 425	Training Loss 0.4821 	Training Prec@1 83.026 	Training Prec@5 99.284 	Validation Loss 0.7075 	Validation Prec@1 77.670 	Validation Prec@5 98.570 

lr: 0.06263836047641694
TRAINING - Epoch: [425][0/196]	Time 0.816 (0.816)	Data 0.084 (0.084)	Loss 0.4714 (0.4714)	Prec@1 85.938 (85.938)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [425][100/196]	Time 0.063 (0.092)	Data 0.000 (0.001)	Loss 0.5332 (0.4798)	Prec@1 80.078 (83.072)	Prec@5 99.219 (99.277)
EVALUATING - Epoch: [425][0/79]	Time 0.084 (0.084)	Data 0.063 (0.063)	Loss 0.5940 (0.5940)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:29

 Epoch: 426	Training Loss 0.4802 	Training Prec@1 83.232 	Training Prec@5 99.274 	Validation Loss 0.7154 	Validation Prec@1 76.070 	Validation Prec@5 98.370 

lr: 0.06248570108826229
TRAINING - Epoch: [426][0/196]	Time 0.331 (0.331)	Data 0.084 (0.084)	Loss 0.5358 (0.5358)	Prec@1 80.469 (80.469)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [426][100/196]	Time 0.083 (0.089)	Data 0.000 (0.001)	Loss 0.4877 (0.4758)	Prec@1 81.250 (83.513)	Prec@5 99.219 (99.296)
EVALUATING - Epoch: [426][0/79]	Time 0.084 (0.084)	Data 0.065 (0.065)	Loss 0.6535 (0.6535)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:48:42

 Epoch: 427	Training Loss 0.4785 	Training Prec@1 83.414 	Training Prec@5 99.330 	Validation Loss 0.7288 	Validation Prec@1 75.520 	Validation Prec@5 98.430 

lr: 0.062332917498061954
TRAINING - Epoch: [427][0/196]	Time 0.787 (0.787)	Data 0.108 (0.108)	Loss 0.4315 (0.4315)	Prec@1 84.375 (84.375)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [427][100/196]	Time 0.091 (0.085)	Data 0.000 (0.001)	Loss 0.4505 (0.4846)	Prec@1 84.766 (83.176)	Prec@5 99.609 (99.292)
EVALUATING - Epoch: [427][0/79]	Time 0.087 (0.087)	Data 0.068 (0.068)	Loss 0.5927 (0.5927)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:43

 Epoch: 428	Training Loss 0.4849 	Training Prec@1 83.172 	Training Prec@5 99.228 	Validation Loss 0.6648 	Validation Prec@1 77.960 	Validation Prec@5 98.640 

lr: 0.06218001122586427
TRAINING - Epoch: [428][0/196]	Time 0.816 (0.816)	Data 0.093 (0.093)	Loss 0.4713 (0.4713)	Prec@1 82.422 (82.422)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [428][100/196]	Time 0.034 (0.086)	Data 0.000 (0.001)	Loss 0.4591 (0.4709)	Prec@1 84.375 (83.331)	Prec@5 100.000 (99.319)
EVALUATING - Epoch: [428][0/79]	Time 0.080 (0.080)	Data 0.057 (0.057)	Loss 0.7080 (0.7080)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:42

 Epoch: 429	Training Loss 0.4820 	Training Prec@1 83.038 	Training Prec@5 99.256 	Validation Loss 0.7684 	Validation Prec@1 75.060 	Validation Prec@5 98.680 

lr: 0.0620269837929383
TRAINING - Epoch: [429][0/196]	Time 0.820 (0.820)	Data 0.095 (0.095)	Loss 0.5172 (0.5172)	Prec@1 82.422 (82.422)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [429][100/196]	Time 0.083 (0.094)	Data 0.000 (0.001)	Loss 0.5434 (0.4736)	Prec@1 80.859 (83.342)	Prec@5 99.609 (99.335)
EVALUATING - Epoch: [429][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 0.8576 (0.8576)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:50

 Epoch: 430	Training Loss 0.4747 	Training Prec@1 83.364 	Training Prec@5 99.302 	Validation Loss 0.8382 	Validation Prec@1 73.940 	Validation Prec@5 98.030 

lr: 0.06187383672175836
TRAINING - Epoch: [430][0/196]	Time 0.786 (0.786)	Data 0.089 (0.089)	Loss 0.4809 (0.4809)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [430][100/196]	Time 0.090 (0.093)	Data 0.000 (0.001)	Loss 0.4453 (0.4859)	Prec@1 83.984 (83.215)	Prec@5 98.828 (99.188)
EVALUATING - Epoch: [430][0/79]	Time 0.083 (0.083)	Data 0.066 (0.066)	Loss 0.4758 (0.4758)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:35

 Epoch: 431	Training Loss 0.4784 	Training Prec@1 83.342 	Training Prec@5 99.312 	Validation Loss 0.6473 	Validation Prec@1 78.620 	Validation Prec@5 98.580 

lr: 0.06172057153598921
TRAINING - Epoch: [431][0/196]	Time 0.732 (0.732)	Data 0.089 (0.089)	Loss 0.4973 (0.4973)	Prec@1 81.641 (81.641)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [431][100/196]	Time 0.086 (0.092)	Data 0.000 (0.001)	Loss 0.3870 (0.4831)	Prec@1 87.109 (82.998)	Prec@5 99.219 (99.223)
EVALUATING - Epoch: [431][0/79]	Time 0.075 (0.075)	Data 0.050 (0.050)	Loss 0.5757 (0.5757)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:48:05

 Epoch: 432	Training Loss 0.4772 	Training Prec@1 83.308 	Training Prec@5 99.240 	Validation Loss 0.7531 	Validation Prec@1 74.980 	Validation Prec@5 98.480 

lr: 0.06156718976047066
TRAINING - Epoch: [432][0/196]	Time 0.760 (0.760)	Data 0.086 (0.086)	Loss 0.4305 (0.4305)	Prec@1 84.766 (84.766)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [432][100/196]	Time 0.084 (0.080)	Data 0.000 (0.001)	Loss 0.4286 (0.4808)	Prec@1 83.984 (83.041)	Prec@5 99.219 (99.281)
EVALUATING - Epoch: [432][0/79]	Time 0.070 (0.070)	Data 0.049 (0.049)	Loss 0.5084 (0.5084)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:30

 Epoch: 433	Training Loss 0.4817 	Training Prec@1 83.212 	Training Prec@5 99.298 	Validation Loss 0.6842 	Validation Prec@1 77.550 	Validation Prec@5 98.600 

lr: 0.06141369292120246
TRAINING - Epoch: [433][0/196]	Time 0.829 (0.829)	Data 0.106 (0.106)	Loss 0.5139 (0.5139)	Prec@1 81.250 (81.250)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [433][100/196]	Time 0.056 (0.087)	Data 0.000 (0.001)	Loss 0.4693 (0.4754)	Prec@1 83.984 (83.482)	Prec@5 99.609 (99.308)
EVALUATING - Epoch: [433][0/79]	Time 0.077 (0.077)	Data 0.054 (0.054)	Loss 0.7259 (0.7259)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:01

 Epoch: 434	Training Loss 0.4789 	Training Prec@1 83.306 	Training Prec@5 99.340 	Validation Loss 0.8067 	Validation Prec@1 73.500 	Validation Prec@5 98.680 

lr: 0.06126008254532918
TRAINING - Epoch: [434][0/196]	Time 0.743 (0.743)	Data 0.106 (0.106)	Loss 0.4432 (0.4432)	Prec@1 83.984 (83.984)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [434][100/196]	Time 0.089 (0.093)	Data 0.000 (0.001)	Loss 0.4665 (0.4758)	Prec@1 85.156 (83.516)	Prec@5 99.609 (99.284)
EVALUATING - Epoch: [434][0/79]	Time 0.073 (0.073)	Data 0.051 (0.051)	Loss 0.5534 (0.5534)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:53

 Epoch: 435	Training Loss 0.4801 	Training Prec@1 83.304 	Training Prec@5 99.328 	Validation Loss 0.6365 	Validation Prec@1 78.690 	Validation Prec@5 98.960 

lr: 0.06110636016112492
TRAINING - Epoch: [435][0/196]	Time 0.757 (0.757)	Data 0.088 (0.088)	Loss 0.6301 (0.6301)	Prec@1 76.953 (76.953)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [435][100/196]	Time 0.089 (0.093)	Data 0.000 (0.001)	Loss 0.5054 (0.4662)	Prec@1 83.594 (83.632)	Prec@5 100.000 (99.381)
EVALUATING - Epoch: [435][0/79]	Time 0.084 (0.084)	Data 0.065 (0.065)	Loss 0.6510 (0.6510)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:49

 Epoch: 436	Training Loss 0.4685 	Training Prec@1 83.692 	Training Prec@5 99.326 	Validation Loss 0.7457 	Validation Prec@1 75.790 	Validation Prec@5 98.330 

lr: 0.060952527297978204
TRAINING - Epoch: [436][0/196]	Time 0.654 (0.654)	Data 0.084 (0.084)	Loss 0.5193 (0.5193)	Prec@1 83.203 (83.203)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [436][100/196]	Time 0.096 (0.093)	Data 0.000 (0.001)	Loss 0.4638 (0.4835)	Prec@1 82.422 (82.921)	Prec@5 99.219 (99.323)
EVALUATING - Epoch: [436][0/79]	Time 0.078 (0.078)	Data 0.054 (0.054)	Loss 0.6891 (0.6891)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:49:41

 Epoch: 437	Training Loss 0.4806 	Training Prec@1 83.192 	Training Prec@5 99.270 	Validation Loss 0.7802 	Validation Prec@1 74.840 	Validation Prec@5 98.150 

lr: 0.06079858548637668
TRAINING - Epoch: [437][0/196]	Time 0.781 (0.781)	Data 0.102 (0.102)	Loss 0.5119 (0.5119)	Prec@1 81.641 (81.641)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [437][100/196]	Time 0.084 (0.081)	Data 0.000 (0.001)	Loss 0.4910 (0.4822)	Prec@1 83.203 (82.882)	Prec@5 98.438 (99.304)
EVALUATING - Epoch: [437][0/79]	Time 0.072 (0.072)	Data 0.051 (0.051)	Loss 0.6247 (0.6247)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:20

 Epoch: 438	Training Loss 0.4810 	Training Prec@1 82.956 	Training Prec@5 99.284 	Validation Loss 0.6405 	Validation Prec@1 78.600 	Validation Prec@5 98.970 

lr: 0.06064453625789194
TRAINING - Epoch: [438][0/196]	Time 0.833 (0.833)	Data 0.099 (0.099)	Loss 0.5306 (0.5306)	Prec@1 80.859 (80.859)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [438][100/196]	Time 0.059 (0.088)	Data 0.000 (0.001)	Loss 0.4796 (0.4803)	Prec@1 80.859 (83.338)	Prec@5 100.000 (99.292)
EVALUATING - Epoch: [438][0/79]	Time 0.080 (0.080)	Data 0.064 (0.064)	Loss 0.8355 (0.8355)	Prec@1 69.531 (69.531)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:15

 Epoch: 439	Training Loss 0.4776 	Training Prec@1 83.424 	Training Prec@5 99.280 	Validation Loss 0.7328 	Validation Prec@1 76.180 	Validation Prec@5 97.900 

lr: 0.06049038114516425
TRAINING - Epoch: [439][0/196]	Time 0.771 (0.771)	Data 0.094 (0.094)	Loss 0.4736 (0.4736)	Prec@1 84.766 (84.766)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [439][100/196]	Time 0.092 (0.096)	Data 0.000 (0.001)	Loss 0.4159 (0.4788)	Prec@1 85.938 (83.296)	Prec@5 100.000 (99.304)
EVALUATING - Epoch: [439][0/79]	Time 0.077 (0.077)	Data 0.057 (0.057)	Loss 0.7552 (0.7552)	Prec@1 76.562 (76.562)	Prec@5 96.875 (96.875)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:19

 Epoch: 440	Training Loss 0.4749 	Training Prec@1 83.494 	Training Prec@5 99.316 	Validation Loss 0.7513 	Validation Prec@1 75.710 	Validation Prec@5 98.460 

lr: 0.06033612168188738
TRAINING - Epoch: [440][0/196]	Time 0.797 (0.797)	Data 0.108 (0.108)	Loss 0.4741 (0.4741)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [440][100/196]	Time 0.090 (0.095)	Data 0.000 (0.001)	Loss 0.4517 (0.4736)	Prec@1 82.031 (83.234)	Prec@5 98.828 (99.327)
EVALUATING - Epoch: [440][0/79]	Time 0.076 (0.076)	Data 0.056 (0.056)	Loss 0.5750 (0.5750)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:40

 Epoch: 441	Training Loss 0.4805 	Training Prec@1 83.064 	Training Prec@5 99.314 	Validation Loss 0.6194 	Validation Prec@1 79.290 	Validation Prec@5 98.900 

lr: 0.0601817594027932
TRAINING - Epoch: [441][0/196]	Time 0.794 (0.794)	Data 0.087 (0.087)	Loss 0.4968 (0.4968)	Prec@1 82.422 (82.422)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [441][100/196]	Time 0.093 (0.095)	Data 0.000 (0.001)	Loss 0.4890 (0.4654)	Prec@1 83.984 (83.830)	Prec@5 99.609 (99.273)
EVALUATING - Epoch: [441][0/79]	Time 0.077 (0.077)	Data 0.055 (0.055)	Loss 0.4902 (0.4902)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:19	Time of Finish: 2024-03-31 19:54:36

 Epoch: 442	Training Loss 0.4733 	Training Prec@1 83.602 	Training Prec@5 99.252 	Validation Loss 0.6253 	Validation Prec@1 79.460 	Validation Prec@5 98.780 

lr: 0.060027295843636586
TRAINING - Epoch: [442][0/196]	Time 0.772 (0.772)	Data 0.087 (0.087)	Loss 0.5166 (0.5166)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [442][100/196]	Time 0.092 (0.082)	Data 0.000 (0.001)	Loss 0.4622 (0.4740)	Prec@1 82.812 (83.300)	Prec@5 99.219 (99.389)
EVALUATING - Epoch: [442][0/79]	Time 0.074 (0.074)	Data 0.051 (0.051)	Loss 0.6668 (0.6668)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:54

 Epoch: 443	Training Loss 0.4776 	Training Prec@1 83.296 	Training Prec@5 99.316 	Validation Loss 0.7819 	Validation Prec@1 75.290 	Validation Prec@5 98.330 

lr: 0.05987273254117996
TRAINING - Epoch: [443][0/196]	Time 0.819 (0.819)	Data 0.113 (0.113)	Loss 0.3844 (0.3844)	Prec@1 86.328 (86.328)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [443][100/196]	Time 0.038 (0.083)	Data 0.000 (0.001)	Loss 0.5794 (0.4681)	Prec@1 79.688 (83.578)	Prec@5 99.219 (99.393)
EVALUATING - Epoch: [443][0/79]	Time 0.071 (0.071)	Data 0.050 (0.050)	Loss 0.6632 (0.6632)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:23

 Epoch: 444	Training Loss 0.4744 	Training Prec@1 83.568 	Training Prec@5 99.354 	Validation Loss 0.8241 	Validation Prec@1 73.910 	Validation Prec@5 97.730 

lr: 0.059718071033178166
TRAINING - Epoch: [444][0/196]	Time 0.777 (0.777)	Data 0.093 (0.093)	Loss 0.6083 (0.6083)	Prec@1 78.125 (78.125)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [444][100/196]	Time 0.078 (0.092)	Data 0.000 (0.001)	Loss 0.3677 (0.4762)	Prec@1 89.062 (83.280)	Prec@5 99.609 (99.393)
EVALUATING - Epoch: [444][0/79]	Time 0.076 (0.076)	Data 0.055 (0.055)	Loss 0.4913 (0.4913)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:32:59

 Epoch: 445	Training Loss 0.4684 	Training Prec@1 83.588 	Training Prec@5 99.380 	Validation Loss 0.6704 	Validation Prec@1 77.440 	Validation Prec@5 98.620 

lr: 0.05956331285836309
TRAINING - Epoch: [445][0/196]	Time 0.757 (0.757)	Data 0.087 (0.087)	Loss 0.4509 (0.4509)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [445][100/196]	Time 0.085 (0.093)	Data 0.000 (0.001)	Loss 0.3797 (0.4676)	Prec@1 85.547 (83.540)	Prec@5 100.000 (99.319)
EVALUATING - Epoch: [445][0/79]	Time 0.076 (0.076)	Data 0.061 (0.061)	Loss 0.5703 (0.5703)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:48:50

 Epoch: 446	Training Loss 0.4723 	Training Prec@1 83.324 	Training Prec@5 99.340 	Validation Loss 0.6286 	Validation Prec@1 79.040 	Validation Prec@5 98.790 

lr: 0.0594084595564283
TRAINING - Epoch: [446][0/196]	Time 0.530 (0.530)	Data 0.109 (0.109)	Loss 0.4658 (0.4658)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [446][100/196]	Time 0.086 (0.089)	Data 0.000 (0.001)	Loss 0.5154 (0.4709)	Prec@1 83.984 (83.648)	Prec@5 99.219 (99.238)
EVALUATING - Epoch: [446][0/79]	Time 0.080 (0.080)	Data 0.053 (0.053)	Loss 0.5566 (0.5566)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:36

 Epoch: 447	Training Loss 0.4708 	Training Prec@1 83.446 	Training Prec@5 99.306 	Validation Loss 0.6348 	Validation Prec@1 78.950 	Validation Prec@5 98.740 

lr: 0.0592535126680139
TRAINING - Epoch: [447][0/196]	Time 0.781 (0.781)	Data 0.093 (0.093)	Loss 0.4698 (0.4698)	Prec@1 84.766 (84.766)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [447][100/196]	Time 0.086 (0.080)	Data 0.000 (0.001)	Loss 0.5238 (0.4742)	Prec@1 83.203 (83.369)	Prec@5 99.219 (99.412)
EVALUATING - Epoch: [447][0/79]	Time 0.074 (0.074)	Data 0.050 (0.050)	Loss 0.9674 (0.9674)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:07

 Epoch: 448	Training Loss 0.4770 	Training Prec@1 83.396 	Training Prec@5 99.326 	Validation Loss 0.9605 	Validation Prec@1 71.150 	Validation Prec@5 98.100 

lr: 0.05909847373469093
TRAINING - Epoch: [448][0/196]	Time 0.834 (0.834)	Data 0.108 (0.108)	Loss 0.4341 (0.4341)	Prec@1 84.375 (84.375)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [448][100/196]	Time 0.050 (0.092)	Data 0.000 (0.001)	Loss 0.5810 (0.4751)	Prec@1 80.469 (83.257)	Prec@5 98.828 (99.412)
EVALUATING - Epoch: [448][0/79]	Time 0.075 (0.075)	Data 0.053 (0.053)	Loss 0.8495 (0.8495)	Prec@1 72.656 (72.656)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:59

 Epoch: 449	Training Loss 0.4731 	Training Prec@1 83.328 	Training Prec@5 99.410 	Validation Loss 0.8477 	Validation Prec@1 73.090 	Validation Prec@5 98.470 

lr: 0.058943344298946335
TRAINING - Epoch: [449][0/196]	Time 0.757 (0.757)	Data 0.084 (0.084)	Loss 0.4670 (0.4670)	Prec@1 83.203 (83.203)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [449][100/196]	Time 0.065 (0.093)	Data 0.000 (0.001)	Loss 0.5660 (0.4762)	Prec@1 82.422 (83.462)	Prec@5 98.438 (99.319)
EVALUATING - Epoch: [449][0/79]	Time 0.086 (0.086)	Data 0.067 (0.067)	Loss 0.9237 (0.9237)	Prec@1 71.875 (71.875)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:06

 Epoch: 450	Training Loss 0.4774 	Training Prec@1 83.398 	Training Prec@5 99.300 	Validation Loss 1.0521 	Validation Prec@1 67.910 	Validation Prec@5 97.420 

lr: 0.0587881259041674
TRAINING - Epoch: [450][0/196]	Time 0.765 (0.765)	Data 0.096 (0.096)	Loss 0.4548 (0.4548)	Prec@1 83.984 (83.984)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [450][100/196]	Time 0.086 (0.093)	Data 0.000 (0.001)	Loss 0.5614 (0.4698)	Prec@1 79.297 (83.489)	Prec@5 99.609 (99.366)
EVALUATING - Epoch: [450][0/79]	Time 0.079 (0.079)	Data 0.062 (0.062)	Loss 0.6035 (0.6035)	Prec@1 78.906 (78.906)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:04

 Epoch: 451	Training Loss 0.4700 	Training Prec@1 83.508 	Training Prec@5 99.378 	Validation Loss 0.6877 	Validation Prec@1 77.130 	Validation Prec@5 98.810 

lr: 0.05863282009462647
TRAINING - Epoch: [451][0/196]	Time 0.510 (0.510)	Data 0.103 (0.103)	Loss 0.4346 (0.4346)	Prec@1 86.328 (86.328)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [451][100/196]	Time 0.083 (0.087)	Data 0.000 (0.001)	Loss 0.4166 (0.4639)	Prec@1 85.156 (83.942)	Prec@5 100.000 (99.354)
EVALUATING - Epoch: [451][0/79]	Time 0.079 (0.079)	Data 0.056 (0.056)	Loss 0.6096 (0.6096)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:11

 Epoch: 452	Training Loss 0.4683 	Training Prec@1 83.688 	Training Prec@5 99.336 	Validation Loss 0.7961 	Validation Prec@1 75.070 	Validation Prec@5 98.300 

lr: 0.05847742841546558
TRAINING - Epoch: [452][0/196]	Time 0.794 (0.794)	Data 0.092 (0.092)	Loss 0.4714 (0.4714)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [452][100/196]	Time 0.091 (0.087)	Data 0.000 (0.001)	Loss 0.4499 (0.4730)	Prec@1 86.328 (83.304)	Prec@5 99.609 (99.373)
EVALUATING - Epoch: [452][0/79]	Time 0.076 (0.076)	Data 0.054 (0.054)	Loss 0.5007 (0.5007)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:45

 Epoch: 453	Training Loss 0.4724 	Training Prec@1 83.438 	Training Prec@5 99.354 	Validation Loss 0.6466 	Validation Prec@1 78.230 	Validation Prec@5 99.000 

lr: 0.05832195241268112
TRAINING - Epoch: [453][0/196]	Time 0.748 (0.748)	Data 0.091 (0.091)	Loss 0.4826 (0.4826)	Prec@1 83.203 (83.203)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [453][100/196]	Time 0.056 (0.089)	Data 0.000 (0.001)	Loss 0.5076 (0.4752)	Prec@1 80.078 (83.253)	Prec@5 100.000 (99.304)
EVALUATING - Epoch: [453][0/79]	Time 0.073 (0.073)	Data 0.050 (0.050)	Loss 0.7925 (0.7925)	Prec@1 75.781 (75.781)	Prec@5 96.875 (96.875)
Time cost: 00:17	Time of Finish: 2024-03-31 19:38:34

 Epoch: 454	Training Loss 0.4716 	Training Prec@1 83.546 	Training Prec@5 99.308 	Validation Loss 0.8732 	Validation Prec@1 73.500 	Validation Prec@5 98.270 

lr: 0.05816639363310836
TRAINING - Epoch: [454][0/196]	Time 0.793 (0.793)	Data 0.097 (0.097)	Loss 0.5317 (0.5317)	Prec@1 80.078 (80.078)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [454][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.4909 (0.4610)	Prec@1 86.328 (83.748)	Prec@5 98.438 (99.385)
EVALUATING - Epoch: [454][0/79]	Time 0.070 (0.070)	Data 0.050 (0.050)	Loss 0.6270 (0.6270)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:20

 Epoch: 455	Training Loss 0.4698 	Training Prec@1 83.510 	Training Prec@5 99.324 	Validation Loss 0.7528 	Validation Prec@1 75.200 	Validation Prec@5 98.540 

lr: 0.058010753624406206
TRAINING - Epoch: [455][0/196]	Time 0.756 (0.756)	Data 0.119 (0.119)	Loss 0.3419 (0.3419)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [455][100/196]	Time 0.088 (0.094)	Data 0.000 (0.001)	Loss 0.5304 (0.4653)	Prec@1 82.031 (83.876)	Prec@5 99.219 (99.393)
EVALUATING - Epoch: [455][0/79]	Time 0.082 (0.082)	Data 0.060 (0.060)	Loss 0.7720 (0.7720)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:29

 Epoch: 456	Training Loss 0.4666 	Training Prec@1 83.828 	Training Prec@5 99.398 	Validation Loss 0.7466 	Validation Prec@1 75.810 	Validation Prec@5 98.420 

lr: 0.05785503393504159
TRAINING - Epoch: [456][0/196]	Time 0.374 (0.374)	Data 0.105 (0.105)	Loss 0.5093 (0.5093)	Prec@1 82.422 (82.422)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [456][100/196]	Time 0.088 (0.087)	Data 0.000 (0.001)	Loss 0.4400 (0.4733)	Prec@1 85.938 (83.513)	Prec@5 99.609 (99.254)
EVALUATING - Epoch: [456][0/79]	Time 0.074 (0.074)	Data 0.055 (0.055)	Loss 0.5320 (0.5320)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:25

 Epoch: 457	Training Loss 0.4694 	Training Prec@1 83.670 	Training Prec@5 99.280 	Validation Loss 0.6746 	Validation Prec@1 77.400 	Validation Prec@5 98.500 

lr: 0.05769923611427429
TRAINING - Epoch: [457][0/196]	Time 0.740 (0.740)	Data 0.098 (0.098)	Loss 0.4377 (0.4377)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [457][100/196]	Time 0.089 (0.083)	Data 0.000 (0.001)	Loss 0.4463 (0.4707)	Prec@1 83.203 (83.215)	Prec@5 99.609 (99.343)
EVALUATING - Epoch: [457][0/79]	Time 0.090 (0.090)	Data 0.068 (0.068)	Loss 0.9985 (0.9985)	Prec@1 71.094 (71.094)	Prec@5 96.875 (96.875)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:13

 Epoch: 458	Training Loss 0.4758 	Training Prec@1 83.070 	Training Prec@5 99.344 	Validation Loss 0.9693 	Validation Prec@1 70.800 	Validation Prec@5 97.620 

lr: 0.057543361712141416
TRAINING - Epoch: [458][0/196]	Time 0.761 (0.761)	Data 0.090 (0.090)	Loss 0.5215 (0.5215)	Prec@1 82.422 (82.422)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [458][100/196]	Time 0.056 (0.091)	Data 0.000 (0.001)	Loss 0.5219 (0.4523)	Prec@1 80.469 (84.302)	Prec@5 98.828 (99.424)
EVALUATING - Epoch: [458][0/79]	Time 0.074 (0.074)	Data 0.055 (0.055)	Loss 0.9422 (0.9422)	Prec@1 71.094 (71.094)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:04

 Epoch: 459	Training Loss 0.4590 	Training Prec@1 84.082 	Training Prec@5 99.386 	Validation Loss 0.9125 	Validation Prec@1 72.530 	Validation Prec@5 97.780 

lr: 0.0573874122794419
TRAINING - Epoch: [459][0/196]	Time 0.743 (0.743)	Data 0.094 (0.094)	Loss 0.3996 (0.3996)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [459][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.4342 (0.4700)	Prec@1 83.594 (83.478)	Prec@5 100.000 (99.250)
EVALUATING - Epoch: [459][0/79]	Time 0.074 (0.074)	Data 0.054 (0.054)	Loss 0.6323 (0.6323)	Prec@1 79.688 (79.688)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:39

 Epoch: 460	Training Loss 0.4656 	Training Prec@1 83.690 	Training Prec@5 99.308 	Validation Loss 0.7180 	Validation Prec@1 76.400 	Validation Prec@5 98.730 

lr: 0.057231389367721264
TRAINING - Epoch: [460][0/196]	Time 0.728 (0.728)	Data 0.083 (0.083)	Loss 0.5900 (0.5900)	Prec@1 80.859 (80.859)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [460][100/196]	Time 0.084 (0.094)	Data 0.000 (0.001)	Loss 0.4934 (0.4583)	Prec@1 85.156 (84.158)	Prec@5 99.219 (99.242)
EVALUATING - Epoch: [460][0/79]	Time 0.069 (0.069)	Data 0.050 (0.050)	Loss 0.5284 (0.5284)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:44

 Epoch: 461	Training Loss 0.4659 	Training Prec@1 83.706 	Training Prec@5 99.304 	Validation Loss 0.6515 	Validation Prec@1 78.390 	Validation Prec@5 98.940 

lr: 0.05707529452925597
TRAINING - Epoch: [461][0/196]	Time 0.489 (0.489)	Data 0.084 (0.084)	Loss 0.4677 (0.4677)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [461][100/196]	Time 0.091 (0.090)	Data 0.000 (0.001)	Loss 0.5487 (0.4733)	Prec@1 80.078 (83.505)	Prec@5 99.219 (99.339)
EVALUATING - Epoch: [461][0/79]	Time 0.080 (0.080)	Data 0.062 (0.062)	Loss 0.6432 (0.6432)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:33

 Epoch: 462	Training Loss 0.4694 	Training Prec@1 83.574 	Training Prec@5 99.326 	Validation Loss 0.7232 	Validation Prec@1 76.390 	Validation Prec@5 98.400 

lr: 0.05691912931703819
TRAINING - Epoch: [462][0/196]	Time 0.788 (0.788)	Data 0.099 (0.099)	Loss 0.5811 (0.5811)	Prec@1 78.516 (78.516)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [462][100/196]	Time 0.095 (0.084)	Data 0.000 (0.001)	Loss 0.4911 (0.4683)	Prec@1 82.422 (83.613)	Prec@5 99.219 (99.312)
EVALUATING - Epoch: [462][0/79]	Time 0.072 (0.072)	Data 0.054 (0.054)	Loss 0.7954 (0.7954)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:48

 Epoch: 463	Training Loss 0.4712 	Training Prec@1 83.500 	Training Prec@5 99.330 	Validation Loss 0.8328 	Validation Prec@1 74.760 	Validation Prec@5 97.250 

lr: 0.05676289528476017
TRAINING - Epoch: [463][0/196]	Time 0.778 (0.778)	Data 0.080 (0.080)	Loss 0.4314 (0.4314)	Prec@1 85.547 (85.547)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [463][100/196]	Time 0.054 (0.090)	Data 0.000 (0.001)	Loss 0.5026 (0.4672)	Prec@1 83.203 (83.795)	Prec@5 99.219 (99.343)
EVALUATING - Epoch: [463][0/79]	Time 0.074 (0.074)	Data 0.052 (0.052)	Loss 0.5853 (0.5853)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:23

 Epoch: 464	Training Loss 0.4679 	Training Prec@1 83.682 	Training Prec@5 99.292 	Validation Loss 0.8012 	Validation Prec@1 73.960 	Validation Prec@5 98.180 

lr: 0.05660659398679885
TRAINING - Epoch: [464][0/196]	Time 0.789 (0.789)	Data 0.091 (0.091)	Loss 0.4453 (0.4453)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [464][100/196]	Time 0.088 (0.093)	Data 0.000 (0.001)	Loss 0.4682 (0.4713)	Prec@1 82.422 (83.424)	Prec@5 99.219 (99.389)
EVALUATING - Epoch: [464][0/79]	Time 0.079 (0.079)	Data 0.059 (0.059)	Loss 0.6927 (0.6927)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:17

 Epoch: 465	Training Loss 0.4706 	Training Prec@1 83.584 	Training Prec@5 99.318 	Validation Loss 0.7314 	Validation Prec@1 76.220 	Validation Prec@5 98.470 

lr: 0.056450226978200437
TRAINING - Epoch: [465][0/196]	Time 0.790 (0.790)	Data 0.099 (0.099)	Loss 0.4803 (0.4803)	Prec@1 82.812 (82.812)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [465][100/196]	Time 0.087 (0.095)	Data 0.000 (0.001)	Loss 0.4339 (0.4480)	Prec@1 86.719 (84.313)	Prec@5 98.438 (99.424)
EVALUATING - Epoch: [465][0/79]	Time 0.078 (0.078)	Data 0.053 (0.053)	Loss 0.5058 (0.5058)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:48:26

 Epoch: 466	Training Loss 0.4611 	Training Prec@1 83.918 	Training Prec@5 99.352 	Validation Loss 0.6911 	Validation Prec@1 76.190 	Validation Prec@5 98.830 

lr: 0.056293795814664864
TRAINING - Epoch: [466][0/196]	Time 0.597 (0.597)	Data 0.081 (0.081)	Loss 0.5966 (0.5966)	Prec@1 77.734 (77.734)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [466][100/196]	Time 0.084 (0.094)	Data 0.000 (0.001)	Loss 0.5024 (0.4557)	Prec@1 81.641 (83.984)	Prec@5 99.219 (99.292)
EVALUATING - Epoch: [466][0/79]	Time 0.075 (0.075)	Data 0.055 (0.055)	Loss 0.4227 (0.4227)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:19	Time of Finish: 2024-03-31 19:52:14

 Epoch: 467	Training Loss 0.4648 	Training Prec@1 83.734 	Training Prec@5 99.262 	Validation Loss 0.6179 	Validation Prec@1 79.730 	Validation Prec@5 98.780 

lr: 0.05613730205253036
TRAINING - Epoch: [467][0/196]	Time 0.809 (0.809)	Data 0.113 (0.113)	Loss 0.4246 (0.4246)	Prec@1 86.719 (86.719)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [467][100/196]	Time 0.088 (0.086)	Data 0.000 (0.001)	Loss 0.4288 (0.4572)	Prec@1 84.766 (84.127)	Prec@5 99.609 (99.296)
EVALUATING - Epoch: [467][0/79]	Time 0.086 (0.086)	Data 0.065 (0.065)	Loss 0.4868 (0.4868)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:19

 Epoch: 468	Training Loss 0.4625 	Training Prec@1 83.930 	Training Prec@5 99.308 	Validation Loss 0.7002 	Validation Prec@1 77.530 	Validation Prec@5 98.440 

lr: 0.055980747248757956
TRAINING - Epoch: [468][0/196]	Time 0.744 (0.744)	Data 0.096 (0.096)	Loss 0.4548 (0.4548)	Prec@1 87.500 (87.500)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [468][100/196]	Time 0.086 (0.087)	Data 0.000 (0.001)	Loss 0.4808 (0.4634)	Prec@1 82.031 (83.915)	Prec@5 100.000 (99.459)
EVALUATING - Epoch: [468][0/79]	Time 0.081 (0.081)	Data 0.062 (0.062)	Loss 0.5241 (0.5241)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:12

 Epoch: 469	Training Loss 0.4685 	Training Prec@1 83.540 	Training Prec@5 99.404 	Validation Loss 0.7741 	Validation Prec@1 74.790 	Validation Prec@5 98.610 

lr: 0.05582413296091597
TRAINING - Epoch: [469][0/196]	Time 0.767 (0.767)	Data 0.094 (0.094)	Loss 0.4566 (0.4566)	Prec@1 82.812 (82.812)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [469][100/196]	Time 0.091 (0.092)	Data 0.000 (0.001)	Loss 0.5067 (0.4654)	Prec@1 81.641 (83.427)	Prec@5 98.047 (99.335)
EVALUATING - Epoch: [469][0/79]	Time 0.070 (0.070)	Data 0.049 (0.049)	Loss 0.6129 (0.6129)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:20

 Epoch: 470	Training Loss 0.4670 	Training Prec@1 83.472 	Training Prec@5 99.376 	Validation Loss 0.5883 	Validation Prec@1 80.210 	Validation Prec@5 98.880 

lr: 0.05566746074716453
TRAINING - Epoch: [470][0/196]	Time 0.786 (0.786)	Data 0.104 (0.104)	Loss 0.4113 (0.4113)	Prec@1 85.938 (85.938)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [470][100/196]	Time 0.093 (0.094)	Data 0.000 (0.001)	Loss 0.4706 (0.4575)	Prec@1 82.031 (83.907)	Prec@5 99.609 (99.389)
EVALUATING - Epoch: [470][0/79]	Time 0.084 (0.084)	Data 0.060 (0.060)	Loss 0.5936 (0.5936)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:41

 Epoch: 471	Training Loss 0.4608 	Training Prec@1 83.808 	Training Prec@5 99.358 	Validation Loss 0.6937 	Validation Prec@1 76.730 	Validation Prec@5 98.740 

lr: 0.05551073216624009
TRAINING - Epoch: [471][0/196]	Time 0.819 (0.819)	Data 0.107 (0.107)	Loss 0.3863 (0.3863)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [471][100/196]	Time 0.090 (0.092)	Data 0.000 (0.001)	Loss 0.5405 (0.4629)	Prec@1 81.641 (83.745)	Prec@5 99.219 (99.327)
EVALUATING - Epoch: [471][0/79]	Time 0.070 (0.070)	Data 0.050 (0.050)	Loss 0.5570 (0.5570)	Prec@1 76.562 (76.562)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:49:37

 Epoch: 472	Training Loss 0.4674 	Training Prec@1 83.626 	Training Prec@5 99.324 	Validation Loss 0.7556 	Validation Prec@1 75.260 	Validation Prec@5 98.690 

lr: 0.05535394877743986
TRAINING - Epoch: [472][0/196]	Time 0.792 (0.792)	Data 0.079 (0.079)	Loss 0.4861 (0.4861)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [472][100/196]	Time 0.094 (0.086)	Data 0.000 (0.001)	Loss 0.5406 (0.4652)	Prec@1 82.422 (83.706)	Prec@5 98.438 (99.346)
EVALUATING - Epoch: [472][0/79]	Time 0.080 (0.080)	Data 0.058 (0.058)	Loss 0.6980 (0.6980)	Prec@1 75.781 (75.781)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:24

 Epoch: 473	Training Loss 0.4639 	Training Prec@1 83.824 	Training Prec@5 99.330 	Validation Loss 0.7680 	Validation Prec@1 74.720 	Validation Prec@5 98.220 

lr: 0.055197112140606415
TRAINING - Epoch: [473][0/196]	Time 0.801 (0.801)	Data 0.092 (0.092)	Loss 0.5098 (0.5098)	Prec@1 82.812 (82.812)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [473][100/196]	Time 0.099 (0.086)	Data 0.000 (0.001)	Loss 0.4544 (0.4493)	Prec@1 83.984 (84.363)	Prec@5 99.219 (99.420)
EVALUATING - Epoch: [473][0/79]	Time 0.087 (0.087)	Data 0.065 (0.065)	Loss 0.7657 (0.7657)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:35

 Epoch: 474	Training Loss 0.4604 	Training Prec@1 83.836 	Training Prec@5 99.364 	Validation Loss 0.7722 	Validation Prec@1 75.070 	Validation Prec@5 98.020 

lr: 0.05504022381611198
TRAINING - Epoch: [474][0/196]	Time 0.781 (0.781)	Data 0.089 (0.089)	Loss 0.4588 (0.4588)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [474][100/196]	Time 0.078 (0.095)	Data 0.000 (0.001)	Loss 0.5285 (0.4589)	Prec@1 80.078 (83.988)	Prec@5 98.828 (99.373)
EVALUATING - Epoch: [474][0/79]	Time 0.078 (0.078)	Data 0.054 (0.054)	Loss 0.5605 (0.5605)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:38

 Epoch: 475	Training Loss 0.4575 	Training Prec@1 84.052 	Training Prec@5 99.388 	Validation Loss 0.6704 	Validation Prec@1 77.220 	Validation Prec@5 98.760 

lr: 0.05488328536484314
TRAINING - Epoch: [475][0/196]	Time 0.730 (0.730)	Data 0.106 (0.106)	Loss 0.4276 (0.4276)	Prec@1 86.719 (86.719)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [475][100/196]	Time 0.093 (0.093)	Data 0.000 (0.001)	Loss 0.6317 (0.4578)	Prec@1 78.125 (83.938)	Prec@5 97.656 (99.373)
EVALUATING - Epoch: [475][0/79]	Time 0.079 (0.079)	Data 0.061 (0.061)	Loss 0.9746 (0.9746)	Prec@1 71.094 (71.094)	Prec@5 96.875 (96.875)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:33

 Epoch: 476	Training Loss 0.4631 	Training Prec@1 83.758 	Training Prec@5 99.350 	Validation Loss 1.0299 	Validation Prec@1 70.410 	Validation Prec@5 96.270 

lr: 0.05472629834818511
TRAINING - Epoch: [476][0/196]	Time 0.832 (0.832)	Data 0.095 (0.095)	Loss 0.3325 (0.3325)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [476][100/196]	Time 0.087 (0.094)	Data 0.000 (0.001)	Loss 0.4103 (0.4545)	Prec@1 87.891 (83.996)	Prec@5 99.219 (99.281)
EVALUATING - Epoch: [476][0/79]	Time 0.079 (0.079)	Data 0.056 (0.056)	Loss 0.7043 (0.7043)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:51:43

 Epoch: 477	Training Loss 0.4606 	Training Prec@1 83.752 	Training Prec@5 99.304 	Validation Loss 0.6691 	Validation Prec@1 77.850 	Validation Prec@5 98.760 

lr: 0.05456926432800634
TRAINING - Epoch: [477][0/196]	Time 0.600 (0.600)	Data 0.093 (0.093)	Loss 0.5248 (0.5248)	Prec@1 80.859 (80.859)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [477][100/196]	Time 0.083 (0.082)	Data 0.000 (0.001)	Loss 0.4712 (0.4676)	Prec@1 84.375 (83.625)	Prec@5 100.000 (99.373)
EVALUATING - Epoch: [477][0/79]	Time 0.070 (0.070)	Data 0.051 (0.051)	Loss 0.6294 (0.6294)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:36

 Epoch: 478	Training Loss 0.4642 	Training Prec@1 83.800 	Training Prec@5 99.364 	Validation Loss 0.7477 	Validation Prec@1 76.250 	Validation Prec@5 98.350 

lr: 0.05441218486664286
TRAINING - Epoch: [478][0/196]	Time 0.817 (0.817)	Data 0.099 (0.099)	Loss 0.5737 (0.5737)	Prec@1 81.250 (81.250)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [478][100/196]	Time 0.085 (0.087)	Data 0.000 (0.001)	Loss 0.4021 (0.4656)	Prec@1 86.719 (83.609)	Prec@5 99.609 (99.335)
EVALUATING - Epoch: [478][0/79]	Time 0.087 (0.087)	Data 0.067 (0.067)	Loss 0.7078 (0.7078)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:20

 Epoch: 479	Training Loss 0.4625 	Training Prec@1 83.776 	Training Prec@5 99.368 	Validation Loss 0.7009 	Validation Prec@1 77.840 	Validation Prec@5 98.390 

lr: 0.05425506152688284
TRAINING - Epoch: [479][0/196]	Time 0.796 (0.796)	Data 0.091 (0.091)	Loss 0.3745 (0.3745)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [479][100/196]	Time 0.054 (0.093)	Data 0.000 (0.001)	Loss 0.3554 (0.4522)	Prec@1 86.328 (84.216)	Prec@5 100.000 (99.381)
EVALUATING - Epoch: [479][0/79]	Time 0.076 (0.076)	Data 0.055 (0.055)	Loss 0.8959 (0.8959)	Prec@1 71.094 (71.094)	Prec@5 96.875 (96.875)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:32

 Epoch: 480	Training Loss 0.4591 	Training Prec@1 83.968 	Training Prec@5 99.372 	Validation Loss 0.8749 	Validation Prec@1 71.970 	Validation Prec@5 98.070 

lr: 0.05409789587195101
TRAINING - Epoch: [480][0/196]	Time 0.795 (0.795)	Data 0.100 (0.100)	Loss 0.3893 (0.3893)	Prec@1 85.547 (85.547)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [480][100/196]	Time 0.087 (0.095)	Data 0.000 (0.001)	Loss 0.5026 (0.4662)	Prec@1 82.422 (83.497)	Prec@5 99.609 (99.304)
EVALUATING - Epoch: [480][0/79]	Time 0.086 (0.086)	Data 0.066 (0.066)	Loss 0.9181 (0.9181)	Prec@1 72.656 (72.656)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:31

 Epoch: 481	Training Loss 0.4668 	Training Prec@1 83.652 	Training Prec@5 99.316 	Validation Loss 0.8455 	Validation Prec@1 74.150 	Validation Prec@5 97.550 

lr: 0.05394068946549305
TRAINING - Epoch: [481][0/196]	Time 0.750 (0.750)	Data 0.089 (0.089)	Loss 0.5284 (0.5284)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [481][100/196]	Time 0.090 (0.095)	Data 0.000 (0.001)	Loss 0.5046 (0.4576)	Prec@1 82.031 (83.911)	Prec@5 98.438 (99.296)
EVALUATING - Epoch: [481][0/79]	Time 0.071 (0.071)	Data 0.049 (0.049)	Loss 0.6623 (0.6623)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:49:10

 Epoch: 482	Training Loss 0.4623 	Training Prec@1 83.776 	Training Prec@5 99.320 	Validation Loss 0.6947 	Validation Prec@1 77.960 	Validation Prec@5 98.240 

lr: 0.053783443871560095
TRAINING - Epoch: [482][0/196]	Time 0.483 (0.483)	Data 0.125 (0.125)	Loss 0.4131 (0.4131)	Prec@1 87.500 (87.500)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [482][100/196]	Time 0.087 (0.090)	Data 0.000 (0.001)	Loss 0.4324 (0.4612)	Prec@1 83.984 (83.849)	Prec@5 99.609 (99.304)
EVALUATING - Epoch: [482][0/79]	Time 0.085 (0.085)	Data 0.064 (0.064)	Loss 0.6925 (0.6925)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:49:25

 Epoch: 483	Training Loss 0.4572 	Training Prec@1 84.024 	Training Prec@5 99.318 	Validation Loss 0.7618 	Validation Prec@1 75.840 	Validation Prec@5 98.650 

lr: 0.05362616065459315
TRAINING - Epoch: [483][0/196]	Time 0.815 (0.815)	Data 0.093 (0.093)	Loss 0.4281 (0.4281)	Prec@1 85.547 (85.547)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [483][100/196]	Time 0.097 (0.085)	Data 0.000 (0.001)	Loss 0.5003 (0.4625)	Prec@1 82.422 (83.822)	Prec@5 99.609 (99.304)
EVALUATING - Epoch: [483][0/79]	Time 0.072 (0.072)	Data 0.053 (0.053)	Loss 0.5281 (0.5281)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:39

 Epoch: 484	Training Loss 0.4584 	Training Prec@1 83.882 	Training Prec@5 99.360 	Validation Loss 0.6038 	Validation Prec@1 79.940 	Validation Prec@5 98.580 

lr: 0.05346884137940759
TRAINING - Epoch: [484][0/196]	Time 0.789 (0.789)	Data 0.113 (0.113)	Loss 0.4270 (0.4270)	Prec@1 84.766 (84.766)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [484][100/196]	Time 0.052 (0.086)	Data 0.000 (0.001)	Loss 0.4945 (0.4563)	Prec@1 81.641 (84.124)	Prec@5 99.609 (99.377)
EVALUATING - Epoch: [484][0/79]	Time 0.073 (0.073)	Data 0.052 (0.052)	Loss 0.5117 (0.5117)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:12

 Epoch: 485	Training Loss 0.4600 	Training Prec@1 83.902 	Training Prec@5 99.394 	Validation Loss 0.6030 	Validation Prec@1 80.020 	Validation Prec@5 98.770 

lr: 0.05331148761117744
TRAINING - Epoch: [485][0/196]	Time 0.744 (0.744)	Data 0.081 (0.081)	Loss 0.3862 (0.3862)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [485][100/196]	Time 0.066 (0.092)	Data 0.000 (0.001)	Loss 0.5725 (0.4583)	Prec@1 83.203 (83.903)	Prec@5 98.828 (99.343)
EVALUATING - Epoch: [485][0/79]	Time 0.079 (0.079)	Data 0.057 (0.057)	Loss 0.6173 (0.6173)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:02

 Epoch: 486	Training Loss 0.4603 	Training Prec@1 83.878 	Training Prec@5 99.344 	Validation Loss 0.8479 	Validation Prec@1 72.600 	Validation Prec@5 98.800 

lr: 0.05315410091541998
TRAINING - Epoch: [486][0/196]	Time 0.808 (0.808)	Data 0.086 (0.086)	Loss 0.4486 (0.4486)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [486][100/196]	Time 0.081 (0.093)	Data 0.000 (0.001)	Loss 0.5338 (0.4621)	Prec@1 81.250 (83.698)	Prec@5 98.828 (99.408)
EVALUATING - Epoch: [486][0/79]	Time 0.082 (0.082)	Data 0.067 (0.067)	Loss 0.5088 (0.5088)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:32

 Epoch: 487	Training Loss 0.4616 	Training Prec@1 83.718 	Training Prec@5 99.412 	Validation Loss 0.6808 	Validation Prec@1 77.400 	Validation Prec@5 98.410 

lr: 0.052996682857980024
TRAINING - Epoch: [487][0/196]	Time 0.809 (0.809)	Data 0.103 (0.103)	Loss 0.5080 (0.5080)	Prec@1 81.641 (81.641)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [487][100/196]	Time 0.094 (0.093)	Data 0.000 (0.001)	Loss 0.4705 (0.4561)	Prec@1 82.812 (84.008)	Prec@5 99.609 (99.354)
EVALUATING - Epoch: [487][0/79]	Time 0.075 (0.075)	Data 0.052 (0.052)	Loss 0.7323 (0.7323)	Prec@1 73.438 (73.438)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:50:44

 Epoch: 488	Training Loss 0.4531 	Training Prec@1 84.084 	Training Prec@5 99.362 	Validation Loss 0.8124 	Validation Prec@1 74.270 	Validation Prec@5 98.320 

lr: 0.052839235005014466
TRAINING - Epoch: [488][0/196]	Time 0.809 (0.809)	Data 0.090 (0.090)	Loss 0.3823 (0.3823)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [488][100/196]	Time 0.084 (0.084)	Data 0.000 (0.001)	Loss 0.5126 (0.4503)	Prec@1 81.250 (84.433)	Prec@5 99.609 (99.401)
EVALUATING - Epoch: [488][0/79]	Time 0.072 (0.072)	Data 0.051 (0.051)	Loss 0.5054 (0.5054)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:09

 Epoch: 489	Training Loss 0.4533 	Training Prec@1 84.242 	Training Prec@5 99.410 	Validation Loss 0.6117 	Validation Prec@1 79.790 	Validation Prec@5 98.920 

lr: 0.052681758922976565
TRAINING - Epoch: [489][0/196]	Time 0.761 (0.761)	Data 0.102 (0.102)	Loss 0.5517 (0.5517)	Prec@1 79.297 (79.297)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [489][100/196]	Time 0.084 (0.084)	Data 0.000 (0.001)	Loss 0.4612 (0.4586)	Prec@1 85.938 (83.911)	Prec@5 99.219 (99.474)
EVALUATING - Epoch: [489][0/79]	Time 0.087 (0.087)	Data 0.066 (0.066)	Loss 0.8257 (0.8257)	Prec@1 71.875 (71.875)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:33

 Epoch: 490	Training Loss 0.4578 	Training Prec@1 83.990 	Training Prec@5 99.418 	Validation Loss 0.8903 	Validation Prec@1 72.340 	Validation Prec@5 97.930 

lr: 0.052524256178600494
TRAINING - Epoch: [490][0/196]	Time 0.748 (0.748)	Data 0.097 (0.097)	Loss 0.3843 (0.3843)	Prec@1 86.719 (86.719)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [490][100/196]	Time 0.095 (0.092)	Data 0.000 (0.001)	Loss 0.4459 (0.4498)	Prec@1 84.375 (84.251)	Prec@5 98.828 (99.424)
EVALUATING - Epoch: [490][0/79]	Time 0.074 (0.074)	Data 0.054 (0.054)	Loss 0.5667 (0.5667)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:38:59

 Epoch: 491	Training Loss 0.4597 	Training Prec@1 83.968 	Training Prec@5 99.408 	Validation Loss 0.6063 	Validation Prec@1 79.980 	Validation Prec@5 98.830 

lr: 0.05236672833888567
TRAINING - Epoch: [491][0/196]	Time 0.778 (0.778)	Data 0.087 (0.087)	Loss 0.5329 (0.5329)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)
TRAINING - Epoch: [491][100/196]	Time 0.091 (0.093)	Data 0.000 (0.001)	Loss 0.4451 (0.4590)	Prec@1 85.156 (84.100)	Prec@5 100.000 (99.389)
EVALUATING - Epoch: [491][0/79]	Time 0.075 (0.075)	Data 0.052 (0.052)	Loss 0.6653 (0.6653)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:32

 Epoch: 492	Training Loss 0.4562 	Training Prec@1 84.086 	Training Prec@5 99.390 	Validation Loss 0.6971 	Validation Prec@1 76.980 	Validation Prec@5 98.690 

lr: 0.05220917697108115
TRAINING - Epoch: [492][0/196]	Time 0.799 (0.799)	Data 0.081 (0.081)	Loss 0.3949 (0.3949)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [492][100/196]	Time 0.087 (0.094)	Data 0.000 (0.001)	Loss 0.4283 (0.4555)	Prec@1 83.984 (83.915)	Prec@5 100.000 (99.404)
EVALUATING - Epoch: [492][0/79]	Time 0.073 (0.073)	Data 0.052 (0.052)	Loss 0.4602 (0.4602)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:49:53

 Epoch: 493	Training Loss 0.4515 	Training Prec@1 84.182 	Training Prec@5 99.394 	Validation Loss 0.6106 	Validation Prec@1 80.070 	Validation Prec@5 99.020 

lr: 0.052051603642670134
TRAINING - Epoch: [493][0/196]	Time 0.780 (0.780)	Data 0.080 (0.080)	Loss 0.5158 (0.5158)	Prec@1 81.641 (81.641)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [493][100/196]	Time 0.095 (0.080)	Data 0.000 (0.001)	Loss 0.4899 (0.4408)	Prec@1 83.594 (84.479)	Prec@5 98.438 (99.443)
EVALUATING - Epoch: [493][0/79]	Time 0.084 (0.084)	Data 0.064 (0.064)	Loss 0.6314 (0.6314)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:45

 Epoch: 494	Training Loss 0.4485 	Training Prec@1 84.280 	Training Prec@5 99.428 	Validation Loss 0.7356 	Validation Prec@1 76.320 	Validation Prec@5 98.200 

lr: 0.05189400992135429
TRAINING - Epoch: [494][0/196]	Time 0.780 (0.780)	Data 0.095 (0.095)	Loss 0.4208 (0.4208)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [494][100/196]	Time 0.027 (0.084)	Data 0.000 (0.001)	Loss 0.4806 (0.4483)	Prec@1 84.375 (84.336)	Prec@5 99.609 (99.424)
EVALUATING - Epoch: [494][0/79]	Time 0.084 (0.084)	Data 0.063 (0.063)	Loss 0.7068 (0.7068)	Prec@1 76.562 (76.562)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:57

 Epoch: 495	Training Loss 0.4535 	Training Prec@1 84.224 	Training Prec@5 99.352 	Validation Loss 0.6349 	Validation Prec@1 78.800 	Validation Prec@5 98.940 

lr: 0.05173639737503812
TRAINING - Epoch: [495][0/196]	Time 0.801 (0.801)	Data 0.088 (0.088)	Loss 0.4602 (0.4602)	Prec@1 83.594 (83.594)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [495][100/196]	Time 0.089 (0.092)	Data 0.000 (0.001)	Loss 0.4839 (0.4438)	Prec@1 83.594 (84.495)	Prec@5 98.438 (99.431)
EVALUATING - Epoch: [495][0/79]	Time 0.079 (0.079)	Data 0.062 (0.062)	Loss 0.7615 (0.7615)	Prec@1 73.438 (73.438)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:10

 Epoch: 496	Training Loss 0.4583 	Training Prec@1 83.928 	Training Prec@5 99.388 	Validation Loss 0.7425 	Validation Prec@1 75.880 	Validation Prec@5 98.610 

lr: 0.05157876757181349
TRAINING - Epoch: [496][0/196]	Time 0.743 (0.743)	Data 0.085 (0.085)	Loss 0.4655 (0.4655)	Prec@1 82.812 (82.812)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [496][100/196]	Time 0.092 (0.092)	Data 0.000 (0.001)	Loss 0.3919 (0.4462)	Prec@1 84.766 (84.298)	Prec@5 99.609 (99.455)
EVALUATING - Epoch: [496][0/79]	Time 0.073 (0.073)	Data 0.051 (0.051)	Loss 0.5340 (0.5340)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:52

 Epoch: 497	Training Loss 0.4536 	Training Prec@1 84.044 	Training Prec@5 99.408 	Validation Loss 0.6998 	Validation Prec@1 77.120 	Validation Prec@5 98.770 

lr: 0.05142112207994394
TRAINING - Epoch: [497][0/196]	Time 0.347 (0.347)	Data 0.081 (0.081)	Loss 0.4553 (0.4553)	Prec@1 83.203 (83.203)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [497][100/196]	Time 0.081 (0.089)	Data 0.000 (0.001)	Loss 0.4225 (0.4382)	Prec@1 83.984 (84.448)	Prec@5 99.219 (99.532)
EVALUATING - Epoch: [497][0/79]	Time 0.073 (0.073)	Data 0.050 (0.050)	Loss 0.7326 (0.7326)	Prec@1 72.656 (72.656)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:03

 Epoch: 498	Training Loss 0.4501 	Training Prec@1 84.188 	Training Prec@5 99.424 	Validation Loss 0.7500 	Validation Prec@1 75.240 	Validation Prec@5 98.760 

lr: 0.05126346246784903
TRAINING - Epoch: [498][0/196]	Time 0.777 (0.777)	Data 0.095 (0.095)	Loss 0.3944 (0.3944)	Prec@1 86.328 (86.328)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [498][100/196]	Time 0.089 (0.084)	Data 0.000 (0.001)	Loss 0.5488 (0.4497)	Prec@1 82.812 (84.182)	Prec@5 98.828 (99.377)
EVALUATING - Epoch: [498][0/79]	Time 0.096 (0.096)	Data 0.073 (0.073)	Loss 0.6088 (0.6088)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:22

 Epoch: 499	Training Loss 0.4512 	Training Prec@1 84.242 	Training Prec@5 99.370 	Validation Loss 0.7246 	Validation Prec@1 76.940 	Validation Prec@5 98.600 

lr: 0.051105790304088905
TRAINING - Epoch: [499][0/196]	Time 0.805 (0.805)	Data 0.082 (0.082)	Loss 0.4762 (0.4762)	Prec@1 83.594 (83.594)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [499][100/196]	Time 0.056 (0.088)	Data 0.000 (0.001)	Loss 0.3834 (0.4464)	Prec@1 87.891 (84.418)	Prec@5 98.828 (99.377)
EVALUATING - Epoch: [499][0/79]	Time 0.082 (0.082)	Data 0.060 (0.060)	Loss 0.8585 (0.8585)	Prec@1 75.000 (75.000)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:52

 Epoch: 500	Training Loss 0.4504 	Training Prec@1 84.294 	Training Prec@5 99.382 	Validation Loss 0.9395 	Validation Prec@1 71.800 	Validation Prec@5 98.230 

lr: 0.05094810715734852
TRAINING - Epoch: [500][0/196]	Time 0.710 (0.710)	Data 0.082 (0.082)	Loss 0.4381 (0.4381)	Prec@1 85.938 (85.938)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [500][100/196]	Time 0.089 (0.094)	Data 0.000 (0.001)	Loss 0.4891 (0.4445)	Prec@1 85.156 (84.429)	Prec@5 98.828 (99.397)
EVALUATING - Epoch: [500][0/79]	Time 0.081 (0.081)	Data 0.060 (0.060)	Loss 0.8157 (0.8157)	Prec@1 69.531 (69.531)	Prec@5 96.875 (96.875)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:21

 Epoch: 501	Training Loss 0.4530 	Training Prec@1 84.194 	Training Prec@5 99.402 	Validation Loss 0.9104 	Validation Prec@1 69.920 	Validation Prec@5 97.570 

lr: 0.05079041459642211
TRAINING - Epoch: [501][0/196]	Time 0.774 (0.774)	Data 0.095 (0.095)	Loss 0.4598 (0.4598)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [501][100/196]	Time 0.084 (0.093)	Data 0.000 (0.001)	Loss 0.4712 (0.4452)	Prec@1 82.812 (84.491)	Prec@5 99.609 (99.385)
EVALUATING - Epoch: [501][0/79]	Time 0.094 (0.094)	Data 0.069 (0.069)	Loss 0.6221 (0.6221)	Prec@1 76.562 (76.562)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:05

 Epoch: 502	Training Loss 0.4527 	Training Prec@1 84.176 	Training Prec@5 99.376 	Validation Loss 0.7194 	Validation Prec@1 76.420 	Validation Prec@5 98.620 

lr: 0.05063271419019761
TRAINING - Epoch: [502][0/196]	Time 0.557 (0.557)	Data 0.121 (0.121)	Loss 0.5349 (0.5349)	Prec@1 80.859 (80.859)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [502][100/196]	Time 0.086 (0.092)	Data 0.000 (0.001)	Loss 0.5287 (0.4593)	Prec@1 82.812 (83.895)	Prec@5 98.828 (99.308)
EVALUATING - Epoch: [502][0/79]	Time 0.072 (0.072)	Data 0.051 (0.051)	Loss 0.5396 (0.5396)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:48:13

 Epoch: 503	Training Loss 0.4551 	Training Prec@1 84.056 	Training Prec@5 99.356 	Validation Loss 0.6662 	Validation Prec@1 78.910 	Validation Prec@5 98.530 

lr: 0.05047500750764092
TRAINING - Epoch: [503][0/196]	Time 0.808 (0.808)	Data 0.100 (0.100)	Loss 0.3791 (0.3791)	Prec@1 87.891 (87.891)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [503][100/196]	Time 0.088 (0.078)	Data 0.000 (0.001)	Loss 0.4319 (0.4434)	Prec@1 86.328 (84.572)	Prec@5 99.609 (99.459)
EVALUATING - Epoch: [503][0/79]	Time 0.076 (0.076)	Data 0.050 (0.050)	Loss 0.7216 (0.7216)	Prec@1 74.219 (74.219)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:38:00

 Epoch: 504	Training Loss 0.4452 	Training Prec@1 84.402 	Training Prec@5 99.474 	Validation Loss 0.6686 	Validation Prec@1 77.670 	Validation Prec@5 98.860 

lr: 0.0503172961177805
TRAINING - Epoch: [504][0/196]	Time 0.793 (0.793)	Data 0.101 (0.101)	Loss 0.4726 (0.4726)	Prec@1 82.812 (82.812)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [504][100/196]	Time 0.049 (0.090)	Data 0.000 (0.001)	Loss 0.4660 (0.4553)	Prec@1 85.547 (83.926)	Prec@5 99.219 (99.350)
EVALUATING - Epoch: [504][0/79]	Time 0.073 (0.073)	Data 0.052 (0.052)	Loss 0.7627 (0.7627)	Prec@1 73.438 (73.438)	Prec@5 96.094 (96.094)
Time cost: 00:17	Time of Finish: 2024-03-31 19:38:56

 Epoch: 505	Training Loss 0.4545 	Training Prec@1 83.974 	Training Prec@5 99.324 	Validation Loss 0.8073 	Validation Prec@1 74.900 	Validation Prec@5 97.460 

lr: 0.05015958158969154
TRAINING - Epoch: [505][0/196]	Time 0.805 (0.805)	Data 0.108 (0.108)	Loss 0.4696 (0.4696)	Prec@1 83.594 (83.594)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [505][100/196]	Time 0.082 (0.095)	Data 0.000 (0.001)	Loss 0.4125 (0.4464)	Prec@1 83.594 (84.371)	Prec@5 100.000 (99.501)
EVALUATING - Epoch: [505][0/79]	Time 0.084 (0.084)	Data 0.062 (0.062)	Loss 0.5691 (0.5691)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:24

 Epoch: 506	Training Loss 0.4449 	Training Prec@1 84.420 	Training Prec@5 99.434 	Validation Loss 0.6485 	Validation Prec@1 78.690 	Validation Prec@5 98.880 

lr: 0.050001865492480514
TRAINING - Epoch: [506][0/196]	Time 0.706 (0.706)	Data 0.095 (0.095)	Loss 0.4063 (0.4063)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [506][100/196]	Time 0.095 (0.094)	Data 0.000 (0.001)	Loss 0.4415 (0.4349)	Prec@1 84.766 (85.087)	Prec@5 99.219 (99.412)
EVALUATING - Epoch: [506][0/79]	Time 0.075 (0.075)	Data 0.051 (0.051)	Loss 0.7454 (0.7454)	Prec@1 73.438 (73.438)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:49:35

 Epoch: 507	Training Loss 0.4490 	Training Prec@1 84.468 	Training Prec@5 99.398 	Validation Loss 0.8749 	Validation Prec@1 73.640 	Validation Prec@5 97.940 

lr: 0.049844149395269495
TRAINING - Epoch: [507][0/196]	Time 0.547 (0.547)	Data 0.088 (0.088)	Loss 0.4434 (0.4434)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [507][100/196]	Time 0.091 (0.088)	Data 0.000 (0.001)	Loss 0.3953 (0.4488)	Prec@1 86.719 (84.205)	Prec@5 100.000 (99.455)
EVALUATING - Epoch: [507][0/79]	Time 0.074 (0.074)	Data 0.053 (0.053)	Loss 0.5511 (0.5511)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:58

 Epoch: 508	Training Loss 0.4457 	Training Prec@1 84.492 	Training Prec@5 99.436 	Validation Loss 0.6741 	Validation Prec@1 77.690 	Validation Prec@5 98.590 

lr: 0.04968643486718054
TRAINING - Epoch: [508][0/196]	Time 0.815 (0.815)	Data 0.107 (0.107)	Loss 0.3766 (0.3766)	Prec@1 86.328 (86.328)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [508][100/196]	Time 0.092 (0.086)	Data 0.000 (0.001)	Loss 0.4451 (0.4449)	Prec@1 82.812 (84.541)	Prec@5 99.609 (99.439)
EVALUATING - Epoch: [508][0/79]	Time 0.080 (0.080)	Data 0.058 (0.058)	Loss 0.6460 (0.6460)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:55

 Epoch: 509	Training Loss 0.4439 	Training Prec@1 84.532 	Training Prec@5 99.400 	Validation Loss 0.7383 	Validation Prec@1 76.250 	Validation Prec@5 98.210 

lr: 0.049528723477320104
TRAINING - Epoch: [509][0/196]	Time 0.761 (0.761)	Data 0.093 (0.093)	Loss 0.4152 (0.4152)	Prec@1 87.500 (87.500)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [509][100/196]	Time 0.056 (0.087)	Data 0.000 (0.001)	Loss 0.4010 (0.4485)	Prec@1 84.766 (84.267)	Prec@5 100.000 (99.350)
EVALUATING - Epoch: [509][0/79]	Time 0.074 (0.074)	Data 0.054 (0.054)	Loss 0.6116 (0.6116)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:24

 Epoch: 510	Training Loss 0.4529 	Training Prec@1 83.942 	Training Prec@5 99.404 	Validation Loss 0.6957 	Validation Prec@1 77.660 	Validation Prec@5 98.330 

lr: 0.04937101679476342
TRAINING - Epoch: [510][0/196]	Time 0.808 (0.808)	Data 0.098 (0.098)	Loss 0.4322 (0.4322)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [510][100/196]	Time 0.090 (0.093)	Data 0.000 (0.001)	Loss 0.4210 (0.4475)	Prec@1 84.766 (84.398)	Prec@5 100.000 (99.339)
EVALUATING - Epoch: [510][0/79]	Time 0.081 (0.081)	Data 0.063 (0.063)	Loss 0.5902 (0.5902)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:20

 Epoch: 511	Training Loss 0.4481 	Training Prec@1 84.330 	Training Prec@5 99.370 	Validation Loss 0.6712 	Validation Prec@1 76.750 	Validation Prec@5 98.920 

lr: 0.0492133163885389
TRAINING - Epoch: [511][0/196]	Time 0.780 (0.780)	Data 0.097 (0.097)	Loss 0.3609 (0.3609)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [511][100/196]	Time 0.086 (0.095)	Data 0.000 (0.001)	Loss 0.6053 (0.4398)	Prec@1 77.344 (84.704)	Prec@5 100.000 (99.447)
EVALUATING - Epoch: [511][0/79]	Time 0.087 (0.087)	Data 0.070 (0.070)	Loss 0.3978 (0.3978)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:07

 Epoch: 512	Training Loss 0.4456 	Training Prec@1 84.368 	Training Prec@5 99.408 	Validation Loss 0.6030 	Validation Prec@1 79.350 	Validation Prec@5 98.940 

lr: 0.0490556238276125
TRAINING - Epoch: [512][0/196]	Time 0.791 (0.791)	Data 0.102 (0.102)	Loss 0.5743 (0.5743)	Prec@1 83.203 (83.203)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [512][100/196]	Time 0.089 (0.094)	Data 0.000 (0.001)	Loss 0.3656 (0.4435)	Prec@1 89.062 (84.704)	Prec@5 99.609 (99.482)
EVALUATING - Epoch: [512][0/79]	Time 0.075 (0.075)	Data 0.056 (0.056)	Loss 0.6341 (0.6341)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:19	Time of Finish: 2024-03-31 19:51:20

 Epoch: 513	Training Loss 0.4504 	Training Prec@1 84.400 	Training Prec@5 99.412 	Validation Loss 0.7468 	Validation Prec@1 75.610 	Validation Prec@5 98.580 

lr: 0.04889794068087211
TRAINING - Epoch: [513][0/196]	Time 0.769 (0.769)	Data 0.105 (0.105)	Loss 0.4414 (0.4414)	Prec@1 83.984 (83.984)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [513][100/196]	Time 0.094 (0.082)	Data 0.000 (0.001)	Loss 0.3592 (0.4455)	Prec@1 84.766 (84.282)	Prec@5 100.000 (99.408)
EVALUATING - Epoch: [513][0/79]	Time 0.077 (0.077)	Data 0.056 (0.056)	Loss 0.6251 (0.6251)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:10

 Epoch: 514	Training Loss 0.4498 	Training Prec@1 84.094 	Training Prec@5 99.400 	Validation Loss 0.7936 	Validation Prec@1 74.750 	Validation Prec@5 98.820 

lr: 0.048740268517111975
TRAINING - Epoch: [514][0/196]	Time 0.750 (0.750)	Data 0.087 (0.087)	Loss 0.4652 (0.4652)	Prec@1 80.078 (80.078)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [514][100/196]	Time 0.030 (0.083)	Data 0.000 (0.001)	Loss 0.4708 (0.4482)	Prec@1 84.375 (84.232)	Prec@5 99.609 (99.404)
EVALUATING - Epoch: [514][0/79]	Time 0.077 (0.077)	Data 0.057 (0.057)	Loss 0.6012 (0.6012)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:34

 Epoch: 515	Training Loss 0.4503 	Training Prec@1 84.160 	Training Prec@5 99.402 	Validation Loss 0.6912 	Validation Prec@1 77.660 	Validation Prec@5 98.840 

lr: 0.048582608905017095
TRAINING - Epoch: [515][0/196]	Time 0.760 (0.760)	Data 0.096 (0.096)	Loss 0.3482 (0.3482)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [515][100/196]	Time 0.095 (0.094)	Data 0.000 (0.001)	Loss 0.4046 (0.4459)	Prec@1 85.547 (84.456)	Prec@5 99.609 (99.408)
EVALUATING - Epoch: [515][0/79]	Time 0.074 (0.074)	Data 0.052 (0.052)	Loss 0.5097 (0.5097)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:47

 Epoch: 516	Training Loss 0.4475 	Training Prec@1 84.420 	Training Prec@5 99.398 	Validation Loss 0.5706 	Validation Prec@1 80.560 	Validation Prec@5 99.130 

lr: 0.04842496341314752
TRAINING - Epoch: [516][0/196]	Time 0.819 (0.819)	Data 0.094 (0.094)	Loss 0.3813 (0.3813)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [516][100/196]	Time 0.087 (0.093)	Data 0.000 (0.001)	Loss 0.3705 (0.4514)	Prec@1 86.328 (84.251)	Prec@5 99.609 (99.439)
EVALUATING - Epoch: [516][0/79]	Time 0.088 (0.088)	Data 0.067 (0.067)	Loss 0.6512 (0.6512)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:53

 Epoch: 517	Training Loss 0.4458 	Training Prec@1 84.424 	Training Prec@5 99.440 	Validation Loss 0.7160 	Validation Prec@1 77.050 	Validation Prec@5 98.730 

lr: 0.048267333609922906
TRAINING - Epoch: [517][0/196]	Time 0.821 (0.821)	Data 0.104 (0.104)	Loss 0.5296 (0.5296)	Prec@1 83.203 (83.203)	Prec@5 98.047 (98.047)
TRAINING - Epoch: [517][100/196]	Time 0.085 (0.094)	Data 0.000 (0.001)	Loss 0.3605 (0.4415)	Prec@1 86.328 (84.545)	Prec@5 100.000 (99.385)
EVALUATING - Epoch: [517][0/79]	Time 0.082 (0.082)	Data 0.061 (0.061)	Loss 0.4535 (0.4535)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:19	Time of Finish: 2024-03-31 19:50:54

 Epoch: 518	Training Loss 0.4455 	Training Prec@1 84.384 	Training Prec@5 99.390 	Validation Loss 0.5197 	Validation Prec@1 82.530 	Validation Prec@5 99.280 

lr: 0.04810972106360673
TRAINING - Epoch: [518][0/196]	Time 0.770 (0.770)	Data 0.102 (0.102)	Loss 0.5001 (0.5001)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [518][100/196]	Time 0.092 (0.085)	Data 0.000 (0.001)	Loss 0.3710 (0.4361)	Prec@1 87.891 (84.715)	Prec@5 99.219 (99.439)
EVALUATING - Epoch: [518][0/79]	Time 0.076 (0.076)	Data 0.054 (0.054)	Loss 0.4834 (0.4834)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:55

 Epoch: 519	Training Loss 0.4420 	Training Prec@1 84.596 	Training Prec@5 99.422 	Validation Loss 0.5553 	Validation Prec@1 81.950 	Validation Prec@5 99.200 

lr: 0.04795212734229087
TRAINING - Epoch: [519][0/196]	Time 0.711 (0.711)	Data 0.080 (0.080)	Loss 0.4627 (0.4627)	Prec@1 85.547 (85.547)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [519][100/196]	Time 0.092 (0.085)	Data 0.000 (0.001)	Loss 0.4158 (0.4375)	Prec@1 83.984 (84.742)	Prec@5 99.609 (99.385)
EVALUATING - Epoch: [519][0/79]	Time 0.069 (0.069)	Data 0.049 (0.049)	Loss 0.6935 (0.6935)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:37

 Epoch: 520	Training Loss 0.4414 	Training Prec@1 84.588 	Training Prec@5 99.420 	Validation Loss 0.7433 	Validation Prec@1 76.590 	Validation Prec@5 98.460 

lr: 0.047794554013879866
TRAINING - Epoch: [520][0/196]	Time 0.793 (0.793)	Data 0.111 (0.111)	Loss 0.3660 (0.3660)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [520][100/196]	Time 0.091 (0.095)	Data 0.000 (0.001)	Loss 0.3880 (0.4350)	Prec@1 85.938 (84.897)	Prec@5 100.000 (99.478)
EVALUATING - Epoch: [520][0/79]	Time 0.073 (0.073)	Data 0.049 (0.049)	Loss 0.6970 (0.6970)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:14

 Epoch: 521	Training Loss 0.4380 	Training Prec@1 84.838 	Training Prec@5 99.422 	Validation Loss 0.7119 	Validation Prec@1 77.620 	Validation Prec@5 98.590 

lr: 0.04763700264607535
TRAINING - Epoch: [521][0/196]	Time 0.799 (0.799)	Data 0.095 (0.095)	Loss 0.4217 (0.4217)	Prec@1 86.328 (86.328)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [521][100/196]	Time 0.088 (0.091)	Data 0.000 (0.001)	Loss 0.3754 (0.4347)	Prec@1 84.375 (84.642)	Prec@5 99.219 (99.408)
EVALUATING - Epoch: [521][0/79]	Time 0.088 (0.088)	Data 0.074 (0.074)	Loss 0.5572 (0.5572)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:57

 Epoch: 522	Training Loss 0.4390 	Training Prec@1 84.592 	Training Prec@5 99.416 	Validation Loss 0.7256 	Validation Prec@1 77.120 	Validation Prec@5 98.620 

lr: 0.047479474806360535
TRAINING - Epoch: [522][0/196]	Time 0.810 (0.810)	Data 0.108 (0.108)	Loss 0.3842 (0.3842)	Prec@1 86.328 (86.328)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [522][100/196]	Time 0.069 (0.092)	Data 0.000 (0.001)	Loss 0.4360 (0.4442)	Prec@1 83.594 (84.305)	Prec@5 99.219 (99.424)
EVALUATING - Epoch: [522][0/79]	Time 0.081 (0.081)	Data 0.061 (0.061)	Loss 0.8846 (0.8846)	Prec@1 72.656 (72.656)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:49:05

 Epoch: 523	Training Loss 0.4413 	Training Prec@1 84.418 	Training Prec@5 99.394 	Validation Loss 0.7793 	Validation Prec@1 74.570 	Validation Prec@5 97.970 

lr: 0.04732197206198445
TRAINING - Epoch: [523][0/196]	Time 0.921 (0.921)	Data 0.219 (0.219)	Loss 0.3993 (0.3993)	Prec@1 87.891 (87.891)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [523][100/196]	Time 0.087 (0.086)	Data 0.000 (0.002)	Loss 0.3364 (0.4301)	Prec@1 87.500 (84.870)	Prec@5 100.000 (99.482)
EVALUATING - Epoch: [523][0/79]	Time 0.079 (0.079)	Data 0.056 (0.056)	Loss 0.5818 (0.5818)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:19

 Epoch: 524	Training Loss 0.4450 	Training Prec@1 84.340 	Training Prec@5 99.434 	Validation Loss 0.6530 	Validation Prec@1 79.120 	Validation Prec@5 98.530 

lr: 0.047164495979946555
TRAINING - Epoch: [524][0/196]	Time 0.788 (0.788)	Data 0.090 (0.090)	Loss 0.4390 (0.4390)	Prec@1 86.719 (86.719)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [524][100/196]	Time 0.098 (0.083)	Data 0.000 (0.001)	Loss 0.4140 (0.4316)	Prec@1 85.938 (84.889)	Prec@5 100.000 (99.431)
EVALUATING - Epoch: [524][0/79]	Time 0.081 (0.081)	Data 0.062 (0.062)	Loss 0.5186 (0.5186)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:08

 Epoch: 525	Training Loss 0.4395 	Training Prec@1 84.568 	Training Prec@5 99.418 	Validation Loss 0.6083 	Validation Prec@1 79.940 	Validation Prec@5 99.080 

lr: 0.04700704812698099
TRAINING - Epoch: [525][0/196]	Time 0.796 (0.796)	Data 0.077 (0.077)	Loss 0.3803 (0.3803)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [525][100/196]	Time 0.083 (0.094)	Data 0.000 (0.001)	Loss 0.3719 (0.4358)	Prec@1 90.234 (84.866)	Prec@5 98.828 (99.424)
EVALUATING - Epoch: [525][0/79]	Time 0.073 (0.073)	Data 0.050 (0.050)	Loss 0.5433 (0.5433)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:37

 Epoch: 526	Training Loss 0.4334 	Training Prec@1 84.856 	Training Prec@5 99.448 	Validation Loss 0.6343 	Validation Prec@1 79.520 	Validation Prec@5 98.720 

lr: 0.04684963006954104
TRAINING - Epoch: [526][0/196]	Time 0.817 (0.817)	Data 0.100 (0.100)	Loss 0.5223 (0.5223)	Prec@1 82.812 (82.812)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [526][100/196]	Time 0.095 (0.094)	Data 0.000 (0.001)	Loss 0.3407 (0.4391)	Prec@1 87.109 (84.483)	Prec@5 100.000 (99.462)
EVALUATING - Epoch: [526][0/79]	Time 0.075 (0.075)	Data 0.056 (0.056)	Loss 0.5088 (0.5088)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:25

 Epoch: 527	Training Loss 0.4390 	Training Prec@1 84.700 	Training Prec@5 99.432 	Validation Loss 0.5875 	Validation Prec@1 80.160 	Validation Prec@5 98.980 

lr: 0.04669224337378357
TRAINING - Epoch: [527][0/196]	Time 0.755 (0.755)	Data 0.096 (0.096)	Loss 0.4132 (0.4132)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [527][100/196]	Time 0.093 (0.093)	Data 0.000 (0.001)	Loss 0.4915 (0.4447)	Prec@1 80.078 (84.448)	Prec@5 98.438 (99.408)
EVALUATING - Epoch: [527][0/79]	Time 0.081 (0.081)	Data 0.060 (0.060)	Loss 0.6316 (0.6316)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:50:20

 Epoch: 528	Training Loss 0.4394 	Training Prec@1 84.524 	Training Prec@5 99.428 	Validation Loss 0.6997 	Validation Prec@1 77.640 	Validation Prec@5 98.440 

lr: 0.04653488960555344
TRAINING - Epoch: [528][0/196]	Time 0.786 (0.786)	Data 0.078 (0.078)	Loss 0.5518 (0.5518)	Prec@1 82.422 (82.422)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [528][100/196]	Time 0.096 (0.084)	Data 0.000 (0.001)	Loss 0.4478 (0.4307)	Prec@1 82.812 (84.897)	Prec@5 100.000 (99.493)
EVALUATING - Epoch: [528][0/79]	Time 0.080 (0.080)	Data 0.059 (0.059)	Loss 0.7050 (0.7050)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:33

 Epoch: 529	Training Loss 0.4366 	Training Prec@1 84.702 	Training Prec@5 99.474 	Validation Loss 0.7723 	Validation Prec@1 74.290 	Validation Prec@5 98.460 

lr: 0.04637757033036786
TRAINING - Epoch: [529][0/196]	Time 0.801 (0.801)	Data 0.087 (0.087)	Loss 0.4321 (0.4321)	Prec@1 85.156 (85.156)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [529][100/196]	Time 0.084 (0.081)	Data 0.000 (0.001)	Loss 0.3893 (0.4388)	Prec@1 85.547 (84.750)	Prec@5 99.219 (99.420)
EVALUATING - Epoch: [529][0/79]	Time 0.068 (0.068)	Data 0.049 (0.049)	Loss 0.6996 (0.6996)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:17

 Epoch: 530	Training Loss 0.4387 	Training Prec@1 84.618 	Training Prec@5 99.404 	Validation Loss 0.6524 	Validation Prec@1 78.690 	Validation Prec@5 98.910 

lr: 0.04622028711340094
TRAINING - Epoch: [530][0/196]	Time 0.816 (0.816)	Data 0.100 (0.100)	Loss 0.4174 (0.4174)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [530][100/196]	Time 0.084 (0.096)	Data 0.000 (0.001)	Loss 0.3863 (0.4252)	Prec@1 85.547 (85.214)	Prec@5 100.000 (99.466)
EVALUATING - Epoch: [530][0/79]	Time 0.084 (0.084)	Data 0.064 (0.064)	Loss 0.5583 (0.5583)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:35

 Epoch: 531	Training Loss 0.4316 	Training Prec@1 84.960 	Training Prec@5 99.484 	Validation Loss 0.7312 	Validation Prec@1 76.480 	Validation Prec@5 98.470 

lr: 0.046063041519467975
TRAINING - Epoch: [531][0/196]	Time 0.826 (0.826)	Data 0.109 (0.109)	Loss 0.3962 (0.3962)	Prec@1 86.719 (86.719)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [531][100/196]	Time 0.089 (0.095)	Data 0.000 (0.001)	Loss 0.3432 (0.4288)	Prec@1 89.062 (84.797)	Prec@5 99.609 (99.439)
EVALUATING - Epoch: [531][0/79]	Time 0.077 (0.077)	Data 0.056 (0.056)	Loss 0.7165 (0.7165)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:54

 Epoch: 532	Training Loss 0.4395 	Training Prec@1 84.476 	Training Prec@5 99.418 	Validation Loss 0.6385 	Validation Prec@1 79.040 	Validation Prec@5 98.410 

lr: 0.045905835113009996
TRAINING - Epoch: [532][0/196]	Time 0.775 (0.775)	Data 0.081 (0.081)	Loss 0.4421 (0.4421)	Prec@1 86.328 (86.328)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [532][100/196]	Time 0.094 (0.095)	Data 0.000 (0.001)	Loss 0.5067 (0.4333)	Prec@1 82.422 (84.974)	Prec@5 100.000 (99.373)
EVALUATING - Epoch: [532][0/79]	Time 0.073 (0.073)	Data 0.051 (0.051)	Loss 0.5638 (0.5638)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:50:37

 Epoch: 533	Training Loss 0.4356 	Training Prec@1 84.688 	Training Prec@5 99.396 	Validation Loss 0.7289 	Validation Prec@1 76.640 	Validation Prec@5 98.580 

lr: 0.04574866945807817
TRAINING - Epoch: [533][0/196]	Time 0.640 (0.640)	Data 0.080 (0.080)	Loss 0.3858 (0.3858)	Prec@1 85.938 (85.938)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [533][100/196]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.4194 (0.4351)	Prec@1 83.984 (85.032)	Prec@5 99.609 (99.358)
EVALUATING - Epoch: [533][0/79]	Time 0.075 (0.075)	Data 0.056 (0.056)	Loss 0.6587 (0.6587)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:23

 Epoch: 534	Training Loss 0.4367 	Training Prec@1 84.892 	Training Prec@5 99.390 	Validation Loss 0.7465 	Validation Prec@1 76.130 	Validation Prec@5 98.330 

lr: 0.04559154611831816
TRAINING - Epoch: [534][0/196]	Time 0.790 (0.790)	Data 0.088 (0.088)	Loss 0.4152 (0.4152)	Prec@1 82.422 (82.422)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [534][100/196]	Time 0.085 (0.080)	Data 0.000 (0.001)	Loss 0.4779 (0.4341)	Prec@1 83.984 (84.653)	Prec@5 99.609 (99.451)
EVALUATING - Epoch: [534][0/79]	Time 0.084 (0.084)	Data 0.063 (0.063)	Loss 0.6837 (0.6837)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:21

 Epoch: 535	Training Loss 0.4340 	Training Prec@1 84.764 	Training Prec@5 99.454 	Validation Loss 0.5927 	Validation Prec@1 79.060 	Validation Prec@5 99.150 

lr: 0.04543446665695469
TRAINING - Epoch: [535][0/196]	Time 0.787 (0.787)	Data 0.098 (0.098)	Loss 0.3634 (0.3634)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [535][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.5656 (0.4339)	Prec@1 81.641 (84.816)	Prec@5 98.438 (99.474)
EVALUATING - Epoch: [535][0/79]	Time 0.074 (0.074)	Data 0.054 (0.054)	Loss 0.6204 (0.6204)	Prec@1 80.469 (80.469)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:46

 Epoch: 536	Training Loss 0.4350 	Training Prec@1 84.728 	Training Prec@5 99.410 	Validation Loss 0.7155 	Validation Prec@1 76.840 	Validation Prec@5 98.640 

lr: 0.0452774326367759
TRAINING - Epoch: [536][0/196]	Time 0.788 (0.788)	Data 0.098 (0.098)	Loss 0.4813 (0.4813)	Prec@1 83.984 (83.984)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [536][100/196]	Time 0.089 (0.095)	Data 0.000 (0.001)	Loss 0.4300 (0.4337)	Prec@1 84.375 (84.874)	Prec@5 100.000 (99.466)
EVALUATING - Epoch: [536][0/79]	Time 0.089 (0.089)	Data 0.065 (0.065)	Loss 0.5945 (0.5945)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:03

 Epoch: 537	Training Loss 0.4315 	Training Prec@1 84.886 	Training Prec@5 99.448 	Validation Loss 0.7311 	Validation Prec@1 76.740 	Validation Prec@5 98.880 

lr: 0.045120445620117876
TRAINING - Epoch: [537][0/196]	Time 0.801 (0.801)	Data 0.082 (0.082)	Loss 0.4142 (0.4142)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [537][100/196]	Time 0.081 (0.093)	Data 0.000 (0.001)	Loss 0.4091 (0.4328)	Prec@1 83.984 (84.727)	Prec@5 99.609 (99.381)
EVALUATING - Epoch: [537][0/79]	Time 0.081 (0.081)	Data 0.057 (0.057)	Loss 0.4785 (0.4785)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:48:50

 Epoch: 538	Training Loss 0.4338 	Training Prec@1 84.756 	Training Prec@5 99.372 	Validation Loss 0.6171 	Validation Prec@1 79.560 	Validation Prec@5 99.010 

lr: 0.04496350716884903
TRAINING - Epoch: [538][0/196]	Time 0.765 (0.765)	Data 0.095 (0.095)	Loss 0.3554 (0.3554)	Prec@1 85.547 (85.547)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [538][100/196]	Time 0.089 (0.081)	Data 0.000 (0.001)	Loss 0.4047 (0.4346)	Prec@1 85.547 (84.855)	Prec@5 100.000 (99.466)
EVALUATING - Epoch: [538][0/79]	Time 0.074 (0.074)	Data 0.051 (0.051)	Loss 0.5547 (0.5547)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:22

 Epoch: 539	Training Loss 0.4375 	Training Prec@1 84.616 	Training Prec@5 99.476 	Validation Loss 0.5716 	Validation Prec@1 80.850 	Validation Prec@5 99.090 

lr: 0.04480661884435461
TRAINING - Epoch: [539][0/196]	Time 0.772 (0.772)	Data 0.087 (0.087)	Loss 0.5089 (0.5089)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [539][100/196]	Time 0.092 (0.084)	Data 0.000 (0.001)	Loss 0.3828 (0.4256)	Prec@1 87.500 (85.129)	Prec@5 99.219 (99.466)
EVALUATING - Epoch: [539][0/79]	Time 0.080 (0.080)	Data 0.058 (0.058)	Loss 0.5427 (0.5427)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:09

 Epoch: 540	Training Loss 0.4338 	Training Prec@1 84.922 	Training Prec@5 99.456 	Validation Loss 0.6283 	Validation Prec@1 79.860 	Validation Prec@5 98.830 

lr: 0.04464978220752114
TRAINING - Epoch: [540][0/196]	Time 0.814 (0.814)	Data 0.099 (0.099)	Loss 0.4507 (0.4507)	Prec@1 86.328 (86.328)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [540][100/196]	Time 0.081 (0.093)	Data 0.000 (0.001)	Loss 0.4162 (0.4373)	Prec@1 83.984 (84.750)	Prec@5 100.000 (99.412)
EVALUATING - Epoch: [540][0/79]	Time 0.083 (0.083)	Data 0.061 (0.061)	Loss 0.4990 (0.4990)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:17

 Epoch: 541	Training Loss 0.4368 	Training Prec@1 84.806 	Training Prec@5 99.372 	Validation Loss 0.6715 	Validation Prec@1 77.660 	Validation Prec@5 98.790 

lr: 0.04449299881872094
TRAINING - Epoch: [541][0/196]	Time 0.812 (0.812)	Data 0.103 (0.103)	Loss 0.4776 (0.4776)	Prec@1 83.594 (83.594)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [541][100/196]	Time 0.090 (0.093)	Data 0.000 (0.001)	Loss 0.3878 (0.4241)	Prec@1 84.766 (85.048)	Prec@5 99.609 (99.559)
EVALUATING - Epoch: [541][0/79]	Time 0.080 (0.080)	Data 0.061 (0.061)	Loss 0.5084 (0.5084)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:01

 Epoch: 542	Training Loss 0.4246 	Training Prec@1 85.046 	Training Prec@5 99.534 	Validation Loss 0.7006 	Validation Prec@1 77.670 	Validation Prec@5 98.790 

lr: 0.04433627023779648
TRAINING - Epoch: [542][0/196]	Time 0.775 (0.775)	Data 0.096 (0.096)	Loss 0.3709 (0.3709)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [542][100/196]	Time 0.088 (0.094)	Data 0.000 (0.001)	Loss 0.3981 (0.4312)	Prec@1 87.500 (84.785)	Prec@5 98.828 (99.412)
EVALUATING - Epoch: [542][0/79]	Time 0.079 (0.079)	Data 0.060 (0.060)	Loss 0.6238 (0.6238)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:50:06

 Epoch: 543	Training Loss 0.4302 	Training Prec@1 84.888 	Training Prec@5 99.460 	Validation Loss 0.5942 	Validation Prec@1 80.840 	Validation Prec@5 99.010 

lr: 0.044179598024045044
TRAINING - Epoch: [543][0/196]	Time 0.822 (0.822)	Data 0.103 (0.103)	Loss 0.4558 (0.4558)	Prec@1 83.594 (83.594)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [543][100/196]	Time 0.079 (0.083)	Data 0.000 (0.001)	Loss 0.4145 (0.4285)	Prec@1 84.766 (85.102)	Prec@5 100.000 (99.439)
EVALUATING - Epoch: [543][0/79]	Time 0.077 (0.077)	Data 0.060 (0.060)	Loss 0.5667 (0.5667)	Prec@1 75.781 (75.781)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:49

 Epoch: 544	Training Loss 0.4284 	Training Prec@1 85.094 	Training Prec@5 99.436 	Validation Loss 0.6097 	Validation Prec@1 79.860 	Validation Prec@5 99.100 

lr: 0.04402298373620306
TRAINING - Epoch: [544][0/196]	Time 0.759 (0.759)	Data 0.083 (0.083)	Loss 0.4313 (0.4313)	Prec@1 84.766 (84.766)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [544][100/196]	Time 0.087 (0.085)	Data 0.000 (0.001)	Loss 0.3593 (0.4246)	Prec@1 87.109 (84.978)	Prec@5 99.219 (99.459)
EVALUATING - Epoch: [544][0/79]	Time 0.086 (0.086)	Data 0.067 (0.067)	Loss 0.5553 (0.5553)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:43

 Epoch: 545	Training Loss 0.4273 	Training Prec@1 84.926 	Training Prec@5 99.468 	Validation Loss 0.5964 	Validation Prec@1 79.890 	Validation Prec@5 99.000 

lr: 0.043866428932430646
TRAINING - Epoch: [545][0/196]	Time 0.786 (0.786)	Data 0.102 (0.102)	Loss 0.4618 (0.4618)	Prec@1 85.547 (85.547)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [545][100/196]	Time 0.088 (0.094)	Data 0.000 (0.001)	Loss 0.4291 (0.4260)	Prec@1 87.109 (85.029)	Prec@5 100.000 (99.420)
EVALUATING - Epoch: [545][0/79]	Time 0.074 (0.074)	Data 0.057 (0.057)	Loss 0.6997 (0.6997)	Prec@1 75.000 (75.000)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:02

 Epoch: 546	Training Loss 0.4321 	Training Prec@1 84.868 	Training Prec@5 99.424 	Validation Loss 0.6735 	Validation Prec@1 77.690 	Validation Prec@5 98.630 

lr: 0.04370993517029616
TRAINING - Epoch: [546][0/196]	Time 0.795 (0.795)	Data 0.084 (0.084)	Loss 0.4488 (0.4488)	Prec@1 82.422 (82.422)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [546][100/196]	Time 0.092 (0.094)	Data 0.000 (0.001)	Loss 0.4517 (0.4310)	Prec@1 82.422 (84.862)	Prec@5 100.000 (99.470)
EVALUATING - Epoch: [546][0/79]	Time 0.084 (0.084)	Data 0.064 (0.064)	Loss 0.5377 (0.5377)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:34

 Epoch: 547	Training Loss 0.4307 	Training Prec@1 84.936 	Training Prec@5 99.452 	Validation Loss 0.6522 	Validation Prec@1 79.010 	Validation Prec@5 98.810 

lr: 0.04355350400676058
TRAINING - Epoch: [547][0/196]	Time 0.796 (0.796)	Data 0.080 (0.080)	Loss 0.3775 (0.3775)	Prec@1 85.547 (85.547)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [547][100/196]	Time 0.094 (0.095)	Data 0.000 (0.001)	Loss 0.4048 (0.4245)	Prec@1 85.156 (84.797)	Prec@5 100.000 (99.447)
EVALUATING - Epoch: [547][0/79]	Time 0.080 (0.080)	Data 0.061 (0.061)	Loss 0.4845 (0.4845)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:49:56

 Epoch: 548	Training Loss 0.4253 	Training Prec@1 84.968 	Training Prec@5 99.486 	Validation Loss 0.6250 	Validation Prec@1 79.240 	Validation Prec@5 98.870 

lr: 0.04339713699816217
TRAINING - Epoch: [548][0/196]	Time 0.743 (0.743)	Data 0.081 (0.081)	Loss 0.4277 (0.4277)	Prec@1 85.156 (85.156)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [548][100/196]	Time 0.056 (0.082)	Data 0.000 (0.001)	Loss 0.3752 (0.4365)	Prec@1 88.281 (84.901)	Prec@5 99.219 (99.397)
EVALUATING - Epoch: [548][0/79]	Time 0.072 (0.072)	Data 0.054 (0.054)	Loss 0.5124 (0.5124)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:13

 Epoch: 549	Training Loss 0.4341 	Training Prec@1 84.852 	Training Prec@5 99.402 	Validation Loss 0.6544 	Validation Prec@1 78.750 	Validation Prec@5 98.280 

lr: 0.04324083570020084
TRAINING - Epoch: [549][0/196]	Time 0.723 (0.723)	Data 0.083 (0.083)	Loss 0.4321 (0.4321)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [549][100/196]	Time 0.091 (0.083)	Data 0.000 (0.001)	Loss 0.4620 (0.4213)	Prec@1 84.766 (85.303)	Prec@5 99.609 (99.470)
EVALUATING - Epoch: [549][0/79]	Time 0.076 (0.076)	Data 0.051 (0.051)	Loss 0.5156 (0.5156)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:40

 Epoch: 550	Training Loss 0.4249 	Training Prec@1 85.198 	Training Prec@5 99.444 	Validation Loss 0.6255 	Validation Prec@1 79.900 	Validation Prec@5 98.740 

lr: 0.043084601667922814
TRAINING - Epoch: [550][0/196]	Time 0.807 (0.807)	Data 0.088 (0.088)	Loss 0.4293 (0.4293)	Prec@1 85.547 (85.547)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [550][100/196]	Time 0.071 (0.093)	Data 0.000 (0.001)	Loss 0.4304 (0.4185)	Prec@1 84.766 (85.326)	Prec@5 99.609 (99.451)
EVALUATING - Epoch: [550][0/79]	Time 0.086 (0.086)	Data 0.064 (0.064)	Loss 0.7285 (0.7285)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:19

 Epoch: 551	Training Loss 0.4262 	Training Prec@1 85.230 	Training Prec@5 99.450 	Validation Loss 0.7762 	Validation Prec@1 75.500 	Validation Prec@5 98.850 

lr: 0.04292843645570503
TRAINING - Epoch: [551][0/196]	Time 0.774 (0.774)	Data 0.085 (0.085)	Loss 0.4653 (0.4653)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [551][100/196]	Time 0.095 (0.094)	Data 0.000 (0.001)	Loss 0.4392 (0.4177)	Prec@1 85.156 (85.528)	Prec@5 99.219 (99.486)
EVALUATING - Epoch: [551][0/79]	Time 0.076 (0.076)	Data 0.057 (0.057)	Loss 0.6907 (0.6907)	Prec@1 78.125 (78.125)	Prec@5 96.875 (96.875)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:08

 Epoch: 552	Training Loss 0.4249 	Training Prec@1 85.244 	Training Prec@5 99.460 	Validation Loss 0.8311 	Validation Prec@1 73.480 	Validation Prec@5 98.320 

lr: 0.042772341617239744
TRAINING - Epoch: [552][0/196]	Time 0.800 (0.800)	Data 0.099 (0.099)	Loss 0.4904 (0.4904)	Prec@1 83.203 (83.203)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [552][100/196]	Time 0.089 (0.094)	Data 0.000 (0.001)	Loss 0.4901 (0.4217)	Prec@1 83.594 (85.125)	Prec@5 98.438 (99.513)
EVALUATING - Epoch: [552][0/79]	Time 0.087 (0.087)	Data 0.064 (0.064)	Loss 0.5819 (0.5819)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:19	Time of Finish: 2024-03-31 19:50:52

 Epoch: 553	Training Loss 0.4191 	Training Prec@1 85.276 	Training Prec@5 99.502 	Validation Loss 0.5985 	Validation Prec@1 80.190 	Validation Prec@5 98.960 

lr: 0.042616318705519095
TRAINING - Epoch: [553][0/196]	Time 0.782 (0.782)	Data 0.081 (0.081)	Loss 0.4500 (0.4500)	Prec@1 82.812 (82.812)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [553][100/196]	Time 0.093 (0.083)	Data 0.000 (0.001)	Loss 0.4796 (0.4217)	Prec@1 83.984 (85.245)	Prec@5 100.000 (99.459)
EVALUATING - Epoch: [553][0/79]	Time 0.077 (0.077)	Data 0.056 (0.056)	Loss 0.6052 (0.6052)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:19

 Epoch: 554	Training Loss 0.4245 	Training Prec@1 85.124 	Training Prec@5 99.448 	Validation Loss 0.6883 	Validation Prec@1 78.360 	Validation Prec@5 98.790 

lr: 0.04246036927281959
TRAINING - Epoch: [554][0/196]	Time 0.779 (0.779)	Data 0.080 (0.080)	Loss 0.4607 (0.4607)	Prec@1 84.766 (84.766)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [554][100/196]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.4759 (0.4227)	Prec@1 85.156 (85.292)	Prec@5 98.438 (99.431)
EVALUATING - Epoch: [554][0/79]	Time 0.073 (0.073)	Data 0.050 (0.050)	Loss 0.4532 (0.4532)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:37

 Epoch: 555	Training Loss 0.4286 	Training Prec@1 84.966 	Training Prec@5 99.436 	Validation Loss 0.5532 	Validation Prec@1 81.190 	Validation Prec@5 99.110 

lr: 0.0423044948706867
TRAINING - Epoch: [555][0/196]	Time 0.763 (0.763)	Data 0.092 (0.092)	Loss 0.3571 (0.3571)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [555][100/196]	Time 0.089 (0.093)	Data 0.000 (0.001)	Loss 0.3972 (0.4292)	Prec@1 85.547 (84.916)	Prec@5 99.609 (99.489)
EVALUATING - Epoch: [555][0/79]	Time 0.072 (0.072)	Data 0.052 (0.052)	Loss 0.5496 (0.5496)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:50

 Epoch: 556	Training Loss 0.4300 	Training Prec@1 85.008 	Training Prec@5 99.468 	Validation Loss 0.6800 	Validation Prec@1 78.070 	Validation Prec@5 98.780 

lr: 0.042148697049919415
TRAINING - Epoch: [556][0/196]	Time 0.742 (0.742)	Data 0.078 (0.078)	Loss 0.4183 (0.4183)	Prec@1 83.984 (83.984)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [556][100/196]	Time 0.086 (0.093)	Data 0.000 (0.001)	Loss 0.4174 (0.4191)	Prec@1 83.594 (85.210)	Prec@5 99.609 (99.416)
EVALUATING - Epoch: [556][0/79]	Time 0.075 (0.075)	Data 0.056 (0.056)	Loss 0.5786 (0.5786)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:12

 Epoch: 557	Training Loss 0.4237 	Training Prec@1 85.062 	Training Prec@5 99.432 	Validation Loss 0.6374 	Validation Prec@1 79.340 	Validation Prec@5 99.240 

lr: 0.041992977360554816
TRAINING - Epoch: [557][0/196]	Time 0.818 (0.818)	Data 0.092 (0.092)	Loss 0.3975 (0.3975)	Prec@1 85.938 (85.938)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [557][100/196]	Time 0.088 (0.093)	Data 0.000 (0.001)	Loss 0.4237 (0.4268)	Prec@1 83.984 (85.118)	Prec@5 99.609 (99.478)
EVALUATING - Epoch: [557][0/79]	Time 0.081 (0.081)	Data 0.061 (0.061)	Loss 0.6018 (0.6018)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:49:15

 Epoch: 558	Training Loss 0.4239 	Training Prec@1 85.240 	Training Prec@5 99.470 	Validation Loss 0.6763 	Validation Prec@1 78.690 	Validation Prec@5 98.410 

lr: 0.04183733735185263
TRAINING - Epoch: [558][0/196]	Time 0.779 (0.779)	Data 0.100 (0.100)	Loss 0.4037 (0.4037)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [558][100/196]	Time 0.090 (0.082)	Data 0.000 (0.001)	Loss 0.4537 (0.4199)	Prec@1 82.422 (85.222)	Prec@5 100.000 (99.509)
EVALUATING - Epoch: [558][0/79]	Time 0.075 (0.075)	Data 0.054 (0.054)	Loss 0.5912 (0.5912)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:12

 Epoch: 559	Training Loss 0.4229 	Training Prec@1 85.248 	Training Prec@5 99.446 	Validation Loss 0.6480 	Validation Prec@1 79.180 	Validation Prec@5 98.970 

lr: 0.0416817785722799
TRAINING - Epoch: [559][0/196]	Time 0.768 (0.768)	Data 0.105 (0.105)	Loss 0.3955 (0.3955)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [559][100/196]	Time 0.090 (0.084)	Data 0.000 (0.001)	Loss 0.3506 (0.4244)	Prec@1 86.328 (84.982)	Prec@5 99.609 (99.528)
EVALUATING - Epoch: [559][0/79]	Time 0.083 (0.083)	Data 0.058 (0.058)	Loss 0.5544 (0.5544)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:11

 Epoch: 560	Training Loss 0.4289 	Training Prec@1 84.948 	Training Prec@5 99.460 	Validation Loss 0.5903 	Validation Prec@1 79.870 	Validation Prec@5 99.010 

lr: 0.041526302569495424
TRAINING - Epoch: [560][0/196]	Time 0.737 (0.737)	Data 0.086 (0.086)	Loss 0.3363 (0.3363)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [560][100/196]	Time 0.088 (0.093)	Data 0.000 (0.001)	Loss 0.4582 (0.4160)	Prec@1 83.984 (85.396)	Prec@5 99.219 (99.520)
EVALUATING - Epoch: [560][0/79]	Time 0.081 (0.081)	Data 0.064 (0.064)	Loss 0.5508 (0.5508)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:33

 Epoch: 561	Training Loss 0.4232 	Training Prec@1 85.146 	Training Prec@5 99.498 	Validation Loss 0.5894 	Validation Prec@1 81.030 	Validation Prec@5 98.770 

lr: 0.04137091089033456
TRAINING - Epoch: [561][0/196]	Time 0.827 (0.827)	Data 0.117 (0.117)	Loss 0.4312 (0.4312)	Prec@1 85.156 (85.156)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [561][100/196]	Time 0.094 (0.094)	Data 0.000 (0.001)	Loss 0.4550 (0.4211)	Prec@1 83.984 (85.183)	Prec@5 99.609 (99.470)
EVALUATING - Epoch: [561][0/79]	Time 0.077 (0.077)	Data 0.058 (0.058)	Loss 0.5366 (0.5366)	Prec@1 82.812 (82.812)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:08

 Epoch: 562	Training Loss 0.4201 	Training Prec@1 85.312 	Training Prec@5 99.462 	Validation Loss 0.5762 	Validation Prec@1 80.730 	Validation Prec@5 99.200 

lr: 0.04121560508079362
TRAINING - Epoch: [562][0/196]	Time 0.802 (0.802)	Data 0.082 (0.082)	Loss 0.3955 (0.3955)	Prec@1 84.766 (84.766)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [562][100/196]	Time 0.092 (0.096)	Data 0.000 (0.001)	Loss 0.3882 (0.4193)	Prec@1 84.766 (85.179)	Prec@5 100.000 (99.482)
EVALUATING - Epoch: [562][0/79]	Time 0.074 (0.074)	Data 0.056 (0.056)	Loss 0.6181 (0.6181)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:19	Time of Finish: 2024-03-31 19:50:46

 Epoch: 563	Training Loss 0.4243 	Training Prec@1 85.126 	Training Prec@5 99.480 	Validation Loss 0.7586 	Validation Prec@1 75.070 	Validation Prec@5 98.620 

lr: 0.04106038668601466
TRAINING - Epoch: [563][0/196]	Time 0.758 (0.758)	Data 0.097 (0.097)	Loss 0.3366 (0.3366)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [563][100/196]	Time 0.099 (0.085)	Data 0.000 (0.001)	Loss 0.3873 (0.4156)	Prec@1 86.328 (85.330)	Prec@5 99.219 (99.555)
EVALUATING - Epoch: [563][0/79]	Time 0.079 (0.079)	Data 0.061 (0.061)	Loss 0.6663 (0.6663)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:56

 Epoch: 564	Training Loss 0.4208 	Training Prec@1 85.096 	Training Prec@5 99.506 	Validation Loss 0.6493 	Validation Prec@1 78.670 	Validation Prec@5 98.820 

lr: 0.040905257250270076
TRAINING - Epoch: [564][0/196]	Time 0.822 (0.822)	Data 0.094 (0.094)	Loss 0.3972 (0.3972)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [564][100/196]	Time 0.085 (0.086)	Data 0.000 (0.001)	Loss 0.4368 (0.4134)	Prec@1 84.766 (85.415)	Prec@5 99.219 (99.478)
EVALUATING - Epoch: [564][0/79]	Time 0.074 (0.074)	Data 0.053 (0.053)	Loss 0.5311 (0.5311)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:16

 Epoch: 565	Training Loss 0.4166 	Training Prec@1 85.336 	Training Prec@5 99.484 	Validation Loss 0.5545 	Validation Prec@1 81.540 	Validation Prec@5 99.290 

lr: 0.040750218316947105
TRAINING - Epoch: [565][0/196]	Time 0.799 (0.799)	Data 0.085 (0.085)	Loss 0.3477 (0.3477)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [565][100/196]	Time 0.097 (0.096)	Data 0.000 (0.001)	Loss 0.4138 (0.4172)	Prec@1 84.375 (85.381)	Prec@5 100.000 (99.443)
EVALUATING - Epoch: [565][0/79]	Time 0.075 (0.075)	Data 0.055 (0.055)	Loss 0.6074 (0.6074)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:22

 Epoch: 566	Training Loss 0.4188 	Training Prec@1 85.308 	Training Prec@5 99.476 	Validation Loss 0.7071 	Validation Prec@1 77.580 	Validation Prec@5 98.460 

lr: 0.04059527142853269
TRAINING - Epoch: [566][0/196]	Time 0.839 (0.839)	Data 0.103 (0.103)	Loss 0.4774 (0.4774)	Prec@1 83.203 (83.203)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [566][100/196]	Time 0.092 (0.095)	Data 0.000 (0.001)	Loss 0.3356 (0.4056)	Prec@1 88.281 (85.744)	Prec@5 99.609 (99.517)
EVALUATING - Epoch: [566][0/79]	Time 0.077 (0.077)	Data 0.059 (0.059)	Loss 0.6405 (0.6405)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:11

 Epoch: 567	Training Loss 0.4173 	Training Prec@1 85.414 	Training Prec@5 99.510 	Validation Loss 0.6355 	Validation Prec@1 79.320 	Validation Prec@5 98.690 

lr: 0.04044041812659791
TRAINING - Epoch: [567][0/196]	Time 0.800 (0.800)	Data 0.101 (0.101)	Loss 0.3816 (0.3816)	Prec@1 87.500 (87.500)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [567][100/196]	Time 0.081 (0.094)	Data 0.000 (0.001)	Loss 0.4126 (0.4057)	Prec@1 86.328 (85.852)	Prec@5 99.609 (99.497)
EVALUATING - Epoch: [567][0/79]	Time 0.075 (0.075)	Data 0.051 (0.051)	Loss 0.6140 (0.6140)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:49:14

 Epoch: 568	Training Loss 0.4164 	Training Prec@1 85.436 	Training Prec@5 99.484 	Validation Loss 0.5828 	Validation Prec@1 80.210 	Validation Prec@5 99.130 

lr: 0.04028565995178282
TRAINING - Epoch: [568][0/196]	Time 0.716 (0.716)	Data 0.107 (0.107)	Loss 0.4869 (0.4869)	Prec@1 81.641 (81.641)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [568][100/196]	Time 0.089 (0.079)	Data 0.000 (0.001)	Loss 0.4428 (0.4100)	Prec@1 84.766 (85.659)	Prec@5 100.000 (99.528)
EVALUATING - Epoch: [568][0/79]	Time 0.074 (0.074)	Data 0.054 (0.054)	Loss 0.4665 (0.4665)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:31

 Epoch: 569	Training Loss 0.4194 	Training Prec@1 85.426 	Training Prec@5 99.468 	Validation Loss 0.6395 	Validation Prec@1 79.220 	Validation Prec@5 98.810 

lr: 0.040130998443781034
TRAINING - Epoch: [569][0/196]	Time 0.783 (0.783)	Data 0.092 (0.092)	Loss 0.3359 (0.3359)	Prec@1 87.500 (87.500)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [569][100/196]	Time 0.092 (0.080)	Data 0.000 (0.001)	Loss 0.3300 (0.4179)	Prec@1 89.844 (85.110)	Prec@5 100.000 (99.528)
EVALUATING - Epoch: [569][0/79]	Time 0.077 (0.077)	Data 0.056 (0.056)	Loss 0.5115 (0.5115)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:03

 Epoch: 570	Training Loss 0.4202 	Training Prec@1 85.128 	Training Prec@5 99.486 	Validation Loss 0.5933 	Validation Prec@1 80.210 	Validation Prec@5 98.810 

lr: 0.039976435141324415
TRAINING - Epoch: [570][0/196]	Time 0.805 (0.805)	Data 0.091 (0.091)	Loss 0.5081 (0.5081)	Prec@1 83.984 (83.984)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [570][100/196]	Time 0.083 (0.095)	Data 0.000 (0.001)	Loss 0.3728 (0.4127)	Prec@1 89.062 (85.705)	Prec@5 100.000 (99.505)
EVALUATING - Epoch: [570][0/79]	Time 0.074 (0.074)	Data 0.055 (0.055)	Loss 0.5127 (0.5127)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:52

 Epoch: 571	Training Loss 0.4097 	Training Prec@1 85.598 	Training Prec@5 99.516 	Validation Loss 0.5667 	Validation Prec@1 81.300 	Validation Prec@5 99.160 

lr: 0.03982197158216778
TRAINING - Epoch: [571][0/196]	Time 0.815 (0.815)	Data 0.104 (0.104)	Loss 0.4096 (0.4096)	Prec@1 84.766 (84.766)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [571][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.3861 (0.4132)	Prec@1 87.500 (85.485)	Prec@5 99.609 (99.474)
EVALUATING - Epoch: [571][0/79]	Time 0.079 (0.079)	Data 0.059 (0.059)	Loss 0.4928 (0.4928)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:53

 Epoch: 572	Training Loss 0.4178 	Training Prec@1 85.422 	Training Prec@5 99.492 	Validation Loss 0.5939 	Validation Prec@1 80.380 	Validation Prec@5 98.780 

lr: 0.039667609303073614
TRAINING - Epoch: [572][0/196]	Time 0.792 (0.792)	Data 0.080 (0.080)	Loss 0.3818 (0.3818)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [572][100/196]	Time 0.085 (0.095)	Data 0.000 (0.001)	Loss 0.4216 (0.4169)	Prec@1 85.547 (85.404)	Prec@5 99.219 (99.470)
EVALUATING - Epoch: [572][0/79]	Time 0.079 (0.079)	Data 0.058 (0.058)	Loss 0.6753 (0.6753)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:51:44

 Epoch: 573	Training Loss 0.4171 	Training Prec@1 85.362 	Training Prec@5 99.492 	Validation Loss 0.7487 	Validation Prec@1 77.210 	Validation Prec@5 98.570 

lr: 0.03951334983979672
TRAINING - Epoch: [573][0/196]	Time 0.693 (0.693)	Data 0.099 (0.099)	Loss 0.3906 (0.3906)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [573][100/196]	Time 0.094 (0.084)	Data 0.000 (0.001)	Loss 0.3534 (0.4182)	Prec@1 89.453 (85.423)	Prec@5 100.000 (99.474)
EVALUATING - Epoch: [573][0/79]	Time 0.076 (0.076)	Data 0.054 (0.054)	Loss 0.4217 (0.4217)	Prec@1 86.719 (86.719)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:44

 Epoch: 574	Training Loss 0.4144 	Training Prec@1 85.530 	Training Prec@5 99.520 	Validation Loss 0.6200 	Validation Prec@1 79.920 	Validation Prec@5 99.030 

lr: 0.03935919472706905
TRAINING - Epoch: [574][0/196]	Time 0.707 (0.707)	Data 0.097 (0.097)	Loss 0.4177 (0.4177)	Prec@1 85.547 (85.547)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [574][100/196]	Time 0.093 (0.084)	Data 0.000 (0.001)	Loss 0.4069 (0.4174)	Prec@1 86.719 (85.303)	Prec@5 99.609 (99.474)
EVALUATING - Epoch: [574][0/79]	Time 0.070 (0.070)	Data 0.049 (0.049)	Loss 0.5425 (0.5425)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:08

 Epoch: 575	Training Loss 0.4158 	Training Prec@1 85.280 	Training Prec@5 99.474 	Validation Loss 0.6085 	Validation Prec@1 79.710 	Validation Prec@5 99.110 

lr: 0.03920514549858431
TRAINING - Epoch: [575][0/196]	Time 0.775 (0.775)	Data 0.106 (0.106)	Loss 0.3499 (0.3499)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [575][100/196]	Time 0.087 (0.093)	Data 0.000 (0.001)	Loss 0.2911 (0.4073)	Prec@1 90.625 (85.733)	Prec@5 99.219 (99.528)
EVALUATING - Epoch: [575][0/79]	Time 0.081 (0.081)	Data 0.062 (0.062)	Loss 0.3814 (0.3814)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:29

 Epoch: 576	Training Loss 0.4087 	Training Prec@1 85.578 	Training Prec@5 99.526 	Validation Loss 0.5681 	Validation Prec@1 80.990 	Validation Prec@5 99.160 

lr: 0.03905120368698278
TRAINING - Epoch: [576][0/196]	Time 0.817 (0.817)	Data 0.097 (0.097)	Loss 0.3604 (0.3604)	Prec@1 86.719 (86.719)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [576][100/196]	Time 0.089 (0.093)	Data 0.000 (0.001)	Loss 0.3550 (0.4132)	Prec@1 87.109 (85.477)	Prec@5 99.219 (99.459)
EVALUATING - Epoch: [576][0/79]	Time 0.089 (0.089)	Data 0.064 (0.064)	Loss 0.7228 (0.7228)	Prec@1 77.344 (77.344)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:10

 Epoch: 577	Training Loss 0.4173 	Training Prec@1 85.406 	Training Prec@5 99.470 	Validation Loss 0.6787 	Validation Prec@1 78.660 	Validation Prec@5 98.700 

lr: 0.03889737082383608
TRAINING - Epoch: [577][0/196]	Time 0.792 (0.792)	Data 0.090 (0.090)	Loss 0.4597 (0.4597)	Prec@1 82.812 (82.812)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [577][100/196]	Time 0.092 (0.094)	Data 0.000 (0.001)	Loss 0.3757 (0.4085)	Prec@1 88.672 (85.698)	Prec@5 99.609 (99.404)
EVALUATING - Epoch: [577][0/79]	Time 0.072 (0.072)	Data 0.054 (0.054)	Loss 0.5271 (0.5271)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:49:56

 Epoch: 578	Training Loss 0.4087 	Training Prec@1 85.746 	Training Prec@5 99.470 	Validation Loss 0.5944 	Validation Prec@1 80.130 	Validation Prec@5 98.980 

lr: 0.038743648439631816
TRAINING - Epoch: [578][0/196]	Time 0.778 (0.778)	Data 0.090 (0.090)	Loss 0.3697 (0.3697)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [578][100/196]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.3480 (0.4077)	Prec@1 88.672 (85.686)	Prec@5 99.609 (99.462)
EVALUATING - Epoch: [578][0/79]	Time 0.085 (0.085)	Data 0.066 (0.066)	Loss 0.4817 (0.4817)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:07

 Epoch: 579	Training Loss 0.4072 	Training Prec@1 85.736 	Training Prec@5 99.512 	Validation Loss 0.5606 	Validation Prec@1 81.430 	Validation Prec@5 99.140 

lr: 0.03859003806375854
TRAINING - Epoch: [579][0/196]	Time 0.789 (0.789)	Data 0.088 (0.088)	Loss 0.5072 (0.5072)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [579][100/196]	Time 0.094 (0.082)	Data 0.000 (0.001)	Loss 0.4476 (0.4018)	Prec@1 83.984 (85.713)	Prec@5 99.609 (99.544)
EVALUATING - Epoch: [579][0/79]	Time 0.075 (0.075)	Data 0.052 (0.052)	Loss 0.6376 (0.6376)	Prec@1 80.469 (80.469)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:07

 Epoch: 580	Training Loss 0.4095 	Training Prec@1 85.552 	Training Prec@5 99.536 	Validation Loss 0.6160 	Validation Prec@1 79.190 	Validation Prec@5 98.960 

lr: 0.03843654122449034
TRAINING - Epoch: [580][0/196]	Time 0.771 (0.771)	Data 0.092 (0.092)	Loss 0.4973 (0.4973)	Prec@1 82.422 (82.422)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [580][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.3804 (0.4161)	Prec@1 86.328 (85.265)	Prec@5 99.609 (99.424)
EVALUATING - Epoch: [580][0/79]	Time 0.081 (0.081)	Data 0.060 (0.060)	Loss 0.4835 (0.4835)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:52

 Epoch: 581	Training Loss 0.4129 	Training Prec@1 85.456 	Training Prec@5 99.458 	Validation Loss 0.5659 	Validation Prec@1 81.160 	Validation Prec@5 99.070 

lr: 0.03828315944897178
TRAINING - Epoch: [581][0/196]	Time 0.781 (0.781)	Data 0.098 (0.098)	Loss 0.4162 (0.4162)	Prec@1 85.547 (85.547)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [581][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.4605 (0.4116)	Prec@1 85.547 (85.702)	Prec@5 99.609 (99.462)
EVALUATING - Epoch: [581][0/79]	Time 0.074 (0.074)	Data 0.053 (0.053)	Loss 0.7514 (0.7514)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:11

 Epoch: 582	Training Loss 0.4123 	Training Prec@1 85.662 	Training Prec@5 99.468 	Validation Loss 0.7287 	Validation Prec@1 77.430 	Validation Prec@5 98.960 

lr: 0.03812989426320263
TRAINING - Epoch: [582][0/196]	Time 0.828 (0.828)	Data 0.091 (0.091)	Loss 0.4498 (0.4498)	Prec@1 84.766 (84.766)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [582][100/196]	Time 0.092 (0.094)	Data 0.001 (0.001)	Loss 0.4399 (0.4084)	Prec@1 85.156 (85.829)	Prec@5 99.219 (99.528)
EVALUATING - Epoch: [582][0/79]	Time 0.090 (0.090)	Data 0.072 (0.072)	Loss 0.5490 (0.5490)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:19	Time of Finish: 2024-03-31 19:50:20

 Epoch: 583	Training Loss 0.4137 	Training Prec@1 85.578 	Training Prec@5 99.446 	Validation Loss 0.6255 	Validation Prec@1 80.020 	Validation Prec@5 98.930 

lr: 0.037976747192022715
TRAINING - Epoch: [583][0/196]	Time 0.761 (0.761)	Data 0.085 (0.085)	Loss 0.4494 (0.4494)	Prec@1 83.984 (83.984)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [583][100/196]	Time 0.079 (0.081)	Data 0.000 (0.001)	Loss 0.2374 (0.4060)	Prec@1 93.359 (85.787)	Prec@5 100.000 (99.455)
EVALUATING - Epoch: [583][0/79]	Time 0.082 (0.082)	Data 0.061 (0.061)	Loss 0.4615 (0.4615)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:07

 Epoch: 584	Training Loss 0.4069 	Training Prec@1 85.752 	Training Prec@5 99.476 	Validation Loss 0.5656 	Validation Prec@1 80.720 	Validation Prec@5 99.200 

lr: 0.03782371975909671
TRAINING - Epoch: [584][0/196]	Time 0.738 (0.738)	Data 0.087 (0.087)	Loss 0.3615 (0.3615)	Prec@1 86.328 (86.328)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [584][100/196]	Time 0.090 (0.084)	Data 0.000 (0.001)	Loss 0.4192 (0.4073)	Prec@1 85.156 (85.473)	Prec@5 99.219 (99.540)
EVALUATING - Epoch: [584][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 0.6437 (0.6437)	Prec@1 76.562 (76.562)	Prec@5 96.094 (96.094)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:50

 Epoch: 585	Training Loss 0.4096 	Training Prec@1 85.512 	Training Prec@5 99.526 	Validation Loss 0.6283 	Validation Prec@1 79.230 	Validation Prec@5 98.690 

lr: 0.03767081348689905
TRAINING - Epoch: [585][0/196]	Time 0.798 (0.798)	Data 0.080 (0.080)	Loss 0.3757 (0.3757)	Prec@1 85.547 (85.547)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [585][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.3611 (0.4060)	Prec@1 88.281 (86.007)	Prec@5 99.609 (99.489)
EVALUATING - Epoch: [585][0/79]	Time 0.074 (0.074)	Data 0.053 (0.053)	Loss 0.5389 (0.5389)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:52

 Epoch: 586	Training Loss 0.4066 	Training Prec@1 85.792 	Training Prec@5 99.526 	Validation Loss 0.5708 	Validation Prec@1 81.580 	Validation Prec@5 99.080 

lr: 0.03751802989669869
TRAINING - Epoch: [586][0/196]	Time 0.670 (0.670)	Data 0.085 (0.085)	Loss 0.4051 (0.4051)	Prec@1 87.109 (87.109)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [586][100/196]	Time 0.087 (0.093)	Data 0.000 (0.001)	Loss 0.3941 (0.3990)	Prec@1 84.766 (86.166)	Prec@5 99.219 (99.582)
EVALUATING - Epoch: [586][0/79]	Time 0.083 (0.083)	Data 0.053 (0.053)	Loss 0.6111 (0.6111)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:16

 Epoch: 587	Training Loss 0.4026 	Training Prec@1 85.998 	Training Prec@5 99.550 	Validation Loss 0.6236 	Validation Prec@1 79.460 	Validation Prec@5 98.910 

lr: 0.03736537050854406
TRAINING - Epoch: [587][0/196]	Time 0.773 (0.773)	Data 0.086 (0.086)	Loss 0.4193 (0.4193)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [587][100/196]	Time 0.091 (0.093)	Data 0.000 (0.001)	Loss 0.4017 (0.4007)	Prec@1 87.109 (85.802)	Prec@5 98.828 (99.517)
EVALUATING - Epoch: [587][0/79]	Time 0.079 (0.079)	Data 0.053 (0.053)	Loss 0.5917 (0.5917)	Prec@1 77.344 (77.344)	Prec@5 100.000 (100.000)
Time cost: 00:19	Time of Finish: 2024-03-31 19:49:54

 Epoch: 588	Training Loss 0.4040 	Training Prec@1 85.694 	Training Prec@5 99.522 	Validation Loss 0.7577 	Validation Prec@1 76.390 	Validation Prec@5 98.470 

lr: 0.03721283684124786
TRAINING - Epoch: [588][0/196]	Time 0.768 (0.768)	Data 0.100 (0.100)	Loss 0.4164 (0.4164)	Prec@1 85.938 (85.938)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [588][100/196]	Time 0.060 (0.076)	Data 0.000 (0.001)	Loss 0.5510 (0.4015)	Prec@1 79.688 (85.725)	Prec@5 98.047 (99.582)
EVALUATING - Epoch: [588][0/79]	Time 0.073 (0.073)	Data 0.051 (0.051)	Loss 0.5243 (0.5243)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:36:56

 Epoch: 589	Training Loss 0.4077 	Training Prec@1 85.660 	Training Prec@5 99.532 	Validation Loss 0.5464 	Validation Prec@1 81.710 	Validation Prec@5 99.020 

lr: 0.03706043041237202
TRAINING - Epoch: [589][0/196]	Time 0.786 (0.786)	Data 0.082 (0.082)	Loss 0.3722 (0.3722)	Prec@1 84.766 (84.766)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [589][100/196]	Time 0.039 (0.084)	Data 0.000 (0.001)	Loss 0.3444 (0.4011)	Prec@1 89.844 (85.682)	Prec@5 99.219 (99.470)
EVALUATING - Epoch: [589][0/79]	Time 0.074 (0.074)	Data 0.054 (0.054)	Loss 0.5568 (0.5568)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:21

 Epoch: 590	Training Loss 0.4071 	Training Prec@1 85.582 	Training Prec@5 99.508 	Validation Loss 0.6823 	Validation Prec@1 78.240 	Validation Prec@5 98.920 

lr: 0.03690815273821258
TRAINING - Epoch: [590][0/196]	Time 0.738 (0.738)	Data 0.099 (0.099)	Loss 0.3770 (0.3770)	Prec@1 88.672 (88.672)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [590][100/196]	Time 0.087 (0.094)	Data 0.000 (0.001)	Loss 0.4693 (0.4058)	Prec@1 85.156 (85.972)	Prec@5 100.000 (99.536)
EVALUATING - Epoch: [590][0/79]	Time 0.073 (0.073)	Data 0.057 (0.057)	Loss 0.5465 (0.5465)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:16

 Epoch: 591	Training Loss 0.4112 	Training Prec@1 85.692 	Training Prec@5 99.550 	Validation Loss 0.5860 	Validation Prec@1 80.220 	Validation Prec@5 99.080 

lr: 0.036756005333784536
TRAINING - Epoch: [591][0/196]	Time 0.743 (0.743)	Data 0.087 (0.087)	Loss 0.3170 (0.3170)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [591][100/196]	Time 0.085 (0.096)	Data 0.000 (0.001)	Loss 0.4318 (0.4073)	Prec@1 83.594 (85.647)	Prec@5 100.000 (99.528)
EVALUATING - Epoch: [591][0/79]	Time 0.075 (0.075)	Data 0.053 (0.053)	Loss 0.4772 (0.4772)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:28

 Epoch: 592	Training Loss 0.4093 	Training Prec@1 85.614 	Training Prec@5 99.514 	Validation Loss 0.6084 	Validation Prec@1 80.440 	Validation Prec@5 98.710 

lr: 0.036603989712806914
TRAINING - Epoch: [592][0/196]	Time 0.298 (0.298)	Data 0.092 (0.092)	Loss 0.3821 (0.3821)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [592][100/196]	Time 0.083 (0.090)	Data 0.000 (0.001)	Loss 0.4759 (0.3995)	Prec@1 83.594 (86.181)	Prec@5 99.609 (99.528)
EVALUATING - Epoch: [592][0/79]	Time 0.080 (0.080)	Data 0.061 (0.061)	Loss 0.5910 (0.5910)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:49

 Epoch: 593	Training Loss 0.4026 	Training Prec@1 85.980 	Training Prec@5 99.516 	Validation Loss 0.5990 	Validation Prec@1 80.160 	Validation Prec@5 98.790 

lr: 0.036452107387687525
TRAINING - Epoch: [593][0/196]	Time 0.809 (0.809)	Data 0.095 (0.095)	Loss 0.2963 (0.2963)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [593][100/196]	Time 0.090 (0.084)	Data 0.000 (0.001)	Loss 0.4461 (0.3909)	Prec@1 84.375 (86.402)	Prec@5 100.000 (99.540)
EVALUATING - Epoch: [593][0/79]	Time 0.077 (0.077)	Data 0.054 (0.054)	Loss 0.6215 (0.6215)	Prec@1 76.562 (76.562)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:32

 Epoch: 594	Training Loss 0.4025 	Training Prec@1 85.910 	Training Prec@5 99.512 	Validation Loss 0.6864 	Validation Prec@1 78.070 	Validation Prec@5 98.410 

lr: 0.036300359869508116
TRAINING - Epoch: [594][0/196]	Time 0.812 (0.812)	Data 0.110 (0.110)	Loss 0.3620 (0.3620)	Prec@1 85.547 (85.547)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [594][100/196]	Time 0.058 (0.087)	Data 0.000 (0.001)	Loss 0.3821 (0.3985)	Prec@1 87.500 (86.115)	Prec@5 99.219 (99.547)
EVALUATING - Epoch: [594][0/79]	Time 0.079 (0.079)	Data 0.059 (0.059)	Loss 0.6178 (0.6178)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:45

 Epoch: 595	Training Loss 0.4018 	Training Prec@1 85.914 	Training Prec@5 99.536 	Validation Loss 0.6409 	Validation Prec@1 78.550 	Validation Prec@5 98.990 

lr: 0.03614874866800916
TRAINING - Epoch: [595][0/196]	Time 0.790 (0.790)	Data 0.104 (0.104)	Loss 0.3305 (0.3305)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [595][100/196]	Time 0.090 (0.094)	Data 0.000 (0.001)	Loss 0.4505 (0.4071)	Prec@1 83.594 (85.682)	Prec@5 99.219 (99.513)
EVALUATING - Epoch: [595][0/79]	Time 0.074 (0.074)	Data 0.054 (0.054)	Loss 0.5239 (0.5239)	Prec@1 82.031 (82.031)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:57

 Epoch: 596	Training Loss 0.4033 	Training Prec@1 85.768 	Training Prec@5 99.526 	Validation Loss 0.5258 	Validation Prec@1 82.090 	Validation Prec@5 99.200 

lr: 0.03599727529157494
TRAINING - Epoch: [596][0/196]	Time 0.747 (0.747)	Data 0.079 (0.079)	Loss 0.3478 (0.3478)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [596][100/196]	Time 0.080 (0.093)	Data 0.000 (0.001)	Loss 0.5033 (0.4055)	Prec@1 82.422 (85.810)	Prec@5 99.609 (99.563)
EVALUATING - Epoch: [596][0/79]	Time 0.086 (0.086)	Data 0.057 (0.057)	Loss 0.4941 (0.4941)	Prec@1 82.031 (82.031)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:24

 Epoch: 597	Training Loss 0.4051 	Training Prec@1 85.746 	Training Prec@5 99.542 	Validation Loss 0.5657 	Validation Prec@1 81.430 	Validation Prec@5 99.160 

lr: 0.035845941247218516
TRAINING - Epoch: [597][0/196]	Time 0.584 (0.584)	Data 0.096 (0.096)	Loss 0.3171 (0.3171)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [597][100/196]	Time 0.088 (0.092)	Data 0.000 (0.001)	Loss 0.3959 (0.4008)	Prec@1 87.109 (85.988)	Prec@5 99.219 (99.517)
EVALUATING - Epoch: [597][0/79]	Time 0.072 (0.072)	Data 0.048 (0.048)	Loss 0.4336 (0.4336)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:48:25

 Epoch: 598	Training Loss 0.4048 	Training Prec@1 85.948 	Training Prec@5 99.530 	Validation Loss 0.5418 	Validation Prec@1 81.770 	Validation Prec@5 99.090 

lr: 0.03569474804056673
TRAINING - Epoch: [598][0/196]	Time 0.797 (0.797)	Data 0.079 (0.079)	Loss 0.3555 (0.3555)	Prec@1 89.062 (89.062)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [598][100/196]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.4434 (0.4062)	Prec@1 83.594 (85.903)	Prec@5 99.609 (99.540)
EVALUATING - Epoch: [598][0/79]	Time 0.074 (0.074)	Data 0.053 (0.053)	Loss 0.5883 (0.5883)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:30

 Epoch: 599	Training Loss 0.4070 	Training Prec@1 85.802 	Training Prec@5 99.526 	Validation Loss 0.6729 	Validation Prec@1 78.550 	Validation Prec@5 98.700 

lr: 0.03554369717584521
TRAINING - Epoch: [599][0/196]	Time 0.787 (0.787)	Data 0.081 (0.081)	Loss 0.3892 (0.3892)	Prec@1 89.062 (89.062)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [599][100/196]	Time 0.029 (0.085)	Data 0.000 (0.001)	Loss 0.3804 (0.4005)	Prec@1 87.109 (86.166)	Prec@5 99.609 (99.447)
EVALUATING - Epoch: [599][0/79]	Time 0.074 (0.074)	Data 0.052 (0.052)	Loss 0.5732 (0.5732)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:09

 Epoch: 600	Training Loss 0.4023 	Training Prec@1 86.006 	Training Prec@5 99.474 	Validation Loss 0.6188 	Validation Prec@1 79.740 	Validation Prec@5 98.970 

lr: 0.03539279015586344
TRAINING - Epoch: [600][0/196]	Time 0.801 (0.801)	Data 0.095 (0.095)	Loss 0.4194 (0.4194)	Prec@1 84.766 (84.766)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [600][100/196]	Time 0.070 (0.095)	Data 0.000 (0.001)	Loss 0.3774 (0.3914)	Prec@1 85.547 (86.293)	Prec@5 98.438 (99.563)
EVALUATING - Epoch: [600][0/79]	Time 0.072 (0.072)	Data 0.051 (0.051)	Loss 0.4434 (0.4434)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:59

 Epoch: 601	Training Loss 0.3968 	Training Prec@1 86.058 	Training Prec@5 99.546 	Validation Loss 0.5422 	Validation Prec@1 81.720 	Validation Prec@5 99.290 

lr: 0.03524202848199977
TRAINING - Epoch: [601][0/196]	Time 0.750 (0.750)	Data 0.098 (0.098)	Loss 0.4719 (0.4719)	Prec@1 85.156 (85.156)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [601][100/196]	Time 0.090 (0.091)	Data 0.000 (0.001)	Loss 0.3901 (0.3962)	Prec@1 83.594 (86.142)	Prec@5 99.609 (99.486)
EVALUATING - Epoch: [601][0/79]	Time 0.069 (0.069)	Data 0.051 (0.051)	Loss 0.4221 (0.4221)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:39

 Epoch: 602	Training Loss 0.4000 	Training Prec@1 85.918 	Training Prec@5 99.536 	Validation Loss 0.6139 	Validation Prec@1 79.730 	Validation Prec@5 98.910 

lr: 0.0350914136541865
TRAINING - Epoch: [602][0/196]	Time 0.557 (0.557)	Data 0.089 (0.089)	Loss 0.4595 (0.4595)	Prec@1 83.984 (83.984)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [602][100/196]	Time 0.085 (0.091)	Data 0.000 (0.001)	Loss 0.4578 (0.3999)	Prec@1 85.156 (85.783)	Prec@5 98.828 (99.466)
EVALUATING - Epoch: [602][0/79]	Time 0.071 (0.071)	Data 0.050 (0.050)	Loss 0.7041 (0.7041)	Prec@1 78.125 (78.125)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:32

 Epoch: 603	Training Loss 0.3973 	Training Prec@1 85.918 	Training Prec@5 99.502 	Validation Loss 0.6697 	Validation Prec@1 78.610 	Validation Prec@5 99.020 

lr: 0.034940947170894986
TRAINING - Epoch: [603][0/196]	Time 0.766 (0.766)	Data 0.082 (0.082)	Loss 0.3210 (0.3210)	Prec@1 90.234 (90.234)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [603][100/196]	Time 0.074 (0.083)	Data 0.000 (0.001)	Loss 0.4249 (0.3923)	Prec@1 85.938 (86.286)	Prec@5 99.219 (99.559)
EVALUATING - Epoch: [603][0/79]	Time 0.073 (0.073)	Data 0.050 (0.050)	Loss 0.3872 (0.3872)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:56

 Epoch: 604	Training Loss 0.3946 	Training Prec@1 86.308 	Training Prec@5 99.528 	Validation Loss 0.5233 	Validation Prec@1 82.230 	Validation Prec@5 99.170 

lr: 0.03479063052912063
TRAINING - Epoch: [604][0/196]	Time 0.817 (0.817)	Data 0.094 (0.094)	Loss 0.3117 (0.3117)	Prec@1 87.500 (87.500)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [604][100/196]	Time 0.055 (0.088)	Data 0.000 (0.001)	Loss 0.3591 (0.3839)	Prec@1 87.891 (86.568)	Prec@5 99.609 (99.578)
EVALUATING - Epoch: [604][0/79]	Time 0.075 (0.075)	Data 0.053 (0.053)	Loss 0.4312 (0.4312)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:37

 Epoch: 605	Training Loss 0.3933 	Training Prec@1 86.222 	Training Prec@5 99.546 	Validation Loss 0.6045 	Validation Prec@1 80.020 	Validation Prec@5 99.030 

lr: 0.03464046522436815
TRAINING - Epoch: [605][0/196]	Time 0.795 (0.795)	Data 0.080 (0.080)	Loss 0.3141 (0.3141)	Prec@1 89.062 (89.062)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [605][100/196]	Time 0.085 (0.094)	Data 0.000 (0.001)	Loss 0.4226 (0.3893)	Prec@1 84.766 (86.235)	Prec@5 99.219 (99.555)
EVALUATING - Epoch: [605][0/79]	Time 0.077 (0.077)	Data 0.055 (0.055)	Loss 0.4510 (0.4510)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:22

 Epoch: 606	Training Loss 0.3936 	Training Prec@1 86.124 	Training Prec@5 99.558 	Validation Loss 0.5237 	Validation Prec@1 82.260 	Validation Prec@5 99.200 

lr: 0.03449045275063652
TRAINING - Epoch: [606][0/196]	Time 0.793 (0.793)	Data 0.087 (0.087)	Loss 0.3573 (0.3573)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [606][100/196]	Time 0.089 (0.094)	Data 0.000 (0.001)	Loss 0.5064 (0.3921)	Prec@1 82.031 (86.255)	Prec@5 99.609 (99.590)
EVALUATING - Epoch: [606][0/79]	Time 0.079 (0.079)	Data 0.057 (0.057)	Loss 0.5291 (0.5291)	Prec@1 81.250 (81.250)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:01

 Epoch: 607	Training Loss 0.3998 	Training Prec@1 86.116 	Training Prec@5 99.538 	Validation Loss 0.6430 	Validation Prec@1 79.800 	Validation Prec@5 98.950 

lr: 0.03434059460040425
TRAINING - Epoch: [607][0/196]	Time 0.377 (0.377)	Data 0.082 (0.082)	Loss 0.3463 (0.3463)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [607][100/196]	Time 0.091 (0.086)	Data 0.000 (0.001)	Loss 0.4254 (0.4097)	Prec@1 83.984 (85.473)	Prec@5 99.609 (99.540)
EVALUATING - Epoch: [607][0/79]	Time 0.080 (0.080)	Data 0.060 (0.060)	Loss 0.4714 (0.4714)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:20

 Epoch: 608	Training Loss 0.3980 	Training Prec@1 86.042 	Training Prec@5 99.550 	Validation Loss 0.5783 	Validation Prec@1 80.620 	Validation Prec@5 99.210 

lr: 0.03419089226461448
TRAINING - Epoch: [608][0/196]	Time 0.820 (0.820)	Data 0.100 (0.100)	Loss 0.3388 (0.3388)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [608][100/196]	Time 0.068 (0.085)	Data 0.000 (0.001)	Loss 0.4419 (0.3931)	Prec@1 83.984 (86.154)	Prec@5 99.609 (99.524)
EVALUATING - Epoch: [608][0/79]	Time 0.073 (0.073)	Data 0.051 (0.051)	Loss 0.5196 (0.5196)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:59

 Epoch: 609	Training Loss 0.3966 	Training Prec@1 86.088 	Training Prec@5 99.530 	Validation Loss 0.5626 	Validation Prec@1 81.400 	Validation Prec@5 99.180 

lr: 0.03404134723266008
TRAINING - Epoch: [609][0/196]	Time 0.807 (0.807)	Data 0.099 (0.099)	Loss 0.3505 (0.3505)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [609][100/196]	Time 0.057 (0.090)	Data 0.000 (0.001)	Loss 0.3914 (0.3908)	Prec@1 86.719 (86.305)	Prec@5 98.828 (99.575)
EVALUATING - Epoch: [609][0/79]	Time 0.084 (0.084)	Data 0.066 (0.066)	Loss 0.5812 (0.5812)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:30

 Epoch: 610	Training Loss 0.3932 	Training Prec@1 86.204 	Training Prec@5 99.556 	Validation Loss 0.6612 	Validation Prec@1 77.970 	Validation Prec@5 98.820 

lr: 0.033891960992369005
TRAINING - Epoch: [610][0/196]	Time 0.810 (0.810)	Data 0.087 (0.087)	Loss 0.4127 (0.4127)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [610][100/196]	Time 0.084 (0.094)	Data 0.000 (0.001)	Loss 0.3816 (0.3933)	Prec@1 87.109 (86.173)	Prec@5 100.000 (99.555)
EVALUATING - Epoch: [610][0/79]	Time 0.071 (0.071)	Data 0.050 (0.050)	Loss 0.4191 (0.4191)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:57

 Epoch: 611	Training Loss 0.3952 	Training Prec@1 86.140 	Training Prec@5 99.584 	Validation Loss 0.5565 	Validation Prec@1 81.140 	Validation Prec@5 98.980 

lr: 0.033742735029989285
TRAINING - Epoch: [611][0/196]	Time 0.802 (0.802)	Data 0.089 (0.089)	Loss 0.4604 (0.4604)	Prec@1 84.766 (84.766)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [611][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.4256 (0.3893)	Prec@1 85.156 (86.235)	Prec@5 99.609 (99.505)
EVALUATING - Epoch: [611][0/79]	Time 0.080 (0.080)	Data 0.058 (0.058)	Loss 0.4890 (0.4890)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:23

 Epoch: 612	Training Loss 0.3901 	Training Prec@1 86.302 	Training Prec@5 99.510 	Validation Loss 0.5433 	Validation Prec@1 81.790 	Validation Prec@5 99.070 

lr: 0.033593670830174414
TRAINING - Epoch: [612][0/196]	Time 0.740 (0.740)	Data 0.101 (0.101)	Loss 0.3693 (0.3693)	Prec@1 88.672 (88.672)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [612][100/196]	Time 0.068 (0.093)	Data 0.000 (0.001)	Loss 0.4203 (0.3948)	Prec@1 84.766 (86.262)	Prec@5 100.000 (99.493)
EVALUATING - Epoch: [612][0/79]	Time 0.080 (0.080)	Data 0.057 (0.057)	Loss 0.5739 (0.5739)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:49:00

 Epoch: 613	Training Loss 0.3954 	Training Prec@1 86.136 	Training Prec@5 99.526 	Validation Loss 0.6246 	Validation Prec@1 79.580 	Validation Prec@5 99.120 

lr: 0.03344476987596848
TRAINING - Epoch: [613][0/196]	Time 0.802 (0.802)	Data 0.083 (0.083)	Loss 0.4076 (0.4076)	Prec@1 86.719 (86.719)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [613][100/196]	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 0.3895 (0.3901)	Prec@1 85.938 (86.282)	Prec@5 100.000 (99.563)
EVALUATING - Epoch: [613][0/79]	Time 0.081 (0.081)	Data 0.063 (0.063)	Loss 0.3919 (0.3919)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:24

 Epoch: 614	Training Loss 0.3867 	Training Prec@1 86.498 	Training Prec@5 99.576 	Validation Loss 0.5873 	Validation Prec@1 80.180 	Validation Prec@5 99.140 

lr: 0.033296033648791426
TRAINING - Epoch: [614][0/196]	Time 0.775 (0.775)	Data 0.086 (0.086)	Loss 0.2972 (0.2972)	Prec@1 89.453 (89.453)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [614][100/196]	Time 0.063 (0.081)	Data 0.000 (0.001)	Loss 0.3980 (0.4031)	Prec@1 86.719 (85.895)	Prec@5 99.609 (99.486)
EVALUATING - Epoch: [614][0/79]	Time 0.076 (0.076)	Data 0.054 (0.054)	Loss 0.5741 (0.5741)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:50

 Epoch: 615	Training Loss 0.3980 	Training Prec@1 86.112 	Training Prec@5 99.504 	Validation Loss 0.5704 	Validation Prec@1 81.250 	Validation Prec@5 99.170 

lr: 0.033147463628424315
TRAINING - Epoch: [615][0/196]	Time 0.789 (0.789)	Data 0.100 (0.100)	Loss 0.3853 (0.3853)	Prec@1 87.109 (87.109)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [615][100/196]	Time 0.058 (0.094)	Data 0.000 (0.001)	Loss 0.3541 (0.3886)	Prec@1 86.719 (86.475)	Prec@5 100.000 (99.497)
EVALUATING - Epoch: [615][0/79]	Time 0.086 (0.086)	Data 0.065 (0.065)	Loss 0.6592 (0.6592)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:18

 Epoch: 616	Training Loss 0.3916 	Training Prec@1 86.362 	Training Prec@5 99.538 	Validation Loss 0.6457 	Validation Prec@1 79.580 	Validation Prec@5 98.970 

lr: 0.03299906129299467
TRAINING - Epoch: [616][0/196]	Time 0.735 (0.735)	Data 0.107 (0.107)	Loss 0.3651 (0.3651)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [616][100/196]	Time 0.084 (0.092)	Data 0.000 (0.001)	Loss 0.2973 (0.3973)	Prec@1 88.281 (86.084)	Prec@5 100.000 (99.567)
EVALUATING - Epoch: [616][0/79]	Time 0.081 (0.081)	Data 0.063 (0.063)	Loss 0.4038 (0.4038)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:50

 Epoch: 617	Training Loss 0.3911 	Training Prec@1 86.272 	Training Prec@5 99.564 	Validation Loss 0.5247 	Validation Prec@1 82.640 	Validation Prec@5 99.200 

lr: 0.032850828118961624
TRAINING - Epoch: [617][0/196]	Time 0.752 (0.752)	Data 0.082 (0.082)	Loss 0.5445 (0.5445)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [617][100/196]	Time 0.083 (0.094)	Data 0.000 (0.001)	Loss 0.4201 (0.3954)	Prec@1 85.938 (86.344)	Prec@5 98.828 (99.567)
EVALUATING - Epoch: [617][0/79]	Time 0.073 (0.073)	Data 0.053 (0.053)	Loss 0.4398 (0.4398)	Prec@1 82.031 (82.031)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:45

 Epoch: 618	Training Loss 0.3898 	Training Prec@1 86.378 	Training Prec@5 99.572 	Validation Loss 0.6411 	Validation Prec@1 79.230 	Validation Prec@5 98.980 

lr: 0.0327027655811014
TRAINING - Epoch: [618][0/196]	Time 0.825 (0.825)	Data 0.114 (0.114)	Loss 0.3916 (0.3916)	Prec@1 83.984 (83.984)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [618][100/196]	Time 0.092 (0.084)	Data 0.000 (0.001)	Loss 0.4309 (0.3897)	Prec@1 85.156 (86.351)	Prec@5 100.000 (99.571)
EVALUATING - Epoch: [618][0/79]	Time 0.083 (0.083)	Data 0.062 (0.062)	Loss 0.5990 (0.5990)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:00

 Epoch: 619	Training Loss 0.3881 	Training Prec@1 86.332 	Training Prec@5 99.568 	Validation Loss 0.6963 	Validation Prec@1 78.040 	Validation Prec@5 98.690 

lr: 0.032554875152492495
TRAINING - Epoch: [619][0/196]	Time 0.768 (0.768)	Data 0.081 (0.081)	Loss 0.4411 (0.4411)	Prec@1 84.766 (84.766)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [619][100/196]	Time 0.042 (0.082)	Data 0.000 (0.001)	Loss 0.4573 (0.3864)	Prec@1 84.375 (86.262)	Prec@5 99.609 (99.536)
EVALUATING - Epoch: [619][0/79]	Time 0.088 (0.088)	Data 0.065 (0.065)	Loss 0.7042 (0.7042)	Prec@1 74.219 (74.219)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:05

 Epoch: 620	Training Loss 0.3877 	Training Prec@1 86.312 	Training Prec@5 99.576 	Validation Loss 0.6165 	Validation Prec@1 79.730 	Validation Prec@5 98.820 

lr: 0.03240715830450111
TRAINING - Epoch: [620][0/196]	Time 0.768 (0.768)	Data 0.079 (0.079)	Loss 0.4529 (0.4529)	Prec@1 82.031 (82.031)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [620][100/196]	Time 0.082 (0.093)	Data 0.000 (0.001)	Loss 0.4089 (0.3829)	Prec@1 84.766 (86.417)	Prec@5 100.000 (99.602)
EVALUATING - Epoch: [620][0/79]	Time 0.079 (0.079)	Data 0.060 (0.060)	Loss 0.4716 (0.4716)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:31

 Epoch: 621	Training Loss 0.3858 	Training Prec@1 86.464 	Training Prec@5 99.578 	Validation Loss 0.5917 	Validation Prec@1 80.370 	Validation Prec@5 99.230 

lr: 0.03225961650676652
TRAINING - Epoch: [621][0/196]	Time 0.768 (0.768)	Data 0.082 (0.082)	Loss 0.4306 (0.4306)	Prec@1 82.031 (82.031)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [621][100/196]	Time 0.090 (0.093)	Data 0.000 (0.001)	Loss 0.4032 (0.3775)	Prec@1 86.719 (86.645)	Prec@5 99.609 (99.660)
EVALUATING - Epoch: [621][0/79]	Time 0.085 (0.085)	Data 0.061 (0.061)	Loss 0.4903 (0.4903)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:36

 Epoch: 622	Training Loss 0.3826 	Training Prec@1 86.488 	Training Prec@5 99.624 	Validation Loss 0.5130 	Validation Prec@1 82.780 	Validation Prec@5 99.280 

lr: 0.03211225122718636
TRAINING - Epoch: [622][0/196]	Time 0.454 (0.454)	Data 0.102 (0.102)	Loss 0.3310 (0.3310)	Prec@1 87.891 (87.891)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [622][100/196]	Time 0.087 (0.089)	Data 0.000 (0.001)	Loss 0.3634 (0.3830)	Prec@1 87.500 (86.429)	Prec@5 99.609 (99.602)
EVALUATING - Epoch: [622][0/79]	Time 0.071 (0.071)	Data 0.052 (0.052)	Loss 0.6107 (0.6107)	Prec@1 78.125 (78.125)	Prec@5 96.875 (96.875)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:35

 Epoch: 623	Training Loss 0.3840 	Training Prec@1 86.494 	Training Prec@5 99.576 	Validation Loss 0.6116 	Validation Prec@1 80.110 	Validation Prec@5 98.910 

lr: 0.031965063931902134
TRAINING - Epoch: [623][0/196]	Time 0.779 (0.779)	Data 0.104 (0.104)	Loss 0.3159 (0.3159)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [623][100/196]	Time 0.082 (0.085)	Data 0.000 (0.001)	Loss 0.4175 (0.3880)	Prec@1 87.500 (86.638)	Prec@5 98.828 (99.466)
EVALUATING - Epoch: [623][0/79]	Time 0.077 (0.077)	Data 0.058 (0.058)	Loss 0.4958 (0.4958)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:06

 Epoch: 624	Training Loss 0.3874 	Training Prec@1 86.546 	Training Prec@5 99.536 	Validation Loss 0.5722 	Validation Prec@1 81.400 	Validation Prec@5 99.010 

lr: 0.03181805608528451
TRAINING - Epoch: [624][0/196]	Time 0.805 (0.805)	Data 0.106 (0.106)	Loss 0.3126 (0.3126)	Prec@1 89.453 (89.453)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [624][100/196]	Time 0.055 (0.087)	Data 0.000 (0.001)	Loss 0.4337 (0.3787)	Prec@1 83.984 (86.808)	Prec@5 99.609 (99.559)
EVALUATING - Epoch: [624][0/79]	Time 0.091 (0.091)	Data 0.073 (0.073)	Loss 0.5854 (0.5854)	Prec@1 78.125 (78.125)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:59

 Epoch: 625	Training Loss 0.3871 	Training Prec@1 86.500 	Training Prec@5 99.512 	Validation Loss 0.6508 	Validation Prec@1 78.490 	Validation Prec@5 98.950 

lr: 0.0316712291499189
TRAINING - Epoch: [625][0/196]	Time 0.805 (0.805)	Data 0.099 (0.099)	Loss 0.4631 (0.4631)	Prec@1 84.766 (84.766)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [625][100/196]	Time 0.087 (0.095)	Data 0.000 (0.001)	Loss 0.3321 (0.3903)	Prec@1 87.891 (86.189)	Prec@5 100.000 (99.513)
EVALUATING - Epoch: [625][0/79]	Time 0.073 (0.073)	Data 0.050 (0.050)	Loss 0.6040 (0.6040)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:01

 Epoch: 626	Training Loss 0.3808 	Training Prec@1 86.628 	Training Prec@5 99.576 	Validation Loss 0.6230 	Validation Prec@1 79.850 	Validation Prec@5 98.940 

lr: 0.03152458458659076
TRAINING - Epoch: [626][0/196]	Time 0.777 (0.777)	Data 0.082 (0.082)	Loss 0.3721 (0.3721)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [626][100/196]	Time 0.079 (0.094)	Data 0.000 (0.001)	Loss 0.3802 (0.3815)	Prec@1 84.766 (86.259)	Prec@5 99.219 (99.594)
EVALUATING - Epoch: [626][0/79]	Time 0.074 (0.074)	Data 0.051 (0.051)	Loss 0.3967 (0.3967)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:38

 Epoch: 627	Training Loss 0.3801 	Training Prec@1 86.490 	Training Prec@5 99.606 	Validation Loss 0.5254 	Validation Prec@1 82.780 	Validation Prec@5 99.200 

lr: 0.031378123854271134
TRAINING - Epoch: [627][0/196]	Time 0.774 (0.774)	Data 0.090 (0.090)	Loss 0.3934 (0.3934)	Prec@1 85.547 (85.547)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [627][100/196]	Time 0.094 (0.092)	Data 0.000 (0.001)	Loss 0.3896 (0.3804)	Prec@1 85.547 (86.653)	Prec@5 99.219 (99.590)
EVALUATING - Epoch: [627][0/79]	Time 0.076 (0.076)	Data 0.055 (0.055)	Loss 0.3776 (0.3776)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:51

 Epoch: 628	Training Loss 0.3798 	Training Prec@1 86.630 	Training Prec@5 99.596 	Validation Loss 0.5029 	Validation Prec@1 83.700 	Validation Prec@5 99.250 

lr: 0.03123184841010216
TRAINING - Epoch: [628][0/196]	Time 0.728 (0.728)	Data 0.102 (0.102)	Loss 0.3051 (0.3051)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [628][100/196]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 0.3974 (0.3753)	Prec@1 87.891 (86.823)	Prec@5 100.000 (99.547)
EVALUATING - Epoch: [628][0/79]	Time 0.076 (0.076)	Data 0.054 (0.054)	Loss 0.4893 (0.4893)	Prec@1 82.812 (82.812)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:14

 Epoch: 629	Training Loss 0.3821 	Training Prec@1 86.518 	Training Prec@5 99.556 	Validation Loss 0.5837 	Validation Prec@1 81.280 	Validation Prec@5 99.060 

lr: 0.031085759709382498
TRAINING - Epoch: [629][0/196]	Time 0.783 (0.783)	Data 0.094 (0.094)	Loss 0.3374 (0.3374)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [629][100/196]	Time 0.042 (0.087)	Data 0.000 (0.001)	Loss 0.3351 (0.3711)	Prec@1 89.453 (86.908)	Prec@5 99.609 (99.633)
EVALUATING - Epoch: [629][0/79]	Time 0.088 (0.088)	Data 0.068 (0.068)	Loss 0.6860 (0.6860)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:37:37

 Epoch: 630	Training Loss 0.3716 	Training Prec@1 86.860 	Training Prec@5 99.626 	Validation Loss 0.5492 	Validation Prec@1 81.740 	Validation Prec@5 99.240 

lr: 0.030939859205552915
TRAINING - Epoch: [630][0/196]	Time 0.715 (0.715)	Data 0.088 (0.088)	Loss 0.3197 (0.3197)	Prec@1 85.938 (85.938)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [630][100/196]	Time 0.088 (0.092)	Data 0.000 (0.001)	Loss 0.4550 (0.3804)	Prec@1 82.812 (86.475)	Prec@5 100.000 (99.547)
EVALUATING - Epoch: [630][0/79]	Time 0.074 (0.074)	Data 0.056 (0.056)	Loss 0.4873 (0.4873)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:20

 Epoch: 631	Training Loss 0.3825 	Training Prec@1 86.514 	Training Prec@5 99.564 	Validation Loss 0.5673 	Validation Prec@1 80.870 	Validation Prec@5 99.300 

lr: 0.030794148350181783
TRAINING - Epoch: [631][0/196]	Time 0.784 (0.784)	Data 0.081 (0.081)	Loss 0.4019 (0.4019)	Prec@1 85.547 (85.547)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [631][100/196]	Time 0.087 (0.094)	Data 0.000 (0.001)	Loss 0.3803 (0.3822)	Prec@1 86.719 (86.390)	Prec@5 100.000 (99.536)
EVALUATING - Epoch: [631][0/79]	Time 0.085 (0.085)	Data 0.066 (0.066)	Loss 0.5876 (0.5876)	Prec@1 78.906 (78.906)	Prec@5 98.438 (98.438)
Time cost: 00:19	Time of Finish: 2024-03-31 19:48:59

 Epoch: 632	Training Loss 0.3859 	Training Prec@1 86.336 	Training Prec@5 99.538 	Validation Loss 0.6057 	Validation Prec@1 80.340 	Validation Prec@5 99.190 

lr: 0.030648628592950672
TRAINING - Epoch: [632][0/196]	Time 0.497 (0.497)	Data 0.089 (0.089)	Loss 0.2515 (0.2515)	Prec@1 91.016 (91.016)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [632][100/196]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.3249 (0.3724)	Prec@1 86.719 (86.993)	Prec@5 100.000 (99.586)
EVALUATING - Epoch: [632][0/79]	Time 0.082 (0.082)	Data 0.064 (0.064)	Loss 0.8287 (0.8287)	Prec@1 76.562 (76.562)	Prec@5 95.312 (95.312)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:44

 Epoch: 633	Training Loss 0.3778 	Training Prec@1 86.844 	Training Prec@5 99.568 	Validation Loss 0.7940 	Validation Prec@1 76.320 	Validation Prec@5 98.160 

lr: 0.030503301381639893
TRAINING - Epoch: [633][0/196]	Time 0.778 (0.778)	Data 0.079 (0.079)	Loss 0.4087 (0.4087)	Prec@1 85.547 (85.547)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [633][100/196]	Time 0.093 (0.084)	Data 0.000 (0.001)	Loss 0.4742 (0.3700)	Prec@1 84.375 (87.167)	Prec@5 98.828 (99.602)
EVALUATING - Epoch: [633][0/79]	Time 0.079 (0.079)	Data 0.061 (0.061)	Loss 0.4386 (0.4386)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:48

 Epoch: 634	Training Loss 0.3770 	Training Prec@1 86.868 	Training Prec@5 99.580 	Validation Loss 0.5423 	Validation Prec@1 81.760 	Validation Prec@5 98.950 

lr: 0.030358168162114164
TRAINING - Epoch: [634][0/196]	Time 0.770 (0.770)	Data 0.091 (0.091)	Loss 0.3284 (0.3284)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [634][100/196]	Time 0.082 (0.093)	Data 0.000 (0.001)	Loss 0.4360 (0.3706)	Prec@1 84.375 (87.071)	Prec@5 99.609 (99.667)
EVALUATING - Epoch: [634][0/79]	Time 0.082 (0.082)	Data 0.063 (0.063)	Loss 0.5852 (0.5852)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:26

 Epoch: 635	Training Loss 0.3816 	Training Prec@1 86.608 	Training Prec@5 99.628 	Validation Loss 0.5265 	Validation Prec@1 82.530 	Validation Prec@5 99.330 

lr: 0.03021323037830808
TRAINING - Epoch: [635][0/196]	Time 0.768 (0.768)	Data 0.091 (0.091)	Loss 0.4020 (0.4020)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [635][100/196]	Time 0.084 (0.094)	Data 0.000 (0.001)	Loss 0.3621 (0.3739)	Prec@1 87.500 (86.901)	Prec@5 98.828 (99.559)
EVALUATING - Epoch: [635][0/79]	Time 0.079 (0.079)	Data 0.060 (0.060)	Loss 0.4828 (0.4828)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:06

 Epoch: 636	Training Loss 0.3756 	Training Prec@1 86.840 	Training Prec@5 99.570 	Validation Loss 0.6425 	Validation Prec@1 79.410 	Validation Prec@5 98.740 

lr: 0.03006848947221194
TRAINING - Epoch: [636][0/196]	Time 0.804 (0.804)	Data 0.086 (0.086)	Loss 0.3333 (0.3333)	Prec@1 89.453 (89.453)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [636][100/196]	Time 0.083 (0.095)	Data 0.000 (0.001)	Loss 0.4152 (0.3770)	Prec@1 85.547 (86.572)	Prec@5 99.219 (99.621)
EVALUATING - Epoch: [636][0/79]	Time 0.076 (0.076)	Data 0.055 (0.055)	Loss 0.4770 (0.4770)	Prec@1 81.250 (81.250)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:49:56

 Epoch: 637	Training Loss 0.3782 	Training Prec@1 86.694 	Training Prec@5 99.576 	Validation Loss 0.6038 	Validation Prec@1 80.500 	Validation Prec@5 98.760 

lr: 0.02992394688385722
TRAINING - Epoch: [637][0/196]	Time 0.507 (0.507)	Data 0.090 (0.090)	Loss 0.3588 (0.3588)	Prec@1 88.672 (88.672)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [637][100/196]	Time 0.090 (0.082)	Data 0.000 (0.001)	Loss 0.3618 (0.3683)	Prec@1 86.719 (87.136)	Prec@5 99.219 (99.664)
EVALUATING - Epoch: [637][0/79]	Time 0.073 (0.073)	Data 0.049 (0.049)	Loss 0.5393 (0.5393)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:31

 Epoch: 638	Training Loss 0.3719 	Training Prec@1 86.882 	Training Prec@5 99.624 	Validation Loss 0.5890 	Validation Prec@1 81.220 	Validation Prec@5 99.030 

lr: 0.029779604051302366
TRAINING - Epoch: [638][0/196]	Time 0.754 (0.754)	Data 0.087 (0.087)	Loss 0.4423 (0.4423)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [638][100/196]	Time 0.093 (0.078)	Data 0.000 (0.001)	Loss 0.4238 (0.3796)	Prec@1 86.328 (86.529)	Prec@5 98.828 (99.578)
EVALUATING - Epoch: [638][0/79]	Time 0.085 (0.085)	Data 0.064 (0.064)	Loss 0.4961 (0.4961)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:00

 Epoch: 639	Training Loss 0.3788 	Training Prec@1 86.536 	Training Prec@5 99.604 	Validation Loss 0.5236 	Validation Prec@1 82.380 	Validation Prec@5 99.240 

lr: 0.02963546241061849
TRAINING - Epoch: [639][0/196]	Time 0.792 (0.792)	Data 0.111 (0.111)	Loss 0.3197 (0.3197)	Prec@1 87.109 (87.109)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [639][100/196]	Time 0.086 (0.095)	Data 0.000 (0.001)	Loss 0.3600 (0.3663)	Prec@1 88.281 (87.109)	Prec@5 100.000 (99.656)
EVALUATING - Epoch: [639][0/79]	Time 0.081 (0.081)	Data 0.058 (0.058)	Loss 0.4798 (0.4798)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:54

 Epoch: 640	Training Loss 0.3762 	Training Prec@1 86.676 	Training Prec@5 99.606 	Validation Loss 0.5724 	Validation Prec@1 80.890 	Validation Prec@5 99.150 

lr: 0.029491523395874936
TRAINING - Epoch: [640][0/196]	Time 0.823 (0.823)	Data 0.098 (0.098)	Loss 0.4555 (0.4555)	Prec@1 83.203 (83.203)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [640][100/196]	Time 0.087 (0.095)	Data 0.001 (0.001)	Loss 0.3850 (0.3660)	Prec@1 85.938 (87.129)	Prec@5 100.000 (99.629)
EVALUATING - Epoch: [640][0/79]	Time 0.077 (0.077)	Data 0.057 (0.057)	Loss 0.5547 (0.5547)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:23

 Epoch: 641	Training Loss 0.3728 	Training Prec@1 86.806 	Training Prec@5 99.606 	Validation Loss 0.6023 	Validation Prec@1 80.470 	Validation Prec@5 98.740 

lr: 0.0293477884391252
TRAINING - Epoch: [641][0/196]	Time 0.793 (0.793)	Data 0.098 (0.098)	Loss 0.4195 (0.4195)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [641][100/196]	Time 0.094 (0.095)	Data 0.000 (0.001)	Loss 0.3567 (0.3754)	Prec@1 86.719 (86.804)	Prec@5 100.000 (99.598)
EVALUATING - Epoch: [641][0/79]	Time 0.085 (0.085)	Data 0.063 (0.063)	Loss 0.4374 (0.4374)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:19	Time of Finish: 2024-03-31 19:50:03

 Epoch: 642	Training Loss 0.3754 	Training Prec@1 86.832 	Training Prec@5 99.606 	Validation Loss 0.5462 	Validation Prec@1 82.530 	Validation Prec@5 99.220 

lr: 0.029204258970392576
TRAINING - Epoch: [642][0/196]	Time 0.429 (0.429)	Data 0.078 (0.078)	Loss 0.4585 (0.4585)	Prec@1 85.156 (85.156)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [642][100/196]	Time 0.087 (0.082)	Data 0.000 (0.001)	Loss 0.3096 (0.3781)	Prec@1 89.062 (86.823)	Prec@5 100.000 (99.575)
EVALUATING - Epoch: [642][0/79]	Time 0.077 (0.077)	Data 0.058 (0.058)	Loss 0.4448 (0.4448)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:18

 Epoch: 643	Training Loss 0.3818 	Training Prec@1 86.594 	Training Prec@5 99.616 	Validation Loss 0.5027 	Validation Prec@1 82.990 	Validation Prec@5 99.210 

lr: 0.029060936417655947
TRAINING - Epoch: [643][0/196]	Time 0.785 (0.785)	Data 0.091 (0.091)	Loss 0.3653 (0.3653)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [643][100/196]	Time 0.073 (0.081)	Data 0.000 (0.001)	Loss 0.3554 (0.3770)	Prec@1 87.891 (86.494)	Prec@5 100.000 (99.563)
EVALUATING - Epoch: [643][0/79]	Time 0.074 (0.074)	Data 0.054 (0.054)	Loss 0.4992 (0.4992)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:53

 Epoch: 644	Training Loss 0.3741 	Training Prec@1 86.722 	Training Prec@5 99.600 	Validation Loss 0.5182 	Validation Prec@1 82.760 	Validation Prec@5 99.280 

lr: 0.028917822206835583
TRAINING - Epoch: [644][0/196]	Time 0.717 (0.717)	Data 0.081 (0.081)	Loss 0.2959 (0.2959)	Prec@1 90.625 (90.625)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [644][100/196]	Time 0.084 (0.093)	Data 0.000 (0.001)	Loss 0.3380 (0.3778)	Prec@1 86.328 (86.599)	Prec@5 100.000 (99.629)
EVALUATING - Epoch: [644][0/79]	Time 0.079 (0.079)	Data 0.058 (0.058)	Loss 0.7224 (0.7224)	Prec@1 76.562 (76.562)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:24

 Epoch: 645	Training Loss 0.3780 	Training Prec@1 86.654 	Training Prec@5 99.608 	Validation Loss 0.6706 	Validation Prec@1 78.930 	Validation Prec@5 98.820 

lr: 0.028774917761778963
TRAINING - Epoch: [645][0/196]	Time 0.770 (0.770)	Data 0.110 (0.110)	Loss 0.3731 (0.3731)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [645][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.2708 (0.3601)	Prec@1 91.406 (87.144)	Prec@5 100.000 (99.660)
EVALUATING - Epoch: [645][0/79]	Time 0.077 (0.077)	Data 0.059 (0.059)	Loss 0.4396 (0.4396)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:55

 Epoch: 646	Training Loss 0.3693 	Training Prec@1 86.910 	Training Prec@5 99.608 	Validation Loss 0.5221 	Validation Prec@1 82.550 	Validation Prec@5 99.290 

lr: 0.028632224504246573
TRAINING - Epoch: [646][0/196]	Time 0.832 (0.832)	Data 0.112 (0.112)	Loss 0.4302 (0.4302)	Prec@1 84.375 (84.375)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [646][100/196]	Time 0.089 (0.096)	Data 0.000 (0.001)	Loss 0.3635 (0.3698)	Prec@1 89.453 (86.947)	Prec@5 99.609 (99.656)
EVALUATING - Epoch: [646][0/79]	Time 0.075 (0.075)	Data 0.056 (0.056)	Loss 0.5283 (0.5283)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:49:40

 Epoch: 647	Training Loss 0.3726 	Training Prec@1 86.876 	Training Prec@5 99.574 	Validation Loss 0.6119 	Validation Prec@1 80.630 	Validation Prec@5 98.710 

lr: 0.028489743853897832
TRAINING - Epoch: [647][0/196]	Time 0.500 (0.500)	Data 0.089 (0.089)	Loss 0.4260 (0.4260)	Prec@1 85.938 (85.938)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [647][100/196]	Time 0.096 (0.085)	Data 0.000 (0.001)	Loss 0.3616 (0.3682)	Prec@1 88.281 (86.928)	Prec@5 100.000 (99.648)
EVALUATING - Epoch: [647][0/79]	Time 0.077 (0.077)	Data 0.058 (0.058)	Loss 0.5154 (0.5154)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:50

 Epoch: 648	Training Loss 0.3717 	Training Prec@1 86.712 	Training Prec@5 99.622 	Validation Loss 0.5046 	Validation Prec@1 83.010 	Validation Prec@5 99.370 

lr: 0.028347477228276886
TRAINING - Epoch: [648][0/196]	Time 0.784 (0.784)	Data 0.085 (0.085)	Loss 0.3622 (0.3622)	Prec@1 83.203 (83.203)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [648][100/196]	Time 0.089 (0.085)	Data 0.000 (0.001)	Loss 0.3745 (0.3616)	Prec@1 86.719 (87.357)	Prec@5 99.609 (99.640)
EVALUATING - Epoch: [648][0/79]	Time 0.075 (0.075)	Data 0.055 (0.055)	Loss 0.4137 (0.4137)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:05

 Epoch: 649	Training Loss 0.3689 	Training Prec@1 87.012 	Training Prec@5 99.620 	Validation Loss 0.5655 	Validation Prec@1 81.590 	Validation Prec@5 99.060 

lr: 0.028205426042798545
TRAINING - Epoch: [649][0/196]	Time 0.766 (0.766)	Data 0.082 (0.082)	Loss 0.4719 (0.4719)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [649][100/196]	Time 0.053 (0.094)	Data 0.000 (0.001)	Loss 0.3346 (0.3652)	Prec@1 87.500 (87.291)	Prec@5 100.000 (99.586)
EVALUATING - Epoch: [649][0/79]	Time 0.077 (0.077)	Data 0.053 (0.053)	Loss 0.5627 (0.5627)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:43

 Epoch: 650	Training Loss 0.3724 	Training Prec@1 87.090 	Training Prec@5 99.600 	Validation Loss 0.5669 	Validation Prec@1 81.180 	Validation Prec@5 99.020 

lr: 0.028063591710734245
TRAINING - Epoch: [650][0/196]	Time 0.833 (0.833)	Data 0.170 (0.170)	Loss 0.3299 (0.3299)	Prec@1 88.281 (88.281)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [650][100/196]	Time 0.090 (0.093)	Data 0.000 (0.002)	Loss 0.3390 (0.3616)	Prec@1 87.891 (87.047)	Prec@5 99.609 (99.675)
EVALUATING - Epoch: [650][0/79]	Time 0.073 (0.073)	Data 0.050 (0.050)	Loss 0.6282 (0.6282)	Prec@1 80.469 (80.469)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:37

 Epoch: 651	Training Loss 0.3618 	Training Prec@1 87.192 	Training Prec@5 99.652 	Validation Loss 0.6007 	Validation Prec@1 80.760 	Validation Prec@5 98.940 

lr: 0.02792197564319789
TRAINING - Epoch: [651][0/196]	Time 0.770 (0.770)	Data 0.092 (0.092)	Loss 0.3888 (0.3888)	Prec@1 86.719 (86.719)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [651][100/196]	Time 0.086 (0.094)	Data 0.000 (0.001)	Loss 0.3995 (0.3655)	Prec@1 87.109 (86.939)	Prec@5 99.609 (99.660)
EVALUATING - Epoch: [651][0/79]	Time 0.091 (0.091)	Data 0.074 (0.074)	Loss 0.4545 (0.4545)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:27

 Epoch: 652	Training Loss 0.3673 	Training Prec@1 86.988 	Training Prec@5 99.638 	Validation Loss 0.5415 	Validation Prec@1 82.500 	Validation Prec@5 99.080 

lr: 0.02778057924913187
TRAINING - Epoch: [652][0/196]	Time 0.357 (0.357)	Data 0.085 (0.085)	Loss 0.3641 (0.3641)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [652][100/196]	Time 0.091 (0.090)	Data 0.000 (0.001)	Loss 0.4023 (0.3686)	Prec@1 84.375 (86.742)	Prec@5 99.609 (99.594)
EVALUATING - Epoch: [652][0/79]	Time 0.075 (0.075)	Data 0.051 (0.051)	Loss 0.6889 (0.6889)	Prec@1 78.906 (78.906)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:36

 Epoch: 653	Training Loss 0.3681 	Training Prec@1 86.898 	Training Prec@5 99.560 	Validation Loss 0.6019 	Validation Prec@1 80.290 	Validation Prec@5 99.030 

lr: 0.027639403935293072
TRAINING - Epoch: [653][0/196]	Time 0.804 (0.804)	Data 0.083 (0.083)	Loss 0.4759 (0.4759)	Prec@1 82.422 (82.422)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [653][100/196]	Time 0.095 (0.084)	Data 0.000 (0.001)	Loss 0.3622 (0.3686)	Prec@1 88.672 (87.303)	Prec@5 99.609 (99.598)
EVALUATING - Epoch: [653][0/79]	Time 0.074 (0.074)	Data 0.053 (0.053)	Loss 0.4080 (0.4080)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:54

 Epoch: 654	Training Loss 0.3683 	Training Prec@1 87.146 	Training Prec@5 99.630 	Validation Loss 0.5070 	Validation Prec@1 83.390 	Validation Prec@5 99.310 

lr: 0.027498451106238806
TRAINING - Epoch: [654][0/196]	Time 0.784 (0.784)	Data 0.102 (0.102)	Loss 0.3210 (0.3210)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [654][100/196]	Time 0.056 (0.086)	Data 0.000 (0.001)	Loss 0.3823 (0.3628)	Prec@1 86.328 (87.295)	Prec@5 98.828 (99.590)
EVALUATING - Epoch: [654][0/79]	Time 0.071 (0.071)	Data 0.053 (0.053)	Loss 0.6313 (0.6313)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:34

 Epoch: 655	Training Loss 0.3662 	Training Prec@1 87.236 	Training Prec@5 99.580 	Validation Loss 0.5269 	Validation Prec@1 82.770 	Validation Prec@5 99.220 

lr: 0.027357722164312898
TRAINING - Epoch: [655][0/196]	Time 0.707 (0.707)	Data 0.079 (0.079)	Loss 0.3585 (0.3585)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [655][100/196]	Time 0.052 (0.092)	Data 0.000 (0.001)	Loss 0.3238 (0.3631)	Prec@1 88.672 (87.423)	Prec@5 100.000 (99.582)
EVALUATING - Epoch: [655][0/79]	Time 0.072 (0.072)	Data 0.049 (0.049)	Loss 0.4319 (0.4319)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:42:56

 Epoch: 656	Training Loss 0.3653 	Training Prec@1 87.244 	Training Prec@5 99.604 	Validation Loss 0.5396 	Validation Prec@1 82.300 	Validation Prec@5 99.280 

lr: 0.027217218509631713
TRAINING - Epoch: [656][0/196]	Time 0.769 (0.769)	Data 0.106 (0.106)	Loss 0.3401 (0.3401)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [656][100/196]	Time 0.083 (0.094)	Data 0.000 (0.001)	Loss 0.3108 (0.3556)	Prec@1 88.672 (87.562)	Prec@5 99.219 (99.664)
EVALUATING - Epoch: [656][0/79]	Time 0.092 (0.092)	Data 0.071 (0.071)	Loss 0.4600 (0.4600)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:59

 Epoch: 657	Training Loss 0.3612 	Training Prec@1 87.420 	Training Prec@5 99.630 	Validation Loss 0.5844 	Validation Prec@1 81.370 	Validation Prec@5 99.080 

lr: 0.027076941540070218
TRAINING - Epoch: [657][0/196]	Time 0.352 (0.352)	Data 0.083 (0.083)	Loss 0.3551 (0.3551)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [657][100/196]	Time 0.087 (0.089)	Data 0.000 (0.001)	Loss 0.3399 (0.3571)	Prec@1 86.328 (87.256)	Prec@5 99.609 (99.602)
EVALUATING - Epoch: [657][0/79]	Time 0.083 (0.083)	Data 0.063 (0.063)	Loss 0.3743 (0.3743)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:59

 Epoch: 658	Training Loss 0.3636 	Training Prec@1 87.054 	Training Prec@5 99.574 	Validation Loss 0.4962 	Validation Prec@1 83.550 	Validation Prec@5 99.410 

lr: 0.026936892651248094
TRAINING - Epoch: [658][0/196]	Time 0.755 (0.755)	Data 0.080 (0.080)	Loss 0.3223 (0.3223)	Prec@1 87.891 (87.891)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [658][100/196]	Time 0.094 (0.083)	Data 0.000 (0.001)	Loss 0.4302 (0.3536)	Prec@1 83.203 (87.631)	Prec@5 99.219 (99.675)
EVALUATING - Epoch: [658][0/79]	Time 0.072 (0.072)	Data 0.050 (0.050)	Loss 0.4709 (0.4709)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:23

 Epoch: 659	Training Loss 0.3586 	Training Prec@1 87.416 	Training Prec@5 99.664 	Validation Loss 0.5248 	Validation Prec@1 82.210 	Validation Prec@5 99.250 

lr: 0.026797073236515832
TRAINING - Epoch: [659][0/196]	Time 0.803 (0.803)	Data 0.107 (0.107)	Loss 0.3881 (0.3881)	Prec@1 86.719 (86.719)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [659][100/196]	Time 0.070 (0.088)	Data 0.000 (0.001)	Loss 0.3774 (0.3591)	Prec@1 87.500 (87.264)	Prec@5 99.609 (99.675)
EVALUATING - Epoch: [659][0/79]	Time 0.082 (0.082)	Data 0.062 (0.062)	Loss 0.4533 (0.4533)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:39

 Epoch: 660	Training Loss 0.3606 	Training Prec@1 87.266 	Training Prec@5 99.628 	Validation Loss 0.5438 	Validation Prec@1 81.840 	Validation Prec@5 99.030 

lr: 0.02665748468694088
TRAINING - Epoch: [660][0/196]	Time 0.762 (0.762)	Data 0.077 (0.077)	Loss 0.3518 (0.3518)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [660][100/196]	Time 0.096 (0.094)	Data 0.000 (0.001)	Loss 0.2726 (0.3634)	Prec@1 91.016 (87.369)	Prec@5 99.609 (99.551)
EVALUATING - Epoch: [660][0/79]	Time 0.080 (0.080)	Data 0.060 (0.060)	Loss 0.4077 (0.4077)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:15

 Epoch: 661	Training Loss 0.3609 	Training Prec@1 87.306 	Training Prec@5 99.606 	Validation Loss 0.5317 	Validation Prec@1 82.590 	Validation Prec@5 99.270 

lr: 0.026518128391293794
TRAINING - Epoch: [661][0/196]	Time 0.832 (0.832)	Data 0.102 (0.102)	Loss 0.3311 (0.3311)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [661][100/196]	Time 0.068 (0.094)	Data 0.000 (0.001)	Loss 0.3944 (0.3579)	Prec@1 86.719 (87.295)	Prec@5 99.609 (99.648)
EVALUATING - Epoch: [661][0/79]	Time 0.071 (0.071)	Data 0.048 (0.048)	Loss 0.4239 (0.4239)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:27

 Epoch: 662	Training Loss 0.3614 	Training Prec@1 87.146 	Training Prec@5 99.608 	Validation Loss 0.4952 	Validation Prec@1 83.530 	Validation Prec@5 99.240 

lr: 0.02637900573603447
TRAINING - Epoch: [662][0/196]	Time 0.478 (0.478)	Data 0.099 (0.099)	Loss 0.4283 (0.4283)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [662][100/196]	Time 0.093 (0.089)	Data 0.000 (0.001)	Loss 0.3597 (0.3652)	Prec@1 87.109 (87.210)	Prec@5 100.000 (99.633)
EVALUATING - Epoch: [662][0/79]	Time 0.078 (0.078)	Data 0.060 (0.060)	Loss 0.3902 (0.3902)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:14

 Epoch: 663	Training Loss 0.3604 	Training Prec@1 87.338 	Training Prec@5 99.640 	Validation Loss 0.5718 	Validation Prec@1 81.040 	Validation Prec@5 99.120 

lr: 0.026240118105298256
TRAINING - Epoch: [663][0/196]	Time 0.794 (0.794)	Data 0.098 (0.098)	Loss 0.3413 (0.3413)	Prec@1 87.500 (87.500)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [663][100/196]	Time 0.081 (0.080)	Data 0.000 (0.001)	Loss 0.3731 (0.3630)	Prec@1 84.766 (87.121)	Prec@5 99.609 (99.644)
EVALUATING - Epoch: [663][0/79]	Time 0.084 (0.084)	Data 0.065 (0.065)	Loss 0.4412 (0.4412)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:35

 Epoch: 664	Training Loss 0.3648 	Training Prec@1 87.094 	Training Prec@5 99.628 	Validation Loss 0.5489 	Validation Prec@1 81.990 	Validation Prec@5 99.110 

lr: 0.026101466880882274
TRAINING - Epoch: [664][0/196]	Time 0.802 (0.802)	Data 0.090 (0.090)	Loss 0.4830 (0.4830)	Prec@1 83.203 (83.203)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [664][100/196]	Time 0.041 (0.089)	Data 0.000 (0.001)	Loss 0.3838 (0.3623)	Prec@1 84.766 (87.465)	Prec@5 100.000 (99.667)
EVALUATING - Epoch: [664][0/79]	Time 0.086 (0.086)	Data 0.064 (0.064)	Loss 0.5370 (0.5370)	Prec@1 78.906 (78.906)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:26

 Epoch: 665	Training Loss 0.3625 	Training Prec@1 87.324 	Training Prec@5 99.660 	Validation Loss 0.5835 	Validation Prec@1 81.360 	Validation Prec@5 99.160 

lr: 0.025963053442231553
TRAINING - Epoch: [665][0/196]	Time 0.734 (0.734)	Data 0.103 (0.103)	Loss 0.4177 (0.4177)	Prec@1 84.766 (84.766)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [665][100/196]	Time 0.090 (0.092)	Data 0.000 (0.001)	Loss 0.4304 (0.3545)	Prec@1 83.203 (87.399)	Prec@5 99.609 (99.633)
EVALUATING - Epoch: [665][0/79]	Time 0.077 (0.077)	Data 0.057 (0.057)	Loss 0.5428 (0.5428)	Prec@1 79.688 (79.688)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:10

 Epoch: 666	Training Loss 0.3576 	Training Prec@1 87.450 	Training Prec@5 99.632 	Validation Loss 0.5634 	Validation Prec@1 80.820 	Validation Prec@5 99.280 

lr: 0.025824879166425514
TRAINING - Epoch: [666][0/196]	Time 0.818 (0.818)	Data 0.080 (0.080)	Loss 0.2806 (0.2806)	Prec@1 90.234 (90.234)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [666][100/196]	Time 0.094 (0.095)	Data 0.000 (0.001)	Loss 0.4143 (0.3495)	Prec@1 86.328 (87.713)	Prec@5 99.609 (99.675)
EVALUATING - Epoch: [666][0/79]	Time 0.075 (0.075)	Data 0.056 (0.056)	Loss 0.4590 (0.4590)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:19	Time of Finish: 2024-03-31 19:49:11

 Epoch: 667	Training Loss 0.3550 	Training Prec@1 87.510 	Training Prec@5 99.658 	Validation Loss 0.4830 	Validation Prec@1 83.850 	Validation Prec@5 99.390 

lr: 0.02568694542816404
TRAINING - Epoch: [667][0/196]	Time 0.522 (0.522)	Data 0.090 (0.090)	Loss 0.4338 (0.4338)	Prec@1 84.766 (84.766)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [667][100/196]	Time 0.089 (0.087)	Data 0.000 (0.001)	Loss 0.4571 (0.3571)	Prec@1 83.594 (87.465)	Prec@5 99.609 (99.671)
EVALUATING - Epoch: [667][0/79]	Time 0.077 (0.077)	Data 0.053 (0.053)	Loss 0.3928 (0.3928)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:58

 Epoch: 668	Training Loss 0.3604 	Training Prec@1 87.344 	Training Prec@5 99.652 	Validation Loss 0.5036 	Validation Prec@1 82.960 	Validation Prec@5 99.470 

lr: 0.02554925359975394
TRAINING - Epoch: [668][0/196]	Time 0.750 (0.750)	Data 0.094 (0.094)	Loss 0.3930 (0.3930)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [668][100/196]	Time 0.093 (0.083)	Data 0.000 (0.001)	Loss 0.4181 (0.3554)	Prec@1 86.719 (87.562)	Prec@5 99.219 (99.667)
EVALUATING - Epoch: [668][0/79]	Time 0.078 (0.078)	Data 0.062 (0.062)	Loss 0.4600 (0.4600)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:10

 Epoch: 669	Training Loss 0.3559 	Training Prec@1 87.446 	Training Prec@5 99.686 	Validation Loss 0.5061 	Validation Prec@1 82.940 	Validation Prec@5 99.430 

lr: 0.02541180505109524
TRAINING - Epoch: [669][0/196]	Time 0.780 (0.780)	Data 0.088 (0.088)	Loss 0.3749 (0.3749)	Prec@1 86.719 (86.719)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [669][100/196]	Time 0.027 (0.092)	Data 0.000 (0.001)	Loss 0.3838 (0.3544)	Prec@1 87.500 (87.276)	Prec@5 99.609 (99.687)
EVALUATING - Epoch: [669][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 0.4579 (0.4579)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:41

 Epoch: 670	Training Loss 0.3556 	Training Prec@1 87.378 	Training Prec@5 99.676 	Validation Loss 0.6332 	Validation Prec@1 79.540 	Validation Prec@5 99.160 

lr: 0.02527460114966757
TRAINING - Epoch: [670][0/196]	Time 0.829 (0.829)	Data 0.114 (0.114)	Loss 0.3748 (0.3748)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [670][100/196]	Time 0.094 (0.093)	Data 0.000 (0.001)	Loss 0.4347 (0.3533)	Prec@1 83.594 (87.500)	Prec@5 100.000 (99.625)
EVALUATING - Epoch: [670][0/79]	Time 0.077 (0.077)	Data 0.054 (0.054)	Loss 0.3951 (0.3951)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:16

 Epoch: 671	Training Loss 0.3570 	Training Prec@1 87.300 	Training Prec@5 99.642 	Validation Loss 0.4727 	Validation Prec@1 84.020 	Validation Prec@5 99.370 

lr: 0.02513764326051657
TRAINING - Epoch: [671][0/196]	Time 0.775 (0.775)	Data 0.105 (0.105)	Loss 0.3489 (0.3489)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [671][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.3435 (0.3500)	Prec@1 88.281 (87.666)	Prec@5 99.609 (99.691)
EVALUATING - Epoch: [671][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 0.5327 (0.5327)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:19	Time of Finish: 2024-03-31 19:48:49

 Epoch: 672	Training Loss 0.3538 	Training Prec@1 87.598 	Training Prec@5 99.678 	Validation Loss 0.5646 	Validation Prec@1 81.840 	Validation Prec@5 99.270 

lr: 0.025000932746240257
TRAINING - Epoch: [672][0/196]	Time 0.475 (0.475)	Data 0.086 (0.086)	Loss 0.4311 (0.4311)	Prec@1 85.547 (85.547)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [672][100/196]	Time 0.085 (0.080)	Data 0.000 (0.001)	Loss 0.3897 (0.3519)	Prec@1 86.719 (87.720)	Prec@5 99.219 (99.664)
EVALUATING - Epoch: [672][0/79]	Time 0.082 (0.082)	Data 0.062 (0.062)	Loss 0.3575 (0.3575)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:35

 Epoch: 673	Training Loss 0.3537 	Training Prec@1 87.618 	Training Prec@5 99.664 	Validation Loss 0.5394 	Validation Prec@1 82.540 	Validation Prec@5 99.240 

lr: 0.024864470966975586
TRAINING - Epoch: [673][0/196]	Time 0.809 (0.809)	Data 0.102 (0.102)	Loss 0.2797 (0.2797)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [673][100/196]	Time 0.090 (0.085)	Data 0.000 (0.001)	Loss 0.3909 (0.3496)	Prec@1 86.719 (87.573)	Prec@5 99.219 (99.636)
EVALUATING - Epoch: [673][0/79]	Time 0.083 (0.083)	Data 0.065 (0.065)	Loss 0.3643 (0.3643)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:09

 Epoch: 674	Training Loss 0.3550 	Training Prec@1 87.408 	Training Prec@5 99.630 	Validation Loss 0.4833 	Validation Prec@1 83.730 	Validation Prec@5 99.390 

lr: 0.02472825928038479
TRAINING - Epoch: [674][0/196]	Time 0.788 (0.788)	Data 0.081 (0.081)	Loss 0.3975 (0.3975)	Prec@1 87.109 (87.109)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [674][100/196]	Time 0.093 (0.095)	Data 0.000 (0.001)	Loss 0.3335 (0.3488)	Prec@1 89.062 (87.589)	Prec@5 100.000 (99.602)
EVALUATING - Epoch: [674][0/79]	Time 0.088 (0.088)	Data 0.066 (0.066)	Loss 0.4956 (0.4956)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:18

 Epoch: 675	Training Loss 0.3482 	Training Prec@1 87.580 	Training Prec@5 99.626 	Validation Loss 0.5782 	Validation Prec@1 80.670 	Validation Prec@5 99.250 

lr: 0.024592299041641886
TRAINING - Epoch: [675][0/196]	Time 0.737 (0.737)	Data 0.083 (0.083)	Loss 0.3967 (0.3967)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [675][100/196]	Time 0.080 (0.094)	Data 0.000 (0.001)	Loss 0.3156 (0.3525)	Prec@1 89.453 (87.465)	Prec@5 99.219 (99.698)
EVALUATING - Epoch: [675][0/79]	Time 0.080 (0.080)	Data 0.059 (0.059)	Loss 0.3235 (0.3235)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:26

 Epoch: 676	Training Loss 0.3535 	Training Prec@1 87.584 	Training Prec@5 99.678 	Validation Loss 0.5120 	Validation Prec@1 83.250 	Validation Prec@5 99.250 

lr: 0.024456591603419273
TRAINING - Epoch: [676][0/196]	Time 0.829 (0.829)	Data 0.089 (0.089)	Loss 0.3685 (0.3685)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [676][100/196]	Time 0.087 (0.095)	Data 0.000 (0.001)	Loss 0.3526 (0.3546)	Prec@1 87.109 (87.585)	Prec@5 100.000 (99.683)
EVALUATING - Epoch: [676][0/79]	Time 0.073 (0.073)	Data 0.053 (0.053)	Loss 0.4213 (0.4213)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:49:46

 Epoch: 677	Training Loss 0.3547 	Training Prec@1 87.570 	Training Prec@5 99.664 	Validation Loss 0.5366 	Validation Prec@1 82.430 	Validation Prec@5 99.380 

lr: 0.02432113831587426
TRAINING - Epoch: [677][0/196]	Time 0.465 (0.465)	Data 0.116 (0.116)	Loss 0.3251 (0.3251)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [677][100/196]	Time 0.081 (0.083)	Data 0.000 (0.001)	Loss 0.3556 (0.3556)	Prec@1 88.672 (87.523)	Prec@5 99.609 (99.664)
EVALUATING - Epoch: [677][0/79]	Time 0.073 (0.073)	Data 0.049 (0.049)	Loss 0.3507 (0.3507)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:00

 Epoch: 678	Training Loss 0.3528 	Training Prec@1 87.572 	Training Prec@5 99.654 	Validation Loss 0.4821 	Validation Prec@1 83.450 	Validation Prec@5 99.370 

lr: 0.024185940526635544
TRAINING - Epoch: [678][0/196]	Time 0.764 (0.764)	Data 0.095 (0.095)	Loss 0.3088 (0.3088)	Prec@1 89.062 (89.062)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [678][100/196]	Time 0.085 (0.080)	Data 0.000 (0.001)	Loss 0.3163 (0.3499)	Prec@1 89.062 (87.635)	Prec@5 99.219 (99.679)
EVALUATING - Epoch: [678][0/79]	Time 0.072 (0.072)	Data 0.052 (0.052)	Loss 0.4539 (0.4539)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:33

 Epoch: 679	Training Loss 0.3555 	Training Prec@1 87.478 	Training Prec@5 99.650 	Validation Loss 0.5597 	Validation Prec@1 81.950 	Validation Prec@5 99.180 

lr: 0.024050999580789916
TRAINING - Epoch: [679][0/196]	Time 0.823 (0.823)	Data 0.109 (0.109)	Loss 0.3377 (0.3377)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [679][100/196]	Time 0.083 (0.094)	Data 0.000 (0.001)	Loss 0.3838 (0.3488)	Prec@1 86.719 (87.693)	Prec@5 100.000 (99.636)
EVALUATING - Epoch: [679][0/79]	Time 0.086 (0.086)	Data 0.067 (0.067)	Loss 0.3816 (0.3816)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:33

 Epoch: 680	Training Loss 0.3525 	Training Prec@1 87.564 	Training Prec@5 99.656 	Validation Loss 0.5478 	Validation Prec@1 82.000 	Validation Prec@5 99.310 

lr: 0.023916316820868738
TRAINING - Epoch: [680][0/196]	Time 0.806 (0.806)	Data 0.107 (0.107)	Loss 0.3412 (0.3412)	Prec@1 87.891 (87.891)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [680][100/196]	Time 0.091 (0.091)	Data 0.000 (0.001)	Loss 0.2621 (0.3437)	Prec@1 89.453 (87.922)	Prec@5 100.000 (99.675)
EVALUATING - Epoch: [680][0/79]	Time 0.072 (0.072)	Data 0.052 (0.052)	Loss 0.4825 (0.4825)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:44

 Epoch: 681	Training Loss 0.3466 	Training Prec@1 87.828 	Training Prec@5 99.642 	Validation Loss 0.5798 	Validation Prec@1 80.700 	Validation Prec@5 99.210 

lr: 0.023781893586834784
TRAINING - Epoch: [681][0/196]	Time 0.815 (0.815)	Data 0.094 (0.094)	Loss 0.3487 (0.3487)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [681][100/196]	Time 0.081 (0.092)	Data 0.000 (0.001)	Loss 0.3636 (0.3553)	Prec@1 87.500 (87.492)	Prec@5 99.219 (99.617)
EVALUATING - Epoch: [681][0/79]	Time 0.083 (0.083)	Data 0.062 (0.062)	Loss 0.5139 (0.5139)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:18

 Epoch: 682	Training Loss 0.3504 	Training Prec@1 87.598 	Training Prec@5 99.652 	Validation Loss 0.5394 	Validation Prec@1 82.130 	Validation Prec@5 99.300 

lr: 0.023647731216068727
TRAINING - Epoch: [682][0/196]	Time 0.788 (0.788)	Data 0.104 (0.104)	Loss 0.3777 (0.3777)	Prec@1 83.594 (83.594)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [682][100/196]	Time 0.089 (0.085)	Data 0.000 (0.001)	Loss 0.3448 (0.3470)	Prec@1 87.109 (87.674)	Prec@5 99.609 (99.702)
EVALUATING - Epoch: [682][0/79]	Time 0.077 (0.077)	Data 0.057 (0.057)	Loss 0.4708 (0.4708)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:39

 Epoch: 683	Training Loss 0.3506 	Training Prec@1 87.572 	Training Prec@5 99.692 	Validation Loss 0.5076 	Validation Prec@1 83.000 	Validation Prec@5 99.340 

lr: 0.0235138310433559
TRAINING - Epoch: [683][0/196]	Time 0.789 (0.789)	Data 0.082 (0.082)	Loss 0.2808 (0.2808)	Prec@1 89.453 (89.453)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [683][100/196]	Time 0.058 (0.082)	Data 0.000 (0.001)	Loss 0.3085 (0.3476)	Prec@1 89.062 (87.573)	Prec@5 99.609 (99.702)
EVALUATING - Epoch: [683][0/79]	Time 0.084 (0.084)	Data 0.063 (0.063)	Loss 0.4857 (0.4857)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:12

 Epoch: 684	Training Loss 0.3518 	Training Prec@1 87.472 	Training Prec@5 99.662 	Validation Loss 0.6286 	Validation Prec@1 79.850 	Validation Prec@5 98.900 

lr: 0.023380194400873095
TRAINING - Epoch: [684][0/196]	Time 0.821 (0.821)	Data 0.111 (0.111)	Loss 0.3071 (0.3071)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [684][100/196]	Time 0.083 (0.095)	Data 0.000 (0.001)	Loss 0.3045 (0.3497)	Prec@1 90.234 (87.732)	Prec@5 99.609 (99.656)
EVALUATING - Epoch: [684][0/79]	Time 0.084 (0.084)	Data 0.065 (0.065)	Loss 0.4418 (0.4418)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:12

 Epoch: 685	Training Loss 0.3479 	Training Prec@1 87.710 	Training Prec@5 99.660 	Validation Loss 0.5522 	Validation Prec@1 81.740 	Validation Prec@5 99.280 

lr: 0.023246822618175126
TRAINING - Epoch: [685][0/196]	Time 0.824 (0.824)	Data 0.105 (0.105)	Loss 0.3322 (0.3322)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [685][100/196]	Time 0.085 (0.094)	Data 0.000 (0.001)	Loss 0.3433 (0.3465)	Prec@1 88.281 (87.836)	Prec@5 100.000 (99.675)
EVALUATING - Epoch: [685][0/79]	Time 0.079 (0.079)	Data 0.063 (0.063)	Loss 0.4274 (0.4274)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:12

 Epoch: 686	Training Loss 0.3453 	Training Prec@1 87.808 	Training Prec@5 99.684 	Validation Loss 0.5138 	Validation Prec@1 82.960 	Validation Prec@5 99.310 

lr: 0.023113717022181783
TRAINING - Epoch: [686][0/196]	Time 0.760 (0.760)	Data 0.080 (0.080)	Loss 0.3214 (0.3214)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [686][100/196]	Time 0.088 (0.093)	Data 0.000 (0.001)	Loss 0.3518 (0.3422)	Prec@1 87.500 (87.922)	Prec@5 100.000 (99.683)
EVALUATING - Epoch: [686][0/79]	Time 0.075 (0.075)	Data 0.054 (0.054)	Loss 0.4428 (0.4428)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:59

 Epoch: 687	Training Loss 0.3451 	Training Prec@1 87.864 	Training Prec@5 99.686 	Validation Loss 0.4808 	Validation Prec@1 83.580 	Validation Prec@5 99.400 

lr: 0.022980878937164516
TRAINING - Epoch: [687][0/196]	Time 0.644 (0.644)	Data 0.088 (0.088)	Loss 0.2941 (0.2941)	Prec@1 89.844 (89.844)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [687][100/196]	Time 0.086 (0.084)	Data 0.001 (0.001)	Loss 0.3927 (0.3425)	Prec@1 86.328 (87.991)	Prec@5 99.219 (99.691)
EVALUATING - Epoch: [687][0/79]	Time 0.073 (0.073)	Data 0.050 (0.050)	Loss 0.4062 (0.4062)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:37

 Epoch: 688	Training Loss 0.3452 	Training Prec@1 87.864 	Training Prec@5 99.662 	Validation Loss 0.5440 	Validation Prec@1 82.320 	Validation Prec@5 99.180 

lr: 0.022848309684733354
TRAINING - Epoch: [688][0/196]	Time 0.824 (0.824)	Data 0.097 (0.097)	Loss 0.3343 (0.3343)	Prec@1 87.109 (87.109)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [688][100/196]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.3557 (0.3429)	Prec@1 86.719 (87.798)	Prec@5 100.000 (99.710)
EVALUATING - Epoch: [688][0/79]	Time 0.085 (0.085)	Data 0.065 (0.065)	Loss 0.4235 (0.4235)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:14

 Epoch: 689	Training Loss 0.3456 	Training Prec@1 87.720 	Training Prec@5 99.680 	Validation Loss 0.4875 	Validation Prec@1 83.880 	Validation Prec@5 99.230 

lr: 0.02271601058382367
TRAINING - Epoch: [689][0/196]	Time 0.806 (0.806)	Data 0.100 (0.100)	Loss 0.3150 (0.3150)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [689][100/196]	Time 0.079 (0.094)	Data 0.000 (0.001)	Loss 0.3257 (0.3474)	Prec@1 87.891 (87.898)	Prec@5 100.000 (99.706)
EVALUATING - Epoch: [689][0/79]	Time 0.077 (0.077)	Data 0.054 (0.054)	Loss 0.5477 (0.5477)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:53

 Epoch: 690	Training Loss 0.3483 	Training Prec@1 87.850 	Training Prec@5 99.690 	Validation Loss 0.5489 	Validation Prec@1 81.630 	Validation Prec@5 99.130 

lr: 0.02258398295068306
TRAINING - Epoch: [690][0/196]	Time 0.751 (0.751)	Data 0.078 (0.078)	Loss 0.3809 (0.3809)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [690][100/196]	Time 0.088 (0.093)	Data 0.000 (0.001)	Loss 0.3305 (0.3466)	Prec@1 87.109 (87.755)	Prec@5 100.000 (99.671)
EVALUATING - Epoch: [690][0/79]	Time 0.075 (0.075)	Data 0.055 (0.055)	Loss 0.3191 (0.3191)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:24

 Epoch: 691	Training Loss 0.3434 	Training Prec@1 87.980 	Training Prec@5 99.636 	Validation Loss 0.4634 	Validation Prec@1 84.290 	Validation Prec@5 99.470 

lr: 0.0224522280988583
TRAINING - Epoch: [691][0/196]	Time 0.814 (0.814)	Data 0.097 (0.097)	Loss 0.3324 (0.3324)	Prec@1 89.062 (89.062)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [691][100/196]	Time 0.089 (0.094)	Data 0.000 (0.001)	Loss 0.4241 (0.3355)	Prec@1 84.375 (88.231)	Prec@5 99.609 (99.706)
EVALUATING - Epoch: [691][0/79]	Time 0.077 (0.077)	Data 0.056 (0.056)	Loss 0.4241 (0.4241)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:29

 Epoch: 692	Training Loss 0.3399 	Training Prec@1 88.022 	Training Prec@5 99.698 	Validation Loss 0.5485 	Validation Prec@1 82.420 	Validation Prec@5 99.170 

lr: 0.02232074733918232
TRAINING - Epoch: [692][0/196]	Time 0.735 (0.735)	Data 0.102 (0.102)	Loss 0.3483 (0.3483)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [692][100/196]	Time 0.089 (0.085)	Data 0.000 (0.001)	Loss 0.2342 (0.3350)	Prec@1 92.188 (88.266)	Prec@5 100.000 (99.710)
EVALUATING - Epoch: [692][0/79]	Time 0.070 (0.070)	Data 0.050 (0.050)	Loss 0.4520 (0.4520)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:18

 Epoch: 693	Training Loss 0.3446 	Training Prec@1 87.890 	Training Prec@5 99.704 	Validation Loss 0.4992 	Validation Prec@1 83.290 	Validation Prec@5 99.330 

lr: 0.022189541979761015
TRAINING - Epoch: [693][0/196]	Time 0.729 (0.729)	Data 0.086 (0.086)	Loss 0.3179 (0.3179)	Prec@1 91.016 (91.016)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [693][100/196]	Time 0.084 (0.085)	Data 0.000 (0.001)	Loss 0.3577 (0.3352)	Prec@1 89.062 (88.011)	Prec@5 100.000 (99.691)
EVALUATING - Epoch: [693][0/79]	Time 0.081 (0.081)	Data 0.062 (0.062)	Loss 0.4707 (0.4707)	Prec@1 85.938 (85.938)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:20

 Epoch: 694	Training Loss 0.3425 	Training Prec@1 87.836 	Training Prec@5 99.672 	Validation Loss 0.5552 	Validation Prec@1 82.140 	Validation Prec@5 99.060 

lr: 0.022058613325960336
TRAINING - Epoch: [694][0/196]	Time 0.734 (0.734)	Data 0.079 (0.079)	Loss 0.2832 (0.2832)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [694][100/196]	Time 0.085 (0.093)	Data 0.000 (0.001)	Loss 0.3342 (0.3397)	Prec@1 87.500 (87.833)	Prec@5 100.000 (99.741)
EVALUATING - Epoch: [694][0/79]	Time 0.080 (0.080)	Data 0.060 (0.060)	Loss 0.4114 (0.4114)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:34

 Epoch: 695	Training Loss 0.3433 	Training Prec@1 87.730 	Training Prec@5 99.708 	Validation Loss 0.4962 	Validation Prec@1 83.660 	Validation Prec@5 99.410 

lr: 0.021927962680393338
TRAINING - Epoch: [695][0/196]	Time 0.818 (0.818)	Data 0.084 (0.084)	Loss 0.2770 (0.2770)	Prec@1 90.625 (90.625)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [695][100/196]	Time 0.089 (0.093)	Data 0.000 (0.001)	Loss 0.3615 (0.3374)	Prec@1 87.500 (87.995)	Prec@5 100.000 (99.706)
EVALUATING - Epoch: [695][0/79]	Time 0.080 (0.080)	Data 0.061 (0.061)	Loss 0.4308 (0.4308)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:11

 Epoch: 696	Training Loss 0.3390 	Training Prec@1 88.000 	Training Prec@5 99.696 	Validation Loss 0.5033 	Validation Prec@1 82.870 	Validation Prec@5 99.230 

lr: 0.021797591342907065
TRAINING - Epoch: [696][0/196]	Time 0.814 (0.814)	Data 0.104 (0.104)	Loss 0.3310 (0.3310)	Prec@1 89.062 (89.062)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [696][100/196]	Time 0.087 (0.094)	Data 0.000 (0.001)	Loss 0.3746 (0.3351)	Prec@1 86.328 (88.208)	Prec@5 100.000 (99.675)
EVALUATING - Epoch: [696][0/79]	Time 0.075 (0.075)	Data 0.050 (0.050)	Loss 0.5274 (0.5274)	Prec@1 80.469 (80.469)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:48:27

 Epoch: 697	Training Loss 0.3352 	Training Prec@1 88.180 	Training Prec@5 99.678 	Validation Loss 0.5656 	Validation Prec@1 81.990 	Validation Prec@5 99.000 

lr: 0.021667500610569785
TRAINING - Epoch: [697][0/196]	Time 0.452 (0.452)	Data 0.103 (0.103)	Loss 0.3505 (0.3505)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [697][100/196]	Time 0.084 (0.081)	Data 0.000 (0.001)	Loss 0.3321 (0.3468)	Prec@1 87.891 (87.802)	Prec@5 100.000 (99.664)
EVALUATING - Epoch: [697][0/79]	Time 0.076 (0.076)	Data 0.057 (0.057)	Loss 0.5679 (0.5679)	Prec@1 79.688 (79.688)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:21

 Epoch: 698	Training Loss 0.3410 	Training Prec@1 88.054 	Training Prec@5 99.664 	Validation Loss 0.6408 	Validation Prec@1 79.600 	Validation Prec@5 98.730 

lr: 0.02153769177765799
TRAINING - Epoch: [698][0/196]	Time 0.760 (0.760)	Data 0.098 (0.098)	Loss 0.3342 (0.3342)	Prec@1 89.062 (89.062)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [698][100/196]	Time 0.094 (0.082)	Data 0.000 (0.001)	Loss 0.3209 (0.3285)	Prec@1 90.234 (88.506)	Prec@5 99.609 (99.718)
EVALUATING - Epoch: [698][0/79]	Time 0.086 (0.086)	Data 0.064 (0.064)	Loss 0.4794 (0.4794)	Prec@1 79.688 (79.688)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:15

 Epoch: 699	Training Loss 0.3359 	Training Prec@1 88.108 	Training Prec@5 99.684 	Validation Loss 0.5086 	Validation Prec@1 83.340 	Validation Prec@5 99.360 

lr: 0.021408166135643596
TRAINING - Epoch: [699][0/196]	Time 0.812 (0.812)	Data 0.096 (0.096)	Loss 0.2471 (0.2471)	Prec@1 91.016 (91.016)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [699][100/196]	Time 0.086 (0.095)	Data 0.000 (0.001)	Loss 0.2998 (0.3248)	Prec@1 89.844 (88.583)	Prec@5 99.609 (99.694)
EVALUATING - Epoch: [699][0/79]	Time 0.085 (0.085)	Data 0.066 (0.066)	Loss 0.3584 (0.3584)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:10

 Epoch: 700	Training Loss 0.3413 	Training Prec@1 88.108 	Training Prec@5 99.668 	Validation Loss 0.4997 	Validation Prec@1 83.840 	Validation Prec@5 99.350 

lr: 0.021278924973181
TRAINING - Epoch: [700][0/196]	Time 0.812 (0.812)	Data 0.120 (0.120)	Loss 0.3252 (0.3252)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [700][100/196]	Time 0.089 (0.094)	Data 0.000 (0.001)	Loss 0.3721 (0.3410)	Prec@1 87.891 (87.937)	Prec@5 100.000 (99.714)
EVALUATING - Epoch: [700][0/79]	Time 0.072 (0.072)	Data 0.051 (0.051)	Loss 0.4124 (0.4124)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:18

 Epoch: 701	Training Loss 0.3381 	Training Prec@1 88.114 	Training Prec@5 99.714 	Validation Loss 0.4663 	Validation Prec@1 84.210 	Validation Prec@5 99.360 

lr: 0.02114996957609427
TRAINING - Epoch: [701][0/196]	Time 0.802 (0.802)	Data 0.082 (0.082)	Loss 0.3161 (0.3161)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [701][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.3616 (0.3295)	Prec@1 89.062 (88.432)	Prec@5 100.000 (99.741)
EVALUATING - Epoch: [701][0/79]	Time 0.072 (0.072)	Data 0.053 (0.053)	Loss 0.4754 (0.4754)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:32

 Epoch: 702	Training Loss 0.3365 	Training Prec@1 88.232 	Training Prec@5 99.708 	Validation Loss 0.4816 	Validation Prec@1 83.810 	Validation Prec@5 99.250 

lr: 0.021021301227364442
TRAINING - Epoch: [702][0/196]	Time 0.673 (0.673)	Data 0.123 (0.123)	Loss 0.3404 (0.3404)	Prec@1 88.281 (88.281)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [702][100/196]	Time 0.088 (0.083)	Data 0.000 (0.001)	Loss 0.3082 (0.3315)	Prec@1 88.672 (88.478)	Prec@5 100.000 (99.718)
EVALUATING - Epoch: [702][0/79]	Time 0.073 (0.073)	Data 0.049 (0.049)	Loss 0.3881 (0.3881)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:04

 Epoch: 703	Training Loss 0.3331 	Training Prec@1 88.324 	Training Prec@5 99.716 	Validation Loss 0.4900 	Validation Prec@1 83.890 	Validation Prec@5 99.310 

lr: 0.020892921207116704
TRAINING - Epoch: [703][0/196]	Time 0.773 (0.773)	Data 0.092 (0.092)	Loss 0.3201 (0.3201)	Prec@1 89.453 (89.453)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [703][100/196]	Time 0.089 (0.078)	Data 0.000 (0.001)	Loss 0.3162 (0.3259)	Prec@1 90.234 (88.653)	Prec@5 99.609 (99.706)
EVALUATING - Epoch: [703][0/79]	Time 0.074 (0.074)	Data 0.053 (0.053)	Loss 0.3923 (0.3923)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:39:44

 Epoch: 704	Training Loss 0.3295 	Training Prec@1 88.474 	Training Prec@5 99.688 	Validation Loss 0.5170 	Validation Prec@1 83.460 	Validation Prec@5 99.190 

lr: 0.02076483079260762
TRAINING - Epoch: [704][0/196]	Time 0.769 (0.769)	Data 0.107 (0.107)	Loss 0.3010 (0.3010)	Prec@1 87.500 (87.500)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [704][100/196]	Time 0.093 (0.095)	Data 0.000 (0.001)	Loss 0.2905 (0.3344)	Prec@1 89.062 (88.107)	Prec@5 100.000 (99.764)
EVALUATING - Epoch: [704][0/79]	Time 0.077 (0.077)	Data 0.057 (0.057)	Loss 0.3693 (0.3693)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:33

 Epoch: 705	Training Loss 0.3357 	Training Prec@1 88.196 	Training Prec@5 99.736 	Validation Loss 0.4864 	Validation Prec@1 83.730 	Validation Prec@5 99.460 

lr: 0.02063703125821248
TRAINING - Epoch: [705][0/196]	Time 0.751 (0.751)	Data 0.083 (0.083)	Loss 0.3231 (0.3231)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [705][100/196]	Time 0.087 (0.093)	Data 0.000 (0.001)	Loss 0.2499 (0.3297)	Prec@1 91.797 (88.498)	Prec@5 100.000 (99.710)
EVALUATING - Epoch: [705][0/79]	Time 0.093 (0.093)	Data 0.061 (0.061)	Loss 0.3870 (0.3870)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:11

 Epoch: 706	Training Loss 0.3329 	Training Prec@1 88.262 	Training Prec@5 99.692 	Validation Loss 0.4707 	Validation Prec@1 84.450 	Validation Prec@5 99.380 

lr: 0.02050952387541258
TRAINING - Epoch: [706][0/196]	Time 0.819 (0.819)	Data 0.107 (0.107)	Loss 0.2725 (0.2725)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [706][100/196]	Time 0.071 (0.094)	Data 0.000 (0.001)	Loss 0.2718 (0.3266)	Prec@1 91.797 (88.343)	Prec@5 99.609 (99.710)
EVALUATING - Epoch: [706][0/79]	Time 0.077 (0.077)	Data 0.053 (0.053)	Loss 0.4596 (0.4596)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:28

 Epoch: 707	Training Loss 0.3304 	Training Prec@1 88.164 	Training Prec@5 99.696 	Validation Loss 0.5185 	Validation Prec@1 83.360 	Validation Prec@5 99.220 

lr: 0.020382309912782618
TRAINING - Epoch: [707][0/196]	Time 0.756 (0.756)	Data 0.101 (0.101)	Loss 0.3558 (0.3558)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [707][100/196]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.3909 (0.3288)	Prec@1 85.547 (88.212)	Prec@5 98.828 (99.706)
EVALUATING - Epoch: [707][0/79]	Time 0.082 (0.082)	Data 0.058 (0.058)	Loss 0.4235 (0.4235)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:26

 Epoch: 708	Training Loss 0.3319 	Training Prec@1 88.158 	Training Prec@5 99.730 	Validation Loss 0.4704 	Validation Prec@1 84.430 	Validation Prec@5 99.370 

lr: 0.020255390635978025
TRAINING - Epoch: [708][0/196]	Time 0.757 (0.757)	Data 0.083 (0.083)	Loss 0.3675 (0.3675)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [708][100/196]	Time 0.089 (0.080)	Data 0.000 (0.001)	Loss 0.3605 (0.3268)	Prec@1 86.328 (88.304)	Prec@5 100.000 (99.733)
EVALUATING - Epoch: [708][0/79]	Time 0.071 (0.071)	Data 0.050 (0.050)	Loss 0.4819 (0.4819)	Prec@1 81.250 (81.250)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:31

 Epoch: 709	Training Loss 0.3287 	Training Prec@1 88.276 	Training Prec@5 99.742 	Validation Loss 0.4804 	Validation Prec@1 83.980 	Validation Prec@5 99.430 

lr: 0.020128767307722378
TRAINING - Epoch: [709][0/196]	Time 0.818 (0.818)	Data 0.106 (0.106)	Loss 0.2842 (0.2842)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [709][100/196]	Time 0.092 (0.092)	Data 0.000 (0.001)	Loss 0.3179 (0.3228)	Prec@1 87.500 (88.776)	Prec@5 100.000 (99.714)
EVALUATING - Epoch: [709][0/79]	Time 0.077 (0.077)	Data 0.058 (0.058)	Loss 0.3746 (0.3746)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:51

 Epoch: 710	Training Loss 0.3271 	Training Prec@1 88.516 	Training Prec@5 99.656 	Validation Loss 0.5094 	Validation Prec@1 83.030 	Validation Prec@5 99.430 

lr: 0.02000244118779493
TRAINING - Epoch: [710][0/196]	Time 0.751 (0.751)	Data 0.102 (0.102)	Loss 0.3757 (0.3757)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [710][100/196]	Time 0.081 (0.092)	Data 0.000 (0.001)	Loss 0.3117 (0.3223)	Prec@1 90.234 (88.540)	Prec@5 99.609 (99.749)
EVALUATING - Epoch: [710][0/79]	Time 0.078 (0.078)	Data 0.059 (0.059)	Loss 0.4210 (0.4210)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:53

 Epoch: 711	Training Loss 0.3284 	Training Prec@1 88.340 	Training Prec@5 99.736 	Validation Loss 0.4988 	Validation Prec@1 83.390 	Validation Prec@5 99.390 

lr: 0.0198764135330179
TRAINING - Epoch: [711][0/196]	Time 0.812 (0.812)	Data 0.094 (0.094)	Loss 0.3485 (0.3485)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [711][100/196]	Time 0.089 (0.094)	Data 0.000 (0.001)	Loss 0.2701 (0.3298)	Prec@1 91.406 (88.393)	Prec@5 100.000 (99.698)
EVALUATING - Epoch: [711][0/79]	Time 0.079 (0.079)	Data 0.060 (0.060)	Loss 0.4539 (0.4539)	Prec@1 82.031 (82.031)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:35

 Epoch: 712	Training Loss 0.3304 	Training Prec@1 88.286 	Training Prec@5 99.700 	Validation Loss 0.5001 	Validation Prec@1 83.670 	Validation Prec@5 99.200 

lr: 0.019750685597244123
TRAINING - Epoch: [712][0/196]	Time 0.781 (0.781)	Data 0.102 (0.102)	Loss 0.3696 (0.3696)	Prec@1 87.500 (87.500)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [712][100/196]	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 0.3487 (0.3234)	Prec@1 86.328 (88.595)	Prec@5 99.609 (99.764)
EVALUATING - Epoch: [712][0/79]	Time 0.085 (0.085)	Data 0.062 (0.062)	Loss 0.3442 (0.3442)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:23

 Epoch: 713	Training Loss 0.3298 	Training Prec@1 88.342 	Training Prec@5 99.746 	Validation Loss 0.4990 	Validation Prec@1 83.540 	Validation Prec@5 99.270 

lr: 0.0196252586313445
TRAINING - Epoch: [713][0/196]	Time 0.775 (0.775)	Data 0.076 (0.076)	Loss 0.2902 (0.2902)	Prec@1 90.234 (90.234)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [713][100/196]	Time 0.026 (0.084)	Data 0.000 (0.001)	Loss 0.3363 (0.3259)	Prec@1 90.234 (88.274)	Prec@5 100.000 (99.683)
EVALUATING - Epoch: [713][0/79]	Time 0.092 (0.092)	Data 0.072 (0.072)	Loss 0.4811 (0.4811)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:00

 Epoch: 714	Training Loss 0.3227 	Training Prec@1 88.502 	Training Prec@5 99.680 	Validation Loss 0.5507 	Validation Prec@1 81.710 	Validation Prec@5 99.090 

lr: 0.01950013388319562
TRAINING - Epoch: [714][0/196]	Time 0.754 (0.754)	Data 0.095 (0.095)	Loss 0.3501 (0.3501)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [714][100/196]	Time 0.082 (0.094)	Data 0.000 (0.001)	Loss 0.3487 (0.3239)	Prec@1 88.672 (88.575)	Prec@5 100.000 (99.702)
EVALUATING - Epoch: [714][0/79]	Time 0.077 (0.077)	Data 0.058 (0.058)	Loss 0.3254 (0.3254)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:21

 Epoch: 715	Training Loss 0.3254 	Training Prec@1 88.574 	Training Prec@5 99.700 	Validation Loss 0.4503 	Validation Prec@1 84.950 	Validation Prec@5 99.400 

lr: 0.019375312597667265
TRAINING - Epoch: [715][0/196]	Time 0.716 (0.716)	Data 0.103 (0.103)	Loss 0.2307 (0.2307)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [715][100/196]	Time 0.088 (0.092)	Data 0.000 (0.001)	Loss 0.2865 (0.3199)	Prec@1 89.062 (88.970)	Prec@5 100.000 (99.687)
EVALUATING - Epoch: [715][0/79]	Time 0.082 (0.082)	Data 0.064 (0.064)	Loss 0.3096 (0.3096)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:46

 Epoch: 716	Training Loss 0.3253 	Training Prec@1 88.630 	Training Prec@5 99.718 	Validation Loss 0.4772 	Validation Prec@1 84.180 	Validation Prec@5 99.430 

lr: 0.01925079601661
TRAINING - Epoch: [716][0/196]	Time 0.477 (0.477)	Data 0.084 (0.084)	Loss 0.3459 (0.3459)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [716][100/196]	Time 0.102 (0.091)	Data 0.000 (0.001)	Loss 0.2558 (0.3346)	Prec@1 91.797 (88.103)	Prec@5 100.000 (99.745)
EVALUATING - Epoch: [716][0/79]	Time 0.075 (0.075)	Data 0.054 (0.054)	Loss 0.3666 (0.3666)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:12

 Epoch: 717	Training Loss 0.3288 	Training Prec@1 88.342 	Training Prec@5 99.744 	Validation Loss 0.4786 	Validation Prec@1 83.920 	Validation Prec@5 99.240 

lr: 0.019126585378842986
TRAINING - Epoch: [717][0/196]	Time 0.842 (0.842)	Data 0.110 (0.110)	Loss 0.2425 (0.2425)	Prec@1 91.797 (91.797)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [717][100/196]	Time 0.083 (0.086)	Data 0.000 (0.001)	Loss 0.3072 (0.3203)	Prec@1 88.672 (88.618)	Prec@5 99.609 (99.679)
EVALUATING - Epoch: [717][0/79]	Time 0.074 (0.074)	Data 0.053 (0.053)	Loss 0.5758 (0.5758)	Prec@1 76.562 (76.562)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:41

 Epoch: 718	Training Loss 0.3250 	Training Prec@1 88.466 	Training Prec@5 99.694 	Validation Loss 0.6029 	Validation Prec@1 80.380 	Validation Prec@5 98.900 

lr: 0.019002681920141488
TRAINING - Epoch: [718][0/196]	Time 0.811 (0.811)	Data 0.092 (0.092)	Loss 0.3266 (0.3266)	Prec@1 89.453 (89.453)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [718][100/196]	Time 0.026 (0.084)	Data 0.000 (0.001)	Loss 0.3089 (0.3238)	Prec@1 89.062 (88.660)	Prec@5 100.000 (99.710)
EVALUATING - Epoch: [718][0/79]	Time 0.077 (0.077)	Data 0.054 (0.054)	Loss 0.4102 (0.4102)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:02

 Epoch: 719	Training Loss 0.3205 	Training Prec@1 88.734 	Training Prec@5 99.732 	Validation Loss 0.4947 	Validation Prec@1 83.810 	Validation Prec@5 99.330 

lr: 0.01887908687322463
TRAINING - Epoch: [719][0/196]	Time 0.703 (0.703)	Data 0.085 (0.085)	Loss 0.3178 (0.3178)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [719][100/196]	Time 0.087 (0.092)	Data 0.000 (0.001)	Loss 0.2684 (0.3206)	Prec@1 91.797 (88.595)	Prec@5 99.609 (99.702)
EVALUATING - Epoch: [719][0/79]	Time 0.072 (0.072)	Data 0.051 (0.051)	Loss 0.4066 (0.4066)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:44

 Epoch: 720	Training Loss 0.3199 	Training Prec@1 88.666 	Training Prec@5 99.718 	Validation Loss 0.5151 	Validation Prec@1 83.530 	Validation Prec@5 99.250 

lr: 0.01875580146774315
TRAINING - Epoch: [720][0/196]	Time 0.784 (0.784)	Data 0.098 (0.098)	Loss 0.3097 (0.3097)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [720][100/196]	Time 0.089 (0.095)	Data 0.000 (0.001)	Loss 0.3307 (0.3215)	Prec@1 87.891 (88.637)	Prec@5 100.000 (99.745)
EVALUATING - Epoch: [720][0/79]	Time 0.082 (0.082)	Data 0.064 (0.064)	Loss 0.3110 (0.3110)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:59

 Epoch: 721	Training Loss 0.3179 	Training Prec@1 88.722 	Training Prec@5 99.750 	Validation Loss 0.4977 	Validation Prec@1 83.920 	Validation Prec@5 99.290 

lr: 0.018632826930267188
TRAINING - Epoch: [721][0/196]	Time 0.832 (0.832)	Data 0.094 (0.094)	Loss 0.2755 (0.2755)	Prec@1 89.844 (89.844)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [721][100/196]	Time 0.086 (0.094)	Data 0.000 (0.001)	Loss 0.3891 (0.3184)	Prec@1 84.766 (88.649)	Prec@5 100.000 (99.733)
EVALUATING - Epoch: [721][0/79]	Time 0.079 (0.079)	Data 0.055 (0.055)	Loss 0.4466 (0.4466)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:47:39

 Epoch: 722	Training Loss 0.3214 	Training Prec@1 88.622 	Training Prec@5 99.740 	Validation Loss 0.5337 	Validation Prec@1 82.690 	Validation Prec@5 99.340 

lr: 0.018510164484273974
TRAINING - Epoch: [722][0/196]	Time 0.769 (0.769)	Data 0.092 (0.092)	Loss 0.2641 (0.2641)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [722][100/196]	Time 0.087 (0.081)	Data 0.000 (0.001)	Loss 0.2899 (0.3169)	Prec@1 89.453 (88.734)	Prec@5 100.000 (99.691)
EVALUATING - Epoch: [722][0/79]	Time 0.081 (0.081)	Data 0.063 (0.063)	Loss 0.3754 (0.3754)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:19

 Epoch: 723	Training Loss 0.3204 	Training Prec@1 88.700 	Training Prec@5 99.712 	Validation Loss 0.4885 	Validation Prec@1 83.890 	Validation Prec@5 99.420 

lr: 0.018387815350135776
TRAINING - Epoch: [723][0/196]	Time 0.762 (0.762)	Data 0.082 (0.082)	Loss 0.3635 (0.3635)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
TRAINING - Epoch: [723][100/196]	Time 0.052 (0.086)	Data 0.000 (0.001)	Loss 0.4398 (0.3173)	Prec@1 82.031 (88.815)	Prec@5 99.609 (99.725)
EVALUATING - Epoch: [723][0/79]	Time 0.071 (0.071)	Data 0.049 (0.049)	Loss 0.4527 (0.4527)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:54

 Epoch: 724	Training Loss 0.3164 	Training Prec@1 88.802 	Training Prec@5 99.718 	Validation Loss 0.5356 	Validation Prec@1 82.680 	Validation Prec@5 99.150 

lr: 0.01826578074510774
TRAINING - Epoch: [724][0/196]	Time 0.814 (0.814)	Data 0.111 (0.111)	Loss 0.2771 (0.2771)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [724][100/196]	Time 0.066 (0.093)	Data 0.000 (0.001)	Loss 0.2962 (0.3116)	Prec@1 90.625 (89.078)	Prec@5 100.000 (99.729)
EVALUATING - Epoch: [724][0/79]	Time 0.079 (0.079)	Data 0.061 (0.061)	Loss 0.5486 (0.5486)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:16

 Epoch: 725	Training Loss 0.3172 	Training Prec@1 88.786 	Training Prec@5 99.732 	Validation Loss 0.4911 	Validation Prec@1 83.810 	Validation Prec@5 99.500 

lr: 0.018144061883315705
TRAINING - Epoch: [725][0/196]	Time 0.772 (0.772)	Data 0.089 (0.089)	Loss 0.2364 (0.2364)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [725][100/196]	Time 0.094 (0.094)	Data 0.000 (0.001)	Loss 0.2642 (0.3116)	Prec@1 91.016 (88.977)	Prec@5 100.000 (99.737)
EVALUATING - Epoch: [725][0/79]	Time 0.076 (0.076)	Data 0.061 (0.061)	Loss 0.4592 (0.4592)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:09

 Epoch: 726	Training Loss 0.3104 	Training Prec@1 88.992 	Training Prec@5 99.704 	Validation Loss 0.4920 	Validation Prec@1 84.040 	Validation Prec@5 99.270 

lr: 0.01802265997574421
TRAINING - Epoch: [726][0/196]	Time 0.330 (0.330)	Data 0.084 (0.084)	Loss 0.3271 (0.3271)	Prec@1 87.109 (87.109)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [726][100/196]	Time 0.086 (0.088)	Data 0.000 (0.001)	Loss 0.3955 (0.3181)	Prec@1 86.328 (88.858)	Prec@5 99.609 (99.733)
EVALUATING - Epoch: [726][0/79]	Time 0.072 (0.072)	Data 0.052 (0.052)	Loss 0.5764 (0.5764)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:44

 Epoch: 727	Training Loss 0.3160 	Training Prec@1 88.838 	Training Prec@5 99.724 	Validation Loss 0.5465 	Validation Prec@1 82.220 	Validation Prec@5 99.350 

lr: 0.017901576230224342
TRAINING - Epoch: [727][0/196]	Time 0.822 (0.822)	Data 0.085 (0.085)	Loss 0.2593 (0.2593)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [727][100/196]	Time 0.088 (0.084)	Data 0.000 (0.001)	Loss 0.2726 (0.3122)	Prec@1 90.234 (88.966)	Prec@5 99.609 (99.760)
EVALUATING - Epoch: [727][0/79]	Time 0.071 (0.071)	Data 0.049 (0.049)	Loss 0.4669 (0.4669)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:15

 Epoch: 728	Training Loss 0.3124 	Training Prec@1 88.926 	Training Prec@5 99.744 	Validation Loss 0.5493 	Validation Prec@1 82.540 	Validation Prec@5 99.140 

lr: 0.017780811851421864
TRAINING - Epoch: [728][0/196]	Time 0.781 (0.781)	Data 0.098 (0.098)	Loss 0.2582 (0.2582)	Prec@1 90.234 (90.234)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [728][100/196]	Time 0.053 (0.088)	Data 0.000 (0.001)	Loss 0.2740 (0.3135)	Prec@1 91.016 (88.900)	Prec@5 99.609 (99.772)
EVALUATING - Epoch: [728][0/79]	Time 0.083 (0.083)	Data 0.064 (0.064)	Loss 0.3745 (0.3745)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:19

 Epoch: 729	Training Loss 0.3110 	Training Prec@1 89.012 	Training Prec@5 99.754 	Validation Loss 0.4729 	Validation Prec@1 84.640 	Validation Prec@5 99.350 

lr: 0.017660368040825113
TRAINING - Epoch: [729][0/196]	Time 0.824 (0.824)	Data 0.102 (0.102)	Loss 0.2231 (0.2231)	Prec@1 94.141 (94.141)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [729][100/196]	Time 0.088 (0.094)	Data 0.000 (0.001)	Loss 0.3233 (0.3112)	Prec@1 89.453 (88.958)	Prec@5 100.000 (99.768)
EVALUATING - Epoch: [729][0/79]	Time 0.075 (0.075)	Data 0.052 (0.052)	Loss 0.4409 (0.4409)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:42

 Epoch: 730	Training Loss 0.3163 	Training Prec@1 88.826 	Training Prec@5 99.740 	Validation Loss 0.4517 	Validation Prec@1 85.060 	Validation Prec@5 99.490 

lr: 0.017540245996733077
TRAINING - Epoch: [730][0/196]	Time 0.811 (0.811)	Data 0.087 (0.087)	Loss 0.2549 (0.2549)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [730][100/196]	Time 0.084 (0.094)	Data 0.000 (0.001)	Loss 0.2958 (0.3028)	Prec@1 89.844 (89.264)	Prec@5 100.000 (99.764)
EVALUATING - Epoch: [730][0/79]	Time 0.082 (0.082)	Data 0.059 (0.059)	Loss 0.4903 (0.4903)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:47

 Epoch: 731	Training Loss 0.3117 	Training Prec@1 88.872 	Training Prec@5 99.760 	Validation Loss 0.5174 	Validation Prec@1 83.160 	Validation Prec@5 99.220 

lr: 0.017420446914243493
TRAINING - Epoch: [731][0/196]	Time 0.768 (0.768)	Data 0.081 (0.081)	Loss 0.2815 (0.2815)	Prec@1 89.844 (89.844)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [731][100/196]	Time 0.093 (0.095)	Data 0.000 (0.001)	Loss 0.3176 (0.3149)	Prec@1 89.844 (88.877)	Prec@5 100.000 (99.772)
EVALUATING - Epoch: [731][0/79]	Time 0.076 (0.076)	Data 0.054 (0.054)	Loss 0.4116 (0.4116)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:47:42

 Epoch: 732	Training Loss 0.3135 	Training Prec@1 88.930 	Training Prec@5 99.744 	Validation Loss 0.4684 	Validation Prec@1 84.340 	Validation Prec@5 99.550 

lr: 0.01730097198524094
TRAINING - Epoch: [732][0/196]	Time 0.757 (0.757)	Data 0.082 (0.082)	Loss 0.2683 (0.2683)	Prec@1 89.844 (89.844)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [732][100/196]	Time 0.087 (0.085)	Data 0.000 (0.001)	Loss 0.3677 (0.3043)	Prec@1 87.109 (89.221)	Prec@5 100.000 (99.807)
EVALUATING - Epoch: [732][0/79]	Time 0.076 (0.076)	Data 0.055 (0.055)	Loss 0.5347 (0.5347)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:42

 Epoch: 733	Training Loss 0.3094 	Training Prec@1 89.162 	Training Prec@5 99.784 	Validation Loss 0.4655 	Validation Prec@1 84.770 	Validation Prec@5 99.390 

lr: 0.017181822398384977
TRAINING - Epoch: [733][0/196]	Time 0.741 (0.741)	Data 0.113 (0.113)	Loss 0.2782 (0.2782)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [733][100/196]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.3966 (0.3058)	Prec@1 83.984 (89.062)	Prec@5 99.609 (99.764)
EVALUATING - Epoch: [733][0/79]	Time 0.076 (0.076)	Data 0.057 (0.057)	Loss 0.5111 (0.5111)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:57

 Epoch: 734	Training Loss 0.3101 	Training Prec@1 88.954 	Training Prec@5 99.742 	Validation Loss 0.4938 	Validation Prec@1 83.900 	Validation Prec@5 99.450 

lr: 0.017062999339098314
TRAINING - Epoch: [734][0/196]	Time 0.740 (0.740)	Data 0.091 (0.091)	Loss 0.2806 (0.2806)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [734][100/196]	Time 0.086 (0.094)	Data 0.000 (0.001)	Loss 0.3030 (0.3127)	Prec@1 89.844 (88.858)	Prec@5 99.609 (99.752)
EVALUATING - Epoch: [734][0/79]	Time 0.075 (0.075)	Data 0.054 (0.054)	Loss 0.4558 (0.4558)	Prec@1 83.594 (83.594)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:09

 Epoch: 735	Training Loss 0.3076 	Training Prec@1 89.156 	Training Prec@5 99.758 	Validation Loss 0.4865 	Validation Prec@1 84.710 	Validation Prec@5 99.420 

lr: 0.016944503989555094
TRAINING - Epoch: [735][0/196]	Time 0.738 (0.738)	Data 0.103 (0.103)	Loss 0.3781 (0.3781)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [735][100/196]	Time 0.086 (0.092)	Data 0.000 (0.001)	Loss 0.3462 (0.3126)	Prec@1 88.672 (88.989)	Prec@5 99.609 (99.799)
EVALUATING - Epoch: [735][0/79]	Time 0.083 (0.083)	Data 0.066 (0.066)	Loss 0.3463 (0.3463)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:33

 Epoch: 736	Training Loss 0.3115 	Training Prec@1 89.006 	Training Prec@5 99.760 	Validation Loss 0.4596 	Validation Prec@1 84.950 	Validation Prec@5 99.430 

lr: 0.016826337528668994
TRAINING - Epoch: [736][0/196]	Time 0.746 (0.746)	Data 0.089 (0.089)	Loss 0.2535 (0.2535)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [736][100/196]	Time 0.088 (0.093)	Data 0.000 (0.001)	Loss 0.3066 (0.3048)	Prec@1 90.625 (89.341)	Prec@5 99.609 (99.733)
EVALUATING - Epoch: [736][0/79]	Time 0.084 (0.084)	Data 0.066 (0.066)	Loss 0.3839 (0.3839)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:04

 Epoch: 737	Training Loss 0.3078 	Training Prec@1 89.146 	Training Prec@5 99.762 	Validation Loss 0.5037 	Validation Prec@1 83.690 	Validation Prec@5 99.220 

lr: 0.01670850113208158
TRAINING - Epoch: [737][0/196]	Time 0.741 (0.741)	Data 0.099 (0.099)	Loss 0.3437 (0.3437)	Prec@1 87.500 (87.500)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [737][100/196]	Time 0.082 (0.087)	Data 0.000 (0.001)	Loss 0.3845 (0.3122)	Prec@1 86.328 (88.885)	Prec@5 99.219 (99.795)
EVALUATING - Epoch: [737][0/79]	Time 0.077 (0.077)	Data 0.057 (0.057)	Loss 0.3874 (0.3874)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:14

 Epoch: 738	Training Loss 0.3167 	Training Prec@1 88.756 	Training Prec@5 99.734 	Validation Loss 0.4754 	Validation Prec@1 84.170 	Validation Prec@5 99.440 

lr: 0.016590995972150597
TRAINING - Epoch: [738][0/196]	Time 0.787 (0.787)	Data 0.088 (0.088)	Loss 0.2407 (0.2407)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [738][100/196]	Time 0.092 (0.084)	Data 0.000 (0.001)	Loss 0.3223 (0.3015)	Prec@1 87.109 (89.252)	Prec@5 100.000 (99.799)
EVALUATING - Epoch: [738][0/79]	Time 0.083 (0.083)	Data 0.064 (0.064)	Loss 0.3571 (0.3571)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:16

 Epoch: 739	Training Loss 0.3071 	Training Prec@1 89.084 	Training Prec@5 99.776 	Validation Loss 0.5077 	Validation Prec@1 83.710 	Validation Prec@5 99.390 

lr: 0.016473823217938357
TRAINING - Epoch: [739][0/196]	Time 0.798 (0.798)	Data 0.102 (0.102)	Loss 0.2650 (0.2650)	Prec@1 89.844 (89.844)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [739][100/196]	Time 0.088 (0.094)	Data 0.000 (0.001)	Loss 0.3321 (0.3115)	Prec@1 85.938 (88.858)	Prec@5 100.000 (99.776)
EVALUATING - Epoch: [739][0/79]	Time 0.076 (0.076)	Data 0.050 (0.050)	Loss 0.4385 (0.4385)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:10

 Epoch: 740	Training Loss 0.3095 	Training Prec@1 89.038 	Training Prec@5 99.756 	Validation Loss 0.5422 	Validation Prec@1 83.050 	Validation Prec@5 99.350 

lr: 0.01635698403520001
TRAINING - Epoch: [740][0/196]	Time 0.757 (0.757)	Data 0.089 (0.089)	Loss 0.3612 (0.3612)	Prec@1 85.938 (85.938)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [740][100/196]	Time 0.085 (0.094)	Data 0.000 (0.001)	Loss 0.3238 (0.3002)	Prec@1 91.016 (89.569)	Prec@5 99.609 (99.776)
EVALUATING - Epoch: [740][0/79]	Time 0.072 (0.072)	Data 0.052 (0.052)	Loss 0.5351 (0.5351)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:37

 Epoch: 741	Training Loss 0.3010 	Training Prec@1 89.372 	Training Prec@5 99.792 	Validation Loss 0.4829 	Validation Prec@1 84.240 	Validation Prec@5 99.320 

lr: 0.016240479586372016
TRAINING - Epoch: [741][0/196]	Time 0.729 (0.729)	Data 0.099 (0.099)	Loss 0.2505 (0.2505)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [741][100/196]	Time 0.083 (0.094)	Data 0.000 (0.001)	Loss 0.3513 (0.2990)	Prec@1 87.109 (89.252)	Prec@5 99.609 (99.756)
EVALUATING - Epoch: [741][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 0.4253 (0.4253)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:47:47

 Epoch: 742	Training Loss 0.3033 	Training Prec@1 89.186 	Training Prec@5 99.762 	Validation Loss 0.4891 	Validation Prec@1 84.140 	Validation Prec@5 99.250 

lr: 0.016124311030560494
TRAINING - Epoch: [742][0/196]	Time 0.752 (0.752)	Data 0.082 (0.082)	Loss 0.3130 (0.3130)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [742][100/196]	Time 0.089 (0.080)	Data 0.000 (0.001)	Loss 0.2674 (0.2999)	Prec@1 90.234 (89.496)	Prec@5 100.000 (99.749)
EVALUATING - Epoch: [742][0/79]	Time 0.077 (0.077)	Data 0.055 (0.055)	Loss 0.4343 (0.4343)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:35

 Epoch: 743	Training Loss 0.3024 	Training Prec@1 89.332 	Training Prec@5 99.738 	Validation Loss 0.4492 	Validation Prec@1 85.350 	Validation Prec@5 99.410 

lr: 0.01600847952352986
TRAINING - Epoch: [743][0/196]	Time 0.804 (0.804)	Data 0.081 (0.081)	Loss 0.2647 (0.2647)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [743][100/196]	Time 0.084 (0.086)	Data 0.000 (0.001)	Loss 0.3017 (0.3009)	Prec@1 89.062 (89.442)	Prec@5 99.609 (99.752)
EVALUATING - Epoch: [743][0/79]	Time 0.089 (0.089)	Data 0.068 (0.068)	Loss 0.4842 (0.4842)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:43

 Epoch: 744	Training Loss 0.3024 	Training Prec@1 89.290 	Training Prec@5 99.740 	Validation Loss 0.4788 	Validation Prec@1 84.380 	Validation Prec@5 99.490 

lr: 0.015892986217691155
TRAINING - Epoch: [744][0/196]	Time 0.774 (0.774)	Data 0.084 (0.084)	Loss 0.3593 (0.3593)	Prec@1 89.453 (89.453)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [744][100/196]	Time 0.086 (0.094)	Data 0.000 (0.001)	Loss 0.3268 (0.3085)	Prec@1 87.891 (89.209)	Prec@5 100.000 (99.718)
EVALUATING - Epoch: [744][0/79]	Time 0.077 (0.077)	Data 0.053 (0.053)	Loss 0.4504 (0.4504)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:35

 Epoch: 745	Training Loss 0.3054 	Training Prec@1 89.330 	Training Prec@5 99.730 	Validation Loss 0.4586 	Validation Prec@1 84.560 	Validation Prec@5 99.490 

lr: 0.01577783226209063
TRAINING - Epoch: [745][0/196]	Time 0.720 (0.720)	Data 0.081 (0.081)	Loss 0.3159 (0.3159)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [745][100/196]	Time 0.097 (0.094)	Data 0.000 (0.001)	Loss 0.2766 (0.2988)	Prec@1 89.062 (89.592)	Prec@5 100.000 (99.752)
EVALUATING - Epoch: [745][0/79]	Time 0.091 (0.091)	Data 0.073 (0.073)	Loss 0.4412 (0.4412)	Prec@1 87.500 (87.500)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:06

 Epoch: 746	Training Loss 0.3018 	Training Prec@1 89.424 	Training Prec@5 99.758 	Validation Loss 0.5217 	Validation Prec@1 83.120 	Validation Prec@5 99.160 

lr: 0.015663018802398423
TRAINING - Epoch: [746][0/196]	Time 0.763 (0.763)	Data 0.088 (0.088)	Loss 0.2858 (0.2858)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [746][100/196]	Time 0.085 (0.094)	Data 0.000 (0.001)	Loss 0.3281 (0.2994)	Prec@1 89.453 (89.418)	Prec@5 100.000 (99.799)
EVALUATING - Epoch: [746][0/79]	Time 0.076 (0.076)	Data 0.054 (0.054)	Loss 0.4377 (0.4377)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:16

 Epoch: 747	Training Loss 0.3036 	Training Prec@1 89.298 	Training Prec@5 99.770 	Validation Loss 0.4808 	Validation Prec@1 84.210 	Validation Prec@5 99.360 

lr: 0.015548546980896943
TRAINING - Epoch: [747][0/196]	Time 0.757 (0.757)	Data 0.087 (0.087)	Loss 0.2363 (0.2363)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [747][100/196]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.3868 (0.2945)	Prec@1 85.938 (89.600)	Prec@5 100.000 (99.787)
EVALUATING - Epoch: [747][0/79]	Time 0.082 (0.082)	Data 0.061 (0.061)	Loss 0.3712 (0.3712)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:11

 Epoch: 748	Training Loss 0.3010 	Training Prec@1 89.334 	Training Prec@5 99.744 	Validation Loss 0.4885 	Validation Prec@1 84.320 	Validation Prec@5 99.450 

lr: 0.015434417936469718
TRAINING - Epoch: [748][0/196]	Time 0.750 (0.750)	Data 0.098 (0.098)	Loss 0.3415 (0.3415)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [748][100/196]	Time 0.087 (0.085)	Data 0.000 (0.001)	Loss 0.2546 (0.2986)	Prec@1 91.016 (89.527)	Prec@5 99.609 (99.756)
EVALUATING - Epoch: [748][0/79]	Time 0.084 (0.084)	Data 0.064 (0.064)	Loss 0.3489 (0.3489)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:13

 Epoch: 749	Training Loss 0.2993 	Training Prec@1 89.468 	Training Prec@5 99.752 	Validation Loss 0.4378 	Validation Prec@1 85.420 	Validation Prec@5 99.400 

lr: 0.015320632804589928
TRAINING - Epoch: [749][0/196]	Time 0.804 (0.804)	Data 0.084 (0.084)	Loss 0.2094 (0.2094)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [749][100/196]	Time 0.083 (0.093)	Data 0.000 (0.001)	Loss 0.3111 (0.3007)	Prec@1 89.453 (89.283)	Prec@5 99.609 (99.768)
EVALUATING - Epoch: [749][0/79]	Time 0.075 (0.075)	Data 0.057 (0.057)	Loss 0.4793 (0.4793)	Prec@1 85.938 (85.938)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:37

 Epoch: 750	Training Loss 0.2995 	Training Prec@1 89.412 	Training Prec@5 99.760 	Validation Loss 0.4827 	Validation Prec@1 83.970 	Validation Prec@5 99.370 

lr: 0.01520719271730922
TRAINING - Epoch: [750][0/196]	Time 0.823 (0.823)	Data 0.095 (0.095)	Loss 0.3603 (0.3603)	Prec@1 86.328 (86.328)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [750][100/196]	Time 0.057 (0.094)	Data 0.000 (0.001)	Loss 0.3599 (0.3006)	Prec@1 85.938 (89.237)	Prec@5 100.000 (99.768)
EVALUATING - Epoch: [750][0/79]	Time 0.104 (0.104)	Data 0.073 (0.073)	Loss 0.4425 (0.4425)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:27

 Epoch: 751	Training Loss 0.2991 	Training Prec@1 89.402 	Training Prec@5 99.766 	Validation Loss 0.4462 	Validation Prec@1 85.650 	Validation Prec@5 99.430 

lr: 0.015094098803246324
TRAINING - Epoch: [751][0/196]	Time 0.779 (0.779)	Data 0.084 (0.084)	Loss 0.3321 (0.3321)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [751][100/196]	Time 0.092 (0.094)	Data 0.000 (0.001)	Loss 0.2260 (0.3026)	Prec@1 91.406 (89.225)	Prec@5 100.000 (99.745)
EVALUATING - Epoch: [751][0/79]	Time 0.073 (0.073)	Data 0.053 (0.053)	Loss 0.3279 (0.3279)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:03

 Epoch: 752	Training Loss 0.3010 	Training Prec@1 89.370 	Training Prec@5 99.752 	Validation Loss 0.4521 	Validation Prec@1 85.360 	Validation Prec@5 99.350 

lr: 0.014981352187575916
TRAINING - Epoch: [752][0/196]	Time 0.796 (0.796)	Data 0.083 (0.083)	Loss 0.3383 (0.3383)	Prec@1 86.328 (86.328)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [752][100/196]	Time 0.089 (0.086)	Data 0.000 (0.001)	Loss 0.3079 (0.2938)	Prec@1 90.625 (89.585)	Prec@5 100.000 (99.810)
EVALUATING - Epoch: [752][0/79]	Time 0.080 (0.080)	Data 0.062 (0.062)	Loss 0.5696 (0.5696)	Prec@1 83.594 (83.594)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:33

 Epoch: 753	Training Loss 0.2999 	Training Prec@1 89.358 	Training Prec@5 99.802 	Validation Loss 0.5319 	Validation Prec@1 83.020 	Validation Prec@5 99.160 

lr: 0.01486895399201733
TRAINING - Epoch: [753][0/196]	Time 0.790 (0.790)	Data 0.115 (0.115)	Loss 0.2573 (0.2573)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [753][100/196]	Time 0.090 (0.084)	Data 0.000 (0.001)	Loss 0.2437 (0.2977)	Prec@1 92.188 (89.635)	Prec@5 99.219 (99.752)
EVALUATING - Epoch: [753][0/79]	Time 0.075 (0.075)	Data 0.055 (0.055)	Loss 0.5653 (0.5653)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:58

 Epoch: 754	Training Loss 0.2970 	Training Prec@1 89.532 	Training Prec@5 99.776 	Validation Loss 0.5516 	Validation Prec@1 82.770 	Validation Prec@5 99.190 

lr: 0.014756905334823548
TRAINING - Epoch: [754][0/196]	Time 0.801 (0.801)	Data 0.096 (0.096)	Loss 0.3408 (0.3408)	Prec@1 87.500 (87.500)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [754][100/196]	Time 0.087 (0.095)	Data 0.000 (0.001)	Loss 0.3448 (0.2972)	Prec@1 87.500 (89.360)	Prec@5 99.219 (99.818)
EVALUATING - Epoch: [754][0/79]	Time 0.072 (0.072)	Data 0.050 (0.050)	Loss 0.3969 (0.3969)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:34

 Epoch: 755	Training Loss 0.2996 	Training Prec@1 89.308 	Training Prec@5 99.804 	Validation Loss 0.4368 	Validation Prec@1 85.850 	Validation Prec@5 99.440 

lr: 0.014645207330769922
TRAINING - Epoch: [755][0/196]	Time 0.782 (0.782)	Data 0.080 (0.080)	Loss 0.2178 (0.2178)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [755][100/196]	Time 0.093 (0.095)	Data 0.000 (0.001)	Loss 0.2635 (0.2857)	Prec@1 90.625 (90.060)	Prec@5 100.000 (99.830)
EVALUATING - Epoch: [755][0/79]	Time 0.076 (0.076)	Data 0.058 (0.058)	Loss 0.4027 (0.4027)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:19

 Epoch: 756	Training Loss 0.2905 	Training Prec@1 89.852 	Training Prec@5 99.792 	Validation Loss 0.4552 	Validation Prec@1 84.990 	Validation Prec@5 99.410 

lr: 0.014533861091143152
TRAINING - Epoch: [756][0/196]	Time 0.749 (0.749)	Data 0.082 (0.082)	Loss 0.3291 (0.3291)	Prec@1 85.938 (85.938)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [756][100/196]	Time 0.088 (0.094)	Data 0.000 (0.001)	Loss 0.2915 (0.2945)	Prec@1 88.281 (89.503)	Prec@5 100.000 (99.783)
EVALUATING - Epoch: [756][0/79]	Time 0.089 (0.089)	Data 0.068 (0.068)	Loss 0.4925 (0.4925)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:47:09

 Epoch: 757	Training Loss 0.2939 	Training Prec@1 89.506 	Training Prec@5 99.792 	Validation Loss 0.4691 	Validation Prec@1 84.790 	Validation Prec@5 99.450 

lr: 0.014422867723730281
TRAINING - Epoch: [757][0/196]	Time 0.535 (0.535)	Data 0.107 (0.107)	Loss 0.3091 (0.3091)	Prec@1 87.891 (87.891)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [757][100/196]	Time 0.084 (0.085)	Data 0.000 (0.001)	Loss 0.2528 (0.2980)	Prec@1 90.234 (89.472)	Prec@5 100.000 (99.691)
EVALUATING - Epoch: [757][0/79]	Time 0.072 (0.072)	Data 0.053 (0.053)	Loss 0.3884 (0.3884)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:44

 Epoch: 758	Training Loss 0.2940 	Training Prec@1 89.614 	Training Prec@5 99.752 	Validation Loss 0.4578 	Validation Prec@1 85.040 	Validation Prec@5 99.440 

lr: 0.014312228332807521
TRAINING - Epoch: [758][0/196]	Time 0.800 (0.800)	Data 0.101 (0.101)	Loss 0.2598 (0.2598)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [758][100/196]	Time 0.096 (0.079)	Data 0.000 (0.001)	Loss 0.3012 (0.2957)	Prec@1 89.062 (89.585)	Prec@5 100.000 (99.749)
EVALUATING - Epoch: [758][0/79]	Time 0.078 (0.078)	Data 0.060 (0.060)	Loss 0.3831 (0.3831)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:22

 Epoch: 759	Training Loss 0.2923 	Training Prec@1 89.644 	Training Prec@5 99.762 	Validation Loss 0.4722 	Validation Prec@1 84.940 	Validation Prec@5 99.370 

lr: 0.014201944019129425
TRAINING - Epoch: [759][0/196]	Time 0.725 (0.725)	Data 0.083 (0.083)	Loss 0.2854 (0.2854)	Prec@1 89.844 (89.844)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [759][100/196]	Time 0.089 (0.093)	Data 0.000 (0.001)	Loss 0.2587 (0.2880)	Prec@1 90.625 (89.782)	Prec@5 100.000 (99.768)
EVALUATING - Epoch: [759][0/79]	Time 0.080 (0.080)	Data 0.064 (0.064)	Loss 0.3306 (0.3306)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:54

 Epoch: 760	Training Loss 0.2910 	Training Prec@1 89.712 	Training Prec@5 99.762 	Validation Loss 0.4657 	Validation Prec@1 84.860 	Validation Prec@5 99.400 

lr: 0.014092015879917843
TRAINING - Epoch: [760][0/196]	Time 0.765 (0.765)	Data 0.105 (0.105)	Loss 0.2769 (0.2769)	Prec@1 90.234 (90.234)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [760][100/196]	Time 0.092 (0.094)	Data 0.000 (0.001)	Loss 0.2392 (0.2881)	Prec@1 91.797 (89.755)	Prec@5 100.000 (99.822)
EVALUATING - Epoch: [760][0/79]	Time 0.086 (0.086)	Data 0.066 (0.066)	Loss 0.4038 (0.4038)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:36

 Epoch: 761	Training Loss 0.2913 	Training Prec@1 89.652 	Training Prec@5 99.798 	Validation Loss 0.4716 	Validation Prec@1 84.760 	Validation Prec@5 99.350 

lr: 0.013982445008851083
TRAINING - Epoch: [761][0/196]	Time 0.770 (0.770)	Data 0.094 (0.094)	Loss 0.2727 (0.2727)	Prec@1 90.234 (90.234)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [761][100/196]	Time 0.090 (0.092)	Data 0.000 (0.001)	Loss 0.2660 (0.2925)	Prec@1 91.016 (89.600)	Prec@5 100.000 (99.752)
EVALUATING - Epoch: [761][0/79]	Time 0.074 (0.074)	Data 0.054 (0.054)	Loss 0.5295 (0.5295)	Prec@1 81.250 (81.250)	Prec@5 97.656 (97.656)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:07

 Epoch: 762	Training Loss 0.2911 	Training Prec@1 89.682 	Training Prec@5 99.764 	Validation Loss 0.4492 	Validation Prec@1 85.790 	Validation Prec@5 99.320 

lr: 0.01387323249605295
TRAINING - Epoch: [762][0/196]	Time 0.429 (0.429)	Data 0.080 (0.080)	Loss 0.3119 (0.3119)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [762][100/196]	Time 0.096 (0.083)	Data 0.000 (0.001)	Loss 0.2784 (0.2853)	Prec@1 90.625 (89.573)	Prec@5 100.000 (99.822)
EVALUATING - Epoch: [762][0/79]	Time 0.084 (0.084)	Data 0.064 (0.064)	Loss 0.4356 (0.4356)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:53

 Epoch: 763	Training Loss 0.2887 	Training Prec@1 89.578 	Training Prec@5 99.768 	Validation Loss 0.4638 	Validation Prec@1 85.040 	Validation Prec@5 99.280 

lr: 0.013764379428081895
TRAINING - Epoch: [763][0/196]	Time 0.812 (0.812)	Data 0.092 (0.092)	Loss 0.2606 (0.2606)	Prec@1 91.016 (91.016)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [763][100/196]	Time 0.086 (0.079)	Data 0.000 (0.001)	Loss 0.2728 (0.2903)	Prec@1 87.891 (89.619)	Prec@5 100.000 (99.780)
EVALUATING - Epoch: [763][0/79]	Time 0.070 (0.070)	Data 0.050 (0.050)	Loss 0.4988 (0.4988)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:09

 Epoch: 764	Training Loss 0.2903 	Training Prec@1 89.666 	Training Prec@5 99.784 	Validation Loss 0.4993 	Validation Prec@1 83.500 	Validation Prec@5 99.370 

lr: 0.013655886887920275
TRAINING - Epoch: [764][0/196]	Time 0.806 (0.806)	Data 0.110 (0.110)	Loss 0.3019 (0.3019)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [764][100/196]	Time 0.089 (0.094)	Data 0.000 (0.001)	Loss 0.2732 (0.2797)	Prec@1 90.234 (89.917)	Prec@5 99.609 (99.807)
EVALUATING - Epoch: [764][0/79]	Time 0.078 (0.078)	Data 0.058 (0.058)	Loss 0.4326 (0.4326)	Prec@1 85.156 (85.156)	Prec@5 97.656 (97.656)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:05

 Epoch: 765	Training Loss 0.2858 	Training Prec@1 89.828 	Training Prec@5 99.800 	Validation Loss 0.4534 	Validation Prec@1 84.780 	Validation Prec@5 99.480 

lr: 0.013547755954963584
TRAINING - Epoch: [765][0/196]	Time 0.799 (0.799)	Data 0.089 (0.089)	Loss 0.1764 (0.1764)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [765][100/196]	Time 0.070 (0.094)	Data 0.000 (0.001)	Loss 0.2865 (0.2886)	Prec@1 89.062 (89.906)	Prec@5 100.000 (99.780)
EVALUATING - Epoch: [765][0/79]	Time 0.075 (0.075)	Data 0.050 (0.050)	Loss 0.3438 (0.3438)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:40

 Epoch: 766	Training Loss 0.2899 	Training Prec@1 89.758 	Training Prec@5 99.784 	Validation Loss 0.4365 	Validation Prec@1 85.550 	Validation Prec@5 99.470 

lr: 0.013439987705009624
TRAINING - Epoch: [766][0/196]	Time 0.748 (0.748)	Data 0.089 (0.089)	Loss 0.2915 (0.2915)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [766][100/196]	Time 0.087 (0.091)	Data 0.000 (0.001)	Loss 0.2250 (0.2799)	Prec@1 90.625 (89.995)	Prec@5 100.000 (99.776)
EVALUATING - Epoch: [766][0/79]	Time 0.079 (0.079)	Data 0.060 (0.060)	Loss 0.4133 (0.4133)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:44

 Epoch: 767	Training Loss 0.2850 	Training Prec@1 89.794 	Training Prec@5 99.786 	Validation Loss 0.4446 	Validation Prec@1 85.660 	Validation Prec@5 99.500 

lr: 0.013332583210247865
TRAINING - Epoch: [767][0/196]	Time 0.788 (0.788)	Data 0.099 (0.099)	Loss 0.2333 (0.2333)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [767][100/196]	Time 0.091 (0.081)	Data 0.000 (0.001)	Loss 0.3010 (0.2872)	Prec@1 89.453 (89.693)	Prec@5 99.609 (99.768)
EVALUATING - Epoch: [767][0/79]	Time 0.080 (0.080)	Data 0.060 (0.060)	Loss 0.4506 (0.4506)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:24

 Epoch: 768	Training Loss 0.2837 	Training Prec@1 89.884 	Training Prec@5 99.760 	Validation Loss 0.4712 	Validation Prec@1 84.510 	Validation Prec@5 99.540 

lr: 0.013225543539248766
TRAINING - Epoch: [768][0/196]	Time 0.819 (0.819)	Data 0.094 (0.094)	Loss 0.2767 (0.2767)	Prec@1 90.234 (90.234)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [768][100/196]	Time 0.040 (0.082)	Data 0.000 (0.001)	Loss 0.2638 (0.2807)	Prec@1 90.625 (89.824)	Prec@5 100.000 (99.807)
EVALUATING - Epoch: [768][0/79]	Time 0.075 (0.075)	Data 0.051 (0.051)	Loss 0.4210 (0.4210)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:38

 Epoch: 769	Training Loss 0.2834 	Training Prec@1 89.948 	Training Prec@5 99.786 	Validation Loss 0.4635 	Validation Prec@1 84.900 	Validation Prec@5 99.370 

lr: 0.01311886975695315
TRAINING - Epoch: [769][0/196]	Time 0.756 (0.756)	Data 0.084 (0.084)	Loss 0.2619 (0.2619)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [769][100/196]	Time 0.092 (0.093)	Data 0.000 (0.001)	Loss 0.2132 (0.2877)	Prec@1 91.797 (89.577)	Prec@5 99.609 (99.749)
EVALUATING - Epoch: [769][0/79]	Time 0.081 (0.081)	Data 0.054 (0.054)	Loss 0.4062 (0.4062)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:15

 Epoch: 770	Training Loss 0.2868 	Training Prec@1 89.816 	Training Prec@5 99.738 	Validation Loss 0.4570 	Validation Prec@1 85.050 	Validation Prec@5 99.430 

lr: 0.013012562924661599
TRAINING - Epoch: [770][0/196]	Time 0.793 (0.793)	Data 0.087 (0.087)	Loss 0.3168 (0.3168)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [770][100/196]	Time 0.090 (0.093)	Data 0.000 (0.001)	Loss 0.2554 (0.2787)	Prec@1 90.625 (89.964)	Prec@5 100.000 (99.787)
EVALUATING - Epoch: [770][0/79]	Time 0.079 (0.079)	Data 0.058 (0.058)	Loss 0.3855 (0.3855)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:21

 Epoch: 771	Training Loss 0.2847 	Training Prec@1 89.840 	Training Prec@5 99.774 	Validation Loss 0.4572 	Validation Prec@1 85.010 	Validation Prec@5 99.440 

lr: 0.01290662410002388
TRAINING - Epoch: [771][0/196]	Time 0.450 (0.450)	Data 0.083 (0.083)	Loss 0.2577 (0.2577)	Prec@1 91.797 (91.797)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [771][100/196]	Time 0.088 (0.091)	Data 0.000 (0.001)	Loss 0.2080 (0.2832)	Prec@1 92.578 (89.987)	Prec@5 100.000 (99.791)
EVALUATING - Epoch: [771][0/79]	Time 0.072 (0.072)	Data 0.051 (0.051)	Loss 0.4004 (0.4004)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:34

 Epoch: 772	Training Loss 0.2845 	Training Prec@1 89.914 	Training Prec@5 99.804 	Validation Loss 0.4810 	Validation Prec@1 84.470 	Validation Prec@5 99.390 

lr: 0.012801054337028515
TRAINING - Epoch: [772][0/196]	Time 0.793 (0.793)	Data 0.081 (0.081)	Loss 0.3242 (0.3242)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [772][100/196]	Time 0.084 (0.086)	Data 0.000 (0.001)	Loss 0.2440 (0.2861)	Prec@1 90.625 (89.886)	Prec@5 100.000 (99.791)
EVALUATING - Epoch: [772][0/79]	Time 0.083 (0.083)	Data 0.060 (0.060)	Loss 0.3293 (0.3293)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:11

 Epoch: 773	Training Loss 0.2860 	Training Prec@1 89.808 	Training Prec@5 99.778 	Validation Loss 0.4941 	Validation Prec@1 84.420 	Validation Prec@5 99.380 

lr: 0.01269585468599211
TRAINING - Epoch: [773][0/196]	Time 0.795 (0.795)	Data 0.090 (0.090)	Loss 0.3294 (0.3294)	Prec@1 89.453 (89.453)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [773][100/196]	Time 0.058 (0.086)	Data 0.000 (0.001)	Loss 0.3444 (0.2833)	Prec@1 87.891 (89.933)	Prec@5 99.609 (99.783)
EVALUATING - Epoch: [773][0/79]	Time 0.072 (0.072)	Data 0.052 (0.052)	Loss 0.3399 (0.3399)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:21

 Epoch: 774	Training Loss 0.2836 	Training Prec@1 89.952 	Training Prec@5 99.796 	Validation Loss 0.4227 	Validation Prec@1 86.190 	Validation Prec@5 99.470 

lr: 0.01259102619354909
TRAINING - Epoch: [774][0/196]	Time 0.808 (0.808)	Data 0.099 (0.099)	Loss 0.2897 (0.2897)	Prec@1 91.797 (91.797)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [774][100/196]	Time 0.083 (0.094)	Data 0.000 (0.001)	Loss 0.3113 (0.2755)	Prec@1 88.672 (90.377)	Prec@5 99.609 (99.768)
EVALUATING - Epoch: [774][0/79]	Time 0.079 (0.079)	Data 0.059 (0.059)	Loss 0.4132 (0.4132)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:02

 Epoch: 775	Training Loss 0.2818 	Training Prec@1 90.058 	Training Prec@5 99.782 	Validation Loss 0.4445 	Validation Prec@1 85.800 	Validation Prec@5 99.560 

lr: 0.012486569902641187
TRAINING - Epoch: [775][0/196]	Time 0.766 (0.766)	Data 0.092 (0.092)	Loss 0.2985 (0.2985)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [775][100/196]	Time 0.088 (0.094)	Data 0.000 (0.001)	Loss 0.2601 (0.2787)	Prec@1 92.188 (90.165)	Prec@5 99.609 (99.853)
EVALUATING - Epoch: [775][0/79]	Time 0.081 (0.081)	Data 0.058 (0.058)	Loss 0.4671 (0.4671)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:42

 Epoch: 776	Training Loss 0.2839 	Training Prec@1 89.932 	Training Prec@5 99.796 	Validation Loss 0.4622 	Validation Prec@1 85.250 	Validation Prec@5 99.250 

lr: 0.012382486852507119
TRAINING - Epoch: [776][0/196]	Time 0.432 (0.432)	Data 0.106 (0.106)	Loss 0.3001 (0.3001)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [776][100/196]	Time 0.090 (0.089)	Data 0.000 (0.001)	Loss 0.2629 (0.2736)	Prec@1 90.625 (90.207)	Prec@5 100.000 (99.822)
EVALUATING - Epoch: [776][0/79]	Time 0.079 (0.079)	Data 0.055 (0.055)	Loss 0.4299 (0.4299)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:47

 Epoch: 777	Training Loss 0.2807 	Training Prec@1 89.918 	Training Prec@5 99.820 	Validation Loss 0.4703 	Validation Prec@1 84.500 	Validation Prec@5 99.450 

lr: 0.012278778078672196
TRAINING - Epoch: [777][0/196]	Time 0.809 (0.809)	Data 0.085 (0.085)	Loss 0.2852 (0.2852)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [777][100/196]	Time 0.084 (0.082)	Data 0.000 (0.001)	Loss 0.3043 (0.2798)	Prec@1 91.016 (90.002)	Prec@5 99.609 (99.787)
EVALUATING - Epoch: [777][0/79]	Time 0.084 (0.084)	Data 0.059 (0.059)	Loss 0.4131 (0.4131)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:28

 Epoch: 778	Training Loss 0.2809 	Training Prec@1 90.044 	Training Prec@5 99.784 	Validation Loss 0.4731 	Validation Prec@1 84.540 	Validation Prec@5 99.380 

lr: 0.012175444612938005
TRAINING - Epoch: [778][0/196]	Time 0.811 (0.811)	Data 0.086 (0.086)	Loss 0.2809 (0.2809)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [778][100/196]	Time 0.057 (0.087)	Data 0.000 (0.001)	Loss 0.2307 (0.2850)	Prec@1 91.797 (89.786)	Prec@5 100.000 (99.830)
EVALUATING - Epoch: [778][0/79]	Time 0.087 (0.087)	Data 0.066 (0.066)	Loss 0.4735 (0.4735)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:08

 Epoch: 779	Training Loss 0.2799 	Training Prec@1 90.050 	Training Prec@5 99.838 	Validation Loss 0.4611 	Validation Prec@1 85.200 	Validation Prec@5 99.510 

lr: 0.012072487483372267
TRAINING - Epoch: [779][0/196]	Time 0.724 (0.724)	Data 0.092 (0.092)	Loss 0.3043 (0.3043)	Prec@1 90.234 (90.234)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [779][100/196]	Time 0.087 (0.093)	Data 0.000 (0.001)	Loss 0.3307 (0.2819)	Prec@1 87.500 (90.176)	Prec@5 99.609 (99.830)
EVALUATING - Epoch: [779][0/79]	Time 0.071 (0.071)	Data 0.053 (0.053)	Loss 0.3107 (0.3107)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:30

 Epoch: 780	Training Loss 0.2798 	Training Prec@1 90.124 	Training Prec@5 99.820 	Validation Loss 0.4421 	Validation Prec@1 85.920 	Validation Prec@5 99.490 

lr: 0.011969907714298456
TRAINING - Epoch: [780][0/196]	Time 0.798 (0.798)	Data 0.107 (0.107)	Loss 0.2441 (0.2441)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [780][100/196]	Time 0.097 (0.095)	Data 0.000 (0.001)	Loss 0.3308 (0.2795)	Prec@1 87.891 (89.987)	Prec@5 100.000 (99.869)
EVALUATING - Epoch: [780][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 0.3967 (0.3967)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:55

 Epoch: 781	Training Loss 0.2789 	Training Prec@1 89.938 	Training Prec@5 99.846 	Validation Loss 0.4433 	Validation Prec@1 85.750 	Validation Prec@5 99.370 

lr: 0.011867706326285695
TRAINING - Epoch: [781][0/196]	Time 0.448 (0.448)	Data 0.094 (0.094)	Loss 0.3629 (0.3629)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [781][100/196]	Time 0.096 (0.087)	Data 0.000 (0.001)	Loss 0.2327 (0.2761)	Prec@1 91.406 (90.300)	Prec@5 100.000 (99.749)
EVALUATING - Epoch: [781][0/79]	Time 0.075 (0.075)	Data 0.057 (0.057)	Loss 0.3507 (0.3507)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:28

 Epoch: 782	Training Loss 0.2793 	Training Prec@1 90.108 	Training Prec@5 99.768 	Validation Loss 0.4725 	Validation Prec@1 85.060 	Validation Prec@5 99.450 

lr: 0.01176588433613858
TRAINING - Epoch: [782][0/196]	Time 0.729 (0.729)	Data 0.082 (0.082)	Loss 0.2669 (0.2669)	Prec@1 92.578 (92.578)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [782][100/196]	Time 0.089 (0.081)	Data 0.000 (0.001)	Loss 0.2655 (0.2775)	Prec@1 91.016 (89.971)	Prec@5 100.000 (99.776)
EVALUATING - Epoch: [782][0/79]	Time 0.072 (0.072)	Data 0.050 (0.050)	Loss 0.3415 (0.3415)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:59

 Epoch: 783	Training Loss 0.2782 	Training Prec@1 90.022 	Training Prec@5 99.814 	Validation Loss 0.4688 	Validation Prec@1 84.810 	Validation Prec@5 99.510 

lr: 0.011664442756887113
TRAINING - Epoch: [783][0/196]	Time 0.764 (0.764)	Data 0.094 (0.094)	Loss 0.3384 (0.3384)	Prec@1 91.016 (91.016)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [783][100/196]	Time 0.048 (0.092)	Data 0.000 (0.001)	Loss 0.3072 (0.2751)	Prec@1 87.891 (90.172)	Prec@5 100.000 (99.888)
EVALUATING - Epoch: [783][0/79]	Time 0.073 (0.073)	Data 0.051 (0.051)	Loss 0.3264 (0.3264)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:32

 Epoch: 784	Training Loss 0.2793 	Training Prec@1 90.008 	Training Prec@5 99.828 	Validation Loss 0.4262 	Validation Prec@1 85.890 	Validation Prec@5 99.530 

lr: 0.01156338259777648
TRAINING - Epoch: [784][0/196]	Time 0.760 (0.760)	Data 0.083 (0.083)	Loss 0.2868 (0.2868)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [784][100/196]	Time 0.071 (0.094)	Data 0.000 (0.001)	Loss 0.3364 (0.2758)	Prec@1 88.281 (90.223)	Prec@5 100.000 (99.818)
EVALUATING - Epoch: [784][0/79]	Time 0.077 (0.077)	Data 0.054 (0.054)	Loss 0.3377 (0.3377)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:39

 Epoch: 785	Training Loss 0.2759 	Training Prec@1 90.234 	Training Prec@5 99.816 	Validation Loss 0.4435 	Validation Prec@1 85.520 	Validation Prec@5 99.490 

lr: 0.011462704864257192
TRAINING - Epoch: [785][0/196]	Time 0.785 (0.785)	Data 0.088 (0.088)	Loss 0.2470 (0.2470)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [785][100/196]	Time 0.088 (0.094)	Data 0.000 (0.001)	Loss 0.3257 (0.2772)	Prec@1 89.844 (90.060)	Prec@5 99.609 (99.795)
EVALUATING - Epoch: [785][0/79]	Time 0.078 (0.078)	Data 0.058 (0.058)	Loss 0.3885 (0.3885)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:28

 Epoch: 786	Training Loss 0.2742 	Training Prec@1 90.240 	Training Prec@5 99.782 	Validation Loss 0.4690 	Validation Prec@1 85.130 	Validation Prec@5 99.400 

lr: 0.011362410557974942
TRAINING - Epoch: [786][0/196]	Time 0.509 (0.509)	Data 0.094 (0.094)	Loss 0.2025 (0.2025)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [786][100/196]	Time 0.067 (0.087)	Data 0.000 (0.001)	Loss 0.2510 (0.2746)	Prec@1 91.016 (90.289)	Prec@5 99.609 (99.803)
EVALUATING - Epoch: [786][0/79]	Time 0.071 (0.071)	Data 0.050 (0.050)	Loss 0.4881 (0.4881)	Prec@1 84.375 (84.375)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:56

 Epoch: 787	Training Loss 0.2769 	Training Prec@1 90.148 	Training Prec@5 99.794 	Validation Loss 0.4705 	Validation Prec@1 84.980 	Validation Prec@5 99.420 

lr: 0.01126250067676075
TRAINING - Epoch: [787][0/196]	Time 0.764 (0.764)	Data 0.083 (0.083)	Loss 0.2298 (0.2298)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [787][100/196]	Time 0.095 (0.080)	Data 0.000 (0.001)	Loss 0.2473 (0.2755)	Prec@1 92.188 (90.172)	Prec@5 100.000 (99.799)
EVALUATING - Epoch: [787][0/79]	Time 0.070 (0.070)	Data 0.049 (0.049)	Loss 0.4258 (0.4258)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:18

 Epoch: 788	Training Loss 0.2762 	Training Prec@1 90.132 	Training Prec@5 99.808 	Validation Loss 0.4368 	Validation Prec@1 85.870 	Validation Prec@5 99.440 

lr: 0.011162976214620944
TRAINING - Epoch: [788][0/196]	Time 0.811 (0.811)	Data 0.100 (0.100)	Loss 0.3078 (0.3078)	Prec@1 89.453 (89.453)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [788][100/196]	Time 0.086 (0.093)	Data 0.000 (0.001)	Loss 0.2991 (0.2763)	Prec@1 88.672 (90.188)	Prec@5 99.609 (99.795)
EVALUATING - Epoch: [788][0/79]	Time 0.079 (0.079)	Data 0.060 (0.060)	Loss 0.4483 (0.4483)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:06

 Epoch: 789	Training Loss 0.2754 	Training Prec@1 90.218 	Training Prec@5 99.802 	Validation Loss 0.4478 	Validation Prec@1 85.720 	Validation Prec@5 99.470 

lr: 0.011063838161727277
TRAINING - Epoch: [789][0/196]	Time 0.800 (0.800)	Data 0.081 (0.081)	Loss 0.1872 (0.1872)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [789][100/196]	Time 0.090 (0.094)	Data 0.000 (0.001)	Loss 0.3169 (0.2700)	Prec@1 87.109 (90.540)	Prec@5 99.609 (99.814)
EVALUATING - Epoch: [789][0/79]	Time 0.082 (0.082)	Data 0.060 (0.060)	Loss 0.4223 (0.4223)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:27

 Epoch: 790	Training Loss 0.2733 	Training Prec@1 90.332 	Training Prec@5 99.816 	Validation Loss 0.4584 	Validation Prec@1 85.350 	Validation Prec@5 99.490 

lr: 0.010965087504407178
TRAINING - Epoch: [790][0/196]	Time 0.789 (0.789)	Data 0.082 (0.082)	Loss 0.3131 (0.3131)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [790][100/196]	Time 0.087 (0.095)	Data 0.000 (0.001)	Loss 0.2962 (0.2757)	Prec@1 91.016 (90.281)	Prec@5 100.000 (99.795)
EVALUATING - Epoch: [790][0/79]	Time 0.070 (0.070)	Data 0.050 (0.050)	Loss 0.5108 (0.5108)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:37

 Epoch: 791	Training Loss 0.2718 	Training Prec@1 90.384 	Training Prec@5 99.796 	Validation Loss 0.4768 	Validation Prec@1 84.600 	Validation Prec@5 99.440 

lr: 0.010866725225133805
TRAINING - Epoch: [791][0/196]	Time 0.484 (0.484)	Data 0.106 (0.106)	Loss 0.2545 (0.2545)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [791][100/196]	Time 0.084 (0.083)	Data 0.000 (0.001)	Loss 0.3668 (0.2694)	Prec@1 89.844 (90.405)	Prec@5 100.000 (99.795)
EVALUATING - Epoch: [791][0/79]	Time 0.076 (0.076)	Data 0.057 (0.057)	Loss 0.3949 (0.3949)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:02

 Epoch: 792	Training Loss 0.2697 	Training Prec@1 90.332 	Training Prec@5 99.838 	Validation Loss 0.4334 	Validation Prec@1 85.770 	Validation Prec@5 99.460 

lr: 0.010768752302516366
TRAINING - Epoch: [792][0/196]	Time 0.767 (0.767)	Data 0.082 (0.082)	Loss 0.3113 (0.3113)	Prec@1 89.453 (89.453)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [792][100/196]	Time 0.079 (0.080)	Data 0.000 (0.001)	Loss 0.2347 (0.2701)	Prec@1 92.969 (90.350)	Prec@5 99.609 (99.776)
EVALUATING - Epoch: [792][0/79]	Time 0.075 (0.075)	Data 0.053 (0.053)	Loss 0.3482 (0.3482)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:10

 Epoch: 793	Training Loss 0.2729 	Training Prec@1 90.302 	Training Prec@5 99.786 	Validation Loss 0.4323 	Validation Prec@1 85.710 	Validation Prec@5 99.520 

lr: 0.010671169711290323
TRAINING - Epoch: [793][0/196]	Time 0.776 (0.776)	Data 0.080 (0.080)	Loss 0.3120 (0.3120)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [793][100/196]	Time 0.087 (0.093)	Data 0.000 (0.001)	Loss 0.3223 (0.2699)	Prec@1 89.453 (90.455)	Prec@5 99.609 (99.845)
EVALUATING - Epoch: [793][0/79]	Time 0.076 (0.076)	Data 0.054 (0.054)	Loss 0.3269 (0.3269)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:07

 Epoch: 794	Training Loss 0.2698 	Training Prec@1 90.462 	Training Prec@5 99.816 	Validation Loss 0.4350 	Validation Prec@1 85.860 	Validation Prec@5 99.390 

lr: 0.010573978422307739
TRAINING - Epoch: [794][0/196]	Time 0.763 (0.763)	Data 0.102 (0.102)	Loss 0.2908 (0.2908)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [794][100/196]	Time 0.083 (0.096)	Data 0.000 (0.001)	Loss 0.1934 (0.2720)	Prec@1 92.188 (90.180)	Prec@5 100.000 (99.822)
EVALUATING - Epoch: [794][0/79]	Time 0.069 (0.069)	Data 0.051 (0.051)	Loss 0.3569 (0.3569)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:25

 Epoch: 795	Training Loss 0.2727 	Training Prec@1 90.280 	Training Prec@5 99.810 	Validation Loss 0.4998 	Validation Prec@1 84.240 	Validation Prec@5 99.430 

lr: 0.010477179402527596
TRAINING - Epoch: [795][0/196]	Time 0.742 (0.742)	Data 0.100 (0.100)	Loss 0.2136 (0.2136)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [795][100/196]	Time 0.087 (0.093)	Data 0.000 (0.001)	Loss 0.3008 (0.2724)	Prec@1 89.453 (90.374)	Prec@5 99.609 (99.756)
EVALUATING - Epoch: [795][0/79]	Time 0.080 (0.080)	Data 0.062 (0.062)	Loss 0.3941 (0.3941)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:21

 Epoch: 796	Training Loss 0.2712 	Training Prec@1 90.490 	Training Prec@5 99.786 	Validation Loss 0.4395 	Validation Prec@1 85.440 	Validation Prec@5 99.420 

lr: 0.010380773615006167
TRAINING - Epoch: [796][0/196]	Time 0.535 (0.535)	Data 0.106 (0.106)	Loss 0.2345 (0.2345)	Prec@1 90.234 (90.234)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [796][100/196]	Time 0.091 (0.084)	Data 0.000 (0.001)	Loss 0.1993 (0.2672)	Prec@1 92.188 (90.223)	Prec@5 100.000 (99.853)
EVALUATING - Epoch: [796][0/79]	Time 0.075 (0.075)	Data 0.056 (0.056)	Loss 0.4296 (0.4296)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:56

 Epoch: 797	Training Loss 0.2693 	Training Prec@1 90.332 	Training Prec@5 99.822 	Validation Loss 0.4608 	Validation Prec@1 85.250 	Validation Prec@5 99.500 

lr: 0.01028476201888745
TRAINING - Epoch: [797][0/196]	Time 0.788 (0.788)	Data 0.102 (0.102)	Loss 0.3142 (0.3142)	Prec@1 89.453 (89.453)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [797][100/196]	Time 0.094 (0.083)	Data 0.000 (0.001)	Loss 0.2796 (0.2696)	Prec@1 89.844 (90.405)	Prec@5 99.609 (99.783)
EVALUATING - Epoch: [797][0/79]	Time 0.084 (0.084)	Data 0.062 (0.062)	Loss 0.4265 (0.4265)	Prec@1 82.812 (82.812)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:32

 Epoch: 798	Training Loss 0.2706 	Training Prec@1 90.382 	Training Prec@5 99.810 	Validation Loss 0.4531 	Validation Prec@1 85.210 	Validation Prec@5 99.520 

lr: 0.010189145569393652
TRAINING - Epoch: [798][0/196]	Time 0.771 (0.771)	Data 0.102 (0.102)	Loss 0.2607 (0.2607)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [798][100/196]	Time 0.092 (0.094)	Data 0.000 (0.001)	Loss 0.2057 (0.2700)	Prec@1 94.531 (90.482)	Prec@5 100.000 (99.810)
EVALUATING - Epoch: [798][0/79]	Time 0.084 (0.084)	Data 0.066 (0.066)	Loss 0.4105 (0.4105)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:08

 Epoch: 799	Training Loss 0.2708 	Training Prec@1 90.356 	Training Prec@5 99.824 	Validation Loss 0.4425 	Validation Prec@1 85.420 	Validation Prec@5 99.460 

lr: 0.010093925217815599
TRAINING - Epoch: [799][0/196]	Time 0.764 (0.764)	Data 0.084 (0.084)	Loss 0.4295 (0.4295)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [799][100/196]	Time 0.089 (0.095)	Data 0.000 (0.001)	Loss 0.2463 (0.2696)	Prec@1 90.625 (90.455)	Prec@5 100.000 (99.845)
EVALUATING - Epoch: [799][0/79]	Time 0.079 (0.079)	Data 0.058 (0.058)	Loss 0.3596 (0.3596)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:12

 Epoch: 800	Training Loss 0.2661 	Training Prec@1 90.518 	Training Prec@5 99.860 	Validation Loss 0.4522 	Validation Prec@1 84.830 	Validation Prec@5 99.550 

lr: 0.009999101911503352
TRAINING - Epoch: [800][0/196]	Time 0.789 (0.789)	Data 0.096 (0.096)	Loss 0.2045 (0.2045)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [800][100/196]	Time 0.090 (0.094)	Data 0.000 (0.001)	Loss 0.2363 (0.2609)	Prec@1 92.188 (90.652)	Prec@5 100.000 (99.826)
EVALUATING - Epoch: [800][0/79]	Time 0.079 (0.079)	Data 0.059 (0.059)	Loss 0.4591 (0.4591)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:19	Time of Finish: 2024-03-31 19:46:40

 Epoch: 801	Training Loss 0.2680 	Training Prec@1 90.354 	Training Prec@5 99.838 	Validation Loss 0.4533 	Validation Prec@1 85.300 	Validation Prec@5 99.480 

lr: 0.009904676593856783
TRAINING - Epoch: [801][0/196]	Time 0.688 (0.688)	Data 0.091 (0.091)	Loss 0.2569 (0.2569)	Prec@1 90.625 (90.625)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [801][100/196]	Time 0.098 (0.086)	Data 0.000 (0.001)	Loss 0.3697 (0.2707)	Prec@1 87.500 (90.435)	Prec@5 100.000 (99.818)
EVALUATING - Epoch: [801][0/79]	Time 0.079 (0.079)	Data 0.057 (0.057)	Loss 0.3847 (0.3847)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:15

 Epoch: 802	Training Loss 0.2694 	Training Prec@1 90.358 	Training Prec@5 99.808 	Validation Loss 0.4298 	Validation Prec@1 86.010 	Validation Prec@5 99.550 

lr: 0.009810650204316132
TRAINING - Epoch: [802][0/196]	Time 0.800 (0.800)	Data 0.080 (0.080)	Loss 0.2878 (0.2878)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [802][100/196]	Time 0.082 (0.087)	Data 0.000 (0.001)	Loss 0.2912 (0.2677)	Prec@1 89.062 (90.629)	Prec@5 100.000 (99.783)
EVALUATING - Epoch: [802][0/79]	Time 0.075 (0.075)	Data 0.053 (0.053)	Loss 0.4003 (0.4003)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:19

 Epoch: 803	Training Loss 0.2670 	Training Prec@1 90.496 	Training Prec@5 99.826 	Validation Loss 0.4428 	Validation Prec@1 85.470 	Validation Prec@5 99.530 

lr: 0.00971702367835272
TRAINING - Epoch: [803][0/196]	Time 0.666 (0.666)	Data 0.095 (0.095)	Loss 0.2667 (0.2667)	Prec@1 89.453 (89.453)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [803][100/196]	Time 0.077 (0.092)	Data 0.000 (0.001)	Loss 0.2785 (0.2635)	Prec@1 90.234 (90.664)	Prec@5 100.000 (99.838)
EVALUATING - Epoch: [803][0/79]	Time 0.076 (0.076)	Data 0.057 (0.057)	Loss 0.4048 (0.4048)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:26

 Epoch: 804	Training Loss 0.2671 	Training Prec@1 90.570 	Training Prec@5 99.810 	Validation Loss 0.4398 	Validation Prec@1 86.210 	Validation Prec@5 99.400 

lr: 0.009623797947459541
TRAINING - Epoch: [804][0/196]	Time 0.796 (0.796)	Data 0.087 (0.087)	Loss 0.2082 (0.2082)	Prec@1 91.406 (91.406)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [804][100/196]	Time 0.091 (0.094)	Data 0.000 (0.001)	Loss 0.3409 (0.2646)	Prec@1 88.281 (90.644)	Prec@5 99.609 (99.838)
EVALUATING - Epoch: [804][0/79]	Time 0.074 (0.074)	Data 0.054 (0.054)	Loss 0.4468 (0.4468)	Prec@1 84.375 (84.375)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:05

 Epoch: 805	Training Loss 0.2659 	Training Prec@1 90.534 	Training Prec@5 99.818 	Validation Loss 0.4292 	Validation Prec@1 85.850 	Validation Prec@5 99.540 

lr: 0.009530973939142167
TRAINING - Epoch: [805][0/196]	Time 0.736 (0.736)	Data 0.103 (0.103)	Loss 0.2514 (0.2514)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [805][100/196]	Time 0.092 (0.092)	Data 0.000 (0.001)	Loss 0.3035 (0.2619)	Prec@1 89.844 (90.536)	Prec@5 100.000 (99.838)
EVALUATING - Epoch: [805][0/79]	Time 0.081 (0.081)	Data 0.062 (0.062)	Loss 0.4129 (0.4129)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:12

 Epoch: 806	Training Loss 0.2656 	Training Prec@1 90.492 	Training Prec@5 99.812 	Validation Loss 0.4762 	Validation Prec@1 84.630 	Validation Prec@5 99.360 

lr: 0.00943855257690936
TRAINING - Epoch: [806][0/196]	Time 0.540 (0.540)	Data 0.103 (0.103)	Loss 0.2317 (0.2317)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [806][100/196]	Time 0.086 (0.086)	Data 0.000 (0.001)	Loss 0.2471 (0.2630)	Prec@1 88.672 (90.714)	Prec@5 100.000 (99.799)
EVALUATING - Epoch: [806][0/79]	Time 0.080 (0.080)	Data 0.060 (0.060)	Loss 0.3550 (0.3550)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:46

 Epoch: 807	Training Loss 0.2632 	Training Prec@1 90.594 	Training Prec@5 99.824 	Validation Loss 0.4260 	Validation Prec@1 86.210 	Validation Prec@5 99.550 

lr: 0.00934653478026396
TRAINING - Epoch: [807][0/196]	Time 0.745 (0.745)	Data 0.081 (0.081)	Loss 0.2786 (0.2786)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [807][100/196]	Time 0.092 (0.083)	Data 0.000 (0.001)	Loss 0.2334 (0.2619)	Prec@1 91.797 (90.768)	Prec@5 99.609 (99.810)
EVALUATING - Epoch: [807][0/79]	Time 0.080 (0.080)	Data 0.061 (0.061)	Loss 0.3474 (0.3474)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:42

 Epoch: 808	Training Loss 0.2636 	Training Prec@1 90.542 	Training Prec@5 99.826 	Validation Loss 0.4251 	Validation Prec@1 86.030 	Validation Prec@5 99.560 

lr: 0.009254921464693701
TRAINING - Epoch: [808][0/196]	Time 0.764 (0.764)	Data 0.081 (0.081)	Loss 0.2472 (0.2472)	Prec@1 90.625 (90.625)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [808][100/196]	Time 0.056 (0.091)	Data 0.000 (0.001)	Loss 0.1706 (0.2695)	Prec@1 93.750 (90.590)	Prec@5 100.000 (99.803)
EVALUATING - Epoch: [808][0/79]	Time 0.077 (0.077)	Data 0.054 (0.054)	Loss 0.3491 (0.3491)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:11

 Epoch: 809	Training Loss 0.2661 	Training Prec@1 90.694 	Training Prec@5 99.830 	Validation Loss 0.4239 	Validation Prec@1 86.770 	Validation Prec@5 99.460 

lr: 0.009163713541662184
TRAINING - Epoch: [809][0/196]	Time 0.788 (0.788)	Data 0.096 (0.096)	Loss 0.2438 (0.2438)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [809][100/196]	Time 0.093 (0.094)	Data 0.000 (0.001)	Loss 0.2498 (0.2585)	Prec@1 90.625 (90.687)	Prec@5 99.609 (99.857)
EVALUATING - Epoch: [809][0/79]	Time 0.073 (0.073)	Data 0.050 (0.050)	Loss 0.4615 (0.4615)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:34

 Epoch: 810	Training Loss 0.2637 	Training Prec@1 90.502 	Training Prec@5 99.840 	Validation Loss 0.4762 	Validation Prec@1 84.740 	Validation Prec@5 99.470 

lr: 0.009072911918599665
TRAINING - Epoch: [810][0/196]	Time 0.802 (0.802)	Data 0.094 (0.094)	Loss 0.2207 (0.2207)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [810][100/196]	Time 0.097 (0.095)	Data 0.000 (0.001)	Loss 0.2413 (0.2743)	Prec@1 91.797 (90.377)	Prec@5 100.000 (99.780)
EVALUATING - Epoch: [810][0/79]	Time 0.096 (0.096)	Data 0.074 (0.074)	Loss 0.4421 (0.4421)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:46:10

 Epoch: 811	Training Loss 0.2657 	Training Prec@1 90.512 	Training Prec@5 99.812 	Validation Loss 0.4363 	Validation Prec@1 86.350 	Validation Prec@5 99.490 

lr: 0.008982517498894147
TRAINING - Epoch: [811][0/196]	Time 0.444 (0.444)	Data 0.102 (0.102)	Loss 0.2666 (0.2666)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [811][100/196]	Time 0.086 (0.089)	Data 0.000 (0.001)	Loss 0.1882 (0.2690)	Prec@1 93.750 (90.165)	Prec@5 100.000 (99.791)
EVALUATING - Epoch: [811][0/79]	Time 0.087 (0.087)	Data 0.064 (0.064)	Loss 0.3999 (0.3999)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:28

 Epoch: 812	Training Loss 0.2685 	Training Prec@1 90.304 	Training Prec@5 99.790 	Validation Loss 0.4297 	Validation Prec@1 85.740 	Validation Prec@5 99.580 

lr: 0.008892531181882386
TRAINING - Epoch: [812][0/196]	Time 0.815 (0.815)	Data 0.102 (0.102)	Loss 0.2970 (0.2970)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [812][100/196]	Time 0.086 (0.084)	Data 0.000 (0.001)	Loss 0.2642 (0.2642)	Prec@1 89.453 (90.815)	Prec@5 100.000 (99.853)
EVALUATING - Epoch: [812][0/79]	Time 0.078 (0.078)	Data 0.057 (0.057)	Loss 0.3012 (0.3012)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:08

 Epoch: 813	Training Loss 0.2605 	Training Prec@1 90.802 	Training Prec@5 99.846 	Validation Loss 0.4365 	Validation Prec@1 85.550 	Validation Prec@5 99.580 

lr: 0.008802953862840867
TRAINING - Epoch: [813][0/196]	Time 0.829 (0.829)	Data 0.106 (0.106)	Loss 0.2369 (0.2369)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [813][100/196]	Time 0.044 (0.087)	Data 0.000 (0.001)	Loss 0.2841 (0.2582)	Prec@1 90.625 (91.054)	Prec@5 100.000 (99.807)
EVALUATING - Epoch: [813][0/79]	Time 0.096 (0.096)	Data 0.076 (0.076)	Loss 0.3899 (0.3899)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:29

 Epoch: 814	Training Loss 0.2632 	Training Prec@1 90.714 	Training Prec@5 99.814 	Validation Loss 0.4571 	Validation Prec@1 85.480 	Validation Prec@5 99.410 

lr: 0.008713786432976975
TRAINING - Epoch: [814][0/196]	Time 0.733 (0.733)	Data 0.096 (0.096)	Loss 0.2086 (0.2086)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [814][100/196]	Time 0.086 (0.092)	Data 0.000 (0.001)	Loss 0.2146 (0.2543)	Prec@1 91.406 (91.101)	Prec@5 99.219 (99.791)
EVALUATING - Epoch: [814][0/79]	Time 0.089 (0.089)	Data 0.069 (0.069)	Loss 0.3455 (0.3455)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:17

 Epoch: 815	Training Loss 0.2624 	Training Prec@1 90.702 	Training Prec@5 99.790 	Validation Loss 0.4250 	Validation Prec@1 86.400 	Validation Prec@5 99.560 

lr: 0.008625029779420042
TRAINING - Epoch: [815][0/196]	Time 0.795 (0.795)	Data 0.101 (0.101)	Loss 0.3002 (0.3002)	Prec@1 87.891 (87.891)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [815][100/196]	Time 0.082 (0.093)	Data 0.000 (0.001)	Loss 0.2335 (0.2677)	Prec@1 92.578 (90.323)	Prec@5 100.000 (99.799)
EVALUATING - Epoch: [815][0/79]	Time 0.069 (0.069)	Data 0.049 (0.049)	Loss 0.2949 (0.2949)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:01

 Epoch: 816	Training Loss 0.2640 	Training Prec@1 90.644 	Training Prec@5 99.824 	Validation Loss 0.4388 	Validation Prec@1 85.890 	Validation Prec@5 99.580 

lr: 0.00853668478521265
TRAINING - Epoch: [816][0/196]	Time 0.512 (0.512)	Data 0.100 (0.100)	Loss 0.2558 (0.2558)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [816][100/196]	Time 0.083 (0.087)	Data 0.000 (0.001)	Loss 0.2418 (0.2624)	Prec@1 92.188 (90.617)	Prec@5 100.000 (99.845)
EVALUATING - Epoch: [816][0/79]	Time 0.078 (0.078)	Data 0.053 (0.053)	Loss 0.3917 (0.3917)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:46

 Epoch: 817	Training Loss 0.2614 	Training Prec@1 90.678 	Training Prec@5 99.836 	Validation Loss 0.4246 	Validation Prec@1 86.110 	Validation Prec@5 99.410 

lr: 0.008448752329301716
TRAINING - Epoch: [817][0/196]	Time 0.774 (0.774)	Data 0.080 (0.080)	Loss 0.3101 (0.3101)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [817][100/196]	Time 0.088 (0.082)	Data 0.000 (0.001)	Loss 0.2298 (0.2605)	Prec@1 91.797 (90.640)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [817][0/79]	Time 0.069 (0.069)	Data 0.050 (0.050)	Loss 0.3880 (0.3880)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:48

 Epoch: 818	Training Loss 0.2602 	Training Prec@1 90.658 	Training Prec@5 99.832 	Validation Loss 0.4267 	Validation Prec@1 85.960 	Validation Prec@5 99.600 

lr: 0.008361233286529822
TRAINING - Epoch: [818][0/196]	Time 0.759 (0.759)	Data 0.090 (0.090)	Loss 0.2461 (0.2461)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [818][100/196]	Time 0.053 (0.090)	Data 0.000 (0.001)	Loss 0.3187 (0.2576)	Prec@1 87.500 (90.517)	Prec@5 99.609 (99.830)
EVALUATING - Epoch: [818][0/79]	Time 0.070 (0.070)	Data 0.049 (0.049)	Loss 0.3902 (0.3902)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:49

 Epoch: 819	Training Loss 0.2603 	Training Prec@1 90.596 	Training Prec@5 99.810 	Validation Loss 0.4333 	Validation Prec@1 85.790 	Validation Prec@5 99.550 

lr: 0.008274128527626481
TRAINING - Epoch: [819][0/196]	Time 0.810 (0.810)	Data 0.097 (0.097)	Loss 0.2857 (0.2857)	Prec@1 88.281 (88.281)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [819][100/196]	Time 0.088 (0.093)	Data 0.000 (0.001)	Loss 0.2734 (0.2523)	Prec@1 89.844 (91.120)	Prec@5 100.000 (99.826)
EVALUATING - Epoch: [819][0/79]	Time 0.074 (0.074)	Data 0.054 (0.054)	Loss 0.4679 (0.4679)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:52

 Epoch: 820	Training Loss 0.2595 	Training Prec@1 90.806 	Training Prec@5 99.824 	Validation Loss 0.4242 	Validation Prec@1 86.220 	Validation Prec@5 99.490 

lr: 0.00818743891919949
TRAINING - Epoch: [820][0/196]	Time 0.802 (0.802)	Data 0.090 (0.090)	Loss 0.2723 (0.2723)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [820][100/196]	Time 0.088 (0.092)	Data 0.000 (0.001)	Loss 0.2175 (0.2537)	Prec@1 93.750 (91.023)	Prec@5 100.000 (99.880)
EVALUATING - Epoch: [820][0/79]	Time 0.074 (0.074)	Data 0.057 (0.057)	Loss 0.3294 (0.3294)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:36

 Epoch: 821	Training Loss 0.2558 	Training Prec@1 90.928 	Training Prec@5 99.864 	Validation Loss 0.4597 	Validation Prec@1 85.590 	Validation Prec@5 99.420 

lr: 0.008101165323726303
TRAINING - Epoch: [821][0/196]	Time 0.432 (0.432)	Data 0.103 (0.103)	Loss 0.1957 (0.1957)	Prec@1 92.969 (92.969)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [821][100/196]	Time 0.083 (0.084)	Data 0.000 (0.001)	Loss 0.2352 (0.2658)	Prec@1 92.578 (90.594)	Prec@5 100.000 (99.756)
EVALUATING - Epoch: [821][0/79]	Time 0.084 (0.084)	Data 0.066 (0.066)	Loss 0.3348 (0.3348)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:23

 Epoch: 822	Training Loss 0.2643 	Training Prec@1 90.560 	Training Prec@5 99.802 	Validation Loss 0.4297 	Validation Prec@1 86.350 	Validation Prec@5 99.580 

lr: 0.008015308599545438
TRAINING - Epoch: [822][0/196]	Time 0.843 (0.843)	Data 0.114 (0.114)	Loss 0.2479 (0.2479)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [822][100/196]	Time 0.091 (0.084)	Data 0.000 (0.001)	Loss 0.2393 (0.2624)	Prec@1 91.406 (90.934)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [822][0/79]	Time 0.076 (0.076)	Data 0.055 (0.055)	Loss 0.5405 (0.5405)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:49

 Epoch: 823	Training Loss 0.2593 	Training Prec@1 90.806 	Training Prec@5 99.842 	Validation Loss 0.4635 	Validation Prec@1 85.090 	Validation Prec@5 99.520 

lr: 0.007929869600847971
TRAINING - Epoch: [823][0/196]	Time 0.763 (0.763)	Data 0.095 (0.095)	Loss 0.2806 (0.2806)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [823][100/196]	Time 0.092 (0.093)	Data 0.000 (0.001)	Loss 0.2996 (0.2648)	Prec@1 87.500 (90.354)	Prec@5 100.000 (99.799)
EVALUATING - Epoch: [823][0/79]	Time 0.079 (0.079)	Data 0.057 (0.057)	Loss 0.4112 (0.4112)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:53

 Epoch: 824	Training Loss 0.2581 	Training Prec@1 90.654 	Training Prec@5 99.806 	Validation Loss 0.4596 	Validation Prec@1 85.280 	Validation Prec@5 99.460 

lr: 0.007844849177669004
TRAINING - Epoch: [824][0/196]	Time 0.840 (0.840)	Data 0.100 (0.100)	Loss 0.2771 (0.2771)	Prec@1 90.234 (90.234)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [824][100/196]	Time 0.087 (0.094)	Data 0.000 (0.001)	Loss 0.2042 (0.2607)	Prec@1 92.969 (90.629)	Prec@5 100.000 (99.853)
EVALUATING - Epoch: [824][0/79]	Time 0.085 (0.085)	Data 0.065 (0.065)	Loss 0.4592 (0.4592)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:02

 Epoch: 825	Training Loss 0.2581 	Training Prec@1 90.830 	Training Prec@5 99.810 	Validation Loss 0.4335 	Validation Prec@1 86.050 	Validation Prec@5 99.500 

lr: 0.007760248175879194
TRAINING - Epoch: [825][0/196]	Time 0.807 (0.807)	Data 0.106 (0.106)	Loss 0.1709 (0.1709)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [825][100/196]	Time 0.087 (0.093)	Data 0.000 (0.001)	Loss 0.2025 (0.2566)	Prec@1 93.750 (90.931)	Prec@5 100.000 (99.838)
EVALUATING - Epoch: [825][0/79]	Time 0.086 (0.086)	Data 0.065 (0.065)	Loss 0.4168 (0.4168)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:59

 Epoch: 826	Training Loss 0.2593 	Training Prec@1 90.772 	Training Prec@5 99.834 	Validation Loss 0.4342 	Validation Prec@1 86.050 	Validation Prec@5 99.480 

lr: 0.007676067437176386
TRAINING - Epoch: [826][0/196]	Time 0.654 (0.654)	Data 0.094 (0.094)	Loss 0.1812 (0.1812)	Prec@1 94.141 (94.141)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [826][100/196]	Time 0.093 (0.082)	Data 0.000 (0.001)	Loss 0.2797 (0.2543)	Prec@1 89.844 (90.842)	Prec@5 100.000 (99.807)
EVALUATING - Epoch: [826][0/79]	Time 0.076 (0.076)	Data 0.055 (0.055)	Loss 0.4030 (0.4030)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:30

 Epoch: 827	Training Loss 0.2606 	Training Prec@1 90.664 	Training Prec@5 99.832 	Validation Loss 0.4380 	Validation Prec@1 85.730 	Validation Prec@5 99.450 

lr: 0.007592307799077235
TRAINING - Epoch: [827][0/196]	Time 0.749 (0.749)	Data 0.085 (0.085)	Loss 0.2165 (0.2165)	Prec@1 92.188 (92.188)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [827][100/196]	Time 0.090 (0.083)	Data 0.000 (0.001)	Loss 0.2105 (0.2514)	Prec@1 93.359 (90.996)	Prec@5 99.219 (99.845)
EVALUATING - Epoch: [827][0/79]	Time 0.083 (0.083)	Data 0.061 (0.061)	Loss 0.4023 (0.4023)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:03

 Epoch: 828	Training Loss 0.2532 	Training Prec@1 91.008 	Training Prec@5 99.848 	Validation Loss 0.4314 	Validation Prec@1 85.780 	Validation Prec@5 99.550 

lr: 0.007508970094908814
TRAINING - Epoch: [828][0/196]	Time 0.765 (0.765)	Data 0.092 (0.092)	Loss 0.2602 (0.2602)	Prec@1 90.234 (90.234)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [828][100/196]	Time 0.085 (0.093)	Data 0.000 (0.001)	Loss 0.2032 (0.2581)	Prec@1 91.406 (90.942)	Prec@5 99.609 (99.795)
EVALUATING - Epoch: [828][0/79]	Time 0.079 (0.079)	Data 0.061 (0.061)	Loss 0.3446 (0.3446)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:40:30

 Epoch: 829	Training Loss 0.2583 	Training Prec@1 90.914 	Training Prec@5 99.818 	Validation Loss 0.4235 	Validation Prec@1 86.770 	Validation Prec@5 99.480 

lr: 0.0074260551538004
TRAINING - Epoch: [829][0/196]	Time 0.812 (0.812)	Data 0.094 (0.094)	Loss 0.2916 (0.2916)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [829][100/196]	Time 0.093 (0.094)	Data 0.000 (0.001)	Loss 0.3110 (0.2611)	Prec@1 88.281 (90.745)	Prec@5 99.609 (99.826)
EVALUATING - Epoch: [829][0/79]	Time 0.078 (0.078)	Data 0.058 (0.058)	Loss 0.2895 (0.2895)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:31

 Epoch: 830	Training Loss 0.2624 	Training Prec@1 90.660 	Training Prec@5 99.832 	Validation Loss 0.4209 	Validation Prec@1 86.220 	Validation Prec@5 99.510 

lr: 0.007343563800675132
TRAINING - Epoch: [830][0/196]	Time 0.776 (0.776)	Data 0.094 (0.094)	Loss 0.3442 (0.3442)	Prec@1 84.766 (84.766)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [830][100/196]	Time 0.074 (0.093)	Data 0.000 (0.001)	Loss 0.2199 (0.2527)	Prec@1 92.578 (90.787)	Prec@5 99.609 (99.834)
EVALUATING - Epoch: [830][0/79]	Time 0.081 (0.081)	Data 0.060 (0.060)	Loss 0.5148 (0.5148)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:46:06

 Epoch: 831	Training Loss 0.2568 	Training Prec@1 90.720 	Training Prec@5 99.850 	Validation Loss 0.4259 	Validation Prec@1 86.140 	Validation Prec@5 99.550 

lr: 0.007261496856241932
TRAINING - Epoch: [831][0/196]	Time 0.809 (0.809)	Data 0.107 (0.107)	Loss 0.2019 (0.2019)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [831][100/196]	Time 0.094 (0.079)	Data 0.000 (0.001)	Loss 0.2595 (0.2589)	Prec@1 91.016 (90.594)	Prec@5 99.609 (99.876)
EVALUATING - Epoch: [831][0/79]	Time 0.087 (0.087)	Data 0.062 (0.062)	Loss 0.3153 (0.3153)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:45

 Epoch: 832	Training Loss 0.2610 	Training Prec@1 90.654 	Training Prec@5 99.834 	Validation Loss 0.4250 	Validation Prec@1 86.320 	Validation Prec@5 99.540 

lr: 0.007179855136987219
TRAINING - Epoch: [832][0/196]	Time 0.743 (0.743)	Data 0.087 (0.087)	Loss 0.2223 (0.2223)	Prec@1 92.578 (92.578)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [832][100/196]	Time 0.055 (0.081)	Data 0.000 (0.001)	Loss 0.2140 (0.2528)	Prec@1 91.406 (91.019)	Prec@5 100.000 (99.838)
EVALUATING - Epoch: [832][0/79]	Time 0.074 (0.074)	Data 0.051 (0.051)	Loss 0.4253 (0.4253)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:20

 Epoch: 833	Training Loss 0.2553 	Training Prec@1 90.934 	Training Prec@5 99.808 	Validation Loss 0.4258 	Validation Prec@1 86.660 	Validation Prec@5 99.440 

lr: 0.007098639455166835
TRAINING - Epoch: [833][0/196]	Time 0.806 (0.806)	Data 0.082 (0.082)	Loss 0.2454 (0.2454)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [833][100/196]	Time 0.087 (0.093)	Data 0.000 (0.001)	Loss 0.2414 (0.2626)	Prec@1 91.016 (90.714)	Prec@5 100.000 (99.872)
EVALUATING - Epoch: [833][0/79]	Time 0.075 (0.075)	Data 0.052 (0.052)	Loss 0.4049 (0.4049)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:41

 Epoch: 834	Training Loss 0.2584 	Training Prec@1 90.894 	Training Prec@5 99.858 	Validation Loss 0.4368 	Validation Prec@1 86.040 	Validation Prec@5 99.440 

lr: 0.007017850618798014
TRAINING - Epoch: [834][0/196]	Time 0.801 (0.801)	Data 0.078 (0.078)	Loss 0.2696 (0.2696)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [834][100/196]	Time 0.089 (0.094)	Data 0.000 (0.001)	Loss 0.2642 (0.2570)	Prec@1 89.844 (90.807)	Prec@5 99.609 (99.818)
EVALUATING - Epoch: [834][0/79]	Time 0.073 (0.073)	Data 0.051 (0.051)	Loss 0.3399 (0.3399)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:25

 Epoch: 835	Training Loss 0.2547 	Training Prec@1 90.952 	Training Prec@5 99.822 	Validation Loss 0.4433 	Validation Prec@1 85.850 	Validation Prec@5 99.410 

lr: 0.006937489431651212
TRAINING - Epoch: [835][0/196]	Time 0.551 (0.551)	Data 0.108 (0.108)	Loss 0.2227 (0.2227)	Prec@1 93.750 (93.750)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [835][100/196]	Time 0.092 (0.091)	Data 0.000 (0.001)	Loss 0.2465 (0.2557)	Prec@1 92.188 (91.008)	Prec@5 99.609 (99.841)
EVALUATING - Epoch: [835][0/79]	Time 0.076 (0.076)	Data 0.051 (0.051)	Loss 0.4319 (0.4319)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:35

 Epoch: 836	Training Loss 0.2572 	Training Prec@1 90.912 	Training Prec@5 99.822 	Validation Loss 0.4397 	Validation Prec@1 85.850 	Validation Prec@5 99.520 

lr: 0.006857556693242252
TRAINING - Epoch: [836][0/196]	Time 0.828 (0.828)	Data 0.092 (0.092)	Loss 0.2996 (0.2996)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [836][100/196]	Time 0.082 (0.084)	Data 0.000 (0.001)	Loss 0.2750 (0.2580)	Prec@1 91.016 (90.756)	Prec@5 100.000 (99.834)
EVALUATING - Epoch: [836][0/79]	Time 0.085 (0.085)	Data 0.062 (0.062)	Loss 0.3803 (0.3803)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:18

 Epoch: 837	Training Loss 0.2583 	Training Prec@1 90.768 	Training Prec@5 99.842 	Validation Loss 0.4217 	Validation Prec@1 86.470 	Validation Prec@5 99.520 

lr: 0.006778053198824273
TRAINING - Epoch: [837][0/196]	Time 0.797 (0.797)	Data 0.106 (0.106)	Loss 0.2852 (0.2852)	Prec@1 89.062 (89.062)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [837][100/196]	Time 0.028 (0.085)	Data 0.000 (0.001)	Loss 0.2906 (0.2545)	Prec@1 89.453 (90.876)	Prec@5 100.000 (99.838)
EVALUATING - Epoch: [837][0/79]	Time 0.075 (0.075)	Data 0.052 (0.052)	Loss 0.4006 (0.4006)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:53

 Epoch: 838	Training Loss 0.2534 	Training Prec@1 90.864 	Training Prec@5 99.846 	Validation Loss 0.4457 	Validation Prec@1 85.590 	Validation Prec@5 99.460 

lr: 0.0066989797393798844
TRAINING - Epoch: [838][0/196]	Time 0.773 (0.773)	Data 0.087 (0.087)	Loss 0.2534 (0.2534)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [838][100/196]	Time 0.093 (0.094)	Data 0.000 (0.001)	Loss 0.2025 (0.2545)	Prec@1 92.969 (90.807)	Prec@5 99.609 (99.838)
EVALUATING - Epoch: [838][0/79]	Time 0.076 (0.076)	Data 0.051 (0.051)	Loss 0.3730 (0.3730)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:55

 Epoch: 839	Training Loss 0.2547 	Training Prec@1 90.912 	Training Prec@5 99.846 	Validation Loss 0.4321 	Validation Prec@1 85.740 	Validation Prec@5 99.520 

lr: 0.00662033710161325
TRAINING - Epoch: [839][0/196]	Time 0.787 (0.787)	Data 0.080 (0.080)	Loss 0.2089 (0.2089)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [839][100/196]	Time 0.095 (0.092)	Data 0.000 (0.001)	Loss 0.2336 (0.2543)	Prec@1 92.578 (90.950)	Prec@5 99.609 (99.853)
EVALUATING - Epoch: [839][0/79]	Time 0.074 (0.074)	Data 0.053 (0.053)	Loss 0.4118 (0.4118)	Prec@1 83.594 (83.594)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:53

 Epoch: 840	Training Loss 0.2588 	Training Prec@1 90.770 	Training Prec@5 99.846 	Validation Loss 0.4426 	Validation Prec@1 85.840 	Validation Prec@5 99.540 

lr: 0.006542126067942265
TRAINING - Epoch: [840][0/196]	Time 0.785 (0.785)	Data 0.093 (0.093)	Loss 0.2256 (0.2256)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [840][100/196]	Time 0.096 (0.092)	Data 0.000 (0.001)	Loss 0.2769 (0.2540)	Prec@1 91.016 (90.830)	Prec@5 100.000 (99.845)
EVALUATING - Epoch: [840][0/79]	Time 0.077 (0.077)	Data 0.056 (0.056)	Loss 0.3250 (0.3250)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:14

 Epoch: 841	Training Loss 0.2555 	Training Prec@1 90.824 	Training Prec@5 99.832 	Validation Loss 0.4192 	Validation Prec@1 86.160 	Validation Prec@5 99.540 

lr: 0.006464347416490793
TRAINING - Epoch: [841][0/196]	Time 0.815 (0.815)	Data 0.081 (0.081)	Loss 0.2307 (0.2307)	Prec@1 92.578 (92.578)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [841][100/196]	Time 0.091 (0.083)	Data 0.000 (0.001)	Loss 0.1908 (0.2530)	Prec@1 93.750 (90.903)	Prec@5 100.000 (99.869)
EVALUATING - Epoch: [841][0/79]	Time 0.086 (0.086)	Data 0.066 (0.066)	Loss 0.3229 (0.3229)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:05

 Epoch: 842	Training Loss 0.2545 	Training Prec@1 90.866 	Training Prec@5 99.850 	Validation Loss 0.4178 	Validation Prec@1 86.840 	Validation Prec@5 99.520 

lr: 0.006387001921080916
TRAINING - Epoch: [842][0/196]	Time 0.792 (0.792)	Data 0.106 (0.106)	Loss 0.3335 (0.3335)	Prec@1 86.328 (86.328)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [842][100/196]	Time 0.052 (0.086)	Data 0.000 (0.001)	Loss 0.2238 (0.2570)	Prec@1 91.797 (90.934)	Prec@5 100.000 (99.830)
EVALUATING - Epoch: [842][0/79]	Time 0.071 (0.071)	Data 0.050 (0.050)	Loss 0.4034 (0.4034)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:09

 Epoch: 843	Training Loss 0.2556 	Training Prec@1 90.944 	Training Prec@5 99.826 	Validation Loss 0.4371 	Validation Prec@1 86.020 	Validation Prec@5 99.460 

lr: 0.006310090351225232
TRAINING - Epoch: [843][0/196]	Time 0.798 (0.798)	Data 0.088 (0.088)	Loss 0.2408 (0.2408)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [843][100/196]	Time 0.084 (0.094)	Data 0.000 (0.001)	Loss 0.2633 (0.2551)	Prec@1 92.578 (90.764)	Prec@5 100.000 (99.841)
EVALUATING - Epoch: [843][0/79]	Time 0.075 (0.075)	Data 0.054 (0.054)	Loss 0.4135 (0.4135)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:54

 Epoch: 844	Training Loss 0.2578 	Training Prec@1 90.822 	Training Prec@5 99.836 	Validation Loss 0.4368 	Validation Prec@1 85.890 	Validation Prec@5 99.550 

lr: 0.006233613472119191
TRAINING - Epoch: [844][0/196]	Time 0.803 (0.803)	Data 0.116 (0.116)	Loss 0.2482 (0.2482)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [844][100/196]	Time 0.089 (0.093)	Data 0.000 (0.001)	Loss 0.2954 (0.2545)	Prec@1 90.234 (90.969)	Prec@5 100.000 (99.880)
EVALUATING - Epoch: [844][0/79]	Time 0.074 (0.074)	Data 0.051 (0.051)	Loss 0.3375 (0.3375)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:44

 Epoch: 845	Training Loss 0.2536 	Training Prec@1 90.976 	Training Prec@5 99.878 	Validation Loss 0.4367 	Validation Prec@1 85.910 	Validation Prec@5 99.470 

lr: 0.0061575720446335296
TRAINING - Epoch: [845][0/196]	Time 0.318 (0.318)	Data 0.089 (0.089)	Loss 0.2205 (0.2205)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [845][100/196]	Time 0.092 (0.090)	Data 0.000 (0.001)	Loss 0.2125 (0.2570)	Prec@1 91.797 (90.923)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [845][0/79]	Time 0.076 (0.076)	Data 0.053 (0.053)	Loss 0.3095 (0.3095)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:58

 Epoch: 846	Training Loss 0.2560 	Training Prec@1 91.004 	Training Prec@5 99.854 	Validation Loss 0.4345 	Validation Prec@1 85.820 	Validation Prec@5 99.570 

lr: 0.0060819668253066
TRAINING - Epoch: [846][0/196]	Time 0.755 (0.755)	Data 0.085 (0.085)	Loss 0.2369 (0.2369)	Prec@1 91.797 (91.797)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [846][100/196]	Time 0.091 (0.083)	Data 0.000 (0.001)	Loss 0.2995 (0.2498)	Prec@1 89.844 (91.217)	Prec@5 100.000 (99.857)
EVALUATING - Epoch: [846][0/79]	Time 0.090 (0.090)	Data 0.069 (0.069)	Loss 0.3825 (0.3825)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:38

 Epoch: 847	Training Loss 0.2540 	Training Prec@1 90.962 	Training Prec@5 99.848 	Validation Loss 0.4305 	Validation Prec@1 86.180 	Validation Prec@5 99.510 

lr: 0.006006798566336966
TRAINING - Epoch: [847][0/196]	Time 0.739 (0.739)	Data 0.094 (0.094)	Loss 0.3391 (0.3391)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [847][100/196]	Time 0.053 (0.087)	Data 0.000 (0.001)	Loss 0.3164 (0.2551)	Prec@1 89.844 (91.093)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [847][0/79]	Time 0.076 (0.076)	Data 0.053 (0.053)	Loss 0.3873 (0.3873)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:09

 Epoch: 848	Training Loss 0.2577 	Training Prec@1 90.956 	Training Prec@5 99.814 	Validation Loss 0.4206 	Validation Prec@1 86.260 	Validation Prec@5 99.430 

lr: 0.005932068015575818
TRAINING - Epoch: [848][0/196]	Time 0.743 (0.743)	Data 0.108 (0.108)	Loss 0.1942 (0.1942)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [848][100/196]	Time 0.085 (0.094)	Data 0.000 (0.001)	Loss 0.2260 (0.2515)	Prec@1 91.406 (90.985)	Prec@5 100.000 (99.865)
EVALUATING - Epoch: [848][0/79]	Time 0.075 (0.075)	Data 0.056 (0.056)	Loss 0.4145 (0.4145)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:56

 Epoch: 849	Training Loss 0.2507 	Training Prec@1 91.024 	Training Prec@5 99.854 	Validation Loss 0.4123 	Validation Prec@1 86.710 	Validation Prec@5 99.530 

lr: 0.00585777591651961
TRAINING - Epoch: [849][0/196]	Time 0.811 (0.811)	Data 0.085 (0.085)	Loss 0.2217 (0.2217)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [849][100/196]	Time 0.093 (0.094)	Data 0.000 (0.001)	Loss 0.2263 (0.2574)	Prec@1 92.578 (90.849)	Prec@5 100.000 (99.776)
EVALUATING - Epoch: [849][0/79]	Time 0.074 (0.074)	Data 0.052 (0.052)	Loss 0.4089 (0.4089)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:32

 Epoch: 850	Training Loss 0.2565 	Training Prec@1 90.842 	Training Prec@5 99.826 	Validation Loss 0.4305 	Validation Prec@1 85.730 	Validation Prec@5 99.530 

lr: 0.005783923008302611
TRAINING - Epoch: [850][0/196]	Time 0.440 (0.440)	Data 0.149 (0.149)	Loss 0.3195 (0.3195)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [850][100/196]	Time 0.092 (0.091)	Data 0.000 (0.002)	Loss 0.1865 (0.2563)	Prec@1 91.406 (90.698)	Prec@5 100.000 (99.853)
EVALUATING - Epoch: [850][0/79]	Time 0.085 (0.085)	Data 0.065 (0.065)	Loss 0.3674 (0.3674)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:10

 Epoch: 851	Training Loss 0.2567 	Training Prec@1 90.804 	Training Prec@5 99.864 	Validation Loss 0.4274 	Validation Prec@1 86.090 	Validation Prec@5 99.510 

lr: 0.005710510025689544
TRAINING - Epoch: [851][0/196]	Time 0.748 (0.748)	Data 0.104 (0.104)	Loss 0.1902 (0.1902)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [851][100/196]	Time 0.092 (0.082)	Data 0.000 (0.001)	Loss 0.2613 (0.2514)	Prec@1 90.234 (91.120)	Prec@5 100.000 (99.872)
EVALUATING - Epoch: [851][0/79]	Time 0.081 (0.081)	Data 0.061 (0.061)	Loss 0.3246 (0.3246)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:32

 Epoch: 852	Training Loss 0.2543 	Training Prec@1 90.992 	Training Prec@5 99.860 	Validation Loss 0.4219 	Validation Prec@1 86.450 	Validation Prec@5 99.540 

lr: 0.0056375376990683455
TRAINING - Epoch: [852][0/196]	Time 0.756 (0.756)	Data 0.078 (0.078)	Loss 0.2216 (0.2216)	Prec@1 92.188 (92.188)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [852][100/196]	Time 0.051 (0.087)	Data 0.000 (0.001)	Loss 0.2497 (0.2484)	Prec@1 89.453 (91.186)	Prec@5 100.000 (99.853)
EVALUATING - Epoch: [852][0/79]	Time 0.072 (0.072)	Data 0.050 (0.050)	Loss 0.3062 (0.3062)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:23

 Epoch: 853	Training Loss 0.2532 	Training Prec@1 90.964 	Training Prec@5 99.846 	Validation Loss 0.4202 	Validation Prec@1 86.550 	Validation Prec@5 99.570 

lr: 0.0055650067544428155
TRAINING - Epoch: [853][0/196]	Time 0.715 (0.715)	Data 0.083 (0.083)	Loss 0.2165 (0.2165)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [853][100/196]	Time 0.091 (0.093)	Data 0.000 (0.001)	Loss 0.3041 (0.2556)	Prec@1 88.672 (90.954)	Prec@5 99.609 (99.803)
EVALUATING - Epoch: [853][0/79]	Time 0.073 (0.073)	Data 0.053 (0.053)	Loss 0.3657 (0.3657)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:47

 Epoch: 854	Training Loss 0.2558 	Training Prec@1 90.950 	Training Prec@5 99.836 	Validation Loss 0.4225 	Validation Prec@1 86.220 	Validation Prec@5 99.510 

lr: 0.00549291791342545
TRAINING - Epoch: [854][0/196]	Time 0.806 (0.806)	Data 0.088 (0.088)	Loss 0.2934 (0.2934)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [854][100/196]	Time 0.086 (0.093)	Data 0.000 (0.001)	Loss 0.3129 (0.2573)	Prec@1 88.672 (90.927)	Prec@5 99.609 (99.845)
EVALUATING - Epoch: [854][0/79]	Time 0.075 (0.075)	Data 0.052 (0.052)	Loss 0.4100 (0.4100)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:57

 Epoch: 855	Training Loss 0.2575 	Training Prec@1 90.864 	Training Prec@5 99.834 	Validation Loss 0.4230 	Validation Prec@1 86.480 	Validation Prec@5 99.500 

lr: 0.005421271893230239
TRAINING - Epoch: [855][0/196]	Time 0.473 (0.473)	Data 0.086 (0.086)	Loss 0.2348 (0.2348)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [855][100/196]	Time 0.089 (0.088)	Data 0.000 (0.001)	Loss 0.2404 (0.2570)	Prec@1 91.016 (90.780)	Prec@5 100.000 (99.845)
EVALUATING - Epoch: [855][0/79]	Time 0.081 (0.081)	Data 0.064 (0.064)	Loss 0.3183 (0.3183)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:11

 Epoch: 856	Training Loss 0.2533 	Training Prec@1 90.972 	Training Prec@5 99.846 	Validation Loss 0.4245 	Validation Prec@1 86.130 	Validation Prec@5 99.620 

lr: 0.005350069406665533
TRAINING - Epoch: [856][0/196]	Time 0.796 (0.796)	Data 0.103 (0.103)	Loss 0.1812 (0.1812)	Prec@1 94.141 (94.141)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [856][100/196]	Time 0.088 (0.080)	Data 0.000 (0.001)	Loss 0.1886 (0.2475)	Prec@1 92.969 (91.112)	Prec@5 100.000 (99.884)
EVALUATING - Epoch: [856][0/79]	Time 0.077 (0.077)	Data 0.060 (0.060)	Loss 0.3666 (0.3666)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:31

 Epoch: 857	Training Loss 0.2548 	Training Prec@1 90.976 	Training Prec@5 99.852 	Validation Loss 0.4233 	Validation Prec@1 86.540 	Validation Prec@5 99.560 

lr: 0.005279311162126951
TRAINING - Epoch: [857][0/196]	Time 0.758 (0.758)	Data 0.083 (0.083)	Loss 0.2294 (0.2294)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [857][100/196]	Time 0.054 (0.090)	Data 0.000 (0.001)	Loss 0.2876 (0.2557)	Prec@1 92.188 (90.903)	Prec@5 99.609 (99.826)
EVALUATING - Epoch: [857][0/79]	Time 0.085 (0.085)	Data 0.066 (0.066)	Loss 0.4051 (0.4051)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:58

 Epoch: 858	Training Loss 0.2553 	Training Prec@1 90.918 	Training Prec@5 99.850 	Validation Loss 0.4282 	Validation Prec@1 86.250 	Validation Prec@5 99.440 

lr: 0.00520899786359034
TRAINING - Epoch: [858][0/196]	Time 0.827 (0.827)	Data 0.105 (0.105)	Loss 0.3166 (0.3166)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [858][100/196]	Time 0.087 (0.095)	Data 0.000 (0.001)	Loss 0.2858 (0.2566)	Prec@1 88.281 (90.842)	Prec@5 100.000 (99.822)
EVALUATING - Epoch: [858][0/79]	Time 0.068 (0.068)	Data 0.050 (0.050)	Loss 0.3608 (0.3608)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:56

 Epoch: 859	Training Loss 0.2546 	Training Prec@1 90.938 	Training Prec@5 99.810 	Validation Loss 0.4236 	Validation Prec@1 86.360 	Validation Prec@5 99.470 

lr: 0.005139130210604761
TRAINING - Epoch: [859][0/196]	Time 0.779 (0.779)	Data 0.101 (0.101)	Loss 0.2884 (0.2884)	Prec@1 89.453 (89.453)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [859][100/196]	Time 0.092 (0.093)	Data 0.000 (0.001)	Loss 0.1737 (0.2511)	Prec@1 94.922 (91.078)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [859][0/79]	Time 0.078 (0.078)	Data 0.056 (0.056)	Loss 0.3141 (0.3141)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:49

 Epoch: 860	Training Loss 0.2528 	Training Prec@1 91.040 	Training Prec@5 99.840 	Validation Loss 0.4393 	Validation Prec@1 85.900 	Validation Prec@5 99.480 

lr: 0.005069708898285566
TRAINING - Epoch: [860][0/196]	Time 0.392 (0.392)	Data 0.103 (0.103)	Loss 0.2413 (0.2413)	Prec@1 91.406 (91.406)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [860][100/196]	Time 0.090 (0.085)	Data 0.000 (0.001)	Loss 0.2950 (0.2561)	Prec@1 89.062 (90.903)	Prec@5 99.609 (99.803)
EVALUATING - Epoch: [860][0/79]	Time 0.077 (0.077)	Data 0.053 (0.053)	Loss 0.5166 (0.5166)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:40

 Epoch: 861	Training Loss 0.2552 	Training Prec@1 90.880 	Training Prec@5 99.842 	Validation Loss 0.4256 	Validation Prec@1 86.220 	Validation Prec@5 99.500 

lr: 0.00500073461730739
TRAINING - Epoch: [861][0/196]	Time 0.820 (0.820)	Data 0.093 (0.093)	Loss 0.2172 (0.2172)	Prec@1 92.188 (92.188)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [861][100/196]	Time 0.097 (0.083)	Data 0.000 (0.001)	Loss 0.2519 (0.2508)	Prec@1 89.453 (91.128)	Prec@5 99.609 (99.841)
EVALUATING - Epoch: [861][0/79]	Time 0.083 (0.083)	Data 0.062 (0.062)	Loss 0.3086 (0.3086)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:51

 Epoch: 862	Training Loss 0.2523 	Training Prec@1 90.988 	Training Prec@5 99.846 	Validation Loss 0.4275 	Validation Prec@1 86.180 	Validation Prec@5 99.580 

lr: 0.004932208053897369
TRAINING - Epoch: [862][0/196]	Time 0.795 (0.795)	Data 0.096 (0.096)	Loss 0.2664 (0.2664)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [862][100/196]	Time 0.058 (0.090)	Data 0.000 (0.001)	Loss 0.1925 (0.2548)	Prec@1 93.359 (90.919)	Prec@5 100.000 (99.838)
EVALUATING - Epoch: [862][0/79]	Time 0.079 (0.079)	Data 0.055 (0.055)	Loss 0.3301 (0.3301)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:56

 Epoch: 863	Training Loss 0.2527 	Training Prec@1 91.000 	Training Prec@5 99.828 	Validation Loss 0.4122 	Validation Prec@1 86.960 	Validation Prec@5 99.520 

lr: 0.0048641298898283196
TRAINING - Epoch: [863][0/196]	Time 0.812 (0.812)	Data 0.092 (0.092)	Loss 0.2451 (0.2451)	Prec@1 91.016 (91.016)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [863][100/196]	Time 0.083 (0.094)	Data 0.000 (0.001)	Loss 0.2007 (0.2588)	Prec@1 94.141 (90.640)	Prec@5 100.000 (99.818)
EVALUATING - Epoch: [863][0/79]	Time 0.080 (0.080)	Data 0.061 (0.061)	Loss 0.3232 (0.3232)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:47

 Epoch: 864	Training Loss 0.2544 	Training Prec@1 90.890 	Training Prec@5 99.822 	Validation Loss 0.4223 	Validation Prec@1 86.460 	Validation Prec@5 99.410 

lr: 0.004796500802411872
TRAINING - Epoch: [864][0/196]	Time 0.786 (0.786)	Data 0.085 (0.085)	Loss 0.3861 (0.3861)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [864][100/196]	Time 0.087 (0.095)	Data 0.000 (0.001)	Loss 0.2349 (0.2538)	Prec@1 90.234 (91.070)	Prec@5 100.000 (99.830)
EVALUATING - Epoch: [864][0/79]	Time 0.070 (0.070)	Data 0.051 (0.051)	Loss 0.3935 (0.3935)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:05

 Epoch: 865	Training Loss 0.2519 	Training Prec@1 91.056 	Training Prec@5 99.824 	Validation Loss 0.4213 	Validation Prec@1 86.400 	Validation Prec@5 99.610 

lr: 0.004729321464491807
TRAINING - Epoch: [865][0/196]	Time 0.474 (0.474)	Data 0.093 (0.093)	Loss 0.3256 (0.3256)	Prec@1 88.281 (88.281)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [865][100/196]	Time 0.089 (0.085)	Data 0.000 (0.001)	Loss 0.2224 (0.2524)	Prec@1 92.969 (91.190)	Prec@5 100.000 (99.853)
EVALUATING - Epoch: [865][0/79]	Time 0.091 (0.091)	Data 0.065 (0.065)	Loss 0.3547 (0.3547)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:05

 Epoch: 866	Training Loss 0.2547 	Training Prec@1 90.962 	Training Prec@5 99.848 	Validation Loss 0.4468 	Validation Prec@1 85.330 	Validation Prec@5 99.480 

lr: 0.004662592544437297
TRAINING - Epoch: [866][0/196]	Time 0.800 (0.800)	Data 0.080 (0.080)	Loss 0.2376 (0.2376)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [866][100/196]	Time 0.095 (0.086)	Data 0.000 (0.001)	Loss 0.1439 (0.2550)	Prec@1 96.094 (90.876)	Prec@5 99.609 (99.826)
EVALUATING - Epoch: [866][0/79]	Time 0.080 (0.080)	Data 0.055 (0.055)	Loss 0.3281 (0.3281)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:31

 Epoch: 867	Training Loss 0.2482 	Training Prec@1 91.086 	Training Prec@5 99.854 	Validation Loss 0.4042 	Validation Prec@1 86.910 	Validation Prec@5 99.600 

lr: 0.004596314706136345
TRAINING - Epoch: [867][0/196]	Time 0.809 (0.809)	Data 0.089 (0.089)	Loss 0.3233 (0.3233)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [867][100/196]	Time 0.037 (0.091)	Data 0.000 (0.001)	Loss 0.2145 (0.2538)	Prec@1 93.359 (91.008)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [867][0/79]	Time 0.073 (0.073)	Data 0.055 (0.055)	Loss 0.3840 (0.3840)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:41:27

 Epoch: 868	Training Loss 0.2535 	Training Prec@1 90.942 	Training Prec@5 99.864 	Validation Loss 0.4412 	Validation Prec@1 85.500 	Validation Prec@5 99.520 

lr: 0.004530488608989092
TRAINING - Epoch: [868][0/196]	Time 0.739 (0.739)	Data 0.086 (0.086)	Loss 0.2383 (0.2383)	Prec@1 92.188 (92.188)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [868][100/196]	Time 0.091 (0.092)	Data 0.000 (0.001)	Loss 0.2676 (0.2504)	Prec@1 90.234 (91.139)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [868][0/79]	Time 0.094 (0.094)	Data 0.059 (0.059)	Loss 0.3221 (0.3221)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:32

 Epoch: 869	Training Loss 0.2523 	Training Prec@1 90.968 	Training Prec@5 99.860 	Validation Loss 0.4079 	Validation Prec@1 86.650 	Validation Prec@5 99.570 

lr: 0.004465114907901314
TRAINING - Epoch: [869][0/196]	Time 0.816 (0.816)	Data 0.109 (0.109)	Loss 0.2781 (0.2781)	Prec@1 90.234 (90.234)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [869][100/196]	Time 0.082 (0.093)	Data 0.000 (0.001)	Loss 0.3198 (0.2566)	Prec@1 88.672 (90.934)	Prec@5 100.000 (99.834)
EVALUATING - Epoch: [869][0/79]	Time 0.069 (0.069)	Data 0.049 (0.049)	Loss 0.3883 (0.3883)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:12

 Epoch: 870	Training Loss 0.2577 	Training Prec@1 90.800 	Training Prec@5 99.824 	Validation Loss 0.4351 	Validation Prec@1 85.970 	Validation Prec@5 99.530 

lr: 0.004400194253277865
TRAINING - Epoch: [870][0/196]	Time 0.775 (0.775)	Data 0.110 (0.110)	Loss 0.2033 (0.2033)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [870][100/196]	Time 0.068 (0.082)	Data 0.000 (0.001)	Loss 0.2323 (0.2585)	Prec@1 91.797 (90.633)	Prec@5 100.000 (99.838)
EVALUATING - Epoch: [870][0/79]	Time 0.073 (0.073)	Data 0.049 (0.049)	Loss 0.2808 (0.2808)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:47

 Epoch: 871	Training Loss 0.2565 	Training Prec@1 90.706 	Training Prec@5 99.850 	Validation Loss 0.4072 	Validation Prec@1 86.620 	Validation Prec@5 99.610 

lr: 0.004335727291016259
TRAINING - Epoch: [871][0/196]	Time 0.837 (0.837)	Data 0.125 (0.125)	Loss 0.2268 (0.2268)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [871][100/196]	Time 0.087 (0.083)	Data 0.000 (0.001)	Loss 0.2601 (0.2573)	Prec@1 90.234 (90.776)	Prec@5 99.609 (99.807)
EVALUATING - Epoch: [871][0/79]	Time 0.073 (0.073)	Data 0.053 (0.053)	Loss 0.3548 (0.3548)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:08

 Epoch: 872	Training Loss 0.2550 	Training Prec@1 90.978 	Training Prec@5 99.816 	Validation Loss 0.4101 	Validation Prec@1 86.810 	Validation Prec@5 99.570 

lr: 0.004271714662500167
TRAINING - Epoch: [872][0/196]	Time 0.775 (0.775)	Data 0.096 (0.096)	Loss 0.2997 (0.2997)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [872][100/196]	Time 0.087 (0.094)	Data 0.000 (0.001)	Loss 0.1915 (0.2562)	Prec@1 93.750 (90.791)	Prec@5 100.000 (99.834)
EVALUATING - Epoch: [872][0/79]	Time 0.075 (0.075)	Data 0.053 (0.053)	Loss 0.3597 (0.3597)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:14

 Epoch: 873	Training Loss 0.2507 	Training Prec@1 91.158 	Training Prec@5 99.858 	Validation Loss 0.4106 	Validation Prec@1 86.630 	Validation Prec@5 99.570 

lr: 0.004208157004593109
TRAINING - Epoch: [873][0/196]	Time 0.740 (0.740)	Data 0.110 (0.110)	Loss 0.3204 (0.3204)	Prec@1 86.328 (86.328)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [873][100/196]	Time 0.094 (0.093)	Data 0.000 (0.001)	Loss 0.1935 (0.2537)	Prec@1 93.359 (91.058)	Prec@5 100.000 (99.822)
EVALUATING - Epoch: [873][0/79]	Time 0.076 (0.076)	Data 0.055 (0.055)	Loss 0.3758 (0.3758)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:11

 Epoch: 874	Training Loss 0.2492 	Training Prec@1 91.148 	Training Prec@5 99.844 	Validation Loss 0.4149 	Validation Prec@1 86.470 	Validation Prec@5 99.600 

lr: 0.004145054949632094
TRAINING - Epoch: [874][0/196]	Time 0.817 (0.817)	Data 0.101 (0.101)	Loss 0.2232 (0.2232)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [874][100/196]	Time 0.088 (0.093)	Data 0.000 (0.001)	Loss 0.2129 (0.2585)	Prec@1 91.406 (90.714)	Prec@5 100.000 (99.857)
EVALUATING - Epoch: [874][0/79]	Time 0.072 (0.072)	Data 0.052 (0.052)	Loss 0.3915 (0.3915)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:21

 Epoch: 875	Training Loss 0.2537 	Training Prec@1 90.880 	Training Prec@5 99.856 	Validation Loss 0.4387 	Validation Prec@1 85.990 	Validation Prec@5 99.510 

lr: 0.0040824091254213065
TRAINING - Epoch: [875][0/196]	Time 0.808 (0.808)	Data 0.101 (0.101)	Loss 0.3584 (0.3584)	Prec@1 86.328 (86.328)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [875][100/196]	Time 0.056 (0.083)	Data 0.000 (0.001)	Loss 0.2177 (0.2501)	Prec@1 91.406 (90.950)	Prec@5 100.000 (99.845)
EVALUATING - Epoch: [875][0/79]	Time 0.074 (0.074)	Data 0.051 (0.051)	Loss 0.3413 (0.3413)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:21

 Epoch: 876	Training Loss 0.2492 	Training Prec@1 91.070 	Training Prec@5 99.852 	Validation Loss 0.4147 	Validation Prec@1 86.480 	Validation Prec@5 99.530 

lr: 0.004020220155225895
TRAINING - Epoch: [876][0/196]	Time 0.799 (0.799)	Data 0.083 (0.083)	Loss 0.2077 (0.2077)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [876][100/196]	Time 0.087 (0.079)	Data 0.000 (0.001)	Loss 0.2910 (0.2550)	Prec@1 90.625 (90.973)	Prec@5 100.000 (99.845)
EVALUATING - Epoch: [876][0/79]	Time 0.085 (0.085)	Data 0.065 (0.065)	Loss 0.3338 (0.3338)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:20

 Epoch: 877	Training Loss 0.2519 	Training Prec@1 91.112 	Training Prec@5 99.844 	Validation Loss 0.4182 	Validation Prec@1 86.430 	Validation Prec@5 99.480 

lr: 0.003958488657765722
TRAINING - Epoch: [877][0/196]	Time 0.801 (0.801)	Data 0.100 (0.100)	Loss 0.2469 (0.2469)	Prec@1 90.625 (90.625)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [877][100/196]	Time 0.093 (0.095)	Data 0.000 (0.001)	Loss 0.2343 (0.2493)	Prec@1 91.797 (91.089)	Prec@5 100.000 (99.872)
EVALUATING - Epoch: [877][0/79]	Time 0.078 (0.078)	Data 0.062 (0.062)	Loss 0.3531 (0.3531)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:44

 Epoch: 878	Training Loss 0.2487 	Training Prec@1 91.158 	Training Prec@5 99.842 	Validation Loss 0.4070 	Validation Prec@1 86.350 	Validation Prec@5 99.550 

lr: 0.0038972152472092772
TRAINING - Epoch: [878][0/196]	Time 0.762 (0.762)	Data 0.102 (0.102)	Loss 0.3059 (0.3059)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [878][100/196]	Time 0.067 (0.093)	Data 0.000 (0.001)	Loss 0.2612 (0.2606)	Prec@1 90.625 (90.780)	Prec@5 100.000 (99.841)
EVALUATING - Epoch: [878][0/79]	Time 0.083 (0.083)	Data 0.061 (0.061)	Loss 0.3454 (0.3454)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:15

 Epoch: 879	Training Loss 0.2560 	Training Prec@1 90.932 	Training Prec@5 99.844 	Validation Loss 0.4200 	Validation Prec@1 86.310 	Validation Prec@5 99.590 

lr: 0.0038364005331675195
TRAINING - Epoch: [879][0/196]	Time 0.768 (0.768)	Data 0.094 (0.094)	Loss 0.1531 (0.1531)	Prec@1 95.312 (95.312)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [879][100/196]	Time 0.097 (0.093)	Data 0.000 (0.001)	Loss 0.2008 (0.2483)	Prec@1 92.188 (91.170)	Prec@5 100.000 (99.853)
EVALUATING - Epoch: [879][0/79]	Time 0.082 (0.082)	Data 0.059 (0.059)	Loss 0.2987 (0.2987)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:45:24

 Epoch: 880	Training Loss 0.2522 	Training Prec@1 91.032 	Training Prec@5 99.840 	Validation Loss 0.4072 	Validation Prec@1 86.870 	Validation Prec@5 99.580 

lr: 0.003776045120687813
TRAINING - Epoch: [880][0/196]	Time 0.782 (0.782)	Data 0.079 (0.079)	Loss 0.2637 (0.2637)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [880][100/196]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.2575 (0.2470)	Prec@1 91.406 (91.298)	Prec@5 99.609 (99.822)
EVALUATING - Epoch: [880][0/79]	Time 0.076 (0.076)	Data 0.057 (0.057)	Loss 0.3553 (0.3553)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:06

 Epoch: 881	Training Loss 0.2517 	Training Prec@1 91.092 	Training Prec@5 99.828 	Validation Loss 0.4134 	Validation Prec@1 86.780 	Validation Prec@5 99.530 

lr: 0.0037161496102479192
TRAINING - Epoch: [881][0/196]	Time 0.758 (0.758)	Data 0.091 (0.091)	Loss 0.1861 (0.1861)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [881][100/196]	Time 0.091 (0.085)	Data 0.000 (0.001)	Loss 0.2438 (0.2549)	Prec@1 91.797 (91.128)	Prec@5 100.000 (99.803)
EVALUATING - Epoch: [881][0/79]	Time 0.074 (0.074)	Data 0.055 (0.055)	Loss 0.4392 (0.4392)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:37

 Epoch: 882	Training Loss 0.2517 	Training Prec@1 91.172 	Training Prec@5 99.838 	Validation Loss 0.4114 	Validation Prec@1 86.690 	Validation Prec@5 99.480 

lr: 0.0036567145977500315
TRAINING - Epoch: [882][0/196]	Time 0.778 (0.778)	Data 0.082 (0.082)	Loss 0.2753 (0.2753)	Prec@1 89.453 (89.453)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [882][100/196]	Time 0.095 (0.093)	Data 0.000 (0.001)	Loss 0.2013 (0.2530)	Prec@1 94.141 (90.865)	Prec@5 100.000 (99.826)
EVALUATING - Epoch: [882][0/79]	Time 0.072 (0.072)	Data 0.053 (0.053)	Loss 0.3485 (0.3485)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:16

 Epoch: 883	Training Loss 0.2548 	Training Prec@1 90.842 	Training Prec@5 99.824 	Validation Loss 0.4181 	Validation Prec@1 86.020 	Validation Prec@5 99.550 

lr: 0.0035977406745148267
TRAINING - Epoch: [883][0/196]	Time 0.778 (0.778)	Data 0.108 (0.108)	Loss 0.3472 (0.3472)	Prec@1 87.891 (87.891)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [883][100/196]	Time 0.092 (0.093)	Data 0.000 (0.001)	Loss 0.1221 (0.2502)	Prec@1 95.312 (91.116)	Prec@5 100.000 (99.857)
EVALUATING - Epoch: [883][0/79]	Time 0.082 (0.082)	Data 0.059 (0.059)	Loss 0.3636 (0.3636)	Prec@1 88.281 (88.281)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:36

 Epoch: 884	Training Loss 0.2542 	Training Prec@1 90.974 	Training Prec@5 99.850 	Validation Loss 0.4146 	Validation Prec@1 86.620 	Validation Prec@5 99.550 

lr: 0.0035392284272755857
TRAINING - Epoch: [884][0/196]	Time 0.766 (0.766)	Data 0.085 (0.085)	Loss 0.2630 (0.2630)	Prec@1 91.406 (91.406)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [884][100/196]	Time 0.094 (0.095)	Data 0.000 (0.001)	Loss 0.2637 (0.2596)	Prec@1 90.625 (90.733)	Prec@5 100.000 (99.810)
EVALUATING - Epoch: [884][0/79]	Time 0.070 (0.070)	Data 0.051 (0.051)	Loss 0.3665 (0.3665)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:19	Time of Finish: 2024-03-31 19:45:45

 Epoch: 885	Training Loss 0.2564 	Training Prec@1 90.932 	Training Prec@5 99.828 	Validation Loss 0.4265 	Validation Prec@1 86.220 	Validation Prec@5 99.430 

lr: 0.0034811784381723805
TRAINING - Epoch: [885][0/196]	Time 0.530 (0.530)	Data 0.118 (0.118)	Loss 0.2177 (0.2177)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [885][100/196]	Time 0.083 (0.081)	Data 0.000 (0.001)	Loss 0.1973 (0.2499)	Prec@1 92.578 (91.050)	Prec@5 100.000 (99.814)
EVALUATING - Epoch: [885][0/79]	Time 0.080 (0.080)	Data 0.061 (0.061)	Loss 0.3778 (0.3778)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:53

 Epoch: 886	Training Loss 0.2495 	Training Prec@1 91.086 	Training Prec@5 99.846 	Validation Loss 0.4247 	Validation Prec@1 86.750 	Validation Prec@5 99.520 

lr: 0.003423591284746258
TRAINING - Epoch: [886][0/196]	Time 0.838 (0.838)	Data 0.111 (0.111)	Loss 0.2370 (0.2370)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [886][100/196]	Time 0.091 (0.084)	Data 0.000 (0.001)	Loss 0.3293 (0.2581)	Prec@1 88.672 (90.818)	Prec@5 100.000 (99.861)
EVALUATING - Epoch: [886][0/79]	Time 0.079 (0.079)	Data 0.060 (0.060)	Loss 0.3670 (0.3670)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:16

 Epoch: 887	Training Loss 0.2543 	Training Prec@1 90.968 	Training Prec@5 99.840 	Validation Loss 0.4231 	Validation Prec@1 86.580 	Validation Prec@5 99.530 

lr: 0.0033664675399334696
TRAINING - Epoch: [887][0/196]	Time 0.775 (0.775)	Data 0.092 (0.092)	Loss 0.2073 (0.2073)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [887][100/196]	Time 0.084 (0.094)	Data 0.000 (0.001)	Loss 0.2935 (0.2535)	Prec@1 89.453 (91.019)	Prec@5 100.000 (99.814)
EVALUATING - Epoch: [887][0/79]	Time 0.077 (0.077)	Data 0.056 (0.056)	Loss 0.2945 (0.2945)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:15

 Epoch: 888	Training Loss 0.2536 	Training Prec@1 91.000 	Training Prec@5 99.836 	Validation Loss 0.4101 	Validation Prec@1 86.640 	Validation Prec@5 99.560 

lr: 0.0033098077720598276
TRAINING - Epoch: [888][0/196]	Time 0.775 (0.775)	Data 0.091 (0.091)	Loss 0.2910 (0.2910)	Prec@1 87.891 (87.891)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [888][100/196]	Time 0.067 (0.095)	Data 0.000 (0.001)	Loss 0.2707 (0.2510)	Prec@1 91.016 (90.989)	Prec@5 100.000 (99.865)
EVALUATING - Epoch: [888][0/79]	Time 0.075 (0.075)	Data 0.050 (0.050)	Loss 0.3394 (0.3394)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:24

 Epoch: 889	Training Loss 0.2556 	Training Prec@1 90.836 	Training Prec@5 99.854 	Validation Loss 0.4214 	Validation Prec@1 86.480 	Validation Prec@5 99.540 

lr: 0.003253612544835042
TRAINING - Epoch: [889][0/196]	Time 0.727 (0.727)	Data 0.088 (0.088)	Loss 0.1982 (0.1982)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [889][100/196]	Time 0.083 (0.094)	Data 0.000 (0.001)	Loss 0.2858 (0.2543)	Prec@1 90.234 (90.733)	Prec@5 100.000 (99.907)
EVALUATING - Epoch: [889][0/79]	Time 0.067 (0.067)	Data 0.048 (0.048)	Loss 0.3559 (0.3559)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:06

 Epoch: 890	Training Loss 0.2514 	Training Prec@1 90.960 	Training Prec@5 99.872 	Validation Loss 0.4146 	Validation Prec@1 86.460 	Validation Prec@5 99.520 

lr: 0.003197882417347059
TRAINING - Epoch: [890][0/196]	Time 0.488 (0.488)	Data 0.083 (0.083)	Loss 0.2411 (0.2411)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [890][100/196]	Time 0.088 (0.087)	Data 0.000 (0.001)	Loss 0.2456 (0.2517)	Prec@1 91.797 (90.989)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [890][0/79]	Time 0.086 (0.086)	Data 0.061 (0.061)	Loss 0.3252 (0.3252)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:28

 Epoch: 891	Training Loss 0.2519 	Training Prec@1 91.090 	Training Prec@5 99.842 	Validation Loss 0.4101 	Validation Prec@1 86.940 	Validation Prec@5 99.550 

lr: 0.003142617944056558
TRAINING - Epoch: [891][0/196]	Time 0.791 (0.791)	Data 0.091 (0.091)	Loss 0.2623 (0.2623)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [891][100/196]	Time 0.089 (0.088)	Data 0.000 (0.001)	Loss 0.2476 (0.2529)	Prec@1 90.625 (91.000)	Prec@5 99.609 (99.838)
EVALUATING - Epoch: [891][0/79]	Time 0.113 (0.113)	Data 0.078 (0.078)	Loss 0.3238 (0.3238)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
Time cost: 00:19	Time of Finish: 2024-03-31 19:45:24

 Epoch: 892	Training Loss 0.2528 	Training Prec@1 91.030 	Training Prec@5 99.838 	Validation Loss 0.4248 	Validation Prec@1 86.280 	Validation Prec@5 99.520 

lr: 0.0030878196747913807
TRAINING - Epoch: [892][0/196]	Time 0.734 (0.734)	Data 0.115 (0.115)	Loss 0.2789 (0.2789)	Prec@1 89.844 (89.844)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [892][100/196]	Time 0.062 (0.094)	Data 0.000 (0.001)	Loss 0.2571 (0.2585)	Prec@1 90.625 (90.931)	Prec@5 99.609 (99.810)
EVALUATING - Epoch: [892][0/79]	Time 0.080 (0.080)	Data 0.058 (0.058)	Loss 0.3735 (0.3735)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:49

 Epoch: 893	Training Loss 0.2529 	Training Prec@1 91.030 	Training Prec@5 99.844 	Validation Loss 0.4143 	Validation Prec@1 86.410 	Validation Prec@5 99.570 

lr: 0.003033488154741126
TRAINING - Epoch: [893][0/196]	Time 0.840 (0.840)	Data 0.098 (0.098)	Loss 0.2542 (0.2542)	Prec@1 92.578 (92.578)	Prec@5 98.828 (98.828)
TRAINING - Epoch: [893][100/196]	Time 0.094 (0.101)	Data 0.000 (0.001)	Loss 0.2451 (0.2540)	Prec@1 90.625 (90.903)	Prec@5 99.609 (99.865)
EVALUATING - Epoch: [893][0/79]	Time 0.101 (0.101)	Data 0.066 (0.066)	Loss 0.3560 (0.3560)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:45:09

 Epoch: 894	Training Loss 0.2544 	Training Prec@1 91.010 	Training Prec@5 99.860 	Validation Loss 0.4148 	Validation Prec@1 86.280 	Validation Prec@5 99.640 

lr: 0.00297962392445168
TRAINING - Epoch: [894][0/196]	Time 0.793 (0.793)	Data 0.103 (0.103)	Loss 0.2787 (0.2787)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [894][100/196]	Time 0.097 (0.093)	Data 0.000 (0.001)	Loss 0.2288 (0.2563)	Prec@1 92.188 (90.946)	Prec@5 99.609 (99.838)
EVALUATING - Epoch: [894][0/79]	Time 0.085 (0.085)	Data 0.064 (0.064)	Loss 0.2964 (0.2964)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:26

 Epoch: 895	Training Loss 0.2567 	Training Prec@1 91.002 	Training Prec@5 99.844 	Validation Loss 0.4189 	Validation Prec@1 86.460 	Validation Prec@5 99.570 

lr: 0.0029262275198198343
TRAINING - Epoch: [895][0/196]	Time 0.452 (0.452)	Data 0.200 (0.200)	Loss 0.2196 (0.2196)	Prec@1 94.141 (94.141)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [895][100/196]	Time 0.092 (0.087)	Data 0.000 (0.002)	Loss 0.2284 (0.2565)	Prec@1 91.016 (90.954)	Prec@5 100.000 (99.872)
EVALUATING - Epoch: [895][0/79]	Time 0.078 (0.078)	Data 0.050 (0.050)	Loss 0.3519 (0.3519)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:19

 Epoch: 896	Training Loss 0.2494 	Training Prec@1 91.164 	Training Prec@5 99.876 	Validation Loss 0.4190 	Validation Prec@1 86.450 	Validation Prec@5 99.500 

lr: 0.0028732994720879973
TRAINING - Epoch: [896][0/196]	Time 0.831 (0.831)	Data 0.099 (0.099)	Loss 0.2536 (0.2536)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [896][100/196]	Time 0.093 (0.079)	Data 0.000 (0.001)	Loss 0.2545 (0.2532)	Prec@1 92.578 (90.992)	Prec@5 100.000 (99.822)
EVALUATING - Epoch: [896][0/79]	Time 0.076 (0.076)	Data 0.051 (0.051)	Loss 0.3954 (0.3954)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:40

 Epoch: 897	Training Loss 0.2542 	Training Prec@1 90.934 	Training Prec@5 99.848 	Validation Loss 0.4228 	Validation Prec@1 86.320 	Validation Prec@5 99.550 

lr: 0.0028208403078388636
TRAINING - Epoch: [897][0/196]	Time 0.779 (0.779)	Data 0.082 (0.082)	Loss 0.2719 (0.2719)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [897][100/196]	Time 0.053 (0.091)	Data 0.000 (0.001)	Loss 0.2768 (0.2560)	Prec@1 89.062 (90.733)	Prec@5 100.000 (99.814)
EVALUATING - Epoch: [897][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 0.3602 (0.3602)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:43

 Epoch: 898	Training Loss 0.2561 	Training Prec@1 90.846 	Training Prec@5 99.824 	Validation Loss 0.4211 	Validation Prec@1 86.800 	Validation Prec@5 99.440 

lr: 0.002768850548990174
TRAINING - Epoch: [898][0/196]	Time 0.789 (0.789)	Data 0.085 (0.085)	Loss 0.2731 (0.2731)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [898][100/196]	Time 0.084 (0.095)	Data 0.000 (0.001)	Loss 0.2612 (0.2533)	Prec@1 89.844 (91.012)	Prec@5 99.609 (99.795)
EVALUATING - Epoch: [898][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 0.3761 (0.3761)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:02

 Epoch: 899	Training Loss 0.2539 	Training Prec@1 90.908 	Training Prec@5 99.838 	Validation Loss 0.4224 	Validation Prec@1 86.530 	Validation Prec@5 99.570 

lr: 0.0027173307127895696
TRAINING - Epoch: [899][0/196]	Time 0.819 (0.819)	Data 0.109 (0.109)	Loss 0.3567 (0.3567)	Prec@1 87.109 (87.109)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [899][100/196]	Time 0.088 (0.093)	Data 0.000 (0.001)	Loss 0.2937 (0.2589)	Prec@1 91.406 (90.791)	Prec@5 99.609 (99.849)
EVALUATING - Epoch: [899][0/79]	Time 0.085 (0.085)	Data 0.061 (0.061)	Loss 0.3079 (0.3079)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:58

 Epoch: 900	Training Loss 0.2563 	Training Prec@1 90.916 	Training Prec@5 99.850 	Validation Loss 0.4222 	Validation Prec@1 86.170 	Validation Prec@5 99.550 

lr: 0.002666281311809424
TRAINING - Epoch: [900][0/196]	Time 0.332 (0.332)	Data 0.107 (0.107)	Loss 0.2399 (0.2399)	Prec@1 92.188 (92.188)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [900][100/196]	Time 0.095 (0.088)	Data 0.000 (0.001)	Loss 0.3164 (0.2464)	Prec@1 88.672 (91.209)	Prec@5 100.000 (99.872)
EVALUATING - Epoch: [900][0/79]	Time 0.079 (0.079)	Data 0.060 (0.060)	Loss 0.3028 (0.3028)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:24

 Epoch: 901	Training Loss 0.2463 	Training Prec@1 91.212 	Training Prec@5 99.854 	Validation Loss 0.4229 	Validation Prec@1 86.850 	Validation Prec@5 99.460 

lr: 0.0026157028539417074
TRAINING - Epoch: [901][0/196]	Time 0.792 (0.792)	Data 0.085 (0.085)	Loss 0.2696 (0.2696)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [901][100/196]	Time 0.090 (0.082)	Data 0.000 (0.001)	Loss 0.2524 (0.2564)	Prec@1 90.234 (90.768)	Prec@5 99.609 (99.780)
EVALUATING - Epoch: [901][0/79]	Time 0.072 (0.072)	Data 0.051 (0.051)	Loss 0.3699 (0.3699)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:08

 Epoch: 902	Training Loss 0.2556 	Training Prec@1 90.856 	Training Prec@5 99.824 	Validation Loss 0.4138 	Validation Prec@1 86.840 	Validation Prec@5 99.600 

lr: 0.0025655958423929843
TRAINING - Epoch: [902][0/196]	Time 0.775 (0.775)	Data 0.098 (0.098)	Loss 0.2719 (0.2719)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [902][100/196]	Time 0.054 (0.088)	Data 0.000 (0.001)	Loss 0.2704 (0.2524)	Prec@1 89.844 (90.903)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [902][0/79]	Time 0.079 (0.079)	Data 0.058 (0.058)	Loss 0.3471 (0.3471)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:59

 Epoch: 903	Training Loss 0.2549 	Training Prec@1 90.864 	Training Prec@5 99.824 	Validation Loss 0.4127 	Validation Prec@1 86.430 	Validation Prec@5 99.520 

lr: 0.002515960775679364
TRAINING - Epoch: [903][0/196]	Time 0.810 (0.810)	Data 0.092 (0.092)	Loss 0.2362 (0.2362)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [903][100/196]	Time 0.083 (0.094)	Data 0.000 (0.001)	Loss 0.3590 (0.2465)	Prec@1 86.719 (91.259)	Prec@5 100.000 (99.903)
EVALUATING - Epoch: [903][0/79]	Time 0.072 (0.072)	Data 0.050 (0.050)	Loss 0.3314 (0.3314)	Prec@1 85.156 (85.156)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:13

 Epoch: 904	Training Loss 0.2497 	Training Prec@1 91.196 	Training Prec@5 99.890 	Validation Loss 0.4276 	Validation Prec@1 86.170 	Validation Prec@5 99.530 

lr: 0.002466798147621597
TRAINING - Epoch: [904][0/196]	Time 0.759 (0.759)	Data 0.083 (0.083)	Loss 0.2270 (0.2270)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [904][100/196]	Time 0.090 (0.093)	Data 0.000 (0.001)	Loss 0.2789 (0.2557)	Prec@1 91.406 (90.830)	Prec@5 98.828 (99.849)
EVALUATING - Epoch: [904][0/79]	Time 0.076 (0.076)	Data 0.056 (0.056)	Loss 0.3230 (0.3230)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:29

 Epoch: 905	Training Loss 0.2535 	Training Prec@1 90.952 	Training Prec@5 99.842 	Validation Loss 0.4107 	Validation Prec@1 86.480 	Validation Prec@5 99.570 

lr: 0.002418108447340101
TRAINING - Epoch: [905][0/196]	Time 0.370 (0.370)	Data 0.120 (0.120)	Loss 0.2051 (0.2051)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [905][100/196]	Time 0.085 (0.088)	Data 0.000 (0.001)	Loss 0.2307 (0.2606)	Prec@1 93.359 (90.637)	Prec@5 100.000 (99.841)
EVALUATING - Epoch: [905][0/79]	Time 0.076 (0.076)	Data 0.052 (0.052)	Loss 0.3149 (0.3149)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:00

 Epoch: 906	Training Loss 0.2553 	Training Prec@1 90.858 	Training Prec@5 99.850 	Validation Loss 0.4291 	Validation Prec@1 86.180 	Validation Prec@5 99.510 

lr: 0.002369892159250122
TRAINING - Epoch: [906][0/196]	Time 0.770 (0.770)	Data 0.108 (0.108)	Loss 0.1685 (0.1685)	Prec@1 94.141 (94.141)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [906][100/196]	Time 0.087 (0.081)	Data 0.000 (0.001)	Loss 0.2902 (0.2513)	Prec@1 91.406 (91.186)	Prec@5 99.219 (99.849)
EVALUATING - Epoch: [906][0/79]	Time 0.074 (0.074)	Data 0.053 (0.053)	Loss 0.3690 (0.3690)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:16

 Epoch: 907	Training Loss 0.2544 	Training Prec@1 91.068 	Training Prec@5 99.828 	Validation Loss 0.4205 	Validation Prec@1 86.420 	Validation Prec@5 99.490 

lr: 0.002322149763056941
TRAINING - Epoch: [907][0/196]	Time 0.746 (0.746)	Data 0.089 (0.089)	Loss 0.2655 (0.2655)	Prec@1 89.453 (89.453)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [907][100/196]	Time 0.046 (0.089)	Data 0.000 (0.001)	Loss 0.2592 (0.2530)	Prec@1 91.016 (90.989)	Prec@5 100.000 (99.865)
EVALUATING - Epoch: [907][0/79]	Time 0.089 (0.089)	Data 0.067 (0.067)	Loss 0.4539 (0.4539)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:47

 Epoch: 908	Training Loss 0.2502 	Training Prec@1 91.138 	Training Prec@5 99.852 	Validation Loss 0.4333 	Validation Prec@1 86.070 	Validation Prec@5 99.500 

lr: 0.00227488173375104
TRAINING - Epoch: [908][0/196]	Time 0.803 (0.803)	Data 0.088 (0.088)	Loss 0.2613 (0.2613)	Prec@1 89.062 (89.062)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [908][100/196]	Time 0.065 (0.094)	Data 0.000 (0.001)	Loss 0.2772 (0.2595)	Prec@1 90.625 (90.838)	Prec@5 100.000 (99.799)
EVALUATING - Epoch: [908][0/79]	Time 0.081 (0.081)	Data 0.057 (0.057)	Loss 0.3290 (0.3290)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:41

 Epoch: 909	Training Loss 0.2535 	Training Prec@1 91.082 	Training Prec@5 99.838 	Validation Loss 0.4177 	Validation Prec@1 86.520 	Validation Prec@5 99.500 

lr: 0.0022280885416034227
TRAINING - Epoch: [909][0/196]	Time 0.709 (0.709)	Data 0.081 (0.081)	Loss 0.2910 (0.2910)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [909][100/196]	Time 0.085 (0.095)	Data 0.000 (0.001)	Loss 0.2527 (0.2474)	Prec@1 91.016 (91.151)	Prec@5 100.000 (99.861)
EVALUATING - Epoch: [909][0/79]	Time 0.079 (0.079)	Data 0.057 (0.057)	Loss 0.3586 (0.3586)	Prec@1 84.375 (84.375)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:43

 Epoch: 910	Training Loss 0.2519 	Training Prec@1 91.048 	Training Prec@5 99.834 	Validation Loss 0.4139 	Validation Prec@1 86.530 	Validation Prec@5 99.610 

lr: 0.0021817706521609285
TRAINING - Epoch: [910][0/196]	Time 0.377 (0.377)	Data 0.091 (0.091)	Loss 0.3679 (0.3679)	Prec@1 86.328 (86.328)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [910][100/196]	Time 0.083 (0.091)	Data 0.000 (0.001)	Loss 0.1990 (0.2568)	Prec@1 93.750 (90.822)	Prec@5 99.609 (99.857)
EVALUATING - Epoch: [910][0/79]	Time 0.090 (0.090)	Data 0.073 (0.073)	Loss 0.3272 (0.3272)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:50

 Epoch: 911	Training Loss 0.2569 	Training Prec@1 90.856 	Training Prec@5 99.842 	Validation Loss 0.4268 	Validation Prec@1 86.170 	Validation Prec@5 99.490 

lr: 0.002135928526241608
TRAINING - Epoch: [911][0/196]	Time 0.828 (0.828)	Data 0.095 (0.095)	Loss 0.2951 (0.2951)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [911][100/196]	Time 0.092 (0.084)	Data 0.000 (0.001)	Loss 0.2669 (0.2510)	Prec@1 91.406 (90.985)	Prec@5 100.000 (99.857)
EVALUATING - Epoch: [911][0/79]	Time 0.087 (0.087)	Data 0.067 (0.067)	Loss 0.4166 (0.4166)	Prec@1 85.156 (85.156)	Prec@5 98.438 (98.438)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:16

 Epoch: 912	Training Loss 0.2540 	Training Prec@1 90.876 	Training Prec@5 99.836 	Validation Loss 0.4239 	Validation Prec@1 86.440 	Validation Prec@5 99.470 

lr: 0.0020905626199301114
TRAINING - Epoch: [912][0/196]	Time 0.773 (0.773)	Data 0.109 (0.109)	Loss 0.1525 (0.1525)	Prec@1 96.484 (96.484)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [912][100/196]	Time 0.056 (0.086)	Data 0.000 (0.001)	Loss 0.1748 (0.2452)	Prec@1 94.531 (91.248)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [912][0/79]	Time 0.072 (0.072)	Data 0.049 (0.049)	Loss 0.3544 (0.3544)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:25

 Epoch: 913	Training Loss 0.2504 	Training Prec@1 91.064 	Training Prec@5 99.848 	Validation Loss 0.4229 	Validation Prec@1 86.440 	Validation Prec@5 99.480 

lr: 0.0020456733845731507
TRAINING - Epoch: [913][0/196]	Time 0.845 (0.845)	Data 0.102 (0.102)	Loss 0.2617 (0.2617)	Prec@1 89.453 (89.453)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [913][100/196]	Time 0.090 (0.094)	Data 0.000 (0.001)	Loss 0.2636 (0.2518)	Prec@1 91.797 (90.958)	Prec@5 100.000 (99.869)
EVALUATING - Epoch: [913][0/79]	Time 0.090 (0.090)	Data 0.067 (0.067)	Loss 0.3923 (0.3923)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:08

 Epoch: 914	Training Loss 0.2551 	Training Prec@1 90.872 	Training Prec@5 99.852 	Validation Loss 0.4179 	Validation Prec@1 86.490 	Validation Prec@5 99.490 

lr: 0.002001261266775055
TRAINING - Epoch: [914][0/196]	Time 0.793 (0.793)	Data 0.091 (0.091)	Loss 0.2051 (0.2051)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [914][100/196]	Time 0.092 (0.095)	Data 0.000 (0.001)	Loss 0.2236 (0.2597)	Prec@1 90.625 (90.722)	Prec@5 100.000 (99.845)
EVALUATING - Epoch: [914][0/79]	Time 0.072 (0.072)	Data 0.050 (0.050)	Loss 0.3655 (0.3655)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:33

 Epoch: 915	Training Loss 0.2542 	Training Prec@1 90.992 	Training Prec@5 99.866 	Validation Loss 0.4079 	Validation Prec@1 86.640 	Validation Prec@5 99.530 

lr: 0.0019573267083932843
TRAINING - Epoch: [915][0/196]	Time 0.465 (0.465)	Data 0.141 (0.141)	Loss 0.2587 (0.2587)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [915][100/196]	Time 0.087 (0.090)	Data 0.000 (0.002)	Loss 0.2691 (0.2524)	Prec@1 89.453 (90.861)	Prec@5 99.219 (99.814)
EVALUATING - Epoch: [915][0/79]	Time 0.074 (0.074)	Data 0.056 (0.056)	Loss 0.2682 (0.2682)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:18

 Epoch: 916	Training Loss 0.2483 	Training Prec@1 91.014 	Training Prec@5 99.804 	Validation Loss 0.4020 	Validation Prec@1 86.850 	Validation Prec@5 99.380 

lr: 0.0019138701465340495
TRAINING - Epoch: [916][0/196]	Time 0.774 (0.774)	Data 0.090 (0.090)	Loss 0.2426 (0.2426)	Prec@1 91.016 (91.016)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [916][100/196]	Time 0.085 (0.083)	Data 0.000 (0.001)	Loss 0.2721 (0.2550)	Prec@1 91.406 (90.722)	Prec@5 100.000 (99.838)
EVALUATING - Epoch: [916][0/79]	Time 0.076 (0.076)	Data 0.054 (0.054)	Loss 0.3109 (0.3109)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:25

 Epoch: 917	Training Loss 0.2549 	Training Prec@1 90.820 	Training Prec@5 99.836 	Validation Loss 0.4207 	Validation Prec@1 86.130 	Validation Prec@5 99.540 

lr: 0.0018708920135479489
TRAINING - Epoch: [917][0/196]	Time 0.751 (0.751)	Data 0.104 (0.104)	Loss 0.2412 (0.2412)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [917][100/196]	Time 0.052 (0.086)	Data 0.000 (0.001)	Loss 0.2855 (0.2581)	Prec@1 89.844 (90.799)	Prec@5 100.000 (99.810)
EVALUATING - Epoch: [917][0/79]	Time 0.073 (0.073)	Data 0.050 (0.050)	Loss 0.3152 (0.3152)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:52

 Epoch: 918	Training Loss 0.2557 	Training Prec@1 90.914 	Training Prec@5 99.830 	Validation Loss 0.3988 	Validation Prec@1 86.960 	Validation Prec@5 99.520 

lr: 0.0018283927370256888
TRAINING - Epoch: [918][0/196]	Time 0.742 (0.742)	Data 0.092 (0.092)	Loss 0.2085 (0.2085)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [918][100/196]	Time 0.082 (0.090)	Data 0.000 (0.001)	Loss 0.2578 (0.2526)	Prec@1 91.406 (90.791)	Prec@5 99.609 (99.865)
EVALUATING - Epoch: [918][0/79]	Time 0.084 (0.084)	Data 0.065 (0.065)	Loss 0.3665 (0.3665)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:42:47

 Epoch: 919	Training Loss 0.2526 	Training Prec@1 90.882 	Training Prec@5 99.840 	Validation Loss 0.4089 	Validation Prec@1 86.530 	Validation Prec@5 99.490 

lr: 0.001786372739793814
TRAINING - Epoch: [919][0/196]	Time 0.739 (0.739)	Data 0.089 (0.089)	Loss 0.2321 (0.2321)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [919][100/196]	Time 0.073 (0.092)	Data 0.000 (0.001)	Loss 0.2651 (0.2576)	Prec@1 90.234 (90.753)	Prec@5 100.000 (99.826)
EVALUATING - Epoch: [919][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 0.4215 (0.4215)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:26

 Epoch: 920	Training Loss 0.2578 	Training Prec@1 90.860 	Training Prec@5 99.820 	Validation Loss 0.4106 	Validation Prec@1 86.800 	Validation Prec@5 99.580 

lr: 0.0017448324399105054
TRAINING - Epoch: [920][0/196]	Time 0.461 (0.461)	Data 0.092 (0.092)	Loss 0.2046 (0.2046)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [920][100/196]	Time 0.091 (0.084)	Data 0.000 (0.001)	Loss 0.1742 (0.2442)	Prec@1 92.969 (91.163)	Prec@5 100.000 (99.822)
EVALUATING - Epoch: [920][0/79]	Time 0.085 (0.085)	Data 0.067 (0.067)	Loss 0.3588 (0.3588)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:17

 Epoch: 921	Training Loss 0.2515 	Training Prec@1 91.058 	Training Prec@5 99.820 	Validation Loss 0.4170 	Validation Prec@1 86.180 	Validation Prec@5 99.530 

lr: 0.0017037722506614223
TRAINING - Epoch: [921][0/196]	Time 0.761 (0.761)	Data 0.084 (0.084)	Loss 0.2481 (0.2481)	Prec@1 90.234 (90.234)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [921][100/196]	Time 0.083 (0.080)	Data 0.000 (0.001)	Loss 0.3037 (0.2615)	Prec@1 90.625 (90.497)	Prec@5 99.609 (99.841)
EVALUATING - Epoch: [921][0/79]	Time 0.073 (0.073)	Data 0.051 (0.051)	Loss 0.5014 (0.5014)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:00

 Epoch: 922	Training Loss 0.2557 	Training Prec@1 90.862 	Training Prec@5 99.830 	Validation Loss 0.4073 	Validation Prec@1 86.560 	Validation Prec@5 99.590 

lr: 0.0016631925805556
TRAINING - Epoch: [922][0/196]	Time 0.820 (0.820)	Data 0.104 (0.104)	Loss 0.2428 (0.2428)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [922][100/196]	Time 0.090 (0.095)	Data 0.000 (0.001)	Loss 0.2761 (0.2459)	Prec@1 92.188 (91.136)	Prec@5 100.000 (99.865)
EVALUATING - Epoch: [922][0/79]	Time 0.077 (0.077)	Data 0.057 (0.057)	Loss 0.3966 (0.3966)	Prec@1 85.938 (85.938)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:13

 Epoch: 923	Training Loss 0.2511 	Training Prec@1 90.928 	Training Prec@5 99.862 	Validation Loss 0.4178 	Validation Prec@1 86.570 	Validation Prec@5 99.570 

lr: 0.0016230938333213474
TRAINING - Epoch: [923][0/196]	Time 0.760 (0.760)	Data 0.087 (0.087)	Loss 0.2901 (0.2901)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [923][100/196]	Time 0.089 (0.093)	Data 0.000 (0.001)	Loss 0.2692 (0.2629)	Prec@1 89.062 (90.625)	Prec@5 100.000 (99.810)
EVALUATING - Epoch: [923][0/79]	Time 0.101 (0.101)	Data 0.075 (0.075)	Loss 0.3567 (0.3567)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:20

 Epoch: 924	Training Loss 0.2576 	Training Prec@1 90.728 	Training Prec@5 99.826 	Validation Loss 0.4112 	Validation Prec@1 86.810 	Validation Prec@5 99.670 

lr: 0.001583476407902288
TRAINING - Epoch: [924][0/196]	Time 0.744 (0.744)	Data 0.089 (0.089)	Loss 0.2983 (0.2983)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [924][100/196]	Time 0.095 (0.092)	Data 0.000 (0.001)	Loss 0.2384 (0.2518)	Prec@1 92.188 (90.946)	Prec@5 100.000 (99.838)
EVALUATING - Epoch: [924][0/79]	Time 0.083 (0.083)	Data 0.058 (0.058)	Loss 0.2688 (0.2688)	Prec@1 91.406 (91.406)	Prec@5 98.438 (98.438)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:31

 Epoch: 925	Training Loss 0.2513 	Training Prec@1 90.896 	Training Prec@5 99.856 	Validation Loss 0.4239 	Validation Prec@1 86.200 	Validation Prec@5 99.550 

lr: 0.0015443406984533311
TRAINING - Epoch: [925][0/196]	Time 0.838 (0.838)	Data 0.111 (0.111)	Loss 0.2957 (0.2957)	Prec@1 89.453 (89.453)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [925][100/196]	Time 0.092 (0.083)	Data 0.000 (0.001)	Loss 0.2923 (0.2499)	Prec@1 89.453 (91.143)	Prec@5 100.000 (99.853)
EVALUATING - Epoch: [925][0/79]	Time 0.083 (0.083)	Data 0.059 (0.059)	Loss 0.4061 (0.4061)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:27

 Epoch: 926	Training Loss 0.2505 	Training Prec@1 91.104 	Training Prec@5 99.838 	Validation Loss 0.4108 	Validation Prec@1 86.490 	Validation Prec@5 99.570 

lr: 0.001505687094336813
TRAINING - Epoch: [926][0/196]	Time 0.776 (0.776)	Data 0.083 (0.083)	Loss 0.2324 (0.2324)	Prec@1 92.188 (92.188)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [926][100/196]	Time 0.087 (0.084)	Data 0.000 (0.001)	Loss 0.2408 (0.2468)	Prec@1 91.797 (91.108)	Prec@5 100.000 (99.865)
EVALUATING - Epoch: [926][0/79]	Time 0.082 (0.082)	Data 0.059 (0.059)	Loss 0.3909 (0.3909)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:35

 Epoch: 927	Training Loss 0.2500 	Training Prec@1 90.922 	Training Prec@5 99.856 	Validation Loss 0.4196 	Validation Prec@1 87.080 	Validation Prec@5 99.470 

lr: 0.001467515980118566
TRAINING - Epoch: [927][0/196]	Time 0.771 (0.771)	Data 0.084 (0.084)	Loss 0.3349 (0.3349)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [927][100/196]	Time 0.092 (0.094)	Data 0.000 (0.001)	Loss 0.2371 (0.2489)	Prec@1 91.797 (90.838)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [927][0/79]	Time 0.069 (0.069)	Data 0.049 (0.049)	Loss 0.2937 (0.2937)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:35

 Epoch: 928	Training Loss 0.2496 	Training Prec@1 90.914 	Training Prec@5 99.832 	Validation Loss 0.4238 	Validation Prec@1 86.560 	Validation Prec@5 99.590 

lr: 0.0014298277355641222
TRAINING - Epoch: [928][0/196]	Time 0.791 (0.791)	Data 0.094 (0.094)	Loss 0.1882 (0.1882)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [928][100/196]	Time 0.089 (0.094)	Data 0.000 (0.001)	Loss 0.2585 (0.2565)	Prec@1 91.016 (91.012)	Prec@5 100.000 (99.803)
EVALUATING - Epoch: [928][0/79]	Time 0.081 (0.081)	Data 0.058 (0.058)	Loss 0.4303 (0.4303)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:35

 Epoch: 929	Training Loss 0.2529 	Training Prec@1 91.064 	Training Prec@5 99.810 	Validation Loss 0.4216 	Validation Prec@1 86.270 	Validation Prec@5 99.460 

lr: 0.0013926227356349222
TRAINING - Epoch: [929][0/196]	Time 0.748 (0.748)	Data 0.108 (0.108)	Loss 0.1740 (0.1740)	Prec@1 94.141 (94.141)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [929][100/196]	Time 0.083 (0.094)	Data 0.000 (0.001)	Loss 0.3270 (0.2541)	Prec@1 87.500 (90.733)	Prec@5 100.000 (99.869)
EVALUATING - Epoch: [929][0/79]	Time 0.080 (0.080)	Data 0.061 (0.061)	Loss 0.3005 (0.3005)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:19	Time of Finish: 2024-03-31 19:44:49

 Epoch: 930	Training Loss 0.2512 	Training Prec@1 90.982 	Training Prec@5 99.840 	Validation Loss 0.4083 	Validation Prec@1 86.640 	Validation Prec@5 99.550 

lr: 0.0013559013504846108
TRAINING - Epoch: [930][0/196]	Time 0.437 (0.437)	Data 0.082 (0.082)	Loss 0.2366 (0.2366)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [930][100/196]	Time 0.085 (0.082)	Data 0.000 (0.001)	Loss 0.2018 (0.2557)	Prec@1 91.406 (90.934)	Prec@5 100.000 (99.826)
EVALUATING - Epoch: [930][0/79]	Time 0.075 (0.075)	Data 0.053 (0.053)	Loss 0.3659 (0.3659)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:17	Time of Finish: 2024-03-31 19:43:16

 Epoch: 931	Training Loss 0.2577 	Training Prec@1 90.778 	Training Prec@5 99.788 	Validation Loss 0.4175 	Validation Prec@1 86.410 	Validation Prec@5 99.550 

lr: 0.0013196639454553195
TRAINING - Epoch: [931][0/196]	Time 0.776 (0.776)	Data 0.081 (0.081)	Loss 0.2182 (0.2182)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [931][100/196]	Time 0.084 (0.086)	Data 0.000 (0.001)	Loss 0.3005 (0.2512)	Prec@1 91.797 (91.062)	Prec@5 99.609 (99.818)
EVALUATING - Epoch: [931][0/79]	Time 0.075 (0.075)	Data 0.054 (0.054)	Loss 0.4286 (0.4286)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:52

 Epoch: 932	Training Loss 0.2557 	Training Prec@1 90.786 	Training Prec@5 99.836 	Validation Loss 0.4197 	Validation Prec@1 86.560 	Validation Prec@5 99.540 

lr: 0.0012839108810740456
TRAINING - Epoch: [932][0/196]	Time 0.820 (0.820)	Data 0.104 (0.104)	Loss 0.1702 (0.1702)	Prec@1 96.094 (96.094)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [932][100/196]	Time 0.055 (0.093)	Data 0.000 (0.001)	Loss 0.2498 (0.2540)	Prec@1 89.844 (90.780)	Prec@5 100.000 (99.810)
EVALUATING - Epoch: [932][0/79]	Time 0.072 (0.072)	Data 0.053 (0.053)	Loss 0.2710 (0.2710)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:58

 Epoch: 933	Training Loss 0.2528 	Training Prec@1 90.840 	Training Prec@5 99.844 	Validation Loss 0.4094 	Validation Prec@1 86.980 	Validation Prec@5 99.420 

lr: 0.001248642513049089
TRAINING - Epoch: [933][0/196]	Time 0.702 (0.702)	Data 0.081 (0.081)	Loss 0.2647 (0.2647)	Prec@1 90.625 (90.625)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [933][100/196]	Time 0.089 (0.094)	Data 0.000 (0.001)	Loss 0.2831 (0.2586)	Prec@1 91.406 (90.791)	Prec@5 100.000 (99.857)
EVALUATING - Epoch: [933][0/79]	Time 0.076 (0.076)	Data 0.059 (0.059)	Loss 0.3551 (0.3551)	Prec@1 89.062 (89.062)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:43:31

 Epoch: 934	Training Loss 0.2581 	Training Prec@1 90.756 	Training Prec@5 99.830 	Validation Loss 0.4128 	Validation Prec@1 86.590 	Validation Prec@5 99.590 

lr: 0.001213859192266455
TRAINING - Epoch: [934][0/196]	Time 0.781 (0.781)	Data 0.098 (0.098)	Loss 0.1961 (0.1961)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [934][100/196]	Time 0.080 (0.094)	Data 0.000 (0.001)	Loss 0.2587 (0.2529)	Prec@1 90.625 (91.012)	Prec@5 100.000 (99.861)
EVALUATING - Epoch: [934][0/79]	Time 0.074 (0.074)	Data 0.053 (0.053)	Loss 0.4031 (0.4031)	Prec@1 86.719 (86.719)	Prec@5 99.219 (99.219)
Time cost: 00:18	Time of Finish: 2024-03-31 19:44:14

 Epoch: 935	Training Loss 0.2540 	Training Prec@1 91.054 	Training Prec@5 99.856 	Validation Loss 0.3978 	Validation Prec@1 87.250 	Validation Prec@5 99.480 

lr: 0.001179561264786434
TRAINING - Epoch: [935][0/196]	Time 0.459 (0.459)	Data 0.110 (0.110)	Loss 0.2526 (0.2526)	Prec@1 88.672 (88.672)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [935][100/196]	Time 0.030 (0.032)	Data 0.000 (0.001)	Loss 0.2239 (0.2482)	Prec@1 95.312 (91.112)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [935][0/79]	Time 0.069 (0.069)	Data 0.048 (0.048)	Loss 0.3525 (0.3525)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:05

 Epoch: 936	Training Loss 0.2539 	Training Prec@1 90.894 	Training Prec@5 99.854 	Validation Loss 0.4096 	Validation Prec@1 86.790 	Validation Prec@5 99.540 

lr: 0.0011457490718400994
TRAINING - Epoch: [936][0/196]	Time 0.275 (0.275)	Data 0.097 (0.097)	Loss 0.2071 (0.2071)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [936][100/196]	Time 0.027 (0.029)	Data 0.000 (0.001)	Loss 0.2159 (0.2578)	Prec@1 93.359 (90.888)	Prec@5 100.000 (99.841)
EVALUATING - Epoch: [936][0/79]	Time 0.073 (0.073)	Data 0.056 (0.056)	Loss 0.3317 (0.3317)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:42

 Epoch: 937	Training Loss 0.2553 	Training Prec@1 90.896 	Training Prec@5 99.866 	Validation Loss 0.4212 	Validation Prec@1 86.280 	Validation Prec@5 99.520 

lr: 0.0011124229498259595
TRAINING - Epoch: [937][0/196]	Time 0.270 (0.270)	Data 0.085 (0.085)	Loss 0.2677 (0.2677)	Prec@1 91.797 (91.797)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [937][100/196]	Time 0.026 (0.029)	Data 0.000 (0.001)	Loss 0.2335 (0.2425)	Prec@1 92.188 (91.313)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [937][0/79]	Time 0.075 (0.075)	Data 0.058 (0.058)	Loss 0.4417 (0.4417)	Prec@1 89.062 (89.062)	Prec@5 98.438 (98.438)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:41

 Epoch: 938	Training Loss 0.2505 	Training Prec@1 91.110 	Training Prec@5 99.850 	Validation Loss 0.4267 	Validation Prec@1 86.040 	Validation Prec@5 99.500 

lr: 0.001079583230306583
TRAINING - Epoch: [938][0/196]	Time 0.276 (0.276)	Data 0.084 (0.084)	Loss 0.2808 (0.2808)	Prec@1 90.625 (90.625)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [938][100/196]	Time 0.028 (0.031)	Data 0.000 (0.001)	Loss 0.2071 (0.2465)	Prec@1 94.531 (91.101)	Prec@5 98.828 (99.869)
EVALUATING - Epoch: [938][0/79]	Time 0.072 (0.072)	Data 0.057 (0.057)	Loss 0.3341 (0.3341)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:57

 Epoch: 939	Training Loss 0.2499 	Training Prec@1 91.158 	Training Prec@5 99.852 	Validation Loss 0.4190 	Validation Prec@1 86.740 	Validation Prec@5 99.450 

lr: 0.0010472302400052784
TRAINING - Epoch: [939][0/196]	Time 0.292 (0.292)	Data 0.096 (0.096)	Loss 0.2553 (0.2553)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [939][100/196]	Time 0.036 (0.037)	Data 0.000 (0.001)	Loss 0.2432 (0.2511)	Prec@1 91.016 (91.166)	Prec@5 100.000 (99.841)
EVALUATING - Epoch: [939][0/79]	Time 0.067 (0.067)	Data 0.048 (0.048)	Loss 0.2959 (0.2959)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:07	Time of Finish: 2024-03-31 19:32:13

 Epoch: 940	Training Loss 0.2504 	Training Prec@1 91.176 	Training Prec@5 99.836 	Validation Loss 0.4143 	Validation Prec@1 86.230 	Validation Prec@5 99.550 

lr: 0.0010153643008029088
TRAINING - Epoch: [940][0/196]	Time 0.269 (0.269)	Data 0.080 (0.080)	Loss 0.2232 (0.2232)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [940][100/196]	Time 0.032 (0.031)	Data 0.000 (0.001)	Loss 0.2511 (0.2495)	Prec@1 89.844 (91.232)	Prec@5 100.000 (99.818)
EVALUATING - Epoch: [940][0/79]	Time 0.063 (0.063)	Data 0.049 (0.049)	Loss 0.4098 (0.4098)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:24

 Epoch: 941	Training Loss 0.2524 	Training Prec@1 91.072 	Training Prec@5 99.838 	Validation Loss 0.4032 	Validation Prec@1 86.830 	Validation Prec@5 99.610 

lr: 0.0009839857297346318
TRAINING - Epoch: [941][0/196]	Time 0.318 (0.318)	Data 0.077 (0.077)	Loss 0.2179 (0.2179)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [941][100/196]	Time 0.026 (0.039)	Data 0.000 (0.001)	Loss 0.2689 (0.2515)	Prec@1 92.188 (91.019)	Prec@5 100.000 (99.857)
EVALUATING - Epoch: [941][0/79]	Time 0.068 (0.068)	Data 0.048 (0.048)	Loss 0.3291 (0.3291)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:07	Time of Finish: 2024-03-31 19:32:23

 Epoch: 942	Training Loss 0.2549 	Training Prec@1 90.886 	Training Prec@5 99.860 	Validation Loss 0.4230 	Validation Prec@1 86.200 	Validation Prec@5 99.520 

lr: 0.0009530948389867752
TRAINING - Epoch: [942][0/196]	Time 0.279 (0.279)	Data 0.091 (0.091)	Loss 0.2426 (0.2426)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [942][100/196]	Time 0.027 (0.034)	Data 0.000 (0.001)	Loss 0.2673 (0.2486)	Prec@1 93.359 (91.170)	Prec@5 99.609 (99.826)
EVALUATING - Epoch: [942][0/79]	Time 0.066 (0.066)	Data 0.047 (0.047)	Loss 0.3367 (0.3367)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:19

 Epoch: 943	Training Loss 0.2515 	Training Prec@1 91.150 	Training Prec@5 99.838 	Validation Loss 0.4215 	Validation Prec@1 86.300 	Validation Prec@5 99.400 

lr: 0.0009226919358937056
TRAINING - Epoch: [943][0/196]	Time 0.292 (0.292)	Data 0.077 (0.077)	Loss 0.2490 (0.2490)	Prec@1 92.188 (92.188)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [943][100/196]	Time 0.027 (0.033)	Data 0.000 (0.001)	Loss 0.2848 (0.2491)	Prec@1 88.672 (91.201)	Prec@5 100.000 (99.845)
EVALUATING - Epoch: [943][0/79]	Time 0.073 (0.073)	Data 0.056 (0.056)	Loss 0.3823 (0.3823)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:30

 Epoch: 944	Training Loss 0.2525 	Training Prec@1 91.114 	Training Prec@5 99.852 	Validation Loss 0.4192 	Validation Prec@1 86.830 	Validation Prec@5 99.450 

lr: 0.0008927773229348031
TRAINING - Epoch: [944][0/196]	Time 0.293 (0.293)	Data 0.084 (0.084)	Loss 0.2557 (0.2557)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [944][100/196]	Time 0.029 (0.031)	Data 0.000 (0.001)	Loss 0.2271 (0.2536)	Prec@1 90.234 (90.996)	Prec@5 99.609 (99.853)
EVALUATING - Epoch: [944][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 0.3742 (0.3742)	Prec@1 85.938 (85.938)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:20

 Epoch: 945	Training Loss 0.2537 	Training Prec@1 90.942 	Training Prec@5 99.858 	Validation Loss 0.4093 	Validation Prec@1 86.730 	Validation Prec@5 99.580 

lr: 0.0008633512977314192
TRAINING - Epoch: [945][0/196]	Time 0.277 (0.277)	Data 0.088 (0.088)	Loss 0.2187 (0.2187)	Prec@1 94.531 (94.531)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [945][100/196]	Time 0.035 (0.031)	Data 0.000 (0.001)	Loss 0.3045 (0.2464)	Prec@1 91.016 (91.116)	Prec@5 99.609 (99.849)
EVALUATING - Epoch: [945][0/79]	Time 0.066 (0.066)	Data 0.048 (0.048)	Loss 0.3544 (0.3544)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:09

 Epoch: 946	Training Loss 0.2502 	Training Prec@1 91.112 	Training Prec@5 99.846 	Validation Loss 0.4050 	Validation Prec@1 86.830 	Validation Prec@5 99.530 

lr: 0.0008344141530439508
TRAINING - Epoch: [946][0/196]	Time 0.288 (0.288)	Data 0.076 (0.076)	Loss 0.2482 (0.2482)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [946][100/196]	Time 0.028 (0.030)	Data 0.000 (0.001)	Loss 0.3012 (0.2558)	Prec@1 90.625 (90.965)	Prec@5 100.000 (99.872)
EVALUATING - Epoch: [946][0/79]	Time 0.067 (0.067)	Data 0.047 (0.047)	Loss 0.4000 (0.4000)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:55

 Epoch: 947	Training Loss 0.2555 	Training Prec@1 90.938 	Training Prec@5 99.852 	Validation Loss 0.4189 	Validation Prec@1 86.680 	Validation Prec@5 99.430 

lr: 0.0008059661767688875
TRAINING - Epoch: [947][0/196]	Time 0.273 (0.273)	Data 0.092 (0.092)	Loss 0.2627 (0.2627)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [947][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.2454 (0.2479)	Prec@1 91.016 (91.027)	Prec@5 100.000 (99.865)
EVALUATING - Epoch: [947][0/79]	Time 0.067 (0.067)	Data 0.047 (0.047)	Loss 0.3570 (0.3570)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:56

 Epoch: 948	Training Loss 0.2510 	Training Prec@1 91.036 	Training Prec@5 99.846 	Validation Loss 0.4049 	Validation Prec@1 86.860 	Validation Prec@5 99.550 

lr: 0.0007780076519359911
TRAINING - Epoch: [948][0/196]	Time 0.269 (0.269)	Data 0.085 (0.085)	Loss 0.2901 (0.2901)	Prec@1 90.625 (90.625)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [948][100/196]	Time 0.032 (0.029)	Data 0.000 (0.001)	Loss 0.3076 (0.2565)	Prec@1 88.672 (91.012)	Prec@5 100.000 (99.803)
EVALUATING - Epoch: [948][0/79]	Time 0.070 (0.070)	Data 0.055 (0.055)	Loss 0.2614 (0.2614)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:58

 Epoch: 949	Training Loss 0.2525 	Training Prec@1 91.082 	Training Prec@5 99.808 	Validation Loss 0.4141 	Validation Prec@1 86.490 	Validation Prec@5 99.440 

lr: 0.0007505388567054261
TRAINING - Epoch: [949][0/196]	Time 0.321 (0.321)	Data 0.095 (0.095)	Loss 0.2548 (0.2548)	Prec@1 91.406 (91.406)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [949][100/196]	Time 0.025 (0.031)	Data 0.000 (0.001)	Loss 0.2277 (0.2441)	Prec@1 92.188 (91.352)	Prec@5 99.609 (99.861)
EVALUATING - Epoch: [949][0/79]	Time 0.073 (0.073)	Data 0.054 (0.054)	Loss 0.4018 (0.4018)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:03

 Epoch: 950	Training Loss 0.2509 	Training Prec@1 91.078 	Training Prec@5 99.840 	Validation Loss 0.4181 	Validation Prec@1 86.440 	Validation Prec@5 99.510 

lr: 0.00072356006436505
TRAINING - Epoch: [950][0/196]	Time 0.275 (0.275)	Data 0.083 (0.083)	Loss 0.2157 (0.2157)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [950][100/196]	Time 0.025 (0.032)	Data 0.000 (0.001)	Loss 0.3464 (0.2573)	Prec@1 86.719 (90.954)	Prec@5 100.000 (99.845)
EVALUATING - Epoch: [950][0/79]	Time 0.072 (0.072)	Data 0.049 (0.049)	Loss 0.3723 (0.3723)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:16

 Epoch: 951	Training Loss 0.2577 	Training Prec@1 90.876 	Training Prec@5 99.838 	Validation Loss 0.4173 	Validation Prec@1 86.680 	Validation Prec@5 99.540 

lr: 0.0006970715433276602
TRAINING - Epoch: [951][0/196]	Time 0.293 (0.293)	Data 0.084 (0.084)	Loss 0.2848 (0.2848)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [951][100/196]	Time 0.027 (0.031)	Data 0.000 (0.001)	Loss 0.2843 (0.2585)	Prec@1 92.188 (90.633)	Prec@5 100.000 (99.834)
EVALUATING - Epoch: [951][0/79]	Time 0.077 (0.077)	Data 0.059 (0.059)	Loss 0.2977 (0.2977)	Prec@1 88.281 (88.281)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:05

 Epoch: 952	Training Loss 0.2592 	Training Prec@1 90.680 	Training Prec@5 99.826 	Validation Loss 0.4134 	Validation Prec@1 86.680 	Validation Prec@5 99.530 

lr: 0.0006710735571283236
TRAINING - Epoch: [952][0/196]	Time 0.276 (0.276)	Data 0.083 (0.083)	Loss 0.2827 (0.2827)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [952][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.2668 (0.2493)	Prec@1 90.625 (91.108)	Prec@5 99.609 (99.849)
EVALUATING - Epoch: [952][0/79]	Time 0.070 (0.070)	Data 0.052 (0.052)	Loss 0.3023 (0.3023)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:55

 Epoch: 953	Training Loss 0.2508 	Training Prec@1 91.062 	Training Prec@5 99.844 	Validation Loss 0.4109 	Validation Prec@1 86.570 	Validation Prec@5 99.570 

lr: 0.000645566364421768
TRAINING - Epoch: [953][0/196]	Time 0.280 (0.280)	Data 0.082 (0.082)	Loss 0.2115 (0.2115)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [953][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.2288 (0.2500)	Prec@1 91.016 (91.240)	Prec@5 100.000 (99.841)
EVALUATING - Epoch: [953][0/79]	Time 0.073 (0.073)	Data 0.055 (0.055)	Loss 0.3121 (0.3121)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:55

 Epoch: 954	Training Loss 0.2475 	Training Prec@1 91.308 	Training Prec@5 99.850 	Validation Loss 0.4044 	Validation Prec@1 86.740 	Validation Prec@5 99.580 

lr: 0.0006205502189797889
TRAINING - Epoch: [954][0/196]	Time 0.291 (0.291)	Data 0.079 (0.079)	Loss 0.2256 (0.2256)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [954][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.1943 (0.2503)	Prec@1 92.578 (91.139)	Prec@5 100.000 (99.841)
EVALUATING - Epoch: [954][0/79]	Time 0.070 (0.070)	Data 0.051 (0.051)	Loss 0.3593 (0.3593)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:04

 Epoch: 955	Training Loss 0.2528 	Training Prec@1 91.016 	Training Prec@5 99.840 	Validation Loss 0.4173 	Validation Prec@1 86.880 	Validation Prec@5 99.560 

lr: 0.0005960253696887631
TRAINING - Epoch: [955][0/196]	Time 0.289 (0.289)	Data 0.088 (0.088)	Loss 0.2593 (0.2593)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [955][100/196]	Time 0.027 (0.031)	Data 0.000 (0.001)	Loss 0.1734 (0.2502)	Prec@1 93.750 (90.992)	Prec@5 100.000 (99.834)
EVALUATING - Epoch: [955][0/79]	Time 0.070 (0.070)	Data 0.052 (0.052)	Loss 0.3485 (0.3485)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:04

 Epoch: 956	Training Loss 0.2502 	Training Prec@1 90.936 	Training Prec@5 99.834 	Validation Loss 0.4024 	Validation Prec@1 87.080 	Validation Prec@5 99.550 

lr: 0.0005719920605471336
TRAINING - Epoch: [956][0/196]	Time 0.285 (0.285)	Data 0.097 (0.097)	Loss 0.2356 (0.2356)	Prec@1 92.188 (92.188)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [956][100/196]	Time 0.026 (0.032)	Data 0.000 (0.001)	Loss 0.3052 (0.2456)	Prec@1 90.234 (91.286)	Prec@5 100.000 (99.892)
EVALUATING - Epoch: [956][0/79]	Time 0.075 (0.075)	Data 0.060 (0.060)	Loss 0.3125 (0.3125)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:06

 Epoch: 957	Training Loss 0.2492 	Training Prec@1 91.210 	Training Prec@5 99.844 	Validation Loss 0.4196 	Validation Prec@1 86.640 	Validation Prec@5 99.540 

lr: 0.0005484505306629895
TRAINING - Epoch: [957][0/196]	Time 0.277 (0.277)	Data 0.087 (0.087)	Loss 0.2972 (0.2972)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [957][100/196]	Time 0.035 (0.033)	Data 0.000 (0.001)	Loss 0.3172 (0.2547)	Prec@1 89.062 (90.911)	Prec@5 100.000 (99.830)
EVALUATING - Epoch: [957][0/79]	Time 0.067 (0.067)	Data 0.048 (0.048)	Loss 0.2594 (0.2594)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:12

 Epoch: 958	Training Loss 0.2532 	Training Prec@1 90.984 	Training Prec@5 99.840 	Validation Loss 0.4189 	Validation Prec@1 86.250 	Validation Prec@5 99.580 

lr: 0.0005254010142517007
TRAINING - Epoch: [958][0/196]	Time 0.316 (0.316)	Data 0.079 (0.079)	Loss 0.2293 (0.2293)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [958][100/196]	Time 0.027 (0.031)	Data 0.000 (0.001)	Loss 0.2100 (0.2517)	Prec@1 92.188 (91.004)	Prec@5 100.000 (99.853)
EVALUATING - Epoch: [958][0/79]	Time 0.071 (0.071)	Data 0.054 (0.054)	Loss 0.4456 (0.4456)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:04

 Epoch: 959	Training Loss 0.2509 	Training Prec@1 90.968 	Training Prec@5 99.858 	Validation Loss 0.4121 	Validation Prec@1 86.820 	Validation Prec@5 99.560 

lr: 0.0005028437406335925
TRAINING - Epoch: [959][0/196]	Time 0.288 (0.288)	Data 0.079 (0.079)	Loss 0.1659 (0.1659)	Prec@1 94.141 (94.141)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [959][100/196]	Time 0.029 (0.032)	Data 0.000 (0.001)	Loss 0.2540 (0.2480)	Prec@1 93.359 (91.178)	Prec@5 99.609 (99.845)
EVALUATING - Epoch: [959][0/79]	Time 0.079 (0.079)	Data 0.057 (0.057)	Loss 0.3174 (0.3174)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:13

 Epoch: 960	Training Loss 0.2502 	Training Prec@1 91.094 	Training Prec@5 99.822 	Validation Loss 0.4201 	Validation Prec@1 86.630 	Validation Prec@5 99.440 

lr: 0.0004807789342316247
TRAINING - Epoch: [960][0/196]	Time 0.266 (0.266)	Data 0.075 (0.075)	Loss 0.2712 (0.2712)	Prec@1 91.797 (91.797)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [960][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.3174 (0.2491)	Prec@1 87.109 (91.271)	Prec@5 100.000 (99.853)
EVALUATING - Epoch: [960][0/79]	Time 0.068 (0.068)	Data 0.050 (0.050)	Loss 0.3325 (0.3325)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:01

 Epoch: 961	Training Loss 0.2517 	Training Prec@1 91.072 	Training Prec@5 99.846 	Validation Loss 0.4177 	Validation Prec@1 86.750 	Validation Prec@5 99.510 

lr: 0.00045920681456920997
TRAINING - Epoch: [961][0/196]	Time 0.267 (0.267)	Data 0.077 (0.077)	Loss 0.2555 (0.2555)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [961][100/196]	Time 0.037 (0.031)	Data 0.000 (0.001)	Loss 0.2185 (0.2487)	Prec@1 92.969 (91.070)	Prec@5 99.609 (99.872)
EVALUATING - Epoch: [961][0/79]	Time 0.074 (0.074)	Data 0.059 (0.059)	Loss 0.3173 (0.3173)	Prec@1 89.844 (89.844)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:07

 Epoch: 962	Training Loss 0.2506 	Training Prec@1 91.068 	Training Prec@5 99.864 	Validation Loss 0.4108 	Validation Prec@1 86.670 	Validation Prec@5 99.540 

lr: 0.0004381275962679991
TRAINING - Epoch: [962][0/196]	Time 0.268 (0.268)	Data 0.082 (0.082)	Loss 0.2926 (0.2926)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [962][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.2279 (0.2580)	Prec@1 90.625 (90.733)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [962][0/79]	Time 0.066 (0.066)	Data 0.048 (0.048)	Loss 0.3225 (0.3225)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:01

 Epoch: 963	Training Loss 0.2587 	Training Prec@1 90.808 	Training Prec@5 99.830 	Validation Loss 0.4159 	Validation Prec@1 86.700 	Validation Prec@5 99.610 

lr: 0.0004175414890457434
TRAINING - Epoch: [963][0/196]	Time 0.266 (0.266)	Data 0.078 (0.078)	Loss 0.2396 (0.2396)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [963][100/196]	Time 0.025 (0.030)	Data 0.000 (0.001)	Loss 0.1833 (0.2495)	Prec@1 92.188 (91.197)	Prec@5 99.609 (99.818)
EVALUATING - Epoch: [963][0/79]	Time 0.070 (0.070)	Data 0.049 (0.049)	Loss 0.3063 (0.3063)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:00

 Epoch: 964	Training Loss 0.2502 	Training Prec@1 91.150 	Training Prec@5 99.830 	Validation Loss 0.4075 	Validation Prec@1 86.720 	Validation Prec@5 99.560 

lr: 0.0003974486977142412
TRAINING - Epoch: [964][0/196]	Time 0.268 (0.268)	Data 0.083 (0.083)	Loss 0.2467 (0.2467)	Prec@1 90.625 (90.625)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [964][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.2809 (0.2567)	Prec@1 90.234 (90.799)	Prec@5 99.609 (99.830)
EVALUATING - Epoch: [964][0/79]	Time 0.075 (0.075)	Data 0.055 (0.055)	Loss 0.3373 (0.3373)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:00

 Epoch: 965	Training Loss 0.2541 	Training Prec@1 90.868 	Training Prec@5 99.838 	Validation Loss 0.4185 	Validation Prec@1 86.400 	Validation Prec@5 99.470 

lr: 0.0003778494221772445
TRAINING - Epoch: [965][0/196]	Time 0.305 (0.305)	Data 0.082 (0.082)	Loss 0.1958 (0.1958)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [965][100/196]	Time 0.028 (0.030)	Data 0.000 (0.001)	Loss 0.2332 (0.2470)	Prec@1 91.406 (91.190)	Prec@5 100.000 (99.857)
EVALUATING - Epoch: [965][0/79]	Time 0.070 (0.070)	Data 0.052 (0.052)	Loss 0.3480 (0.3480)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:57

 Epoch: 966	Training Loss 0.2476 	Training Prec@1 91.178 	Training Prec@5 99.866 	Validation Loss 0.4114 	Validation Prec@1 86.710 	Validation Prec@5 99.490 

lr: 0.0003587438574285329
TRAINING - Epoch: [966][0/196]	Time 0.289 (0.289)	Data 0.087 (0.087)	Loss 0.2327 (0.2327)	Prec@1 91.797 (91.797)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [966][100/196]	Time 0.029 (0.030)	Data 0.000 (0.001)	Loss 0.2279 (0.2486)	Prec@1 91.797 (91.197)	Prec@5 100.000 (99.853)
EVALUATING - Epoch: [966][0/79]	Time 0.074 (0.074)	Data 0.059 (0.059)	Loss 0.3080 (0.3080)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:59

 Epoch: 967	Training Loss 0.2500 	Training Prec@1 91.104 	Training Prec@5 99.860 	Validation Loss 0.4050 	Validation Prec@1 86.900 	Validation Prec@5 99.620 

lr: 0.0003401321935499208
TRAINING - Epoch: [967][0/196]	Time 0.282 (0.282)	Data 0.102 (0.102)	Loss 0.2950 (0.2950)	Prec@1 90.234 (90.234)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [967][100/196]	Time 0.030 (0.031)	Data 0.000 (0.001)	Loss 0.2198 (0.2490)	Prec@1 92.578 (91.039)	Prec@5 100.000 (99.861)
EVALUATING - Epoch: [967][0/79]	Time 0.077 (0.077)	Data 0.060 (0.060)	Loss 0.3900 (0.3900)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:59

 Epoch: 968	Training Loss 0.2475 	Training Prec@1 91.106 	Training Prec@5 99.862 	Validation Loss 0.4060 	Validation Prec@1 86.790 	Validation Prec@5 99.550 

lr: 0.0003220146157094029
TRAINING - Epoch: [968][0/196]	Time 0.285 (0.285)	Data 0.100 (0.100)	Loss 0.2133 (0.2133)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [968][100/196]	Time 0.029 (0.030)	Data 0.000 (0.001)	Loss 0.2593 (0.2474)	Prec@1 89.453 (91.325)	Prec@5 99.219 (99.834)
EVALUATING - Epoch: [968][0/79]	Time 0.072 (0.072)	Data 0.055 (0.055)	Loss 0.2758 (0.2758)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:53

 Epoch: 969	Training Loss 0.2495 	Training Prec@1 91.128 	Training Prec@5 99.816 	Validation Loss 0.4063 	Validation Prec@1 86.820 	Validation Prec@5 99.550 

lr: 0.00030439130415928933
TRAINING - Epoch: [969][0/196]	Time 0.268 (0.268)	Data 0.085 (0.085)	Loss 0.2182 (0.2182)	Prec@1 94.141 (94.141)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [969][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.2490 (0.2487)	Prec@1 91.406 (91.201)	Prec@5 100.000 (99.826)
EVALUATING - Epoch: [969][0/79]	Time 0.072 (0.072)	Data 0.056 (0.056)	Loss 0.3340 (0.3340)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:57

 Epoch: 970	Training Loss 0.2485 	Training Prec@1 91.088 	Training Prec@5 99.838 	Validation Loss 0.4104 	Validation Prec@1 86.710 	Validation Prec@5 99.560 

lr: 0.00028726243423441783
TRAINING - Epoch: [970][0/196]	Time 0.270 (0.270)	Data 0.088 (0.088)	Loss 0.1868 (0.1868)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [970][100/196]	Time 0.033 (0.029)	Data 0.000 (0.001)	Loss 0.1982 (0.2489)	Prec@1 92.578 (91.070)	Prec@5 100.000 (99.841)
EVALUATING - Epoch: [970][0/79]	Time 0.072 (0.072)	Data 0.056 (0.056)	Loss 0.3191 (0.3191)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:52

 Epoch: 971	Training Loss 0.2502 	Training Prec@1 91.030 	Training Prec@5 99.828 	Validation Loss 0.4093 	Validation Prec@1 86.570 	Validation Prec@5 99.600 

lr: 0.000270628176350422
TRAINING - Epoch: [971][0/196]	Time 0.284 (0.284)	Data 0.099 (0.099)	Loss 0.2853 (0.2853)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [971][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.2626 (0.2443)	Prec@1 89.062 (91.526)	Prec@5 100.000 (99.830)
EVALUATING - Epoch: [971][0/79]	Time 0.070 (0.070)	Data 0.049 (0.049)	Loss 0.3651 (0.3651)	Prec@1 85.156 (85.156)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:58

 Epoch: 972	Training Loss 0.2457 	Training Prec@1 91.364 	Training Prec@5 99.852 	Validation Loss 0.4198 	Validation Prec@1 86.710 	Validation Prec@5 99.460 

lr: 0.00025448869600202113
TRAINING - Epoch: [972][0/196]	Time 0.307 (0.307)	Data 0.084 (0.084)	Loss 0.2168 (0.2168)	Prec@1 91.016 (91.016)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [972][100/196]	Time 0.026 (0.034)	Data 0.000 (0.001)	Loss 0.2476 (0.2438)	Prec@1 89.844 (91.449)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [972][0/79]	Time 0.068 (0.068)	Data 0.051 (0.051)	Loss 0.3913 (0.3913)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:07	Time of Finish: 2024-03-31 19:31:22

 Epoch: 973	Training Loss 0.2430 	Training Prec@1 91.358 	Training Prec@5 99.850 	Validation Loss 0.4104 	Validation Prec@1 86.520 	Validation Prec@5 99.630 

lr: 0.00023884415376137198
TRAINING - Epoch: [973][0/196]	Time 0.290 (0.290)	Data 0.101 (0.101)	Loss 0.2581 (0.2581)	Prec@1 91.406 (91.406)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [973][100/196]	Time 0.033 (0.031)	Data 0.000 (0.001)	Loss 0.2684 (0.2489)	Prec@1 90.625 (91.282)	Prec@5 100.000 (99.853)
EVALUATING - Epoch: [973][0/79]	Time 0.073 (0.073)	Data 0.057 (0.057)	Loss 0.3321 (0.3321)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:03

 Epoch: 974	Training Loss 0.2464 	Training Prec@1 91.216 	Training Prec@5 99.860 	Validation Loss 0.4078 	Validation Prec@1 86.710 	Validation Prec@5 99.610 

lr: 0.00022369470527649173
TRAINING - Epoch: [974][0/196]	Time 0.290 (0.290)	Data 0.094 (0.094)	Loss 0.2607 (0.2607)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [974][100/196]	Time 0.025 (0.031)	Data 0.000 (0.001)	Loss 0.2814 (0.2447)	Prec@1 88.672 (91.325)	Prec@5 100.000 (99.841)
EVALUATING - Epoch: [974][0/79]	Time 0.071 (0.071)	Data 0.051 (0.051)	Loss 0.3524 (0.3524)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:02

 Epoch: 975	Training Loss 0.2442 	Training Prec@1 91.358 	Training Prec@5 99.848 	Validation Loss 0.4049 	Validation Prec@1 86.520 	Validation Prec@5 99.640 

lr: 0.00020904050126967604
TRAINING - Epoch: [975][0/196]	Time 0.268 (0.268)	Data 0.081 (0.081)	Loss 0.2263 (0.2263)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [975][100/196]	Time 0.033 (0.030)	Data 0.000 (0.001)	Loss 0.2338 (0.2441)	Prec@1 90.625 (91.333)	Prec@5 100.000 (99.822)
EVALUATING - Epoch: [975][0/79]	Time 0.069 (0.069)	Data 0.053 (0.053)	Loss 0.3328 (0.3328)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:06

 Epoch: 976	Training Loss 0.2458 	Training Prec@1 91.306 	Training Prec@5 99.848 	Validation Loss 0.4061 	Validation Prec@1 86.520 	Validation Prec@5 99.580 

lr: 0.00019488168753603358
TRAINING - Epoch: [976][0/196]	Time 0.306 (0.306)	Data 0.081 (0.081)	Loss 0.2343 (0.2343)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [976][100/196]	Time 0.027 (0.032)	Data 0.000 (0.001)	Loss 0.2279 (0.2571)	Prec@1 93.359 (91.043)	Prec@5 99.609 (99.834)
EVALUATING - Epoch: [976][0/79]	Time 0.073 (0.073)	Data 0.057 (0.057)	Loss 0.3312 (0.3312)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:09

 Epoch: 977	Training Loss 0.2515 	Training Prec@1 91.138 	Training Prec@5 99.820 	Validation Loss 0.4070 	Validation Prec@1 86.490 	Validation Prec@5 99.590 

lr: 0.0001812184049420203
TRAINING - Epoch: [977][0/196]	Time 0.281 (0.281)	Data 0.094 (0.094)	Loss 0.2285 (0.2285)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [977][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.3009 (0.2435)	Prec@1 87.109 (91.240)	Prec@5 100.000 (99.880)
EVALUATING - Epoch: [977][0/79]	Time 0.065 (0.065)	Data 0.047 (0.047)	Loss 0.2868 (0.2868)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:05

 Epoch: 978	Training Loss 0.2435 	Training Prec@1 91.348 	Training Prec@5 99.866 	Validation Loss 0.4124 	Validation Prec@1 86.590 	Validation Prec@5 99.540 

lr: 0.0001680507894240351
TRAINING - Epoch: [978][0/196]	Time 0.271 (0.271)	Data 0.088 (0.088)	Loss 0.1422 (0.1422)	Prec@1 95.703 (95.703)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [978][100/196]	Time 0.029 (0.030)	Data 0.000 (0.001)	Loss 0.2284 (0.2398)	Prec@1 92.188 (91.503)	Prec@5 100.000 (99.876)
EVALUATING - Epoch: [978][0/79]	Time 0.067 (0.067)	Data 0.047 (0.047)	Loss 0.3256 (0.3256)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:58

 Epoch: 979	Training Loss 0.2450 	Training Prec@1 91.332 	Training Prec@5 99.872 	Validation Loss 0.4039 	Validation Prec@1 87.010 	Validation Prec@5 99.620 

lr: 0.00015537897198706526
TRAINING - Epoch: [979][0/196]	Time 0.267 (0.267)	Data 0.077 (0.077)	Loss 0.2300 (0.2300)	Prec@1 90.234 (90.234)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [979][100/196]	Time 0.026 (0.029)	Data 0.000 (0.001)	Loss 0.2401 (0.2429)	Prec@1 91.016 (91.221)	Prec@5 100.000 (99.841)
EVALUATING - Epoch: [979][0/79]	Time 0.068 (0.068)	Data 0.048 (0.048)	Loss 0.3441 (0.3441)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:56

 Epoch: 980	Training Loss 0.2445 	Training Prec@1 91.240 	Training Prec@5 99.834 	Validation Loss 0.4130 	Validation Prec@1 86.640 	Validation Prec@5 99.580 

lr: 0.00014320307870339287
TRAINING - Epoch: [980][0/196]	Time 0.272 (0.272)	Data 0.088 (0.088)	Loss 0.2949 (0.2949)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [980][100/196]	Time 0.026 (0.029)	Data 0.000 (0.001)	Loss 0.2798 (0.2423)	Prec@1 88.672 (91.259)	Prec@5 99.609 (99.849)
EVALUATING - Epoch: [980][0/79]	Time 0.070 (0.070)	Data 0.048 (0.048)	Loss 0.3595 (0.3595)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:57

 Epoch: 981	Training Loss 0.2433 	Training Prec@1 91.286 	Training Prec@5 99.856 	Validation Loss 0.4095 	Validation Prec@1 86.540 	Validation Prec@5 99.610 

lr: 0.00013152323071134045
TRAINING - Epoch: [981][0/196]	Time 0.269 (0.269)	Data 0.087 (0.087)	Loss 0.2456 (0.2456)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [981][100/196]	Time 0.025 (0.029)	Data 0.000 (0.001)	Loss 0.2613 (0.2432)	Prec@1 91.016 (91.310)	Prec@5 100.000 (99.849)
EVALUATING - Epoch: [981][0/79]	Time 0.070 (0.070)	Data 0.053 (0.053)	Loss 0.3192 (0.3192)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:56

 Epoch: 982	Training Loss 0.2409 	Training Prec@1 91.358 	Training Prec@5 99.872 	Validation Loss 0.3948 	Validation Prec@1 87.040 	Validation Prec@5 99.580 

lr: 0.00012033954421406058
TRAINING - Epoch: [982][0/196]	Time 0.282 (0.282)	Data 0.095 (0.095)	Loss 0.2217 (0.2217)	Prec@1 92.188 (92.188)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [982][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.1764 (0.2358)	Prec@1 94.531 (91.700)	Prec@5 100.000 (99.845)
EVALUATING - Epoch: [982][0/79]	Time 0.075 (0.075)	Data 0.059 (0.059)	Loss 0.4097 (0.4097)	Prec@1 86.719 (86.719)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:02

 Epoch: 983	Training Loss 0.2409 	Training Prec@1 91.468 	Training Prec@5 99.858 	Validation Loss 0.4086 	Validation Prec@1 86.960 	Validation Prec@5 99.530 

lr: 0.00010965213047836464
TRAINING - Epoch: [983][0/196]	Time 0.284 (0.284)	Data 0.079 (0.079)	Loss 0.2390 (0.2390)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [983][100/196]	Time 0.026 (0.030)	Data 0.000 (0.001)	Loss 0.2876 (0.2420)	Prec@1 88.672 (91.464)	Prec@5 100.000 (99.818)
EVALUATING - Epoch: [983][0/79]	Time 0.074 (0.074)	Data 0.058 (0.058)	Loss 0.3492 (0.3492)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:00

 Epoch: 984	Training Loss 0.2383 	Training Prec@1 91.576 	Training Prec@5 99.842 	Validation Loss 0.4024 	Validation Prec@1 86.710 	Validation Prec@5 99.610 

lr: 9.946109583366254e-05
TRAINING - Epoch: [984][0/196]	Time 0.283 (0.283)	Data 0.083 (0.083)	Loss 0.2300 (0.2300)	Prec@1 92.578 (92.578)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [984][100/196]	Time 0.041 (0.030)	Data 0.000 (0.001)	Loss 0.2370 (0.2411)	Prec@1 89.844 (91.232)	Prec@5 99.609 (99.853)
EVALUATING - Epoch: [984][0/79]	Time 0.074 (0.074)	Data 0.053 (0.053)	Loss 0.3257 (0.3257)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:00

 Epoch: 985	Training Loss 0.2396 	Training Prec@1 91.378 	Training Prec@5 99.860 	Validation Loss 0.3981 	Validation Prec@1 87.390 	Validation Prec@5 99.600 

lr: 8.976654167084127e-05
TRAINING - Epoch: [985][0/196]	Time 0.277 (0.277)	Data 0.092 (0.092)	Loss 0.1949 (0.1949)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [985][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.2265 (0.2384)	Prec@1 91.016 (91.580)	Prec@5 100.000 (99.845)
EVALUATING - Epoch: [985][0/79]	Time 0.070 (0.070)	Data 0.053 (0.053)	Loss 0.3497 (0.3497)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:01

 Epoch: 986	Training Loss 0.2388 	Training Prec@1 91.550 	Training Prec@5 99.858 	Validation Loss 0.4061 	Validation Prec@1 86.940 	Validation Prec@5 99.610 

lr: 8.056856444131013e-05
TRAINING - Epoch: [986][0/196]	Time 0.290 (0.290)	Data 0.092 (0.092)	Loss 0.2951 (0.2951)	Prec@1 88.672 (88.672)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [986][100/196]	Time 0.027 (0.030)	Data 0.000 (0.001)	Loss 0.2105 (0.2363)	Prec@1 91.797 (91.627)	Prec@5 100.000 (99.888)
EVALUATING - Epoch: [986][0/79]	Time 0.066 (0.066)	Data 0.048 (0.048)	Loss 0.3038 (0.3038)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:58

 Epoch: 987	Training Loss 0.2399 	Training Prec@1 91.474 	Training Prec@5 99.872 	Validation Loss 0.4027 	Validation Prec@1 86.720 	Validation Prec@5 99.570 

lr: 7.186725565601258e-05
TRAINING - Epoch: [987][0/196]	Time 0.286 (0.286)	Data 0.104 (0.104)	Loss 0.1699 (0.1699)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [987][100/196]	Time 0.026 (0.029)	Data 0.000 (0.001)	Loss 0.2364 (0.2450)	Prec@1 91.797 (91.360)	Prec@5 100.000 (99.865)
EVALUATING - Epoch: [987][0/79]	Time 0.067 (0.067)	Data 0.047 (0.047)	Loss 0.3201 (0.3201)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:57

 Epoch: 988	Training Loss 0.2415 	Training Prec@1 91.504 	Training Prec@5 99.858 	Validation Loss 0.4011 	Validation Prec@1 86.700 	Validation Prec@5 99.650 

lr: 6.366270188452694e-05
TRAINING - Epoch: [988][0/196]	Time 0.278 (0.278)	Data 0.083 (0.083)	Loss 0.2253 (0.2253)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [988][100/196]	Time 0.031 (0.032)	Data 0.000 (0.001)	Loss 0.2873 (0.2368)	Prec@1 91.016 (91.720)	Prec@5 100.000 (99.892)
EVALUATING - Epoch: [988][0/79]	Time 0.067 (0.067)	Data 0.049 (0.049)	Loss 0.3921 (0.3921)	Prec@1 87.500 (87.500)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:04

 Epoch: 989	Training Loss 0.2373 	Training Prec@1 91.640 	Training Prec@5 99.884 	Validation Loss 0.3965 	Validation Prec@1 86.800 	Validation Prec@5 99.590 

lr: 5.5954984754194814e-05
TRAINING - Epoch: [989][0/196]	Time 0.276 (0.276)	Data 0.080 (0.080)	Loss 0.1902 (0.1902)	Prec@1 93.750 (93.750)	Prec@5 99.219 (99.219)
TRAINING - Epoch: [989][100/196]	Time 0.029 (0.030)	Data 0.000 (0.001)	Loss 0.2799 (0.2418)	Prec@1 89.062 (91.321)	Prec@5 99.609 (99.834)
EVALUATING - Epoch: [989][0/79]	Time 0.066 (0.066)	Data 0.048 (0.048)	Loss 0.3826 (0.3826)	Prec@1 90.625 (90.625)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:59

 Epoch: 990	Training Loss 0.2407 	Training Prec@1 91.352 	Training Prec@5 99.862 	Validation Loss 0.3970 	Validation Prec@1 87.140 	Validation Prec@5 99.620 

lr: 4.8744180949327245e-05
TRAINING - Epoch: [990][0/196]	Time 0.329 (0.329)	Data 0.096 (0.096)	Loss 0.2662 (0.2662)	Prec@1 90.234 (90.234)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [990][100/196]	Time 0.035 (0.031)	Data 0.000 (0.001)	Loss 0.1922 (0.2412)	Prec@1 92.188 (91.271)	Prec@5 99.609 (99.876)
EVALUATING - Epoch: [990][0/79]	Time 0.071 (0.071)	Data 0.053 (0.053)	Loss 0.4065 (0.4065)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:03

 Epoch: 991	Training Loss 0.2405 	Training Prec@1 91.330 	Training Prec@5 99.848 	Validation Loss 0.3950 	Validation Prec@1 87.000 	Validation Prec@5 99.450 

lr: 4.2030362210410905e-05
TRAINING - Epoch: [991][0/196]	Time 0.280 (0.280)	Data 0.084 (0.084)	Loss 0.2077 (0.2077)	Prec@1 91.797 (91.797)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [991][100/196]	Time 0.027 (0.031)	Data 0.000 (0.001)	Loss 0.2916 (0.2379)	Prec@1 89.453 (91.642)	Prec@5 100.000 (99.880)
EVALUATING - Epoch: [991][0/79]	Time 0.070 (0.070)	Data 0.050 (0.050)	Loss 0.3748 (0.3748)	Prec@1 91.406 (91.406)	Prec@5 99.219 (99.219)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:02

 Epoch: 992	Training Loss 0.2345 	Training Prec@1 91.734 	Training Prec@5 99.884 	Validation Loss 0.3983 	Validation Prec@1 87.360 	Validation Prec@5 99.600 

lr: 3.58135953334308e-05
TRAINING - Epoch: [992][0/196]	Time 0.274 (0.274)	Data 0.086 (0.086)	Loss 0.1638 (0.1638)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [992][100/196]	Time 0.026 (0.029)	Data 0.000 (0.001)	Loss 0.2256 (0.2342)	Prec@1 91.797 (91.727)	Prec@5 100.000 (99.857)
EVALUATING - Epoch: [992][0/79]	Time 0.073 (0.073)	Data 0.055 (0.055)	Loss 0.3644 (0.3644)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:30:58

 Epoch: 993	Training Loss 0.2366 	Training Prec@1 91.594 	Training Prec@5 99.864 	Validation Loss 0.3985 	Validation Prec@1 87.070 	Validation Prec@5 99.640 

lr: 3.0093942169187487e-05
TRAINING - Epoch: [993][0/196]	Time 0.283 (0.283)	Data 0.089 (0.089)	Loss 0.2707 (0.2707)	Prec@1 89.844 (89.844)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [993][100/196]	Time 0.026 (0.032)	Data 0.000 (0.001)	Loss 0.2497 (0.2382)	Prec@1 91.016 (91.573)	Prec@5 100.000 (99.872)
EVALUATING - Epoch: [993][0/79]	Time 0.069 (0.069)	Data 0.050 (0.050)	Loss 0.3704 (0.3704)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:02

 Epoch: 994	Training Loss 0.2374 	Training Prec@1 91.558 	Training Prec@5 99.874 	Validation Loss 0.4001 	Validation Prec@1 86.980 	Validation Prec@5 99.600 

lr: 2.48714596226642e-05
TRAINING - Epoch: [994][0/196]	Time 0.300 (0.300)	Data 0.077 (0.077)	Loss 0.2601 (0.2601)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [994][100/196]	Time 0.026 (0.033)	Data 0.000 (0.001)	Loss 0.2101 (0.2383)	Prec@1 91.406 (91.515)	Prec@5 100.000 (99.841)
EVALUATING - Epoch: [994][0/79]	Time 0.068 (0.068)	Data 0.048 (0.048)	Loss 0.3604 (0.3604)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:03

 Epoch: 995	Training Loss 0.2383 	Training Prec@1 91.488 	Training Prec@5 99.854 	Validation Loss 0.4050 	Validation Prec@1 87.010 	Validation Prec@5 99.530 

lr: 2.0146199652510595e-05
TRAINING - Epoch: [995][0/196]	Time 0.280 (0.280)	Data 0.091 (0.091)	Loss 0.2412 (0.2412)	Prec@1 91.406 (91.406)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [995][100/196]	Time 0.025 (0.032)	Data 0.000 (0.001)	Loss 0.2591 (0.2431)	Prec@1 90.625 (91.275)	Prec@5 100.000 (99.865)
EVALUATING - Epoch: [995][0/79]	Time 0.074 (0.074)	Data 0.057 (0.057)	Loss 0.4134 (0.4134)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:03

 Epoch: 996	Training Loss 0.2439 	Training Prec@1 91.274 	Training Prec@5 99.866 	Validation Loss 0.4086 	Validation Prec@1 86.880 	Validation Prec@5 99.610 

lr: 1.591820927045985e-05
TRAINING - Epoch: [996][0/196]	Time 0.293 (0.293)	Data 0.090 (0.090)	Loss 0.2475 (0.2475)	Prec@1 89.062 (89.062)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [996][100/196]	Time 0.026 (0.032)	Data 0.000 (0.001)	Loss 0.2338 (0.2404)	Prec@1 92.578 (91.437)	Prec@5 99.609 (99.892)
EVALUATING - Epoch: [996][0/79]	Time 0.070 (0.070)	Data 0.049 (0.049)	Loss 0.3896 (0.3896)	Prec@1 87.500 (87.500)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:02

 Epoch: 997	Training Loss 0.2408 	Training Prec@1 91.382 	Training Prec@5 99.890 	Validation Loss 0.3977 	Validation Prec@1 87.020 	Validation Prec@5 99.600 

lr: 1.2187530540923423e-05
TRAINING - Epoch: [997][0/196]	Time 0.280 (0.280)	Data 0.080 (0.080)	Loss 0.1449 (0.1449)	Prec@1 94.922 (94.922)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [997][100/196]	Time 0.026 (0.031)	Data 0.000 (0.001)	Loss 0.2616 (0.2347)	Prec@1 90.234 (91.553)	Prec@5 100.000 (99.845)
EVALUATING - Epoch: [997][0/79]	Time 0.067 (0.067)	Data 0.047 (0.047)	Loss 0.3577 (0.3577)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:02

 Epoch: 998	Training Loss 0.2393 	Training Prec@1 91.424 	Training Prec@5 99.856 	Validation Loss 0.3991 	Validation Prec@1 87.130 	Validation Prec@5 99.560 

lr: 8.954200580524735e-06
TRAINING - Epoch: [998][0/196]	Time 0.279 (0.279)	Data 0.083 (0.083)	Loss 0.2570 (0.2570)	Prec@1 89.062 (89.062)	Prec@5 100.000 (100.000)
TRAINING - Epoch: [998][100/196]	Time 0.038 (0.032)	Data 0.000 (0.001)	Loss 0.2408 (0.2398)	Prec@1 91.016 (91.418)	Prec@5 100.000 (99.880)
EVALUATING - Epoch: [998][0/79]	Time 0.069 (0.069)	Data 0.051 (0.051)	Loss 0.3607 (0.3607)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:03

 Epoch: 999	Training Loss 0.2385 	Training Prec@1 91.466 	Training Prec@5 99.874 	Validation Loss 0.4020 	Validation Prec@1 87.050 	Validation Prec@5 99.620 

lr: 6.218251557766099e-06
TRAINING - Epoch: [999][0/196]	Time 0.286 (0.286)	Data 0.102 (0.102)	Loss 0.2468 (0.2468)	Prec@1 91.016 (91.016)	Prec@5 99.609 (99.609)
TRAINING - Epoch: [999][100/196]	Time 0.027 (0.031)	Data 0.000 (0.001)	Loss 0.2318 (0.2408)	Prec@1 90.625 (91.673)	Prec@5 100.000 (99.826)
EVALUATING - Epoch: [999][0/79]	Time 0.069 (0.069)	Data 0.050 (0.050)	Loss 0.2926 (0.2926)	Prec@1 89.844 (89.844)	Prec@5 100.000 (100.000)
Time cost: 00:06	Time of Finish: 2024-03-31 19:31:02

 Epoch: 1000	Training Loss 0.2394 	Training Prec@1 91.586 	Training Prec@5 99.830 	Validation Loss 0.4067 	Validation Prec@1 86.870 	Validation Prec@5 99.670 

**************************************************DONE**************************************************

 Best_Epoch: 985	Best_Prec1 87.3900 	Best_Loss 0.398 	
